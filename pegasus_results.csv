Index_ID,ref_post,ref_title,candidate_title
0,some background i have been learning python for over a year now and i know some sql a bit of r and i have completed some small projects using data science data engineering practices i also know how to work in excel but i do not really have experience using databases i am totally willing to make the time and money investment in something like a bootcamp and i have the means to do fulltime training but i do not want to do this if there is a better faster way to get into the industry what i really want to know is what can i do that will get me a job in the field asap is there some specific bootcamp that will make this happen if so what are the best bootcamps or some particular tech skill i could learn that would basically guarantee that i am hireable very soon if i something like learned microsoft sql server or tableau and given my other skills would this be likely to get me hired i have been looking into bootcamps like thinkful springboard and data application lab the concern i have about these is actually that i already know a lot of the stuff they teach and i am worried that these will be a waste of time and not elevate me to where i want to be i also worry about it taking months to complete these programs as they estimate i would like to be finished in no more than about months thoughts,i want to transition into the data scienceanalyst or related field rather than asking whether i should choose a particular boootcamp or learn some language i would like to hear opinions on what path should i choose that will land me a job of some kind in the field as soon as possible,what are some good data science bootcamps
1,hi all i have created a python module to extract sngrams which is different from traditional ngrams as it embodies linguistic syntactic trees thus making it less arbitrary than traditional ngrams as it goes without saying quality of input feature affects model performance this will help you improve your model accuracy even further built on language models of spacy it can help especially for text classification information extraction query understanding machine translation question answering systems below is an example from sngramextractor import sngramextractor ampxb sngram_objsngramextractortextmeta_tagoriginaltrigram_flagyes texteconomic news have little effect on financial markets outputsngram_objget_sngram printtext print isngram bigramoutput isnbigram print isngram trigramoutput isntrigram economic news have little effect on financial markets sngram bigram cloud_every has_cloud lining_a lining_silver has_lining sngram trigram has_lining_silver ampxb textevery cloud has a silver lining outputsngram_objget_sngram printtext print isngram bigramoutput isnbigram print isngram trigramoutput isntrigram ampxb every cloud has a silver lining sngram bigram cloud_every has_cloud lining_a lining_silver has_lining sngram trigram has_lining_silver ampxb pypi,psngram linguistic features for improving machine learning and deep learning model accuracy for the first time in python new release,is there a better way to store and train a model for later use
2,i am looking at some of the modeling programs the company has been using and there are options to smooth binned data layered linear on bin linear on avg linear on log avg and variable gradient are these methods commonly used in any algorithms i am not sure how i would implement it into r ampxb variable gradient is the most confusing it groups data from neighboring bins with a bin factor being determined the level of smoothing is determined by the radius all bins contribute to the calculation of the bin factor with decreasing weight as the distance from the target bin increases the weight is equal to radius distance radius ampxb once you calculate the overall factor a calculation is performed for each bin weighted by an exposure with various radii and a selected credibility level the calculation that yields the largest distance from is then selected as the factor to be used for that bin ampxb over multiple iterations of the model the factors are blended until the model converges and we receive a final coefficient for that bin ampxb since it is a program i have no clue what is going on in the background to calculate the convergence or what type of model this is it ends up being a multiplicative model so i am guessing it is a log linked glm,does anyone use any type of gradient smoothing for binned data,how to deal with missing values in logistic regression
3,let is say i have created a fraud detection model i already have a process that cleans the data and stores the trainable data in a table in a database and now i want to set up a recurring job that retrains my model every x time period how do people go about this when we want to retrain the model does not that data have to be loaded into the environment that the new model is going to be retrained i guess i am confused at how exactly the model takes the data from the database and starts training on it do people use spark to load it into the environment with the modeltobe then start the retraining process does not that mean that the retraining environment has to have enough space to cover that data being brought in apologies if this has already been asked but i have not seen a clear answer from this subredditfrom what i have found on google thanks so much for any assistance,setting up a model for retraining in production,how do i go about retraining my google analytics model
4,i am working with a dataset of patient performancedata and patient demographics for people with a medical condition i am trying to assess the effect of a treatment on the patients and as i am trying to replicate a randomized experiment from a observational study i am performing matching between the treatment and control group when i try to perform mahalanobis distance matching however i keep getting the following warning on matlab warning matrix is close to singular or badly scaled results may be inaccurate rcond e the warning was caused because the determinant of my covariance matrix was very close to so when i calculated the inverse of this matrix as i need to do for finding the mahalanobis distance the matrix element values become very close to as well after reading about this warning a little bit i found that when this warning is displayed the results of mahalanobis distance matching is not very reliable i thought this was because my matrix became very sparse after i introduced onehotencoding to split the multicategorical features into many different features and hence some of my new features were for category values that had very few occurrences less than to address this issue i got rid of the category values with very low occurrences less than or binned them together with other lowoccurrence category values into slightly larger bins so their chances of occurring increased and my datamatrix was less sparse so i reduced the number of features from to and i plotted the histograms for all my features to see their distributions and this is what it looked like note that the element values have been normalized to by subtracting the feature mean and then divided by the feature standard deviation it looked visually satisfactory to me but i still kept getting the same warning in matlab when i tried finding the determinant of my new covariance matrix it was still very small e in a further attempt to fix this issue i checked whether removing all of the categorical features if we consider the onehot encoded features made things any better by making the matrix less sparse the new featurehistogram looked like this this time when i tried mahalanobis distance matching the warning was removed because the determinant of the covariance matrix was larger e so i tried to see if i could include one of the removed multicategorical features without facing the same problem as these are important features i would prefer to include when doing my matching i added a categorical feature with possible values and all the values very well distributed see histogram below but alas simply including these new onehotencoded features seems to cause the determinant of the covariance matrix to become so small that i start getting the same warning in matlab is there any fix to this issue or is it simply impossible to reliably perform mahalanobis distance matching on this dataset without leaving out the multicategorical values,is mahalanobisdistance matching between points not compatible with onehotencoded datasets,how do i deal with missing values in logistic regression
5,hi all i am applying for a data science internship with a well known company in the sf area think uberairbnbpinterest etc one of their points under qualifications is amust be currently pursuing a master is or doctoral degree preferred fields of study are statistics math economics or related discipline this presents a few problems namely that i am a junior undergraduate studying cs that said i have more experience than the typical undergrad and from what i have seen the typical masters student with respect to data science here is what i have got going for me very proficient using python r and sql among many other data analysisscience tools just finished a summer internship at a wellknown tech company as a data science intern built the company is new anomaly detection system in r from the ground up and deployed it just started a fall data science internship in nyc with an ecommerce company will be working on customer segmentation with some sql reports and machine learning taking two data science masters courses tutoring for a masterslevel algorithms course i know i do not fit their exact description but do you think i should apply anyways i would love to intern here and would appreciate any tipsexperiences any of you have had on applying where you do not necessarily meet every single criteria thanks,education level on applications,data science internship and career advice
6,i m am a junior in college major in statistics i go to a non target school and work as an intern at the center for predictive analytics at my university upon graduating i will receive a full fellowship to continue doing analytic research for our math department thus i will not enter the full time job market for approximately years from now i am planning to do some part timeremote work during my years of grad school this semester i have started building the habit of hours per day for self studying and working on ds projects i am committed to keeping up a similar routine for the next years with the intent that i might achieve hours of data science experience within the next years i decided to follow the ds career path after reading a book about big data i think it is a good career for me as i am into data math etc but i am also in it for the money and and mostly motivated by achieving a high salary so that i can save up money and start my own business in my s maybe idk is it unreasonable for me to expect that i should be able to far exceed a salary of k assuming high col within a decade from now if now how many yoe should i expect to achieve similar salary,how many yoe should i expect to have before i hit kk salary range,is a masters worth it
7,hello i am soon to be graduating student this spring in an undergraduate data science degree after doing extensive research i feel like my program had not emphasized math courses as much as i will only have calculus under my belt i have been looking at different graduate schools and i am looking at an ms in computer science i wonder though if my program has lacked sufficient areas for a program like this i was wondering if anyone here has had a similar issue i am starting to think my undergraduate degree in data science was a mistake and that i should have pursued a bs in either computer science or statistics here are some examples of what i have taken cs algorithms and cs data base management cs machine learning data science unsupervised learning data science management structured data data science other general data science things stats intermediate states stats regression stats principle study design stats experimental design by the time i will graduate i will have a minor in stats otherwise i could pursue a ms in stats or data science but i think i am wrong if i pursue those areas since with stats i would have to spend time taking the additional math before the more advance courses and i think the data science ms would just redoing things that my program already covered thoughts,a potential blind spot for new data science degrees,data science masters vs statistics masters
8,a little background on myself i graduated from a good university with a degree in civil engineering then i worked years in construction management and hated it over that time period i took a few classes and began teaching myself programming and data science i created a website and started uploading all the project that i had completed it took a while to get a job but i finally landed a job as a data analyst and love it i had thought about getting a masters during my job hunt since it took so long but stuck it out and landed this job i want to continue my career in the data science direction and want to know how revered masters and phds are in this field a lot of times high level data scientists at great tech companies either for sure have a masters and a lot of times have phds my main draw back on getting these degrees is the money it would cost because i feel like i could honestly teach myself the same skill set without having to pay for the school all in all i have a good job working as a data analyst but how far can this experience im gaining get you without having a masters or phd i almost went into structural engineering career path after college but everyone i talked to said that you had to get a masters and that was that so im interested to see other peoples perspectivesthoughts on this for data science to sum it up is it work it to pay for mastersphd and what curriculum specifically would you get the most out of as it relates to data science,should i get a mastersphd,is it worth getting a phd in data science if i already have a job as a data scientist
9,i checked out the faqs but was hoping for some targeted feedback i am currently entering the th year of my phd in neuroscience on top of a bachelors in psych and a masters in neuro i fundamentally love my work but recent observations have convinced me that continuing on the path of academia is just not right for me and my family late last year i took up python and have completed a couple of small projects to help automate my lab and expedite data analysis it got me thinking about data science i figure i have two years to make myself into a something that some company somewhere will want how can i do it my thoughts are to get some mooc certificates complete a handful of projects in the lab that use data science to save timeimprove outcomes etc network by shouting out of my window at cars driving by i realize that my path is nontraditional but i am hoping there is a way to repackage many of the problemsolving and analytical skills that i have earned in my science education thus far as groundwork for a job in data science all feedback is welcome,two years until i apply for jobs what should i work on,is it worth getting a phd in data science if i already have a job as a data scientist
10,data science has tremendous growth opportunities and is one of the hot careers in the current world many businesses are thriving for skilled data scientists data science requires many skills to become an expert one of the important skills is python programming python is a programming language widely used in many fields it is considered as the king of the coding world data scientists extensively use this language and even beginners find it easy to learn the python language to learn this language there are many python data science courses that guide and train you in an effective way what is python python is an interpreted and objectoriented programming language it is an easily understandable language whose syntaxes can be grasped by a beginner quickly it was found by guido in it is supported in operating systems like linux windows macos and a lot more the python is developed and managed by the python software foundation the second version of python was released in it features list comprehension and reference counting this version was officially stopped functioning in currently only the python version x and later versions are supported why python is used in data science python is the most preferred programming language by the data scientists as it effectively resolves tasks it is one of the top data science tools used in various industries it is an ideal language to implement algorithms pythons scikitlearn is a vital tool that the data scientist find it useful while solving many machine learning tasks data science uses python libraries to solve a task python is very good when it comes to scalability it gives you flexibility and multiple solutions for different problems it is faster than matlab the main reason why youtube started working in python is because of its exceptional scalability features of python language python has a syntax that can be understood easily it has a vast library and community support we can easily test codes as it has interactive modes the errors that arise can be easily understood and cleared quickly it is free software and it can be downloaded online even there are free online python compilers available the code can be extended by adding modules these modules can also be implemented in other languages like c c etc it offers a programmable interface as it is expressive in nature we can code python anywhere the access to this language is simple so we can easily make the program working the different types of python libraries used for data science matplotlib matplotlib is used for effective data visualization it is used to develop line graphs pie charts histograms efficiently it has interactive features like zooming and planning the data in graphics format the analysis and visualization of data are vital for a company this library helps to complete the work efficiently numpy numpy is a library that stands for numerical python as the name suggests it does statistical and mathematical functions that effectively handles a large narray this helps in improving the data and execution rate scikitlearn scikit learn is a data science tool used for machine learning it provides many algorithms and functions that help the user through a constant interface therefore it offers active data sets and capable of solving realtime problems more efficiently pandas pandas is a library that is used for data analysis and manipulation even though the data to be manipulated is large it does the manipulation job easily and quickly it is an absolute best tool for data wrangling it has two types of data structures ie series and data frame series takes care of onedimensional data and the data frame takes care of twodimensional data scipy scipy is a popular library majorly used in the data science field it basically does scientific computation it contains many submodules used primarily in science and engineering fields for fft signal image processing optimization integration interpolation linear algebra ode solvers etc importance of data science data scientists are becoming more important for a company in the st century they are becoming a significant factor in public agencies private companies trades products and nonprofit organizations a data scientist plays as a curator software programmer computer scientist etc they are the central part of managing the collection of digital data according to our analysis we have listed below the major reasons why data science is important in developing the worlds economy data science helps to create a relationship between the company and the client this connection helps to know the customers requirements and work accordingly data scientists are the base for the functioning and the growth of any product thus they become an important part as they are involved in doing significant tasks ie data analysis and problemsolving there is a vast amount of data travelling around the world and if it is used efficiently it results in the successful growth of the product the resulting products have a storytelling capability that creates a reliable connection among the customers this is one of the reasons why data science is popular it can be applied to various industries like healthcare travel software companies etc big data analytics is majorly used to solve the complexities and find a solution for the problems in it companies resource management and human resource it greatly influences the retail or local sellers currently due to the emergence of many supermarkets and shops the customers approaching the retail sellers are drastically decreased thus data analytics helps to build a connection between the customers and local sellers are you finding it difficult to answer the questions in an interview here are some frequently asked data science interview questions on basic concepts q how to maintain a deployed model to maintain a deployed model we have to monitor evaluate compare rebuild q what is random forest model random forest model consists of several decision trees if you split the data into different sections and assign each group of data a decision tree the random forest models combine all the trees q what are recommendation systems a recommendation system recommends the products to the users based on their previous purchases or preferences there are mainly two areas ie collaborative filtering and contentbased filtering q explain the significance of pvalue pvalue lt rejects the nullhypothesis pvalue gt accepts nullhypothesis pvalue it will either except or deny the nullhypothesis q what is logistic regression logistic regression is a method to obtain a binary result from a linear combination of predictor variables q what are the steps in building a decision tree take the full data as the input split the dataset in such a way that the separation of the class is maximum split the input follow steps and to the separated data again stop this process after the complete data is separated best python data science courses many websites provide data science online courses here are the best sites that offer data science training based on python greatlearning coursera edx alison udacity skillathon konvinity simplilearn how data science courses help in a successful career postcovid pandemic the economic downfall due to covid impacts has lead to upskill oneself as the world scenarios are changing drastically adding skills to your resume gives an added advantage of getting a job easily the businesses are going to invest mainly in two domains ie data analysis of customers demand and understanding the business numbers it is nearly impossible to master in data science but this lockdown may help you become a professional by indulging in data science programs firstly start searching for the best data science course on the internet secondly make a master plan in such a way that you complete all the courses successfully many shortterm courses are there online that are similar to the regular courses but you can complete it within a few days for example analytix labs are providing these kinds of courses to upskill yourself so this is the right time where you are free without any work and passing time you can use this time efficiently by enrolling in these courses and become more skilled in data science than before these course providers also give a data science certification for the course you did this will help to build your resume data science is a versatile field that has a broad scope in the current world these data scientists are the ones who are the pillars of businesses they use various factors like programming languages machine learning and statistics in solving a realworld problem when it comes to programming languages it is best to learn python as it is easy to understand and has an interactive interface make efficient use of time in covid lockdown to upskill and build yourself,why python is used in data science how data science courses help in a successful career post covid pandemic,python for data science
11,to be as brief as possible i graduated with a bachelor is in political science almost a decade ago for some reason thinking that i would be okay just having a degree after many years of bouncing around i started taking some moocs which led me to eventually completing a master is in analytics degree i got hired on over a year ago by a fortune company to do wouldata science but it turns out that most of the tools required to do such work r python are not approved for use due to the open source component sas is approved but my department still has not received its licenses i work with billions of rows of data on a daily basis using teradatasql and find trends inconsistencies make recommendations etc but i am really missing the predictive side that i studied so hard to learn given the above what is the best way to transition into a role where i can do more predictive work i do not even need a wouldata scientist title but i just want to work on modeling and use machine learning etc should i put a github together and put some project work in there i just feel a bit hopeless as in without any onthejob predictive analytics work i will never be able to transfer into one of these roles in the future,how to transition from data analyst to a data science role,i am a new data scientist and i do not know what to do
12,from a press release in an effort to inject more financial transparency into college sports the knight commission on intercollegiate athletics has unveiled a revamped and innovative college athletics financial information cafi database the new resource provides unprecedented access to athletics revenues expenses and debt as well as institutionwide academic spending for more than public ncaa division i colleges and universities dating back to the free openaccess database provides telling documentation of major college sports finances at a time when institutions face lawsuits to direct more financial benefits to studentathletes for the first time database users are able to view rich graphics that demonstrate by institution conference or competitive subdivision where the money comes from and where the money goes in college sports,knight commission unveils new college sports financial database,looking for data on college sports
13,i work for an ecommerce company and we are getting to the point where automating much of our warehouse inventory management makes sense i came across this harvard business review article which though interesting is a little sparse on the details for instance it mentions that the team had to account for lowvolume product orders that befuddled its datahungry machinelearning algorithms but it does not go into any details how they went about that it does not have to be amazon but i would like to find some resources that would help me understand how best to go about tackling this problem and problems like it if you cannot think of any available resources how would you go about taking hands off the wheel,how to learn more about amazon is automation,how do i go about creating a data warehouse for my company
14,hello all so i come from a biology genetics background but i would lile some computer science baclground to increase career growth please forgive me for my lack in knowledge of these terminology but i want to make sure i make the right choice before committing to a master is program which might not help me in the long run usf health informatics i originally thought health informatics is the same as bioinformatics but now i am thinking they are not what career choices do i have with health informatics the advisor was not so clear in that department and provided vague career choices he said salary ranges kk usd but im still confused in what they actually do uf medical microbiology i knowvery close to what i am already in but they offer bioinformatics and unix bioinformatics as electives and i figured ill get a taste of what these courses entail and how they are used in the medical field the advisor here said that there is a possibility of getting a graduate cert in bioinformatics all depends on covid class settings but we didnt go too in depth on what bioinformatics can do career wise is there any other program field i should consider i am not a math wiz nor knowledgeable in coding but i am very curious about these fields what advice do you have for a sciencebiology lab tech like myself thanks in advance and stay safe everyone,confusion regarding bioinformatics and health informatics,career advice
15,im currently in healthcare and have clinical and administration background i wanted to start self teaching myself sql and get my foot in the door as an analyst in healthcare ive truly always been scared at of math and numbers i never thought i would ever try to get into a role that required the word data or even analyst but i want to learn entry level skills and shift away from patients is self teaching yourself enough to be marketable for entry level data analyst jobs how hard would it be for someone who has never dived into sqlpython to teach themselves especially only having administration and clinical background are the beginner courses super hard to grasp at first im taking udemy courses and some good old youtube to help me start off any input,is it hard to become an entry level data analyst,how do i go about learning data science
16,hey there will try to keep this short i am a master student in the internet of things with a focus on data analysis i have been looking for summer internships since two weeks with over applications i had only interview and the rest directly refused me i would say the interview went well it was more about introducing myself and them introducing the company and after week i got a call that i was rejected i am applying a tons of applications and mainly in the domain of data science and data analysis i really do not know what is wrong with my resume i included a link below you can find all details about me would love to have a feedback thank you,what is my wrong with my resume,i have a data analyst interview tomorrow and i do not know what to do
17,cross post from rcscareerquestions background i have been a data scientist for about years now i have a bachelors degree in economics i started out doing risk modeling for an insurance company about months ago i was hired by a small consulting company my role here is more of a machine learning engineer i create machine learning systems to automate business processes i am proficient in python sql and r ampxb current job issues machine learning is a hard field to do consulting work in most companies that have adequate data infrastructure already have a data science team those that do not have the appropriate infrastructure cannot benefit from machine learning as a result i am getting little experience in my current role so i am looking for a change for every project i have there are weeks of no work doing this time i get certs and do research right now i only have uipath certification ampxb general concerns about the field of data science i live in a medium sized city on the east coast not a ton of data science jobs additionally i do not enjoy the modeling aspects of the job nearly as much as the engineering i understand most commonly used models when to use them their pitfalls etc however my interest with them is very applied i do not have any desire to develop new machine learning algorithms only using preexisting tools to add business value i would like to use machine learning as one of many tools to automate business processes ampxb future steps i am thinking about leaving machine learning specific roles in favor of a software developer role but i do not know if i could close to my current pay k i can take a slight pay cut but not too significant ampxb questions could i get a decent job as a python software developer with my current experience should i just try to get a machine learning engineer at a different company any other input ampxb tldr i like the engineering side of machine learning the most in a dead end job what should my next step be,data scientist looking for a change,is it worth getting a masters in data science if i already have a job as a data scientist
18,hi everyone i will keep this short because i was just finishing up this post and i got a blue screen and lost everything i had typed for the past hour hahahah dear god here we go again i will laugh if the diagnostic test crashes my pc sorry for the format or misspellings in advance i just want it to be done basically i am going to start applying for jobs on data analysis and i need insight on whether what i am preparing myself with is useful or not some information about myself i am and a night time college student doing a bsc cis recently i just finished a course on sql and found the whole design and visualization of data to be super fun and interesting so much so that i have decided that this is something i want to pursue work experience was a part time job fixing and selling computers been doing this for about a year now and found it really boring since every thing that was damaged was the same things specially ram left it about a month ago and with my free time i have been finding more about the data analysis profession now then i will list what i have been doing with my free time to prepare for the job this will have things that i think are needed and those that i think would be fun to have some knowledge of afterwards ill link and paste the description of job listing that i feel has the most things in common with the rest job listings ampxb things that i have been teaching myself are statistics sql and excel i did take courses on these two but it was to general power bi classification decision trees and model evaluations starting this today i am looking to run some linear regressions to see the relationship between advertising costs and their expenditure i have lined up to learn six sigma and their methodologies but i am not sure if it worth learning this yet intermediate knowledge on visual c and basics of java down the line i will look into r or phyton i have seen vmware pop up in some job listing so i have it on the list of things to know about hadoop analytics and hbase saw some listing that had these and i want to know if they are needed ampxb and that is about it on things i am doing i saw somewhere some predictive analysis on determining the infected outburst of diseases and i thought a similar project could be fun to better understand the spread of diseases ampxb the insight i am looking for is into what preparations i should be focusing on for a job as a data analyst the following list will be an the job description of a job listing provide organization and management of case files review data completeness of information proper execution extract data from data base obtain additional information from other investigative agenciesdata base establishmaintain physical file prepare noticesadvertisements receive suspense petitions claims process sharing requests reconcile inconsistencies prepare declarations gather information and organize investigative package verify case files and case tracking system maintain internal status information on the disposition of all forfeited assets assure information is accurate and perform analytical computations necessary to process data conduct and reconcile inventories distribute and receive documents assist lead analyst or official in obtainingcollecting all documentsinformation to complete case file provide administrative information and assistance concerning case to other investigative agencies local law enforcement agencies us attorney and other doj processing units and higher headquarters extract data from agency data base for management and program reports perform word processing relevant to case documentation perform data entry relevant to case ampxb,looking for insight on data analysis on these job description,is it worth spending a semester learning r or python
19,im at a bit of a crossroads in my masters in data science ive got options when it comes to two groups of courses for the first i can take database systems which covers dbms architecture models sql data modeling and entity relationship diagrams i could also choose to take artificial intelligence which covers heuristic and stochastic searches logical and probabilistic reasoning game playing planning and reinforcement learning this one is the most pressing as i need to choose one for the fall second i can take machine learning which covers current research in the field derived from recently published literature pretty vague i could also take advanced data mining which covers clustering classification and pattern recognition this one concerns courses next year im hoping to get some insight on how choosing one or the other would benefit a career in data science and to see what professional data scientists would recommend for career options thank you,masters course selection,data science career advice
20,i graduated in dec and had a data analytics job lined up in a small management consulting company in dc starting this summer got an email yesterday saying they will be rescinding my offer due to the covid pandemic tbh i kinda saw this coming and was applying at other companies i had an interview at oracle scheduled but they went under hiring freeze weeks ago and now they are ghosting my emails i have applied to over jobs and had referrals for a couple and havent heard back or rejected as far as skills go im pretty good at pythonsql and had a couple technical internships and decent side projects graduated from a nontarget with a cs degree and mostly applying to data analyticsjunior data scientists positions i network almost everyday on linkedin and apply to atleast jobs everyday would appreciate any advice,recent grad who had his offer revoked and interview cancelled,is it worth getting a second bachelors degree
21,hi all i am interested in learning what capabilities and techniques other data science teams have and i was wondering if i could post a quick survey here i think this is in line with the sub is policy especially since hopefully people is answers will be interesting clarification by you i mean either yourself or someone who can work with you do do this almost immediately eg not having to go to it or anything like that do you use other programming languages than python if so what do you use bi tools such as powerbi qlik etc do you have a direct connection to a database or do you just work through an api or library or something else if so what is the main database eg postgres ms sql do you have the ability to host dashboards eg using dash for internal to your company use do you have the ability to host dashboards for clients do you have the ability to set up an api for internal use do you have the ability to set up an api for public use which industry do you work in how large is the company just order of magnitude eg etc,what capabilities does your team have,what do you use for data science
22,i have an undergrad degree in finance and have been working at an asset management firm for over years now while the experience has been awesome i realized my passion lies elsewhere and want to get into data science as a potential career change preferably to something closer to business intelligence or business analytics ive been looking at graduate degrees in business analytics like the one from nyu stern to help me transition i know this is not purely data science but i think it uses a lot of related skill sets i was hoping to get some advice from people here on whether there is a place for me in the analytics field especially coming from a non techengineering background would firms value my less traditional background from a data science standpoint,transitioning to ds from financeinvestment background,is a masters in business analytics worth it if i already have a job as a data scientist
23,i am working in the field of machine vision where accuracy and performance both play a major factor in deciding the approach towards a problem traditional rule based approaches work quite well in such cases i am gradually migrating towards deep learning due to its umpteen advantages where the results seem promising albeit with two huge caveats lack of training data in this field to be precise lack of erroneous data performance issues on inference accuracy and speed are required in equal proportion and cannot be compromised in industrial settings point plays a strong factor i have been dabbling with transfer learning techniques and using pretrained models to overcome this situation for simpler applications such as classification this suits and gives good results in other cases such as detection and localization i have tried using maskrcnn which gives really good results but poor inference speed means it is not production ready the worrying factor in both the cases is how slow detection and inference is compared to traditional vision algorithms a solution would be to buy machine vision software specifically from companies such as cognex halcon etc who sell deep learning bundles they are quite expensive and are to be used out of box with minimal modifications which does not suit me currently point is highly necessary in production lines where each iterationimage may take less than ms for execution deep learning gives a lot of opportunities in getting state of the art results with very less data in most of the situations but in general without inference optimization in using apps such as tensorrt the time metric does not give good results is there an approach in using open source that can solve both point and point creating a cnn from scratch is out of the question,overcome caveats on using deep learning for faster inference on limited performance availability,what is the best way to train a deep neural network on a single set of data
24,hi as part of my cs masters thesis i am working with vector representations of words i am trying to increase the similarity between one word vector w and another w by transforming w however i want to do this in a way that an attempt is made to maintain the similarity between w and the other vectors wwn as best as possible i have spoken to my academic supervisors about this and they suggested using gradient descent as a way of finding a transformation matrix which can do this unfortunately i have no idea about how gradient descent could be applied for this or even if it can be used to solve the problem could someone help me understand how such a problem could be solved using gradient descent if not are there any other solutions to this problem thank you,increase similarity between two vectors whilst maintaining similarity to other vectors,can someone help me understand this wwn similarity problem
25,i am hoping somebody here has some experience with marketing mix models and canprovide some guidance i have experience working around mmms but i have always been at a firm that outsources the actual model building to a consultant i have never gotten close to the nitty gritty details of the model building process i am experienced in r or well versed enough to googlefu my way through most issues if i am successful this will be used as a forecasting tool not an roi measurement accuracy is necessary but nobody will be getting fired because of it is outcome i have gone through the unpleasant process of collecting and aligning weekly sales data with weekly media data impressions by media channel tv print digital for the past months i have also created a comprehensive list of sales promotions and major holidays that impact the business i am looking for advice on what process to take when attempting to build this thing here is my current roadmap determine seasonality holiday impacts and underlying trend of the data probably use the forecast package in r for this but i have also thoughts about just using dummy variables to let my model take care of that after i have deasonalized the data i will build the first draft of the model with media data will probably use a gam approach which i think will handle the minimum thresholds and diminishing returns that are common with advertising pressure a pretty good article about that is here i should note that i am not married to the gam approach review model fit and significant variables do some variable clustering and generally tweak the model apply some type of adstock tranformation to better account for the lag impact of the media i have found a few approaches online that look promising with this seeming to have promise rerun model and play with adstock functions until i have something worthwhile my question is do i need all of these steps or can i just dummy out the seasonal impacts and include the untransformed lagging media variables in my first pas of the model how do i go through the process to both account for the s curve of media impact and the adstock effect of the media,marketing mix model help,how do i go about building a model that incorporates multiple seasonal components
26,hi all i am relatively new to machine learning i have using tensorflow and keras for a few months now and want to try and move on to some more complex problems i was wondering if i already had a model in place would a neural network be well suited to learning how to solve a rubik is cube i have practised using reinforcement learning and qlearning and it feels like those systems could be applied to solving a rubik is cube but i could be being stupid if this seems like to advanced a project another problem i would be interested in solving is a chess game this seems like the traditional ai problem but i worry that the reason why it is more well known is because of the complexity of it thanks in advance i would appreciate any feedback hope i am not being too naive in my initial thoughts,project help,is it possible to train a chess bot to play a game like chess
27,i am conducting some graduate research on a data visualization website and am looking for people to interview the interview should last minutes and i can compensate you paid through venmo or paypal ampxb the research is to make design recommendations to improve the site for users i am studying user experience design ampxb i am looking for people who are educators journalists or those involved in newsmedia those interested in data visualization or statistics andor people who have a keen interest in world news ampxb if you are interested tell me a little a bit about yourself via email at saraheliotuxatgmaildotcom and let me know your availability i will be conducting the interviews this thursday through friday,data enthusiasts paid interview graduate research project,i am looking for data scientists and data analysts interested in data journalism
28,hi everyone i have an odd question i have several vectors representing muscles species vectors in each species and different orientations for each vector different time intervals for this work what matters is not the length of the vector it is the direction it is pointing does anyone know a good way for me to describeshow this so it is easy for other people to understand simple describing it as shifting n degrees around the dorsalventral axis m degrees around etc does not seem to be a good idea with so many vectors and different axes there is no way a person would get a good idea of what is happening if you have any advice i would definitely appreciate it,i need help representing data about d changes in vector orientation,how do i represent different orientations of a vector
29,i cannot view any data in the behavior flow section for my ios app in google analytics i set up tracking months ago and the behavior flow section has always looked like this you may have applied a condition such as a date range an advanced segment or a goal for which there is no data i only want to view pathing between events the events are set up and recording properly there have been hundreds of thousands of sessions in this time frame so there should be sufficient data to pull from there is a ga document for mobile apps which states that events paths are automatically tracked in the behavior flow section i am seeing that i do not have any data for screens so maybe that could be the problem do i need data for screens to view the behavior flow even though i only want to view paths between events if so how do i set that up i thought screen tracking was set up automatically,why cannot i view any data in the behavior flow,how do i track a user is mobile analytics journey
30,i am currently in the midst of interviewing for data science jobs in the bay area i have a master is in statistics but am having trouble talking about my experience i have browsed this subreddit but have not found answers to this specific question i get really nervous in interviews so i want to have written down what exactly i want to communicate about my past projects right now i am able to communicate the problem ie did the drug work the method logistic regression repeated measures mixed model etc and the outcome ie pain scores improved over time but struggled in my last interview when asked for more details because i did not know what details he might have wanted and when i asked he said something like just tell me more about that logistic regression i did not follow it this was a phone interview so i was not sure what level of detail i should go into what other details should i be ready to present what all the variables were how regression works how i coded the variables what the estimates were one of my issues is that the projects i am discussing have been lengthy and very complicated so should i choose smaller projects i am beginning to think presenting a homework problem where i did a basic linear regression or classification tree would be much easier to talk about but of course i would not say it was a homework problem tldr any advice on what exactly interviewers want to know about your past projects any insights to help me feel less intimidated,interviews what do they want to know about my past projects,how do i prepare for a data science interview
31,this is a long story then if you do not mind reading everything i write in this post and then give me any advice i will be very thankful i am a student of forestry engineering at a university in colombia in this career there is a lot of forest measurements and ecology analysis that make me fall in love with r and little by little make me fall in love with statistics and programming i realized after those subjects i wanted to combine ecologybiology with data science i started to search where to learn it and i found a lot of mooc is options datacamp udemy and so on every one of them selling the impressions that with those mooc is anyone could be a data scientist searching more deeply i realized that those courses just make an introduction of what really data science is i have to practice a lot on real problems on real situations different of practicing with the iris dataset or the titanic dataset and i am okay with it but keep reading i will explain why i have fo find another strategy since i am in south america the currency of my country is devaluated so investing my little budget on those mooc is is expensive i do not want to invest a lot of money in courses that i cannot use to apply for a job later or in which i have to study at a different university to really study data science i realized that the best way to be a professional data scientist is that i have to study at another university but i do not have the money at this moment the thing is that if a have to practice a lot search real datasets and accumulate projects more than certifications of a complete career track on those mooc is then i will have to learn from other sites books i wish free and other courses i have read a comment on quora that a course with more practical skills challenges exams is python for data science and machine learning bootcamp then it will be great to see the free course of deep learning in coursera the person who said that believed that those courses are better than datacamp dataquest so i have to start over there but i want another opinion and if that is a great introduction then what is next how can i keep learning when i complete those courses in the future i want to save money for studying this career at another university in another country but meanwhile where should i learn and gain experience with data statistics and programming plus my country made an alliance with a mooc of latin america called platzi to give free courses in ai platzi says that with their courses you cand find a job but i am studying their courses and there are only videos the practice and challenges are all by my self i will finish all these courses on platzi because it is a great opportunity but where can i find more information to practice and become a person that can find a job with it and save money to study those areas professionally noe i know that my practice and portfolio is more important than the certifications so most of the mooc is are practically lying to their students when they say that they cand find jobs with their career tracks and courses thank you for reading all that thank you for your advice and sorry if my engish is not clear or if a have a lot of errors,confused and lost at where to start,is it worth spending money on a data science bootcamp
32,hi fellows im a yearsold senior from brazil and i need to decide either to enroll in an economics bs or a computer science bs i recently started to learn coding and decided i want to study data science in deep during undergraduate studies i havent yet decided wich field but been reading about analytics bi machine learning and deep learning i think that building a business foundation and learn coding by my own could give me valuable insights and job opportunities especially internships and trainee programs on the other hand im afraid that it would limit my possibilities in terms of knowledge and credential itself id be glad if you could share your experiences and advices with me,bs in economics or bs in computer science,data science or business analytics
33,i am trying to feature scale my data and used the following code sc standardscaler x_train scfit_transformx_train ampxb i am getting the following error ampxb traceback most recent call last file ltstdingt line in ltmodulegt file homeanoushkajlocallibpythonsitepackagessklearnbasepy line in fit_transform return selffit fit_paramstransformx file homeanoushkajlocallibpythonsitepackagessklearnpreprocessing_datapy line in fit return selfpartial_fitx y file homeanoushkajlocallibpythonsitepackagessklearnpreprocessing_datapy line in partial_fit force_all_finiteallownan file homeanoushkajlocallibpythonsitepackagessklearnutilsvalidationpy line in check_array array npasarrayarray orderorder dtypedtype file usrlibpythondistpackagesnumpycorenumericpy line in asarray return arraya dtype copyfalse orderorder valueerror could not convert string to float us citizen gtgtgt x_test sctransformx_test traceback most recent call last file ltstdingt line in ltmodulegt file homeanoushkajlocallibpythonsitepackagessklearnpreprocessing_datapy line in transform check_is_fittedself file homeanoushkajlocallibpythonsitepackagessklearnutilsvalidationpy line in check_is_fitted raise notfittederrormsg name typeestimator__name__ sklearnexceptionsnotfittederror this standardscaler instance is not fitted yet call fit with appropriate arguments before using this estimator ampxb can anyone please explain me how to fix it this is my first predictive model so i do not have a lot of experience please help,why am i getting error while performing fit transform,how do i get my data to work
34,i have been working on a timeseries model using rnns and have seemed to have limited success i was hoping to get some help clarifying a few questions note that my model is not for prediction instead it is more like a recurrent variational autoencoder where i am trying to learn latent features of the sequence if i assume my data is a d sequence of length n n n how do i divide the data up into batches i know minibatches are typically of size batch_size seq_length num_features but do i split the data into minibatches using an overlapping sliding window approach or a nonoverlapping window eg minibatch one goes from does minibatch two go from or my gut feeling is that the former is more appropriate when you are using a nonrecurrent nn to model the data eg you will only evaluate the loss on the last element of the sequence as you need the rest of the data for context hence in order to model the entire sequence you need to ensure that every item of the sequence is input such that it is the last element whereas with an rnn as you have a state that you can feed in you are able to evaluate each element of the sequence and can therefore feed in the data much more efficiently in nonoverlapping blocks edit also note that i only have a single sequence of say length,a few questions on modelling time series data with recurrent neural networks,how do you deal with overfitting in rnn
35,hello im mainly using r for my scripts and benchling to take notes i want to know how to have an organized and reproducible workflow now i have a folder with scripts that have the next structure _functions_to_clean_datar _clean_datar _function_to_analyze_datar _analyze_datar but sometimes i have to make some corrections or add more data for that i need to rerun or change some scripts that i used earlier and take notes on benching this is messy since after that i cant run my scripts in order and have the same final results since i need data that i got for example in script to make the corrections in script it would better use r markdown or what should i do please excuse my english,how can i have an organized workflow in r,how do i use r for data analysis
36,im a university student majoring mathmatics in undergraduate school and ill go graduate school in math or statistics i want to be a data scientist that managing data making results now im studying programming such as r python and math linear regression real analysis i have questions the first is im thinking about mooc in data science and therere moocs one is data analyst in udacity second is data science specialization in coursera both has pros and cons i cannot decide which one is good for me you should think that im a student and ill go to graduate school the second question is beside mooc im not sure about what i have to studyshould i study computer science like algorithm graph theory or math statistics,moocs for university student,data science or math
37,i am trying to model a simple neural net to classify data amongst classes the data is quite high dimensional with rows and columns with the last column being the labels which have encoded into integral values for classification purposes i am referring to the proposed architecture in where it is used on iris data to get a conventional learning curve but my learning curve is coming to be something unusual which i have not seen before ampxb does my learning curve graph signify that the model performs poorly as it does not go down like a conventional one using the gradient descent optimizer or is it just some point i am missing any comments in this regard would be appreciated ps the accuracy i am getting based on the above model is close to thanks,can a learning rate graph look unusual and weird,how do i train a deep neural network to recognize missing values
38,how do you manage different models over different datasets and repeated experiments for instance i hash the hyperparams and create a directory with that hash and put everything that belong to that experiment under that directory i run or runs with same hyperparams and take the average of those for that particular model and dataset this works well for a model a on dataset a but at times i find it difficult to compare experiments of different ie comparing model a and dataset a model a on dataset b or model b on dataset a currently i am trying to intregrate dvc for data versioning in my workflow but before jumping in with two legs i wanted to know how others do it,how do you manage multiple experiments in ml,how do you handle running multiple experiments on a single dataset
39,i checked my google analytics account after about a month i was surprised to see a significant uptick in pageviews and visits however i saw that many of most visited webpages are not something i have hosted for example the typical urls supported on my website are bmicalculator bodyfatpercentagecalculator and so one but the ones i seeing now are sharebuttonto compliancedonxyz so it seems that these new pages are almost some random urls when i try to access these on my site mysiteblahsharebuttonto i get but google analytics reports page views for this page over the last month what is happening and what should i do to avoid these situations is my site compromised,pages i am not hosting are showing in google analytics,is there a way to track visits to a certain section of my site without referral traffic
40,hi i have been working in data analytics for the retail arm of a bank about years now i have a keen interest in social sciencedevelopment econ grad and have been thinking of switching for some time now could not because of some personal reasons background econ grad skills include python sql tableau stata plus some research exp i have questions any advice on how i make the switch now if i want to move to an organisation like the gates foundation any social science datasets that i could work on to get my hands dirty and of course add in my resume this is not the stereotypical change in career plan question so any advicesuggestionscriticisms would be a big helpful,advice on switching career to development sector,data science bootcamps
41,q blocks cloud affordable supercomputers for highperformance computing applications like ml model training running simulations big data analytics or creating the next deep fake powerful gpus cuda amp tensor core gpus for ai data science amp design lightningfast computing results costeffective x costeffective package gpu hours data security state of the art security standards dockerized volumes sha encryption salts gpu power launching a gpu powered the virtual computer on q blocks peer to peer computing platform is really easy here is a quick demo train ai models faster select a gpu instance select an ai framework of your choice select access method cli or jupyter lab get a supercomputer at your service one more thing for get gpu hours why qblocks x better breakthrough computing paradigm the community of people with a deep love for supercomputing crafted with love for the crazy ones what is q blocks imagine the uber of computing a way to use millions of underutilized sources of computing to build your next ai model gone are the days when supercomputers were just limited to scientific institutes or governments by connecting together these computing sources spread across the worldq blocks envisions bringing access to a supercomputer in your hands get access to free compute hours contact information facing any trouble in getting started send us a contact form message water street vancouver bc vb b canada ampxb about q blocks q blocks is building affordable supercomputers using peer to peer technology built by a team of scientists and engineers to help our tribe get superfast computing results read the vision for a brief background and the secret master plan,affordable supercomputers for ai data science amp design,data science with opencv
42,hllo all i am python and javascript and scheme developer looking for a project idea a few months or years back i started a project to help me with graphdb and conceptnet with the hope to put it to good use for doing some nlp stuff that was a graphdb embedded in python that is very easy to install or very easy to run similar to sqlite with a gremlin api anyway after some time fiddling around text summarization question answering wikification and reading about opencog i figured out that that nlp does not really need my project and most of the work done in data science evolves around crunching a lot of matrix operations best done in ram or with the help of gpus they are a few like opencog that do use relational model for both their kb and algorithms but i found no other examples so there is no need for my biggerthanram relational data store i diven into the world of datascience a bit deeper i discovered that one of the weaker point of the datascience work flow was wrangling basically some kind of extracttransformload or extractloadtransform if you prefer the tasks handled by google dataprep but that niche is already taken there is even free alternatives i would like to help the datascience community with some working software but i do not know what to do by the way would you find it useful to be able to version a graph and maintain multiple versions of it in the same manner that is done with source code with git,a python developer with too much free time needs your input,what is the best way to store your data
43,st year comp sci undergrad and self teaching ml basics so will be prone to misinterpreting things ampxb i understand that a big problem with neural networks are that they are black box models it is difficult to understand how they achieve outcomes given certain input data this is an issue when nn models could effect the health and safety of individuals ampxb what i am wondering is that if we could describe a mathematical form of the function encoded by neural network models would it help researchers gain insight into how they work ampxb i guess that the mathematical form of the function would be just as cryptic as especially for deep learning models there are a lot of inputs but i have no idea which is why i am asking,would having a mathematically described function that approximates the function encoded in a neural network help researchers understand how a neural network gets its output,question about the effect of nns on data
44,two data scientists walk into a library at the end of a long day data scientist to the librarian can i get a copy of this book on statistical methods goes on to share the name of the obscure book data scientist to data scientist theyll never be able to find that book the librarian clacks away on the keyboard for a couple of seconds before replying found it here are the details of its author publishing house and borrowing history oh and someone left a comment saying they found it super useful for understanding logistic regressions i can grab it for you in a jiffy data scientist to data scientist ummmm why cant the same thing happen with our data that is what a data catalog is here for with the need of data and metadata management and collaboration data catalogs are increasingly becoming relevant read what are data catalogs and why should data teams care about them here,what is a data catalog and why should you even care,what is your data science superpower
45,i wonder if there is such a way to do this i have code that runs on google colab but even with gpu enabled it is training super slow so i am wondering if i can do that on gcp instead i can have an instance with a p gpu however it is such a pain to install cuda the drivers and everything that comes with it idk why but there is a gazillion ways to install them anyways it is a pain even using the public images like cdeeplearningtfentcuvubuntu after installing when when you try to do import tensorflow as tf printnum gpus available lentfconfigexperimentallist_physical_devicesgpu the output is is there a proper way to do this or just manually install everything also can someone verify that tensorflow runs gpu by default like no need to set it like witih keras or tf,how to get google colab environmentimage to gcp,how do i use google colab with tensorflow
46,hi all i want to let you know about a project i had been working on called flashaiio which addresses some of the operational issues i came across when delivering models to clients or at the workplace i prefer spending my time building great models instead of thinking about the infrastructure complexities of hosting and serving them so i put together a service to do exactly that so if you want to enable clients colleagues or apps to send inference requests to your models flashai lets you do this via web requests serve your models without any hassle the workflow is straight forward train your model locally then upload your model file to flashaiio and then send inference requests to your model currently this service supports scikitlearn tensorflow and pytorch models try it out at flashaiio please let me know what you think and if you have any suggestions for other features,host and serve your scikitlearn tensorflow and pytorch models within minutes,how do you deploy models to clients
47,baidu has answered this question empirically but i do not have a good background in math so i do not understand the answer gt many studies theoretically predict that generalization error learning curves take a powerlaw form m mltsupgtltsubgtgltsubgtltsupgt here  is generalization error m is the number of samples in the training set  is a constant property of the problem and ltsubgtgltsubgt or is the scaling exponent that defines the steepness of the learning curvehow quickly a model family can learn from adding more training samplesltsupgtltsupgt unfortunately in real applications we find empirically that g usually settles between and exponents that are unexplained by prior theoretical work here is the same text as a screenshot in case any of the math notation does not display properly for example for image classification on imagenet gt the top classification error exponent is ltsubgtgltsubgt on the other hand the exponent for top classification error is ltsubgtgltsubgt how can this be expressed for a nonmathy layperson for example how much improvement in accuracy results from a x increase in training data x x,in layperson is terms how much does deep learning performance scale with training examples,why do we have such a great deal of variational autoencoders
48,honestly i would like to hear how the industry deals with these issues product line x needs a product npv evaluation and a pricing model while i have transactions on the aggregate product line x i do not have a reliable transaction data for product x in product line x i notify my boss who asks for a solution i propose that the servicing team input transaction data into the system when they service the product servicing team agrees to implement the new procedure into their practices to my boss and the cfo the servicing team does not carry out the process my boss knows and he has not been pushing for any follow up for months now i have moved onto other models and projects but as i run into these problems more and more often i find myself getting apathetic towards everything and any hope of interdepartmental solution this morning i just could not deal with the guy next cube over talking about this concert he went to last week for the th time and just went home there have been better opportunities but i just cannot quit on the work that i have been building for so long now,business process change implementation,how do you deal with product managers that do not understand data science
49,i recently started looking for new roles after years working for the same company and bit out of touch with the market i came across some job postings with title senior analyst data scientist or senior data scientist analyst either it should be senior analyst or data scientist or just senior data scientist the job description lists everything a ds should know mode building stats experimentation cloud etc i recently interviewed for one of those rolesfortune non tech but the tc they offered seemed more like a normal senior analyst kind role around k base for a mcol city i was assuming for a ds role with yoe would be around k k base am i targeting the wrong kind of jobs or its the normal compensation for ds right now,what exactly is senior analyst data scientist role i am confused with responsibilities and corresponding tc,is it normal to ask for more compensation if you are a senior ds
50,i am looking for online resources for this type of issue i am facing but the problem is i do not know what this issue is called or if it even has a name so i have a movie dataset each row observation is a unique movie and one of the columns is a string list of genres you have stuff like scifi adventure zombie war scifi etc this list is not always the same lengths for each row using the way i am taught in my classes is to take all the genres mentioned in the whole column and just onehotencode them but what i am worried is that this will just create a large amount of columns and new movies can always add new genres i was wondering about grouping up the genres in a more workable amount i could use pca on the fully onehot encoded genre columns set but pca creates unreadable columns and it does not tell you what genres were grouped into which i would like to have scifi timetravel together or pirate historical together and since the lists are so arbitrarily organized if a new batch of data with a new genre comes in the pca would have to be redone right i want to see some online resources for different ways of dealing with this than just pca please note my example is arbitrary it could also be a clothing dataset with lists like jacket denim loosefitting etc,dealing with when observations have a variable list of traits,how do i group similar movies based on their genre
51,need help creating a data set ill be using analogies below to help avoid industry specific jargon usage i have a group of friends who all have different food preferences and budgets min and max theyd pay for dinner as well as food they like and food they dislike i need to create a dataset for their preferences so that if on a given night i say id like to go get italian and pay i would be able to pivot the data and see whose budget im within and who likes italian food and who dislikes italians food the problem is i cant figure out how to organize the preference section of the data set while min and max price are easily added as a single cell in a spread sheet for each person some of the individuals like foods and dislike what is the best way to organize the data so i can easily analyze the data set to figure out which individuals i would and would not like to ask to go to dinner with any videos or help would be greatly appreciated thanks for any help that comes my way,creating a data set from scratch having trouble,looking for a data set with italian food preferences
52,hi all hope this is the right place to ask i am yo and have a background in computer science bsc and software engineering msc currently i am working as a software engineer but am not really happy with the work i am doing as it does not feel very challenging i have been looking at more math and statistics including ml related topics and feel like this would be very interesting for me to dive into is there anyone that went through a similar situation i feel like it might be a bit late for me to still start on this as i have already finished my studies what do you think are topics an in which order i should jump into to get the knowledge i need i have some basic knowledge on calculus linear algebra and statistical methods but this all needs to be refreshed any recommendations on how to approach this possible resources to read would also be very welcome i also like working on projects to get more of a feel on it any ideas for small problemsapplications i could work on to put the things i learned into practice,advice for a beginner,how to get started with data science
53,activation functions might seem to be a very small component in the grand scheme of hundreds of layers and millions of parameters in deep neural networks yet their importance is paramount activation functions not only help with training by introducing nonlinearity but they also help with network optimization in this article we will explore the paper by google brain titled searching for activation functions the paper proposes a novel activation function called swish which was discovered using a neural architecture search nas approach and showed significant improvement in performance compared to standard activation functions like relu or leaky relu we will first take a look at the motivation behind the paper followed by a dissection of the structure of swish and its similarities to silu sigmoid weighted linear unit we will then go through the results when swish is applied to several nlp tasks along with the pytorch code to train your own deep neural networks with swish topics covered include motivation swish explained pytorch code notable results conclusion reference article link,article the swish activation function,research google ai and neural networks
54,i am currently in a dual major for computer information systems and data analytics at my state university i am highly feeling that i am not learning a lot in my data analytics courses and want to try to do something through my work that would be valuable to the company while being able to learn more on my own my intended idea was to understand customer attrition by creating first creating a customer ranking system based on things they do in my company is program they use for example for a fleet maintenance program a customer may be scored on the number of work orders they create their parts purchase orders etc these would have some type of weight attached to them that would have to be decided essentially i would use these scores to predict which customers are at risk of leaving us is this something that is possible using ml and what advice would you have for me our customer data is in an aws environment,creating a customer attrition model for my work,how do i go about building a predictive model for a company
55,yesterday i asked a few people about creating a program that can automatically categorize reddit submission into appropriate subreddit using title text the first version is ready and it works a lot of people helped me yesterday and thanks to comments by udeltasheep and uolbaa i was able to create it it is very bad code right now since i just learned python programming and my knowledge of ml is very limited mainly sentdex videos but i feel super happy that i was able to create this program here is how i did it please bear with me because i know i am a total noob first run this google big query select subreddit title from fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ where subreddit in programming business wouldesign entertainment iscience isecurity worldnews politics amobile istartups google amicrosoft bitcoin facebook amazon amovies gadgets notechnology linux gaming apple wouldesign amusic then export the results into a table and export it again to a csv file to your google storage bucket then install google data labs and create a notebook then use the following program to run it i have still got a lot to learn and my next challenge is to create a small webpage so that people can enter the title in a web form and it shows the correct subreddit using it,p automatic reddit categorizer update first version working,is there an easy way to store a large amount of data in google data studio
56,i recently signed an offer to start working as a data scientist after the summer i am extremely excited as the role is known for being ml stats data engineering heavy dashboarding type projects will not be part of the role as they fall under the other teams my background is masters level noncs so i have not formally learnt data structures and algorithms i know the basics of the most important data structures lists sets hashmaps queues contigous data structures etc and intuitions about their corresponding timespace complexity they were needed for some advanced courses eg combinatorial optimisation w c together with some sorting search algorithms binary search dfs bfs but here typically only what was needed was covered for now until i graduate i am looking at areas i can improve before i start working aside from dsampa i have also identified extra cloud skills i have entry level azure certs already but i can go for more cicd testing frameworks and webapi skills for model deployment i do kind of reason dsampa while writing code but maybe actually formally learning about them would make me a far better programmer should i potentially just try and wing it with my current knowledge what do you think are they really that important aside from leetcode you get on interviews which i no longer have to do in the past i have always avoided selflearning these as i believed my time was better spent on extra math stat than on dsampa,is data structures and algorithms worth spending my time on before i start my job,is it worth spending time learning about ml for data science
57,hello all i am a marketing analyst with a large company that has many brands i am their first analyst so i have been responsible for a lot of data wrangling across all of their different marketing channels along with our new digital marketing manager and have been responsible for doing all of their campaign reporting after spending a couple months doing manual exports from each marketing tool we use while getting my feet under me i am finally sick of having to log in and pull data from different marketing tools in an effort to get all of our marketing data into one place i have been working with a developer to build a database on amazon redshift to take in our data from a a variety of sources like pardot and google analytics to finally make reporting easier i am running into one sticking point though what tool can i use to get all of my social media data into one place to import into my database we were thinking about using hootsuite but it does not appear to have a reporting api is anyone aware of a similar product that does i really want to avoid having to build out an individual connection for each brand is linkedin facebook and twitter profile i guess sprout social has a reporting api does anyone have any experience with that i am pretty new to marketing analytics but have been working as an analyst in market research and revenue management for years i am well versed in salesforce google analytics sql powerbi and excel and have been working withlearning python for the last half year ampxb thanks all,social media management platform with reporting api,how do you manage your social media data
58,hello i trying to figure out how the kernel trick gives rise to a decision boundary in my particular case i am looking at string kernels where strings are classified i get that kernelization helps to make decision boundaries for nonlinearly seperably data but whenever they are explaining they usually only seem to show how the dot product give you a similarity score between two data points not how it partitions a set of data into two categories for example in this above link the lili commentator simply gives an example of what looks like two datapoints in d space x and y and calculates the dot product between them but i do not see an explanation about how this product can be used to determine similarity between the two points or how it can be extended into a decision boundary between two groups of points does someone have some insight in regards to this,how do kernels in svms give rise to decision boundaries,how do i deal with missing data
59,hello everyone going to try to keep it as brief as possible to start a bit about my background i graduated with a bs in petroleum eng and did well in school been more than a year and still having a difficult time landing an engineering position without any experience ive been recommended by many people to start a masters program but im having a troubling time deciding what to pursue some have told me to go into ms data science while i continue to search for an opportunity few others have recommended to pursue masters in mechanicalchemical which would open more engineering opportunities now there is quite a few people who have recommended ms in data science and i want to possibly enroll in one of these programs preferably an online program oil and gas is moving rapidly into automation and relying heavily on data science given my undergrad degree directly related to oil and gas i think a ms data science could complement it it would make me more competitive while also allowing me to move into another industry should the oil industry go to shit there is also the possibility of pursuing a masters in chem eng degree and just learning data science on the side through certifications i am having a trouble time determining which route i should pursue if you could share some suggestions or insights on this matter id really appreciate it thank you all in advance ampxb tldr bs in engineering grad but cannot find an opportunity should i pursue ms in data science maybe an online program or ms in chemical engineering while getting data science certs on the side,looking for post undergrad advice,is a masters in engineering worth it if i already have a job as a data scientist
60,q what kind of industry job can i get with interest in text analysis what should i learn more ampxb i have background in graduate studies in social sciences so i have background in using statistical analysis for data analysis but i do not have background in big data analysis nor adept at using statistical software to process big data ampxb current skills r and python i cannot say i am very fluent but i have studied it for a while so i am used to the software for python i am currently more interestedlearning the language to conduct text parsing and analysis ampxb experience i have graduate level research experience where i extracted government recordsused text analysis to gain qualitative information ampxb would a data science certificate necessary to enter the industry are text analysis jobs all tied to big datatext mining if this is so i am considering one year program in big data analysis,what kind of industry job can i get with interest in text analysis,what kind of data analysis skills are needed for big text analysis
61,using normal linear regression methods recommend items users have weights assigned as per the movies they like movies have weights assigned as per genre among many other features can train bothways predict weight for movies or users and get a combined cost function predicting features here as well hence called collaborative filtering also there may be unknown values as all users have not rated all movies so changes in cost function is eminent accordingly train model to predict weights of users movies and output to compare with is the user ratings to account for new users normalise the data by taking means and hence also transform the output so each new user has mean as default rating rather than which would not help to train the model once trained among several things model can be used to predict rating for other movies and suggest the one which is most familiar to the ones user liked,day recommender systems,what is the proper way to use ml to predict user ratings
62,hi all very new to the data science world and was wondering if someone could point me in a direction any direction the problem i am trying to solve is i have a market place at practically every instancepoint in time my supply outweighs my demand only a portion of my supply is sellable the portion of my supply that is sellable can also go back into the supply pool similar to how a consultant can take on multiple projects at once for every isupply there is an ideal set of matches on the wouldemand side what are some basic models that can help me manage my isupply so that they can always find their ideal wouldemand counterpart i am not looking for an answer but maybe a few models i should explore eg is this a multiple regression problem should i do tfidf and then match using something else etc thanks,best models for managing inventory supplydemand,how do you deal with supply and demand imbalanced models
63,hi all like many i would like to enter into data science field but i am in s so i understand i am in the danger zone with respect to career development i read upon few articles on what to learn but it is confusing there is no clear curriculum if you want to do it without enrolling into school i have intermediate programming skills nothing fancy i have high school math skills excluding calculus i knew it back in the day but not anymore i think i can understand logic decently ok i have time and i can put in effort so all you wise data scientist people kindly tell me what to learn math programming to get started as a beginner data scientist if you include resources to learn from as well that would be awesome many many thanks,curriculum to get started,what are some good resources for learning data science as a beginner
64,i am a sole data analyst at a startup and there are many days when i start my day without knowing what i am necessarily going to be doing usually a bug in the data is reported to me and so i spend the days fixing that or someone asks for a report adhoc and i make it for them but as i have improved the infrastructure now there is not as much bugs popping up and i have automated many reports so i do not get asked to do as many anymore and i am trying to find new tasks to do so my question is what is your routine like as a data analyst say you want to be forwardlooking and plan for the next week or month how do you decide on a goal and roadmap,what is your routine like as a data analyst,what is your data strategy for the new year
65,i am not a data scientist but i feel like you all could help me out i am trying to collect data for all firstlevel administrative divisions for all countries and i am having a hard time i started with this web page and just scraped all the data there however the formatting is such that i would have to manually go through to separate all of the data into the correct divisions i was thinking about getting data from this wikipedia page but the data is so dispersed that i would invest more time into engineering the data collection than it would take to manually separate the first source is data ampxb where can i just get a dataset of all countries and their firstlevel divisions ie just state and not counties cities etc,get data for all firstlevel administrative divisions for all countries,looking for a data scientist willing to answer questions for an interview
66,hello ampxb currently we are using logistic regression as statistical method that predicts if loan taken by the customer will be bad or good depending on the probability of default and cutoff point that we have set the problem is that the current model is a bit biased towards some type of clients and i want to rework it from scratch since previous model have been working for a long time all sampled data is already passed through the prism of the model so i basically only see approved customers that may be less than of all customers the question is what should i do if i will make my new model based on only of data that came trough the prism of the model i will face problems several problems relative low default rate rare events predictors that were included in previos model and were really strong wont affect current sample and wont be included new potentially weaker predictors will be included in the model but old predictors from previos model wont so it may lead to worse model in general that only affects my sample of data etc what is industry best practice where should i get all the data if using sampled data is not possible because of a problem i described above thank you in advance,logistic regression for predicting goodbad customers scoring model development,is there a good way to deal with missing data in a regression model
67,so i did not want to be too specific as the above is my general framework but i am not really a web developer and would call myself a data analyst at the moment not a scientist yet however i am happy to provide more details if that would help in your responses i am basically wondering what the architecture of this would look like and if there are any resourcesinfographics as to how to get started specifically step b would that be a mysql database to house the data in the interim before i manipulate it what are some good resources for the interaction of front and back end web design gosh i hope all that makes sense i am happy to clarify and thank you all in advance for your time,tapping this sub for some resources i am looking to a tap into some api feeds b do stuff with the resulting data graph manipulate etc c deliver it in the form of a data product web mobile etc,how do i go about creating a web app for my company
68,hi i am new to machine learning so any help would be greatly appreciated ampxb i am trying to build a basic model that detects anomalies by comparing a rate value against max and min thresholds and classifying them appropriately i have features in my dataset rate of change max threshold min threshold i tried using decision tree and random forest algorithms and they all seem to be going by only the rate of change feature when i look at the feature_importance it shows up as so it doesnt look like it even considers max and min thresholds is it possible to tweak the feature priorities i would prefer the model to look at the threshold values as well is there a way to boostmodify feature selectionimportance,question about feature importanceselection,how to deal with outliers
69,could anyone help with when i use the pretrained model for englishtogerman translation at why am i getting some random translation output phungarchlinux opennmtpy python translatepy model available_modelstransformerendewmtpyonmtaveragedepochpt src datasrctesttxt output predtxt replace_unk verbose sent orlando bloom and amiranda kerr istill love each other pred nein viel leicht nicht pred score sent actors orlando bloom and amodel amiranda kerr want noto go notheir iseparate ways pred seh r interessant und interessant pred score sent however in an interview bloom has isaid nothat he and kerr istill love each other pred seh r interessant ist auch die tatsache dass das ganze noch nicht vollstndig umgesetzt wurde pred score sent amiranda kerr and orlando bloom are parents noto notwoyearold flynn pred seh r interessant und interessant pred score,random translation output with pretrained opennmtpy model,is there a reason why we get such a bad rep in the industry
70,i am trying to predict a time series of a discrete number of amplitudes from continuous curves of the same time resolution i have a feature extractor that comes close and just rounding it works pretty well but sometimes it predicts the wrong label roughly of the time however the feature extractor also has an additional couple of hundreds of meaningful time series builtin so i was thinking i could augment the rounding heuristic with them to improve the predictions but how would i go about combining them though i also have a decent set of supervised examples of how the time series should turn out example the red line is rounded from the blue line and should therefore follow the green line completely but that does not always work because of noise in the blue line,how do i combine several time series into one given a dataset of how the end result should be,question about time series prediction
71,your isp internet service provider can see each individual website that you view and in some cases can actually see the data and parts of the website that you are viewing recently in the uk they passed a law requiring isps to keep every individuals search history for years and this is happening in other countries when there is not even a legal requirement you can stop your isp from breaching your privacy using a few different methods the first of which is using a vpn this costs a monthly subscription fee however this not only protects your browsing history but can also be used to torrent privately without any risks or to protect your ip address from malicious people online nordvpn is one of the largest vpn companies however many other providers can be found online the second method is using the brave browser it is similar to chromefirefox but it has a built in adblocked and built in tor support which hides what websites your are visiting from your isp you simply download the browser and click the settings in the top right and click new private window with tor this is my preferred method as it not only protects your privacy but also blocks ads while you are browsing,do not allow your isp and government to save your browsing history,is there a legal reason to use google analytics to track who is visiting your website
72,i am trying to do the below linear regression in tensorflow but my output is all inf and nans my input dataset has to be yx noise where x is a normal distribution of size and noise is gaussian with mu and sigma output loss w b loss w b loss e w b loss e w e b loss inf w e b e loss inf w e b e loss inf w e b e loss inf w e b e loss inf w inf b inf loss inf w nan b nan loss nan w nan b nan loss nan w nan b nan loss nan w nan b nan import tensorflow as tf from sklearnmodel_selection import train_test_split import numpy as np import pandas as pd from matplotlib import pyplot as plt noisenprandomnormalastypenpfloat x_datanprandomuniformastypenpfloat y_datax_datanoiseastypenpfloat pltscatterx_datay_datas pltshow xtfplaceholdershapedtypetffloat ytfplaceholdershapedtypetffloat learning w and b over the epochs wtfget_variablenameweightdtypetffloatshapeinitializertfzeros_initializer btfget_variablenamebiasdtypetffloatshapeinitializertfzeros_initializer y_pred tfaddtfmultiplyx wb loss tfreduce_meantfsquarey_pred y optimizertftraingradientdescentoptimizerlearning_rateminimizeloss epochs with tfsession as sess inittfglobal_variables_initializer sessruninit for e in rangeepochs _csessrunoptimizerlossfeed_dictx x_datay y_data printlosscwsessrunwbsessrunb pltscatterx_data y_data ro labeloriginal data pltplotx_data sessrunw x_data sessrunb labelfitted line pltlegend pltshow,linear regression on tensorflow all nans,is it possible to train a cnn with a loss function that is similar to the one in r
73,i built a cnn to classify different classes it performs well on most of the classes giving approx accu per class current each class has images but in the future there is a possibility that i might get more data for each class for instance i get more data for some class how should i retrain the model should i retrain the entire thing ie with old and new data should i retrain the model with only new data here i fear that as the model will get new data for a single class the model can possibly forget what it has already learned or might affect the accuracies of other classes if anyone has worked on this problem before please help,retraining cnn with new data,question about training a cnn with multiple classes
74,i am graduating with a masters in management and will be spending the next few months learning some technical data analytics skills i have signed up for a month bootcamp that will teach me data science through the pandas library in python starting from a beginner coding level however looking at the jobs i will be applying to business intelligence most jobs list that they will love it if i know python but they expect me to operate in sql or in some cases r i have only done a small hour course in sql to learn the basics i am curious to know given i will spend the next three months learning data analysis through the pandas library how hard will it be to pick up sql later are the skills very transferrable apologies if this is a sillyobvious question,question about learning sql after learning data analysisbased python pandas library,is it worth spending a month learning python for data analytics
75,hi everyone to start off i am not exactly that good at selflearning entire fields of subjects i taught myself some python and sas sas was more learned on the job tbh but never really to the point of doing my own data science projects okay so i am a year old recent graduate in economics as of last year and i have just started a parttime msc in econ but with a specialization in data science and numerical methods basically a lot of econometrics and classes on mlbig data manipulationnlp it would take me years to complete the program i have also just begun a job as an economist at the government my previous job was waaaaay off course the job will involve a lot of sas programming and producing statistics on international trade data as i have been told naturally i would love to get a job that is more in line with dsml out of school so i was wondering if acquiring experience as an economist would be relevant when i will be applying for ds jobs right now i have no experience with ml and like i said selflearning is not exactly my forte so i figured that taking courses related to the field would provide with a solid springboard towards acquiring all the necessary skills plus i will be able to use the projects done in school for future interviews am i missing something has anyone else done a similar path from economist to data scientist for example am i wasting my time and will my experience be relevant for that future career switch thank you,economist that just started a msc in econ specializing in data science and numerical methods should i just drop it and focus on selflearning everything,is it worth spending a semester learning data science if i already have a job
76,hi there i have been wondering about this for a while without focusing too much on the specific algorithm used are there practical applications of synthetic datasets i know deep learning in general needs vast amounts of samples that are not always easy to find so what if there could be a tool that can generate high quality examples be it images sounds texts or videos for example single letters or group of words on all kinds of backgrounds maybe animated d rendered objects and multiple scenarios angle lights words pronounced on different background noises and so on and so forth of course the trained deep neural network would then be finally trained on a realworld dataset what do you think,do you think generated datasets when realworld ones are scarce can help training and if so who could find them useful,what are some good examples of using synthetic data for deep learning
77,i am trying several different word vectorizations for a binary classification problem the series x consists of lemmatized spacy docs row per review using x and y ie the ratings i used traintest split for what i believe is the correct setup for sklearn is tfidf vectorizer ampxb tfidf vectors x_train_tfidf x_trainmaplambda x strx x_test_tfidf x_testmaplambda x strx ampxb cv tfidfvectorizer ampxb x_train_vec cvfit_transformx_train_tfidf x_test_vec cvtransformx_test_tfidf ampxb and this goes into whatever classification algorithm i am using i am a bit more confused on the general flow that should be done using spacy is own word embeddings this is what i originally did spacy vectors x ispacy_vecs xapplylambda x xvector spacy_array nparraylistx ispacy_vecs dtype npfloat ampxb clf_lr_spacy logisticregression ampxb spacy_clf clf_lr_spacyfitspacy_array y spacy_pred spacy_clfpredictspacy_array ampxb it works but the overall method does not seem sound to me that is that i am not withholding any data as a test set at the same time i do not believe there is a fit or transform for the spacy vectors so i thought it made more sense to train the vectors on the entire corpus ampxb my question concerns the methodology here have i set up the spacy or tfidf for that matter vectors correctly is it proper to get all the embeddings and then split the data,spacy word vectors and sklearn,why does my caffe model do not perform well
78,hi there ampxb i have recently been going through tutorials on creating multitouch markov attribution models in r here ampxb from this i have created a set of users about that have a path to whether they converted or not some users may even have multiple conversions for example user a gt b gt c gt a gt conversion user a gt a gt c user c gt b gt a gt a gt conversion user a gt b gt c gt gt c these users have followed different paths with touch points in various marketing channels a b c to either converting or potentially dropping from their search i also created the time between each touchpoint so for example my dataset has user a lt b lt c lt a lt conversion lt i have been trying to find a source on lead scoring models in machine learning but have not really had any luck i have been thinking of using the transition matrix from that the number of days in the path and the number of touch points to assign a sort of lead score but it all seems sort of arbitrary is there some way to analyze the entire paths of every user and predict how close they are to converting let is say a conversion is i do not really have labels for nonconverting users since when they do not convert their just sort of in an indeterminate state can anyone point me in some sort of direction on this i am a bit lost thanks,lead scoring model for marketing,how do i track a user is journey across multiple touchpoints in google analytics
79,hello i am in bit of a situation right now i have an interview coming up for a data analyst role hiring manager reached out to me for the phone interview and it went well after i cleared the phone interview recruiter started taking care of the process i have asked the recruiter atleast times what to expect in the coding round she has been avoiding that question the interview date has not been set up either i gave thursday as my availability and they said we will send you the invite by monday they said something like this before as well but did not send anything now i have been preparing sql really well and i know how to work with dataframe using rpython i do not know how to do any leetcode type python questions since the recruiter has not been responding should i email the hiring manager on monday about what to expect although i will not learn something in days that i do not have any knowledge of but it will be good to know what to expect so that i am not shocked any help would be really appreciated i am a little stressed right now because it seems like a really good opportunity thanks,is it okay to email hiring manager if the recruiter is not responding,how do i prepare for a data analyst interview
80,hey there i am messing around with google data studio for work but i have stumbled upon a problem and i am not sure how to solve it we have many campaigns all in two languages dutch and french i tried making a filter so that the person viewing the report can select to view only the data of french campaigns or only the dutch but i have not found a way to do this the way i want to ideally i would make two custom dimensions one for the nl campaigns and one for fr i tried to look into it but the formula confuses me gt_lt does anyone knows what formula to use for this i know it has to be something with contains fr but nothing seems to work for me p,google data studio create language button,how do i use google data studio to display two different views of a campaign
81,greetings background i am not from a data science background i am a phd in humanities who stumbled on text analytics then quickly fall in love with it with little knowledge my research is now heavily based on topic models using the stm package in r my supervisor has no idea what am i doing since she knows nothing about data science and thought i am a normal humanities kid when she accepted me when i explore the field of topic modeling i found lots of interesting topic models i would like to try such as hdp keywordassisted tm embedded tm etc however there was little choice in r even python seems to only relying on gensim which certainly do not contain all the model so i am curious why does the r community seem to have little support for topic modeling furthermore is there a way to use the model that has not been developed into packages in my analysis i am learning python do not just tell me to switch to python xd,newbie why so little machine learning model package in r,is there a name for this type of model
82,hi everyone i have put a lot of work into getting a deeplabv model trained and it is working well but the output sometimes misses sections of the object and i am trying to figure out how i can postprocess the segmentation masks to improve the segmentation result my use case is industrial but the image below illustrates the issue where the segmentation mask misses parts of the object circled in red i tried grabcut using the segmentation mask as marks to improve the segmentation result but i could not get it working my thinking is that i should be able to do something like grow the mask to nearby pixels that are similar does anybody have any ideas or advice on how i can postprocess my segmentation results to make them better thanks,need help postprocessing image segmentation masks,how to train a mask segmentation model
83,i am using the following keras implementation of the wavenet architecture ampxb when my input shape is x y with z number of filters in all types of convolutional layers d casual the output is of shape x z i would like my output to be of shape x and so i changed the number of filters for the very last convd layer to be and got my desired output shape ampxb if numbers help more than variables input number of filters output desired output ampxb my fear is that in doing so i am losing learned information is this true is there another way to get the desired output ampxb any ideas will be much appreciated thanks in advance,wavenet output dimensions,keras loss function not working
84,hello i am a physics teacher who is been looking for a career change for some time now and i have settled on data science i am wondering if there is anyone here who is made a career change into the field that could possibly help me out bonus points if you also came from teaching haha my main issue is i am not sure how to build up practical experience and demonstrate it to a potential employer i am currently working through dataquest and after i have completed some of that i was planning on trying to build up a portfolio of projects but from there i really do not have a plan and if i am being honest i am not even sure that is the best way to develop my skills i am also looking to know your story of how you landed your first data science job how did you do it did you find your job through a connection in any case how did you demonstrate your competence with no experience in the field looking forward to hearing people is responses thanks either way,has anyone here made a career change into data science what was your experience like,how do i go about building a data science portfolio
85,hello i am currently doing my capstone project for my postsecondary data science certificate the project which is based on modelling virus outbreaks in north america is due by april the problem for me is that i am currently working full time and i get a limited minute in person window to see my supervisor each week for project clarificationsuggestions i do not really know which data science tools best describe modeling my problem since for my certificate program i have been taking gaps in between classes due to the fact i was doing my undergrad as well as doing the certificate program ampxb by taking certificate classes one at a time instead of altogether it has become difficult for me to refresh my knowledge on the subject since a lot of the relevant coursework i have done were a long time ago i have been making an attempt to go back to my coursework assignmentslabslectures to help me with the project as well as going over modules on linkedinlearning but i feel like i need more direction with the limited interaction i get from my supervisor i would like to know if there are any resources online that can help me in regards to my capstone,need data science project supervisionresources,looking for a mentor for my data science project
86,hey everyone i have a background in linguistics and i am quite new to the field of machine learning there is something that has been bugging me for the past few days that i hope you can help me get a better understading of namely the difference between an algorithm and a model in his blog jason brownlee says that he likes to think of the model as the specific representation learned from data and the algorithm as the process for learning it however i struggle to grasp the difference between the two as well as which one comes first let is consider this snippet of code model decisiontreeclassifier modelfitx_train y_train in the first line i instantiate a specific model in the second one i train it however is the decision tree created by the algorithm or does it already exist as some sort of blueprint for the algorithm to operate on i apologize for the lack of clarity,difference between model and algorithm,question about the decision tree
87,hello my name is simon wright i need your help to create an ai to play eve online there are bots that can play but all they do is mine asteroids which is boring and ruins the game is economy i am years old but i want to learn i have a step plan step have bot watch streams of the game to learn step have bot learn to farm the npc enemies until it gets good step have it participate in real pvp battles this is an experiment mabey when it gets good a bunch of getting together to create an all ai fleet edit is eve online to complacated for reinforcement learning,eve ai,i need help with a project
88,firstly im in the uk unsure if that makes a difference im currently studying a joint economics and finance degree exact same number of econometrics modules as pure econ how viable is a career as a data scientist for me and what would you recommend i do in my free time to flesh myself out im currently in my second year and currently studying dynamic regressions with timeseries data only the second week of the module so a lot more to come first semester covered ols multiple linear regression gaussmarkov assumptions and some tests for heteroskedasticity however its spelled i achieved around in this module for the highest grade in the uk university system and econometricsstats have been by far my strongest modules so far im comfortable with multivariate calculus and have done enough constrained optimisation that every time i close my eyes i see a lagrangian my course doesnt teach r and instead uses stata and eviews which i think theyre going to phase out within a couple years but im currently working through a book to learn it once ive done this im gonna have a go at an extensive project that i can do over time using r would i possibly be looked over what else could i do to strengthen my chances im already planning on taking every econometrics module i can which should be about half in my final year,entering data science with economicseconometricsfinance background,is it worth getting a masters in data science if i already have a job as a data scientist
89,suppose i have an amazon product name dataset comprised of smartphone name and their accessories such as iphone x gb oppo a black airpods pro phone case iphone x clear huawei p pro tempered glass protection cheap softcase for oneplus t blue black two tone oneplus t iphone pro max best case design when a buyer checks out with a phone i would want to recommend its accessories so when the buyer puts in an iphone x gb to their basket i would want the recommendation engine to recommend airpods pro and phone case iphone x clear but not the cheap softcase for oneplus t because it is for another phone and preferrably not the case for iphone too as it would be incompatible is there a way to solve this i have been thinking to use some sort of nlp to process the various product name especially for the accessories as they can be varied but i am puzzled at how to really implement it any suggestions,gadget accessories recommender system need some ideas amp questions to answer,looking for recommendations for an airbnb case for iphone x gb
90,im currently doing my phd in biomedical sciences and trying to learn data science in my free time because i realized i love data analysis and hate wet lab work i already know python and pandas from my phd work but have been learning how to apply it to data science with the udemy data science boot camp however i realized i dont understand a lot of the math behind the machine learning concepts i am also reading isl very slowly and viewing andrew ngs lectures but ultimately my question is is it ok to just understand the general idea of how the algorithms work or should i deeply understand the equations and math behind it another way to phrase it how much does complex math come up in day to day life of a data scientist should i wait until i finish andrew ngs course before attempting more complex kaggle competitions also any advice for hands on experience that isnt kaggle i guess make up my own projects i want to have enough experience to be competitive for insight fellowship or data incubator,is detailed knowledge of math behind machine learning essential,how do i know if i am ready for data science
91,hi everyone my friend who works at domino data lab is recently working on a product survey and she needs some advice from data scientists or ml engineers the survey takes about hour and the reward is a amazon gift card domino data lab is an enterprise mlops platform used by of the fortune and chosen by customers for its high flexibility support of opensource and commercial technologies collaboration reproducibility cost controls for it management features for large teams speed of model development and ability to build and manage large numbers of models customers include tesla johnson amp johnson and lockheed martin you can explore the platform more here if you are interested please book a session here thank you nathan,product survey gift card,can you guys help me find a mentor
92,hi due to covid i have been looking into switching out of my current major hospitality and tourism management and a program that caught my eye was cis i am going into my junior year of college i have the particular credits to switch in without losing too much ground on graduation although i may need to take on a heavy course load or graduate a semester late but my fear is that i do not have enough experience with computers i would say i am more techsavvy than the average person but i have no coding experience i like to work with data and my best skills are communication explaining concepts and ideas organization and aptitude i pick things up quite quickly i do not typically need something explained to me twice cis offers me the lifestyle i desire i am not incredibly passionate about work no matter what i would be doing what i really want is a stable job and a good worklife balance am i making a mistake by switching into a degree i am not entirely familiar with can i catch up to my classmates by learning on my own what resources can i use to learn the foundations of cis thank you all,looking into switching to cis major but i am afraid i have too little computer knowledge,data science career advice
93,i would like to see the values of each activation inside of an rnn after making a prediction i would like to find which neurons get excited when predicting text i want to write a program that makes a prediction and then grabs random activations and overlays them on a graph with the string printed and show a heatmap of what kind of text gets that neuron excited i hope to find out and visualize some of the rules that it learns but i have spent a while trying to figure out how to extract this information from a tensorflow model at the prediction step and have gotten nowhere i am open to using any framework tensorflow pytorch keras etc thanks in advance,visualizing the activations within an rnn,how to get excited about a neuron in rnn
94,not sure if the correct place to post this but i am new to optimize and having the following issues ampxb scenario i create a redirect test to do the following user goes to url user gets redirected to url however if a user goes to the url they also get redirected to scenario i create personalisation to do the following user arrives to specific product page url matching regex oranges product title is changed using this script gtif elementinnertext appleselementinnertext oranges the end result is that the product titlebag of large applesbecomesbag of largeoranges however when the test is started every product across the whole website gets replaced with the full product title of the editor page or targeted url ie every product becomes bag of large oranges i only want to replace apples with oranges can anyone help ampxb thanks for reading,need some help with google optimize,question about google analytics product matching
95,i attempted to code a neural network from scratch using nothing but numpy to see if i understood the concepts the tutorial i followed was neural networks and deep learning by michael nielsen however i took absolutely no code from the tutorial just understood the calculus derived it on my own and then wrote up my own implementation when i try running it with a certain set of hyperparameters learning rate batch size epochs i start off at about accuracy and it stagnates at about while according to the tutorial you should be able to reach gt this is on the mnist data by the way i have no clue what i am doing wrong can someone help me networkpy sigmoidlayerpy inputlayerpy here is the code i use to run it import network sigmoidlayer inputlayer mnist_loader numpy as np train valid test listmaplist mnist_loaderload_data_wrapper n networknetworkinputlayerinputlayer sigmoidlayersigmoidlayer sigmoidlayersigmoidlayer ngrad_desc train test mnist_loader is not my code it is a program that nielsen uses to load in the data no modifications were made to it in the manner i have used it it loads in three sets of data training data validation data unused and testing data each set consists of many tuples and each tuple has two numpy arrays one for the input data and the other one for the correct output,no idea where custom built neural network is going wrong,how to train a neural network from scratch
96,this place gets flooded with posts about tools and people wanting to know if they should make their first million with r or python so i figured maybe we could break that up and have a discussion on another important skill for ds communication i am not employed as a data scientist proper but as an analyst that interacts with a lot of executives i often rely on my communication skills more than my coding chops despite how much i would love my cfo to ask me questions about eigenvalues i am usually expected to communicate company performance across a variety of mundane metrics like sales or conversion sometimes it is harder to explain these things in a clear and concise way than it is to do the analysis on them so i will ask the crowd how do you go about communicating metrics analysis model output or model diagnostics to nontechnical superiors any tips for us younger analysts helpful resources please suggest more basics of technical writing mit,discussion communicating technical results,how do you deal with bosses that do not understand data science
97,so i am working on getting a revenue forecast prediction off the ground at work but im having trouble with one aspect of it handling two date attributes that both add meaningful information to add some context the ideal outcome is to predict forecast revenue as accurately as possible assume revenue is being committed for a future date think airlines or hotel rooms and that there are constraints to be accounted for with overall occupancy limited supply of spaces to be filled again think airlines or hotels the problem is that i could just use university or multivariate time series andor other supervised methods to accomplish this but they leave out the context of the rate at which revenue is being committed of which there are both recent trends that are relevant as well as seasonal trends when compiling this in the data this leads me to an impasse where im not certain exactly how to proceed there are two date parameters the stay date or flight date ie the day for which you are committing revenue and there are effective dates between now and they stay date which are used to quantify the rate of committed revenue against a given stay date in this situation is it better to try to retain a multivariate time series method to preserve the function of forecasting out to a set horizon by adding attributes that capture rate of committed revenue and days out from stay date or would it be more advantageous to iteratively predict one stay date or stay period at a time considering the full set of effective dates at which the additional pickup in revenue is measured additionally are there methods that can do both if this is an overly simplistic question please just simply point me to any resources that may address this otherwise im open to discussion on this topic,need help using multivariate time series or other supervised methods to predict a continuous future outcome with two date attributes,forecasting multiple variable time series
98,i recently attended a data science competition and as expected i did not perform well but i am eager to improve and perform better at the next one to shed light on where i am now i have been able to gain a little bit of theoretical ml knowledge from my university introductory ml course that covers everything from supervised learning to game theory i am familiar with applying offtheshelf ml algorithms and have gotten my feet wet with data wangling and messy datasets my question is this how do i go beyond from where i am now and improve as an aspiring data scientist most guides faq and articles i have been encountering are ways to dive into data science but they do not expound on how to go beyond it i plan on picking up a probstat minor along with my undergraduate cs degree pick up a copy of isl begin doing kaggle competition,suggested selfstudy plan for data science for those acquainted with the basics,how do i know if i am ready for data science
99,hi everyone i am new to datascience and appreciate your sage advice i need to build an incremental learning model and i know there is a lot that goes into something like that but i would like to highlight the most fundamental abstract requirement i have in my particular case and ask you to focus your attention on that however i build the incremental learning model it must never forget what it has learned that is when it learns something new it cannot forget something it already learned i need to know what algorithm or series of algorithms i can use for that i would like to give a toy example to make sure i am understood imagine i decide to use a neural net as the model that learns incrementally imagine as a toy example that i train it the following inputs output observations we can even visualize this as a d graph y x we train it so it has accuracy great so we deploy it and now it starts seeing more observations and must learn from them incrementally in this example pretend that when it sees a new input it will ask me if the model output was correct if it is correct i want it to remember that specific observation and never change it it is fixed this would mean if it is not correct all the fixed points in the model do not move for instance let is imagine it see a new input and comes up with a correct model output it is memory visualized looks like this notice there is a dot at x y so let is imagine it sees a new input and comes up with a model output and asks me if it was correct and i say nope the output should be now it has to do some training to learn that new answer but as i said i do not want it to mess up anything it is already learned as i understand typical neural net training they become more accurate on average meaning when you train it on a new observation it might mess up the weights and biases of already learned observations but on average fewer and fewer that is not what i want i want to incorporate the new information into the model without messing up verified observations now some of you might say dude that is just a lookup table but no it is not because i still want the new observation to have an effect on the untrained or unverified observations like for example like this notice how x is still y and x is still y and x is still y and x is still y but everything else moved alright so i hope i have communicated the requirement effectively my question is which algorithm do i use to accomplish this model requirement the input data and output data of the model will be more complicated than small integers but i could conform all inputs to be numerical before it gets to the model i kinda wonder if the boundary to the data mapping which is the model cannot be directly derived in an nd space in exactly the same way it is derived on a d grid in the above toy example perhaps using something as flexible and sophisticated as a neural net to derive that boundary is not actually necessary idk i would like your opinion i would really appreciate your feedback expertise and experience on this problem thanks,how to build an incremental learning model,what is the proper way of training a neural network
100,i have a masters in economics and since graduating have worked a handful of entrylevel analyst positions i mostly do simple stuff like creating dashboards reports and some basic forecasting i started a new job about a month ago and have come to appreciate how little my program covered the technical aspects of data analysis at my last couple jobs our data was stored in a database and to access it i would query the database with sql that is it those are the only terms anyone used at the new job i have heard people refer to a database a data warehouse a data lake and a few other terms i cannot even remember off the top of my head there is a few nuances that do not seem to make much difference but that i have never encountered before for example when i pull data i am querying views instead of tables i am pretty sure the views are just collections of calculated columns but i am not positive i have asked a few questions but my employer is data team is pretty small and some of the people i have heard these terms from do not actually work with data so there is times where someone mentions a wouldata lake and i am not sure if it is an actual term i should know or if they are misusing it any help is appreciated ideally i would like to grab a textbook or two that explains databases and various lakes warehouses etc that are built on top of them this new position has made me realize that our databases at my past positions were extremely simple and that this is a huge gap in my skillset,good sources to learn differences between various data storage options,what are some of your favorite data warehouse software
101,i had chosen to do my bachelor thesis in area of machine learning user inputs a taken picture of a shoe and software tells him which model of a shoe it is i currently know nothing about this area but i plan to allocate straight months where i plan to study for hours per day i have several years of experience programming in c c java and i know opencv and python a little i do not like this language at all but is is used so widely in ml my math is weak because i did not use my knowledge of calculus and statistics for years and when i did use it i did not know it very well what courses should i take and what is the actual category of a problem i am solving i guess training neural network to recognize different shoes if i input pictures from different angles of a shoe,tell me how to learn machine learning in months,i have a bachelor is in ml but i do not know what to do with it
102,what would you recommend to someone who is entering university to study and why business analytic data science amp analytic or computer science personally im aware that business analyst is involved in business planningunderstanding business trends while data scientists is more of predicting trendsdoing machine learning computer science on the other hand refers to more of building softwares such as mobile phone applications cyber security and so on which university degree do you think might might be less relevantoversaturated in the future i have a feeling that computer science degree might be the one since there are just too many people studying cs now who knows there might be another dot com burst again in the future im personally leaning towards data science amp analytic business analytic what are your views,which university degree would you recommend,data science in the future
103,hi everyone website project repo we have been working on a compilation of frequently asked questions we try our best to answer beginnerunfriendly questions in a simple and straitforward way so that it will never be asked again we would really like some feedbacks before releasing it officially to the students some backgrounds we are teaching assistant for hungyi lee is machine learning course with ish enrolled not online students as course goes on we found that students are emailing us the same questions over and over again those questions look easy for machine learning veterans but are difficult to grasp for beginners therefore we decided to create this project for people who like to learn from approaching ml from different angles,learn machine learning reading answers like stack overflow,self taught machine learning course
104,i have been working for a while in an environment where most of our work products are stand alone scripts to clean data and fit a model which are then used ad hoc to manually produce results files and go from there now there is some opportunity to actually start packaging things into products that provide clients the ability to use some of our analytics in a standalone product however this is a pretty big blind spot in my skills i came into analytics from a statistics background not a cs background so my python knowledge has been pretty specific to modeling and working with data that we for the most part already have and i have no real foundation in how to actually turn something into a piece of software i understand there are virtually unlimited resources out there and i have made some headway but i feel like i am missing basic principles that make it hard to generalize what i am learning i realize i am asking a very broad question but have any of you been in a similar situation and if so could this community provide any advice on effective ways to go from being a pure analystmodeler to becoming at least somewhat literate in how to create a selfcontained data analysis product appreciate any help,best way to start learning how to actually package analyses into products,how do i go about building a data science product
105,hi peeps firstly thanks in advance to each one of you for taking the time out so i have an offer from mscac ds at uni of toronto while the programs is highly ranked and toronto has great scope for dl and computer vision imo im a little confused about more applied dsda roles in ca i know there will be firms like google walmart and scotia but exactly how much less it will be compared to say us job market would i better off selecting a us program if say tomorrow i want to move to australia ps i also have offer from ms analytics gatech hence the confusion pps international student with work ex in credit risk,ds job market in ca after graduating from uoft mscac,is it worth getting a masters in ds if i already have a job
106,any suggestions of softwareservicestools that could be used for dashboards that is continuous monitoring of data and models i and our nontechnical people would like to easily get quick overviews of the data and the state of the models and this realtime monitor should be available all the time via browser mobile phone and possibly a few monitors showing some of the visualizations in our office mostly just simple summary plots with some interactivity eg filtering i can create such plots with for instance python but there is still the whole process of updating the plots regularly serving them via http providing a ui to browse so i was hoping there would be tools to help in this i have heard about powerbi but i would probably need to create more complicated plots with for instance pythonjavascript by performing some computations and interactivity in some cases i could perhaps perform computations elsewhere and store the results in a database for powerbi to use them but what other tools would you suggest what are their pros and cons open source is a plus,softwareplatforms for monitoring data and models,what is the best free or very cheap data analytics software for your business
107,i am studying for my final exam in business analytics at university of ottawa i am confused about the question below what confuses me the most is the following x x x lt y or x x x lt y x x x lt y or x x x lt y why do we set y y to could i have gotten the marks correctly had i chosen another large number say also what is the purpose to setting a large number to y in integer binary programming what does it actually do i am overall pretty confused with the steps in this question and how we got to the solution and why we set the variables in the way we have set them for example x x x lt y or x x x lt y also these constraints confuse me why do we set the variables to fractions x x less than equal to p x x less than equal to p x x less than equal to p your help is greatly appreciated the research and development department of dwr ltd has developed new game consoles zbox and ybox production of these consoles requires setting up computerized and fully automated production lines that would cost for zbox and for ybox once the initial costs are covered each console generates hefty profits unit for zbox and unit for ybox in its current production facilities in kanata dwr ltd has space for creating three production lines capable of manufacturing the consoles and each line can be used to manufacture both consoles if necessary at the same time however management has decided that in order to mitigate the risks only one production line would be open console zbox can be produced at the rate of unitshr on line unitshr on line and unitshr on line the ybox can be produced at the rate of unitshr unitshr and unitshr respectively line has hours production capacity line has hours capacity and line has hours capacity write in the space below the algebraic formulation for the above mixed binary integer programming problem do not solve solution decision variables let xij the number of game console i produced at on production line j where i zbox ybox and j yi if game console i is produced where i zbox ybox yi if game console i is not produced pj if game console zbox and ybox are produced on production line j pj if game console zbox and ybox are not produced on production line j where j max x x x x x x y y subject to x x less than equal to p x x less than equal to p x x less than equal to p p p p x x x lt y or x x x lt y x x x lt y or x x x lt y xij gt and integer yi and pj or for all i and j,university business analytics help,how do i know if my model is ready for production
108,my job reimburses up to kyr for anything that would advance my knowledge or help my career i have an ms so getting another one part time doesnt sound like it would be worth it so im trying to think of ideas individual courses that interest me in statsmath conferences well virtual this year books i guess a lot of them lol advanced boot camp for engineering or deep learning i am reasonable at both but would like to get to the next level maybe a primarily research based masters specifically in deep learning my goal is to just become a better ds and it seems like adding skills in eng or dl might be the most interesting to me interested in what ppl here would do or have done,if your job reimbursed education expenses what would you do,is it worth getting a masters in ds if i already have a job
109,i kind of hate powerpoint but it is also a necessary evil either the client is used to it or worse the project manager is used to it but either way we need to present our progress to the client every once in a while and powerpoint is the standard tool for that one more grief that i have with powerpoint is that i cannot use these nice interactive plots i make with plotly switching in and out of powerpoint is a big no especially since my work is remote so my question is simple is there a presentation tool ie a powerpoint replacement that supports plotly is interactive plots i have discovered a few very nice tools eg whimsical docs but they do not do what i am looking for,is there a presentationlike tool that allows the use of plotly is interactive plots,how do you organize your data
110,i have a very large dataset containing information regarding whether or not a customer who visited an online store purchased a product or did not purchase a product the dataset contains a bunch of demographic information such as what state the person they are in the person is age etc so far i have built a logistic regression model that can predict whether or not someone will purchase a product based on their demographic inputs however now i am looking to do just some basic eda kinda working backwards i know what i have right now is just simple calculations such as what the average purchase percentage is by state etc or what the average age of someone who purchases is compared to someone who does not purchase i am going to run tests on these calculations to see if they are statistically significant do you have any suggestions for things to look into further for this eda,suggestions on insights to look into regarding sales data,looking for a way to calculate age based on a few basic questions
111,suppose i have a dataset of k data points with columns then i split this data into parts train and test in ratio now what i am doing is running a kfold cross validation on train data with cv and linear regression model now i have few questions after this process ampxb if cross_val_scores are varying very greatly does that mean my model is bad and if not then my model is finenot best should i keep tweaking the parameters and adding or removing features till i get good cross_val_scores with less variance when predicting the values of test data should i again train the model on complete training dataset if we use grid search with cv than does gives us best model based on average of kfold error after finding best parameters from grid search should we again train on full training dataset these questions may sound very basic but i am getting really confused here and also not getting a satisfactory answer even after searching for many hours,linear regression kfold and gridsearch,how to deal with missing values
112,hi there im in need of a bit of advice any help would be appreciated im doing a project where we are trying to understand the drivers of a particular time series signalyt i have data on several other predictor variables at corresponding times xt our goal is to build an inference model that relates x with y and not necessarily have high predictive ability the issue is that yt and xt have high degrees of auto correlation i know that if i were to regress xt with yt using data at every time step this would violates the assumption of typical linear regression the auto correlation is so long that it would substantially reduce my data by taking the every nth data point where n is the length of time needed for the autocorrelation to reaches low levels additionally my boss is not keen on adding lagged y variables to the regression as he wants the model to learn the physics between x and y can anyone advise what are my options here,question how to deal with regression with high auto correlation,autoregressive linear regression
113,i am trying to extrapolate some statistics from a large sample set of data but want to make sure my assumptions are correct i have the entire database of medicare part b claims for this is publicly published by cms each year the data contains all the charges for example chest xray for all the medicare part b recipients in the us by provider so say xyz hospital billed medicare times in for chest xrays if i also know that medicare part b recipients make up of the us population can i infer that the total number of chest xrays performed in the us was or i do not need to consider that the age of the group of recipients is on average gt therefore the instance of chest xrays by this group may be larger etc my main question is that if i know the us population is times larger than medicare recipients can i multiply any total i get from the data by and get an estimate of the total of the entire us population am i missing anything,data analysis sanity check,looking for hospital admission data xrays xpost rstatistics
114,the learning curve is insane even compared to other fields in and out of cs the culmination of math and stats makes the curve even higher could you critique my plans for learning to get to the data scientistmachine learning engineer level covered data analytics python numpy pandas data vis r supervised learning unsupervised learning recommender systems scikit learn random forests basic nlp basic nnno implementation some big data sql next to learn reinforcement learning q learning through games more in depth ml algorithms more stats implementing these algorithms more big data some databases like firebase elasticsearch mongodb etc i think my plan is pretty solid so far the main thing is wanting to understand how the implementation of the basic ml algorithms actually work instead of just knowing how to interpret results and using scikit learn and tensorflow from the topics that i have covered so far what do you suggest i learn next from my list or if there is something that i have not listed yet and if you could suggest an online resource or a book for what i should learn next that would be great,man data science and ml sure is broad,what is the next step in my data science journey
115,junior in econ major here i have been wanting to minor in applied statistics and it says aminor in applied statistics on my resume dont think that matters resumes update constantly what is more relevant to help me land an internship andor ultimately get into data science i am learning python and r on my own and plan to spend my entire winter break on really learning python specifically i have always liked statistics but coding is literally the foundation of data science i feel like a cs minor would be better but what if i miss out on some important topics in stats bayesian inference using r distribution functions etc i feel like i can teach myself coding fairly decently and learn more on the job i have only taken statistics courses so far actuarial statistics and economic statistics i guess ap stats from high school if that means anything and just one cs class that only focused on htmljscss and excel,cs or applied stats minor,what are some of your favorite data science projects on your resume
116,hi all many here can build a simple machine learning model to predict whether a customer will churn if they get a nice pandasdataframe with customer data however it gets really complicated if you want this model deployed and integrated in production say a procedure as such pull data from a new customer from shopify predict for this customer whether they will churn if we predict churn true send a discount code to this customer with mailchimp suddenly we have to code data integrations etl pipelines deploy our original machine learning solution spin up an http server etc a huge pain indeed we are building a framework that takes care of exactly all the boring stuff described above we really believe this will bridge the gap between research and realworld ml super excited to share this with all of you please let me know if you have comments or feedback,p integrate your ml model with your favorite apps from a single python file,how do you deal with customer churn
117,hello community i am new to dl so plz excuse me if the questions are very nub i went through several articles and tutorials and before deciding i understood deep learning i wanted to make my own project and this is what i came up with i tried implementing it in fastai using resnet after getting crowdsourcing the data mostly me i got a model predicting one category for everything this is the kaggle link not sure if this is a problem but earlier i had around images per group so i made a video of myself doing the various signs and used opencv to save frame by frame i later removed the ones that did not confine to any group and this increased the size of the dataset from mb to gb was this proper or is it the reason the model is bad this is the link to the dataset i am not sure how to proceed further and would appreciate any help thank you very much,p making a model for nauto hand sign detection,how to store a large dataset for deep learning
118,hey all i will be implementing tag manager for one of our clients but i am unsure about the logistics and best strategy for tackling this for the particular website they are a home builder and therefore have a corporate website with several subdivisions that change the path of the url right now i have a corporate account in ga with filters and views for each of the subdivisions where the filter is set to capture the request uri subdivision name so my question is should i set up a gtm container for each different subdivision path and focus then on perfecting each of those separate pages or should i set up one container to place on the website as a whole are there better options for getting this done in a way that will make future me is work easier and give me more accurate data thanks,gtm implementation,how to set up multiple uri views on a single page
119,so i am working on a modelling problem and trying different techniques to build a model my target variable is not following a normal distribution it is more of a uniform distribution with higher frequency bars gradually increasing towards right irrespective of the modelling techniquei have tried various linear models and their families tree based regressors and ensemble models like xgboost or iterations of the same with transformed variables i notice that the distribution of my predicted variable is always normally distributed why is this happening the distribution of the actual and the predicted variables should be similar in order to effectively call that the model gives out decent results please let me know if anyone has answers as to why would this happen and what are the work arounds google was of not much help,google did not help solve my doubts regarding a modelling problem can you,how to deal with missing values in logistic regression
120,pitched to a vc recently he is definitely interested using ibm watson for image recognition we showed him a demo at probability of a match meaning when you upload a pic watson only returns results that are at least likely to be a match the vc said his partners would like the match to be so in this case that means recognizing the text over other features short sleeve fabric type sleeve length color cut etc no watson can recognize the text but on multiple items posters stickers pictures shirt jacket pants etc that cannot be what the vc and his partners want so what image recognition models or algorithms combine matching features sleeve length fabric color cut collar etc and textimage on the shirt thanks in advance,algorithms for combining models in image recognition object detection computer vision machine vision,is there a name for this type of model i want to use
121,hello everyone i am looking for someone study with on everything ml i am a beginner and i am looking to get started with someone maybe we can go through some books or work on simple kaggle competitions i have formal education in data science and most maths besides high level calculus and linear algebra maybe that could be a start i am mostly looking for someone to study with because i feel alone in my endeavor i have high levels of productivity when working as a team i just want to surround myself with more people of my same interest i feel i have no one to converse on these topics with feel free to pm me or comment below i am free to even making a group if many of you have a similar interest thanks everyone,looking for a ml study partner to help with my motivation,looking for someone to work with
122,i had been taking andrew ng is coursera course that is often recommended for beginners to learn machine learning from i found his explanations for linearlogistic regression and gradient descent very good but i felt he got a little hand wavy when it came to neural networks and how they worked so before moving forward with the course i wanted to make sure i understood at least the basics of what was going on with backpropagation etc i found the book neural networks a visual introduction for beginners by michael taylor to be exactly what i was looking for it dedicates an entire section to each part of what a neural network does including the math behind them then at the end it goes through a basic implementation of one in python it is a pretty easy read and i finally feel like i could explain to someone else what a neural network is and how it works my only complaints are that he does not show the derivations for the partial derivatives of the backpropagation algorithm and tbh it was pretty hard to find anywhere that actually shows the entire steps specifically for the sigmoid activation function which does this weird algebra trick of adding to the numerator of the derivative to make it pretty but it shows that here there is also a few typos throughout the book and at least one i saw in the math but if you follow along closely you should be able to see them anyways i thought this community might be interested in this book it definitely helped me a lot i would recommend going through andrew ng is sections on linearlogistic regression before reading it even though this book goes over gradient descent i think andrew ng does a better job at explaining them i also recommend some exposure to derivatives and matrix multiplication amazon link,book i found very helpful in understanding the basics of neural networks,is there a better way to learn about andrew ng is ml course
123,hello everyone this is my first post on this subreddit to give a little background on myself i am currently a college student completing my bachelor in data analytics finishing up in about a year our program covers statistics like regression and application with minitab dashboard creation powerbi amp tableau basics of sql with work on ssms and working with python cleansing and gathering data we also focus heavily on presentation and being able to deliver clean and precise content i have applied to internships throughout the course of last year and some recently but have not found much success at all and i have been only applying to the ones that emphasize the skills i currently have is there something in particular i am missing like a portfolio or extra projects what should i focus on doing at this point to land an internship this has been really heavy on my mind and graduation is just over the horizon just tell me i have too much anxiety and i should keep trying haha,hiring managers for data analyst interns are you looking for anything specific,how to prepare for data analytics interviews
124,hello i recently had an interview for a data analyst position i was asked algorithm questions swe ones and i completely bombed it rest of the interview was statistics questions which went good my experience got me thinking that a person with cs background would have easily gotten this job after taking few statistics courses in their masters whereas me i majored in statistics in my masters and probably will get rejected because i did not know cs concepts i think this will apply for data scientist roles as well i understand a person with cs background might wanna go with higher paying swe jobs but if someone was really interested in becoming an analyst or data scientist they would have power over majority of the candidate pool i might be completely wrong and missing a lot of points so please correct me if that is the case would love to hear what you guys think about it thanks,will computer science major people start becoming more desirable as the interview process moves more towards leetcode style,data scientist job interview questions
125,suppose i have a dataset where there are multiple features but some of them have a different type for example let is say the features are x y amp d where x y are coordinates doubles and d is depth centimetres as you can see since d is of a different type compared to x amp y i want to change it so it can be of the same type as x amp y but that is not possible i think so i was thinking to change all the features to a different type so the type is the same for all the features would it be better to rescale the features so the values lie between and or would it be better to standardise the features,classification rescaling or standardisation,how to deal with missing features
126,let is say the keyword superman has a search volume of k per month other related search terms can be superman logo k batman vs superman k superman returns k etc using which users search for a certain topic in google in a country say us however there may be thousands of keywords with the word superman in it and we do not always have exact data for many of these keywords with low volume less than in order to find the volume of these topics we use predictions based on the data that we already have for high volume keywords for example we may say that the term future superman will not be searched by a lot of people and its volume can be medium close to similarly terms superman image and superman jacket will have medium volume and terms that people rarely search will have low volume like long sleeve superman shirt and then there are terms like cheap superman shirt or superman college which will have very low volume can you think of an approach on how you can classify keywords into medium low and very low by using some logic when we only know the high volume keywords your answer should be descriptive and backed by reason hint your approach may be to classify certain words which if present will make the keyword low volume or very low volume or your approach can be based on number of words in a keyword spellings where exactly a term appears in a phrase and other common human psychology that works during a search,can someone help me with this problem statement,is there a name for this kind of algorithm
127,as part of my data science program i need to choose between these two classes descriptions below based on the course content which one might be the more useful course in the long run for data science practice if i can only take one let is define useful as being most widely applicable across the many trajectories of ds practice though if anyone wants to share that one course is particularly useful for any niche applications i am all ears intro to optimization this course introduces applications and algorithms for linear network integer and nonlinear optimization topics include the primal and dual simplex methods network flow algorithms branch and bound interior point methods newton and quasinewton methods and heuristic methods students will gain experience in formulating models and implementing algorithms using matlab computational statistics computational statistics is a branch of mathematical sciences concerned with efficient methods for obtaining numerical solutions to statistically formulated problems this course will introduce students to a variety of computationally intensive statistical techniques and the role of computation as a tool of discovery topics include numerical optimization in statistical inference expectationmaximization em algorithm fisher scoring etc random number generation monte carlo methods randomization methods jackknife methods bootstrap methods tools for identification of structure in data estimation of functions orthogonal polynomials splines etc and graphical methods additional topics may vary coursework will include computer assignments in r,choosing between intro to optimization and computation statistics course,what are some of the best resources to learn about data science from scratch
128,hello all im currently a sophomore in college ive been working with data science tools for over a year now mainly python and r and their related mldata cleaning packages tidyversepandassklearntfnumpy etc in various projects of mine and undergrad research long story short ive been applying for internships for the past months and havent even gotten an email back from half of them let alone an interview i have a feeling that this may because im too young and im just competing with juniors or seniors for these roles so i just get auto rejected anyways considering the fact that most companies may not be looking for interns anymore i have accepted the fact that maybe i just need to expand my skill set a bit more so ive decided to tackle another side of data science this summer in self learning data engineering specifically i was thinking about doing a udacity nanodegree program or doing certifications to help boost my resume i was looking at the data engineering nanodegree to be exact i thought that this combined with any projects i do in the summer may make me a better candidate come fall when im a junior now my question to any of you hiring managersrecruiters or anyone out there is purchasing a certification course or doing these long mooc courses a good idea is it worth the money obviously it wont guarantee me an internship but would it stand out to you in anyway if a student had this would i be better off saving my money and just looking through online resources instead of paying for a nanodegree program or a certification program i would like to hear your thoughts on this in general to see what you guys think,udacity nanodegrees or certifications even worth it,data science bootcamps
129,so guys i have been wondering whether every joe dick and vag will be a data scientist in the future i feel like all the schools are opening these certificates and programs companies are hiring like crazy without knowing how to use it and people are running to these programs and certificates because in most cases they need a job rather than actually liking data science i wonder then with all of this inflow of data scientists will the supply exceed the demand one day i feel like one day the companies will wake up and be like oh data science does not work lets use insert another hyped up fancy word to make profit and everyone who gained these data science skills would become lower in value i do know that data is definitely going to be used more and more in the future unless there is a revolution against privacy or something but that is not happening because all the big guys loose out and we cannot let that happen right but then would everyone be a data scientist at the end of the day,future of data science,are data science certificates worth it if i already have a job
130,lets consider this image with some notation on a layer neural network with inputs hidden neurons and out put ampxb is this math basically telling me that to back propagate my error through the network i need to find j z j  z  then multiply my error through w take the weights multiplied by the error and transpose it so that when the weights are cross multiplied by the vector gradient of the derivative of the activation function  becomes a scalar value finally update the weightsw with xt the last part i am confused about because it seems like xt becomes a x matrix and w is a x matrix how does that work out i have read multiple resources on bp including multiple times i just need some conversation about it please,i would like help understanding the maths behind back propagation,how do i deal with missing values in a neural network
131,help with exploratory data analysis i need help with a project i am currently pursuing there are data sets with information about customers some attributes include job desc age past purchase patterns if they own a car or not etc who are prospective customers for a bicycle shop how do i go about analyzing the data so i can discover useful customer insights and recommend which of the customers should be targeted to drive the most value for the shop i am lost as to how to start and what tools to use this is my first ds project and i am still getting to grips with using pandas matplotlib and seaborn i would appreciate if anyone could point me in the right direction and give me some tips as to how i should proceed thanks,help with exploratory data analysis,data analysis for customer journey
132,hey i am trying to develop a system that will detect unusual network traffic on a home wifi router to stop various types of attacks namely distributed denial of service attacks i want this router to learn what normal and abnormal traffic looks like and possibly take action if there is unusual traffic any general ideas on how to go about this my data i have built a packet sniffer that logs all icptcp and udp packets that are streaming through the router i have all of the data that lives in a ip packet is mac addr ports acks ttl flagsetc header as well as the actual data payload ideas i will certainly need to use some sort of unsupervised technique bc there are no labels attached to the traffic i was thinking about using some sort of clustering algorithm or possibly even some type of reinforcement learning due to the streamed nature of my data any advice is welcome thanks,network anomalie detection on wifi router,looking for advice on how to deal with unusual traffic
133,hi i have to build a system to count people entering and leaving a building a variable which increment or decrement ampxb my approach is the following capturing a video feed form a raspberry pi mjpeg sending it over the lan and grabbing it on opencv using videocapture class on a workstation lt this is working fine applying object detection to detect peoples on the video feed using yolov lt this is working fine using data form the object detection to track peoples and count them basically drawing a line in the middle of the screen and see if people cross it and in which direction lt this is where my problem is ampxb i do not know if this method is the best way to do it what kind of object tracking algorithms can be applied on yolo object detection data how can i do it i know that opencv already have some object tracking algorithms implemented like medianflow goturn mosse csrt could i use those ampxb i struggle to find any good sources of information about entity counting using deep learning and about object tracking on object detection ampxb thanks in advance for your precious help,count people in video stream using object detection yoloopencv,best way to track object detection in google colab
134,here is the jupyter notebook so the code that has me completely tripped up is the plot_decisions_region function def plot_decision_regionsx y classifier resolution markers isxov colors aredbluelightgreengraycyan cmap listedcolormapcolorslennpuniquey xx_min xx_max xmin xmax xx_min xx_max xmin xmax xxxx npmeshgridnparangexx_minxx_max resolution nparangexx_minxx_max resolution z classifierpredictnparrayxxravel xxravelt z zreshapexxshape pltcontourfxx xx z alpha cmapcmap pltxlimxxmin xxmax pltylimxxmin xxmax for idx cl in enumeratenpuniquey pltscatterxxycl yxycl alpha ccmapidx markermarkersidxlabelcl here is the pertinent text to it gtfirst we define a number of colors and markers and create a color map from the list of colors via listedcolormap then we determine the minimum and maximum values for the two features and use those feature vectors to create a pair of grid arrays xx and xx via the numpy meshgrid function since we trained our perceptron classifier on two feature dimensions we need to flatten the grid arrays and create a matrix that has the same number of columns as the iris training subset so that we can use the predict method to predict the class labels z of the corresponding grid points after reshaping the predicted class labels z into a grid with the same dimensions as xx and xx we can now draw a contour plot via matplotlib is contourf function that maps the different decision regions to different colors for each predicted class in the grid array i have no idea what to make of it i feel awful asking but would really appreciate it if someone could guide me through it or point me to some resources which i can use to learn it myself i cannot figure out what the meshgrid is purpose here is how exactly a listedcolormap works just completely at sea,trying to read sebastian raschka is python machine learning completely lost on the very first code is visual representation with matplotlib,how to train a cnn to recognize different orientations
135,hey fellow data scientists i am sure you know this it could be your client your boss your colleague they ask for more can we try adding another year is data could you check if weather makes a difference there is nothing wrong in asking but they do not know that adding more data is not like a click away sometimes it takes half an hour sometimes it could take days so what would you do as i jot down the problem i thought of a fews things we can do so my cents here make your model more flexible anticipate the additional ask be smart about how you share the results if you know they will ask for more however comprehensive your model is release in phases clarify the objective what do you want to prove what is the hypothesis how does adding additional data help communicate the investment here adding data can be time consuming are you sure it is worth the effort bring this issue up over coffeelunch now your turn,what do you when people keeps asking to add more data to your model,how do you deal with bosses that do not understand data science
136,hi my organization currently uses sharepoint for our website we use google analytics to track visitor activity but it is forced to be split up into an assets page and a main website page tracking numbers is tricky since we would need to combine but find potential overlap our it guy did some playing around with it but i feel like ga is a little cumbersome for us all the sp tools i found harepoint webtrends tracks users not visitors so that is how employees engage with the website i am not looking for that i want to find out google analyticstype info but in a way that plays with sharepoint nicely and is not too expensive nonprofit if that makes sense we figured out how to track document downloads but i do not think they are accurate at all i hate sharepoint but we just started using it two years ago and we paid a lot of money for it i think it was a dumb choice but i guess it works can yall help me find an appropriate tool i do not know about tech i do communications and social media marketing the data guy at work seems to think i have a statistics and analytic background but i was a lit major it is also frustrating because he gets mad at the communications team if there are seasonal fluctuations in the numbers the business we are in is very cyclical but that is just me ranting lol pardon my writing i am on mobile and i have not had my coffee yet,looking for analytics tools for share point,how do i track users on google analytics
137,i am a colombian yo industrial engineer who have always worked on production plants and quality related jobs currently i am trying to get a certificate on data analitycs and machine learning and i really love this field it is just the kind of thing that want to do for a living since i am starting to get really passionate about it as you may guess machine learning kind of deviates from my current professional experience and considering my age and education getting a job on that field will be quite difficult this is not a self promoting post i just want some advice ie what kind of roles should i apply for how where contactsnetwork thank you in advance,advice for someone who wants to start working on machine learning related jobs,is it worth getting a masters in data science if i already have a job as a machine learning engineer
138,hey everyone it is been months since i started out as a business analyst it is a month internship and i am pretty much guaranteed a full time position after that basically i am a bridge between the management and technological sides and do a lot of software requirements gathering and creating system design uiux and database design i have also written some python scripts to automate a range of reports as and when we start to gather more data i can start getting my hands dirty and do some real work with data there are plans to implement some ml models some for internal use and some for production i am learning ml at the moment and once i am confident with the coding part i can get started at the same time i have an offer for msc data science at university college cork ireland and it starts at september my question is should i work for a while and then go for a master is or should i do the master is now,entry level business analyst confused about what decision to make,i am starting my first data science job and i have a few questions
139,hi i am looking for somebody who would be interested in doing some datascience projects with me my name is corentin and i am doing a master is degree in macroeconomics and finance in belgium so those are two subjects i am interested in i am open to learning about other stuff too i am not a pro at all never done a comprehensive datascience project by myself if anyone wants to come struggle me with you are welcome xd i thought as a first project gdp forecasts could be funny and interesting no need to tell me the jokes about that i know them all xd although as i said i am open to anything interesting feel free to dm me,datascience projects collab,looking for a mentor
140,hello all i asked this question in rgoogletagmanager but i figured the more people i can get to see my question the better ampxb the situation i am trying to try and find a job as a data analyst currently i applied for a position that i was wholly qualified for in every aspect except that i do not know google tag manager so now i am trying to practice with it i have ebay listings i would like to practice with apparently someone was able to track data on their ebay listings page via their google analytics account but this method completely bypasses google tag manager ampxb tldr for the link ebay allows you to code your descriptions for your listings in html if you choose however in order for google tag manager to work you need to paste two snippets of code in your html code one after the ltheadgt tag and one after the ltbodygt tag the problem is neither of these tags shows up in the skeleton of html code that is your listing description ampxb does anyone have any advice thoughts or maybe another website i can practice using google tag manager with i was thinking of soundcloud if ebay cannot work,can i track data from ebay listings with google tag manager google analytics,how do i track a specific person on a website with google tag manager
141,i am currently working on a project where i want to benchmark yolo and ssd against an original model using evolutionary optimised cnn which should be able to recognise objects and their position i have read some articles suggesting building a cnn with neuroevolution but i have not seen one using bounding boxes and this is crucial for the context of the problem moreover the objects i am concerned with are not part of coco or voc datasets so do you think neuroevolution is only going to overcomplicate the bounding boxes or it will be useful because of the multiobjective optimisation that needs to be done the most important question i have is if anyone is aware of an implementation where neuroevolution is used with rcnns thank you very much in advance,neuroevolution on boxlabelled dataset,question about neuroevolution
142,got an offer at a startup for a lead data scientist role and was a bit underwhelmed based on current compensation and experience im interested in the thoughtexperiences of others on this sub prior to drawing a line in the sand details below me currently lead data scientist at a large nonfaang fin tech company years of ds experience using python and r lots of experience deploying live critical production models the offer k base k discretionary bonus k equity at current share price which fully vest over years shares vest monthly for years beginning year after i sign on so year compensation is k years compensation goes to the equivalent of k at that point ill have years exp my expectation was closer to min k base plus k bonus plus the provided equity thoughts thanks in advance,lead data scientist compensation question,is it worth taking a paycut to stay at current job
143,hi everyone i was wondering if i could get some advice on what to do after undergrad while trying to pursue a career in data science i am currently a rising fourth year in university and am a computational math majorstats minor after changing my major a couple times i recently became interested in data science and wanted to go down that career path i wanted to work for a couple years after graduation but after reading a bunch of reddit posts i am thinking that maybe now i should go to grad school what do ya will recommend i currently have an internship as a data science intern at a fairly new company and am hoping that they will offer me a full time for after i graduate but i am not sure if they will or if i even wanna work for them my coding skills right now are alright i am proficient in python and have been using that for most of my projects but i barely know any r sql and my coding skills overall are just alright so i am not sure if i can handle the rigor of such a technical role like data engineeringdata science post grad without strengthening some of those skills first and if i wanted to apply for another job post grad i am not sure what job i should apply for that would lead me down that career path of data science given that my major is not cs would it be data engineering data analytics marketing analytics or financial analytics how much do those starting data sciencedata analytics jobs even make in the first place without having a phdms sorry for the long post i would really appreciate some advice i do not really wanna go to grad school right away i would get a stats ms but after researching i feel like its the best idea thank you,aspiring data scientist postundergrad career advice needed,data science career advice
144,hi i am playing with neural networks trying to solve a simple problem detect black rectangles in a white background this is my model so far class rectangledetectornnmodule def __init__self supersquaredetector self__init__ layers selfconv nnconvdin_channels out_channels kernel_size selfl nnlinearin_features out_features def forwardself x x selfconvx x xflatten x selflx x frelux return x ampxb this is a simple model for a simple task i tried other more complex but it seems that the result is poorest this are some results the model knows something about the task but the result is not good ampxb ampxb ampxb the gray border is the model result ampxb a training with samples give the best result like this so i think the model is not well configured and is not an poor training problem thanks for your help,how to dettect rectangles in a simple image pytorch,how to train a cnn to detect channel shapes
145,i am new in data science so please excuse my limited knowledge i am learning more about classification algorithms and how to appropriately selected algorithms for your task according to this website classification algorithms the author says when the classes are not linearly separable a kernel trick can be used to map a nonlinearly separable space into a higher dimension linearly separable space so do you just check if your class is linearly separable or the entire dataset in any case i could not find a proper source that would explain clearly how do you go about checking linearity of the data with actual implementation can you help how to achieve this further a lot of blogs and tutorials mention that when you are selecting a classification algorithm you have to consider dataset size distribution computation time data type of attributes etc but i came across a notebook which was authored by a university professor wherein he used almost all algorithms like svm adaboost decisiontree random forest bagging boosting etc for the same project does it make sense to use all of them straightaway is there like a resource that can help in making a decision i did come across a few cheat sheets that have a flow chart but they do not seem to be indepth,deciding a classification algorithm,how do i know if my model is performing well
146,good afternoon reddit ampxb im leaving my corporate gig in a few weeks to take time off but i wanted to spend some of that time honing and practicing skills i picked up on the job specifically we have been working extensively with alteryx and tableau and i have past years of experience with sql access excel and vba ampxb if i wanted to continue with these skills or try to translate them into some side gigs on a low budget what are some of the best options out there so far ive found knime as a replacement for alteryx and have taken a look at jupyter as a means to play with both r and python although i personally found the single user license for tableau affordable ive heard that bokeh may be another option in the free zone for visualizations ampxb im really looking for those cheapfree options that will allow me to learn and practice as well as produce actual deliverables for freelance clients if i go that route,data science on a budget,is it worth spending time learning r or python
147,hi everyone i am new to machine learning and rather lost with how to actually code this problem that i have mostly because i am not that good with pandas ampxb anyway i have a data set of about lab test names i have manually labeled about or so of these test names with the correct class we want to assign it to the question is how to code a machine learner in python that will label the other for me ampxb here is what i am thinking ampxb the data set has columns full name short name and class it is in an excel file which i can read into python via pandas ampxb split the dataset into training and prediction sets train on the first and then make predictions on the next ones write each prediction to that row is cell ampxb or am i just going to have to suck it up and do this manually ampxb help appreciated ampxb ice,is this feasible to apply ml to,how do i go about training a model on a dataset with multiple variables
148,warning venting ahead i am new at a datasci job that i generally like and have spent a couple of weeks on a very heavy data wrangling problem in python where i basically am taking some very ugly data distributed across multiple sources and doing lots of magic with it that builds a pipeline that ultimately yields a single postgres database running from a docker container all of which will scale will be really easy to use all done using jupyter so everyone can use it including a db schema visualization within jupyter now when anyone in the future wants to rebuild the database they basically just have to hit a button also there are lots of utilities to ensure db integrity basically lots of tests built in in my presentation my crowning achievement in my mind was that you could literally hit one key and the db immediately is reconstructed from scratch while i am talking so as the thing is running and the db is being populated during this live demo and i am beaming with pride the main boss person is like great what are the results i fucking died inside that was the result for this work periodugggggg i guess i am using to working in a team where everyone gets excited by nerdy data stuff i had to figure out how to say ummm we have a database now you damned in a nice way anyway i am feeling pretty pissed and dejected now likesheesh trying to rediscover my motivation at this point,thought i nailed presentation on pipeline i built business ppl were like where are the results ugh,how do you handle your data wrangling scripts
149,anyone using multiple gpu with keras amp tensorflow does performance scale per gpu or is there a loss as far as i understand it you have to assign each gpu to each piece so i assume there is some loss if you do not split it perfectly but also wondering if it will use them both for what they are assigned i suspect a single gpu will always be preferred if it is big enough how much more work do you have to do to code a model to utilize multiple gpus do they need to be the same gpu how parallel can you do it like can you have one epoch on one and other on another and have it combine the results i suspect not as probably have to happen one after another what can be done in parallel,multiple gpu performance w keras andor tensorflow,question about using multiple gpus with keras
150,objectiveproblem in python i am looking for a fast way to readwrite data from a memory mapped file to a gpu in a previous so overflow post where it is mentioned this is possible using cuda pinned zerocopy memory furthermore it seems that this method was developed by this person though that person was working in c my previous attempts have been with cupy but i am open to any cuda methods what i have tried so far i mentioned how i tried to use cupy which allows you to open numpy files in memmory mapped mode import os import numpy as np import cupy create npy files for i in range numpymemmap npmemmap aregmemmapstri dtypefloat modew shape npsave aregmemmapstri numpymemmap del numpymemmap osremove aregmemmapstri check if they load correctly with npload npymemmap for i in range npymemmapappend npload aregmemmapstrinpy mmap_mode r del npymemmap eventually results in memory error cpymemmap for i in range printi cpymemmapappend cupyload aregmemmapstrinpy mmap_mode r result of what i have tried my attempt resulting in outofmemoryerror it was mentioned that gtit appears that cupyload will require that the entire file fit first in host memory then in device memory and it was also mentioned that gtcupy cannot handle mmap memory so cupy uses gpu memory directly in default you can change default memory allocator if you want to use unified memory i tried using cupycudaset_allocatorcupycudamemorypoolcupycudamemorymalloc_managedmalloc but this did not seem to make a difference at the time of the error my cpu ram was at gigs but my gpu ram was at gigs i am using google colab where my cpu ram is gigs and gpu ram is gigs so it looks like that after the entire file was hosted in host memory it checked that if it could fit in device memory and when it saw that it only has out of the required gigs it threw an error my best guess so now i am trying to figure out a way to use pinned zerocopy memory to handle a memory mapped file which would feed data to the gpu if important the type of data i am trying to transfer are floating point arrays normally for readonly data binary files are loaded into gpu memory but i am working with data i am try to both read and write at every step,how to use cuda pinned zerocopy memory for a memory mapped file,how do i use a local sql file in google colab
151,good day to you all i am an aspiring data analyst who is currently seeking inputs on how to better equip myself with the relevant skills to be one my job skills are mainly focused on data extraction from in house systems and exporting through excel and generating reports via powerpoint recently i started focusing on learning new skills to better improve myself as a data analyst i wish to analyze data and generate insights to what the data means to provide my company with meaningful business decisions as a newbie in this here is the list of coursesresources i have done learning basics of python python crash course from eric matthes ongoing basic statistics university of amsterdam from coursera ongoing introduction to sap analytics cloud ongoing i am taking this as my company uses this and does not use tableau ___ i feel that i am making a lot of progress with learning python as the question examples at the end of every chapter would test my knowledge moreover i find that practicing what i have learnt allows me to retain information easier below are some courses which i am interested in taking once i have completed the above data analysis with python introduction to sql the complete sql bootcamp regression analysis pandas as you can see all the current courses i am taking now are essentially just a beginner is course of what a data analyst does and does not provide indepth teachings could you please recommend what i should focus on and advise if i am on the right track thank you and stay safe everyone,road to become a data analyst,what is the best free or very cheap data analytics course that is right for you
152,i am trying to understand the very basics of neural network i made this simplest neural network in which it trains only with a xor input and output i used this tutorial but didnt used any arrays because i want to understand neural networks from its foundation i successfully wrote the feed forwarding steps of this neural network but its in the backprop that i got stuck truthfully i dont know how the heck it works how should i backprop my neural networks and update the weights after searching i found this website in this i am scratching how to implement this equation in my code lr is the learning rate which i kept delta k is my dz xk i am not sure should i take one input i i or both deltawkjk how to calculate,how the heck does the backpropagation works in neural network,neural network with deltaprop
153,i have a phd in earth science completed in jan and a undergrad in physics but i principally used computer models and machine learning in my dissertation while i am pretty familiar with c matlab python bash scripting etc i do not have a long history of formal data science training i have done some numerical methods courses and plenty of math but not much in the way of computer science most everything i know i picked over the course of grad research for my ml research i have used kernal ridge regressions mainly but done a few other side projects using some other simple model building so i know about tuning hyperparameters and cleaning up data i am asking because i currently have a pretty good paying job but the industry is always tossing and turning and i am trying to prepare for a exit if things get hairy my company sponsors a corporate account at code academy so i try to pickupkeep up my skills do i have enough experience that i could work in dsml fields,am i employable in ds or ml with my background,how do i know if i am ready for data science
154,i am new to such panel data where i have multiple observation for same id in different quarter and i am not sure what kind of machine learning algorithm i can apply i have data from q till q i have rows and unique id and columns for each id i have only past quarter values max quarter for each id are quarters and for some id i have only quarters where few quarter value are not available for that id below is the basic idea of what my data set look like quarter respective business quarter for that year target is the sales volume in ratio i am trying to predict target column for q quarter i have different numeric columns and state quarter and id as category columns i would appreciate if someone could suggest me what kind of modelling could be performed link to my panel data example,which model to apply on such panel data where for each id have only records total records d,looking for a data set with multiple columns
155,hi everyone first post here and i am looking for a bit of career advice after reading the rules i think this is the right place to post but if not i apologize i just graduated class of from college as an economics and applied mathstats double major and am looking to get into data science without any formal data science experience i am going through the first derivatives graduate program interview process and after doing some research am unsure how to assess the program i was hoping someone who has been in the program may be willing to share their experience i was initially drawn for the opportunity to travel for the data science training at a high level global company company and for the chance to get experience that i believe i could eventually translate into a good data science job stateside when i feel ready to settle down some worries that i have seen after doing research the kx suite that they work in is owned by first derivatives so i am not sure how truly useful this work experience would be anywhere other than first derivatives additionally there are a lot of complaints i see about the program but i know that the people who are most likely to write anything at all are more likely to be those who had a bad experience lastly i am not so sure about my initial assessment of first derivatives as a top tier global company which is based on looking around their website,looking for someone who has done the first derivatives data science graduate program or is familiar with their kx suite to talk about their experience and experiences after,data science career advice
156,i am the mom of a toddler and recently ended my job my experience is in qualitative research teaching introlevel courses in the social sciences as well as copyediting some layoutgraphic design academic writing etc i have an ma in the social sciences i have been working through flatiron school is free bootcamp prep course mostly learning python basics so far i like it i have become very interested in data science analytics and visualization as i believe it would allow me to bring together my different jackofalltrades kind of skill set also i am very concerned about getting a job with my qualitativepublishing skills because my formal experience is limited i have done a lot of freelancing and well there are a lot of applicants for not a lot of jobs do you think that in my case a bootcamp would be useful for seeking a job i ask because i have seen a lot about how employers do not like that bootcamps churn out graduates without real life experience however if i am to switch careers this is the only way having a kid is too distracting for selfteaching using free online courses and i cannot swing going back for a whole degree in cs however given a framework i believe that i could create a decent portfolio of interesting projects i could see myself working at an ngo institute or for the government creating reports that are able to both show statistical facts and also give social context using my qualitative background do you think that there is a place for someone like me in the data analytics world,ok i know bootcamps are not a magical golden key and that there are mixed opinions of their graduates from employers but hear me out and let me know what you think do i have a shot at this,is it worth getting a masters in data science if i already have a job as a data scientist
157,hello we are very nice international team years based in swiss germany croatia india hongkong amp we have built the bot from scratch in python bot is using combination of indicators which are based on physical forces amp fractal geometry we have very nice and promising results that is what keep us moving if you are datascentist and you can help us to create the db which we need for bot vol please join us i can explain you our strategy and show results in our call before you join there is nothing to hide we also built the backtester the whole team share the bot source code as reward right now the bot is sending signals for coins and stocks soon it will trade autonomously we are adding minor features and is ready to go,tradingbot my team is looking for datascientist amp who can help to create db we are starting with vol of our bot all team members share the source code as reward,i have built a bot that can predict stock prices based on trading patterns
158,bare with me a sec and please forgive my noobishness if i told you i wanted to become a teacher does not matter what kind i would like to think anyone reading this would have a clear image of what that is and how someone could become a teacher easy enough yes when i approach wouldata science and i have been halfheartedly researching it for a year or so now the path gets a bit convoluted i can give you the a data scientist knows more programing than x and more stats than y answer or post a venn diagram or chart of how to become a data scientist in easy steps or say that all one has to do is learn r stats python machine learning etc etc and know how they apply to finding value in a data set answer but that still seems really nebulous so my question is this can someones please distill the allencompassing wouldata science term for me a bit maybe break it down into some more defined areas with somewhat clearer career paths just to clarify what i am looking for with the teaching example again say i do want to become a teacher i would decide i want to teach a certain subject or a certain grade or both depending say college physics anyone can get what that is and how to get there so my question is that i want to be a wouldata scientist working in the area of ________ so what areastracksbranches can wouldata science be broken into to fill the above blank even if they are only slightly smaller and only minutely less nebulous i would appreciate the insight,can anyone break the vague term wouldata science into different branches or areas for me please,how do i become a data scientist
159,so my request is a bit unusual we already possess a dataset about products and reviews for each product the products are home appliances such as kitchen appliances home electronics etc we want to annotate sentiments for aspects in the reviews of those products ie some common categories of analysis that people review about such as how expensive it is how big how small color usability customer support however to define our aspects we do not want to simply get some terms from the dataset in fact we wish to name these aspects according to common product features that are often analyzed by professional reviewers we could name them ourselves but we are afraid we would introduce bias into the process of creating those aspects so we are looking for some source of data or previous researches that already did something this so i bring the question to you is there any knowledge base that could contain such data about product review features or some specialist papersdocumentation that could contain such information for us to base the creation of our aspects i hope i was clear p this is a though thing to find,home appliances general review aspects data,looking for feedback on a product review
160,i am currently a business analyst which involves some data analysis type work but it is relatively simple and i am not really building models or doing any predictive stuff i have an interest in learning more and moving in that direction but i am wondering what the long term prospects are ive heard of some places that pay data scientists k a year but i assume that is at a top tech company in silicon valley or something realistically speaking what is the ceiling for a data scientist in a smaller market like say san diego and i do not want to include a management role because i am really not that interested in getting into management,what are the long term career prospects in this field,is it worth getting a masters in data science if i already have a job as a business analyst
161,hello and happy friday everyone rather than going into a long life story id like to just simply get to the point of asking the main question i am trying to set myself up for a career change preferably into data science i enrolled in the data science python path on datacamp mainly for the reason that i can work at my own pace my main question is at the end of the courses creating my own portfolio of real world projects and after i get the official certificate from data camp will that put me in a position to get hired somewhere will that be enough to gain an entry level position thank you for taking the time to read this have a great day,oh no not another datacamp noob question,data science certificate
162,hi reddit i play an mmo that has a virtual economy now i would like to write a decision support tool that helps me find better trades how can i use ml or simple statistics to my advantage preface i am not creating a bot that is against the eula of the particular game all money and commodities are virtual there is no connection to real money ampxb this is what i am working with i have a database of all commodities and their historic prices some commodities are volatile and some are highly cyclic as supply and demand changes between days of the week i have seen some busy traders but the market is far from efficient so it is definitely possible to predict price movements in fact i have some commodities that i trade regularly but it is not enough ampxb now i want to crunch all that data and find trading strategies with reasonable return and risk while only requiring me to trade x per day the output could be for example a daily recommendation such as buysell amount x of commodity y on day z the expected return and risk on a specific trade that i want to do individual price forecasts for specific commodities including uncertainty how should i go about it i guess i could split my data and then write some lstm regressions maybe crunch all the data and try to find the best cycles or maybe i could write an rl agent that can suggest trades surely some of you have thought about this before thanks,your ideas how to forecast prices find good trades in game economy,is there a name for this type of model i would like to use
163,i knew about wordvec and i thought it would be very hard but actually it is so simple that it is intuitive you just train a neural network with layers with the goal of predicting a word given its context a few words around it a very short summary the input layer consists of the onehot encoded context words you can either concatenate them or just sum them which loses a bit of context but reduces the number of weights to train significantly the output layer represents the onehot encoded target word this leaves the hidden layer this is the word embedding itself i love the idea and it is very intuitive because of its simplicity it is also intuitive that similar words are represented by similar embedding vectors although it strikes me as magical that one can do arithmetic with it king man woman queen the step to docvec is promised to be very easy but i struggle to understand it completely the idea is that you add a document representation to the input layer but i do not know how the document is represented now let is say that i did understand how you represent the document i understand that it is a vector that you can concatenate to the input vector thereby just increasing the input layer size a little bit but as far as i understand it the document vectors only serve as an input and there is no embedding that can be trained so how is it possible that similar documents are represented by similar embedding vectors,i understand wordvec but i fail to grasp docvec,is there a name for this type of neural network
164,for example the opioid crises big pharma makes opioids pharma reps markets new opioids to doctors doctors give opioids to patients worstcase patients get addicted then later od a recent study claimed that od deaths grew by for every marketing payments to doctors per k people in a county imagine you are on a data science team that has tried to optimize pharmaceutical marketing of drugs to put it bluntly would you personally feel morally culpable for the deaths in the industry even though it seems like it is ultimately the responsibility of the doctor and patient i would feel uneasy working on such a project another example you do sports analytics sports teams use your data analysis to inform strategy over time their new strategy leads to more wins but they also get more concussions or injuriesyou did not decide the play the coach and players did nor were you directly responsible for the injuries the players involved are but it seems like if you look hard enough you could always find ethical issues,when having ethical concerns do degrees of separation matter,is data science the right place for me
165,greetings data scientists of reddit i had applied to a data scientist position at an online marketplace startup of about employees they are now looking to start data science and analytics operations in the company this startup is like amazon for certain exotic items in india and so today i got a call from them informing me i was selected for the role naturally i am happy but here is the thing i will be their first ever data scientist and i have only about months of previous experience in data science from an internship at a different company there is nobody in the company who can guide me and i am far from an expert in the field i am a graduate of industrial engineering with some knowledge of statistics here is the list of what i already didknow because of the internship data wrangling and cleaning of mostly structured data using dplyr and tidyr feature engineering transformations pca imputation of missing data etc deploying machine learning algorithms random forests xgboost support vector machines neural networks cubist etc i used r for all of the above i have extensively read applied predictive modeling by max kuhn and introduction to statistical learning by gareth james et al both these books are my goto reference manuals ____________ from the job description i was given my new job will involve generating insights from data structured unstructured and streaming data building statistical models to improve company operations the data i will be dealing with will mostly involve their inventory database and transactional data _____________________________ is there any advice from the more experienced data scientists here what new things do i have to learn what should i avoid doing i want to succeed as a data scientist or at least do a decent job in this new role i am rather anxious and i do not want to screw this up ____________________ update thanks a ton everyone i will keep everything you have said in mind i feel the advice shared here is a gold mine for any novice data scientist,i just got a job as the first ever data scientist in a startup company i only have about months of prior experience in the field from an internship how can i do a good job,i am a new data scientist and i do not know what to do
166,essentially i would like to merge columns so one shows who is paying and one how long average payments are made by them but i cannot seem to do it without including each individual payment because i need to join tables with the id i used a shortened query example ultimately just looking at if it is possible to create a table consolidating payers y and x which an avg expected payment in the second column thanks let me know if i am even on the right track create table etp claimid int payers varcharmax expectpmt int insert into etp select countcclaimid case when paypayer like y then y when paypayer like x then x etc end as payers avgdatediffddcservicedatectpaydate as expectpmt from etc group by cclaimid paypayername datediffddplacementdatecttransactiondate,sql green thumb trying to make temp table,how to calculate average of total payment over time xpost from rstatistics
167,hi i have been working as a data scientist for about a year and i hold knowledge in statistics holds a masters i took a class in algorithms and data structures but i am not an algorithmic researcher by no means a representative of a small startup in the healthcare domaine that deals with medical texts approached me and said that they are looking for a knowledge graph scientistontology specialist they are looking for someone to build their knowledge graph test it using automated test and build the tests and apis and support the data scientists the team is now being established and the data scientists they are recruiting are much more experienced than i am years my main goal is to learn as much as i can in the field and try to lean towards nlp i dont really care about the domain even though they offered me a really good price for my time i am having doubts i know the saying that in startups everybody does everything but i couldnt get an understanding from the conversation i had with the cto of the company what ml tasks are expected of me and i couldnt find a clear description on how much ml the position involves,offered a job titled graph knowledge scientist dont understand what it is,how much do i need to know for a data scientist position
168,i am currently a masters student in robotics for a class i need to collect few literature articlespapersjournals on the broad topic of robot learning my current interest lies in deep learning reinforcement learning imitation learning robot perception can someone give me advice on any of the following how to start collecting the papers i am overwhelmed by the amount of papers that are in the above field and i am not able to understand most of it suggest other sub topics that comes under robot learning how to go about doing research about a new topic dive in head first or suggestion on good papers on the above topics with its application in robotics good sources to find such papers thanks a lot for your help,help need advice regarding research topic robot learning,looking for research papers on robotics
169,hi everyone on the johns hopkins map to see the evolution of the coronavirus they plot the actual number of cases and recoveries but they also plot the same graph but using the logarithm a friend of mine told me that it is to better see the speed of how those curves evolve but i really have trouble to understand what is the reality behind like in the actual plot the yellow curve seems to be at almost until mid february yet in the logarithmic plot it went off from the beginning ok the log function is more significant for lower values but in that case does it really represents the speed of its evolution thanks for your attention stay home and safe,why use logarithm,how do you handle outliers in your data set
170,i have been tasked with optimizing our onsite navigation for ecommerce so increased conversion rate amp revenue is the goal in the past i have only used google analytics onpage click analysis tools to see which categories in the navigation are the most clicked amp compare that information with which categories get the most revenue from that i get a basic score for each menu item and adjust the menu structure to show the highest earningmost clicked categories towards the top of the navigation also eliminating lowclick items add categories that are not represented etc ampxb has anyone had any experience optimizing site navigation using hard data what kinds of things did you track ampxb i should add that i have enough traffic to get statistically significant results fairly quickly around million sessions monthly the site has not had any real testing analysis and will be getting optimizely in online in a week or so ampxb the current navigation structure is simply alphabetical so that gives you an idea of the starting point lots of room for improvement,what tools amp workflow is best for site navigation analysis,how do i track how many people visited a certain section of my site in a given day
171,i am a newb to machine learning and have taken up a speaker recognition project for this semester and deadlines are fast approaching eek i am currently using gaussian mixture model from sklearn to fit the mfccs i have extracted from some audio dataset that i found online what do components mean in a gmm i understand that it means the number of gaussian distributions that make up a gmm but how is that applicable to clustering how do i decide the number of components for a model i want to fit and how should the covariance matrix be full diag etc is this trial and error what exactly is the output for the gmm predict function using sklearn i am getting a component number as the output but i have no idea how to interpret it please help,some doubts about gmm clustering for speaker recognition noob,how to deal with missing values in a gmm model
172,i have never built a recommendation system before but i understand the concepts behind a collaborative filter given a set of implicit feedback eg students who get above a b on a course vs students who score a b and below i am trying to figure out if it is possible to perform the matrix factorization once on the entire student population to create an adjustable course recommendation system by adjustable i mean where the user could choose a subset of the student population to receive recommendations from eg students who scored above an a students who are currently juniors students who were part time etc from what i can understand i would have to regenerate a separate recommender for each student segment however i was hoping that i could somehow just reweight each student is contribution to the recommendation on the fly limited to the prescribed segments as it is requested by the user so the user can get recommendations generated from everyone or specify only from students who scored belowan a and is sophomore or older,adjustable recommendation system,how do i go about building a recommender system
173,hey fellow data science practictioners i am looking to hear from anyone who has a highpaying position while making a positive impact on society i really like my current job in private industry my coworkers are great i enjoy the company culture i work on interesting problems and get recognition for solutions and i am paid well enough to afford a decent lifestyle with my wife and kid by all means it seems like a dream job but i am looking for something more the work is interesting but the goal is always the same make more money for the company it satisfies my brain and bank account but it does not satisfy my soul i have thought about finding ways to volunteer my time and keep my current job so i can make a positive impact on society while maintaining my wallet but thought maybe just maybe there might be a way to do both with the same job are there any of you out there that found a way to do good for the world and good for yourself at the same time while applying our skill set,highpaying jobs that make a difference in the world,data science or data analytics
174,i f am a current freshman at uc davis and i am planning to switch over to the new official data science major in the fall with a minor in cs i saw some comments on a reddit saying that the statistical data science major with a cs minor would be more useful in the long run the difference between the two is that the new ds major has cs courses builtin to the major itself while the statistical ds course does not have cs courses integrated into the major and is heavier in stats classes that are more theoretical any advice on which one i should go with please let me know thanks,which major to choose for data science,data science major vs statistics major
175,i have some data in a matrix of n points and k dimensions and it clusters reasonably well into n clusters using kmeans clustering let is say i have defined a unit vector separating the mean of these clusters as c which has components in all dims what i want to do now is rotate this data into a new basis for visualization purposes the first dimension of this new basis should be along the axis c so i can see the clusters separated from each other and i want the rest of the dimensions to follow in descending order of variance so that i can see the spread so to put it another way i want to do principle components after first projecting onto a special axis that takes priority is there a quick and standard way of doing this my manual attempts to implement this are really messy but can be sumarized as follows first i have created an orthonormal complete rotation matrix into a basis of c along with k other vectors defined arbitraryily so long as they are orthnormal gt v then i apply this rotation matrix to my data dat_rot vt dat_int t the first column goes directly into my output dat_out dat_rot for the rest i subtract the mean so it is centered dat_subset dat_rot npmeandat_rot axis then i do svd on the remaining vectors u s v nplinalgsvd dat_subset full_matricesfalse and use v to rotate the corresponding subset dat_out vt dat_subsett t return dat_out so yeah it is messy and my results look like garbage because i am pretty sure i am making some mistake along the way in theory though what i want is a plot of plot dat_out dat_out so that i can see the clusters separated along the xaxis and with maximal variance on yaxis this should work right or is my approach flawed on a deeper level is there a faster way to do this any suggestions would be very much appreciated,visualization how to do principle components but with a special dimension,how to deal with missing data
176,probably a very simple question but i am an engineer a bit out of his element i have data from a sodar station measures wind speeds at different heights above ground in a text file that looks like this timestamp label metadata label metadata height col col col height data data data height data data data height data data data timestamp label metadata label metadata height col col col height data data data height data data data height data data data but with metadata labels and an x data table there are k timestamps would you have two separate tables one with data the other metadata with a common index of timestamp i assume for the data table i would use a multiindex with timestamp and height is there a straightforward way to keep everything together assuming there is a benefit for doing so,how would you organize this data and load it into pandas,how to store metadata for time series data
177,steps to creating a kmeans cluster i have a array of length each element of the array of length there are feature vectors i first scale the features to normalize them as the numbers vary a lot i then run pca on the vectors to convert it to a set of features so that i can graph it on a d scale i now have clusters i use an elbow graph to figure out the optimal number of clusters now i want to give these clusters different names based on the underlying datathe features unfortunately i do not know how to look at this underlying data from the cluster information given does anyone have any insight on how to do this,kmeans question on pca reduced dataset using pythong scikit learn,how do i normalize a cluster of features
178,basically i applied for a deep learning internship at a londonbased startup and they asked me to do a task involving implementing an algorithm from a recent paper testing it and exploring the results they said it is generally expected that it will be done in weeks and i am just not sure if they are trying to make me do work for free it seems like quite a bit of work especially since they claim publishing my work could be grounds for rejection so potentially i will not even be able to put it on my github does anyone have experiences like this for my last internship i just had to do a stupid coding test and the most important thing was an actual interview so i am really uncertain whether it is worth it jumping through these hoops,internship recruitment task,is it worth getting a data science internship if i already have a job
179,hey guys my friend wrote an article about how a free data science programs that will help you get knowledge and after that you can get a certificate the certificates might require some payments and if you cant afford it is completely fine the most important part is that you will get the knowledge and you can make tons of practical projects that can easily put you in a good position at your jobs interviews the program in that article is will help you to become a data scientist for about and a half years if you are interested in that then you can learn the full article here on this link but if you are not interested in such a thing you do not have to click or read it since i publish this here only for the people that are interested if there are some if you have some other ideas and better about topics like this feel free to comment and i can tell my friend to write another article that will be also very helpful thank you for understanding,how to become a certified data scientist at harvard university,free data science certificate
180,hello everyone i am from venezuela and i have started to teach myself some ds skills but i noticed that some of the best ways of learning stuff and at the same time generating some experience is with internships any south american friends that could give me some advice on where should i look for internships and what do i need for laying one of these i have just ended high school and i have not started the university yet so i have literally zero background only online free sources and youtube tutorials d i am specifying because i think that advice from people from closer countries to my own might be more relatable to my current situation than full developed countries also if you could give me recommendations on universities that might offer majors in cs or data science it could be very helpful if you are from a developed country and want to give advice you are welcome as well thanks for reading,looking for advice on internships and universities specially if your are from south america like me d,advice on where to start
181,hi everyone i have about years experience in analytics and data science in an industry and have managed a portfolio of projects from use case ideation to model build to monitoring my interest in primarily in working with business to identify the opportunity and business case and design a solution create business case and budget either internally such a predictive or identify a third party vendor and manage the relationship as a i get older i realize i like understanding business problems and identifying what needs to be done but i hate managing data science project plans are there any jobs mostly in use case creation and idea generation and if so what titles would they fall under thanks,does an appropriate job title exist,data science and analytics
182,hi ampxb i have two offers right now both in the us ampxb company a a big bank where my role is a software engineer this may or may not involve any machine learning this company applied for my hb and it got through the lottery it is in a big city ampxb company b research engineer role with nlp and speech the company publishes it is a non profit where the hb is not guaranteed it is in a suburban area i want to keep my options of staying the country open because of which i am leaning towards option a however i feel i might find it difficult to move from the software position role to a research role or a role that will allow me to build nlp applications my background i have a bachelors and masters in computer science with research experience in nlp i have not been on a software development role ampxb any advice on how the switch is in the industry any help will be appreciated thanks,career advice how difficult is to move from software engineer to a nlp engineer role,data scientist or software engineer
183,so i am working on a stock price prediction regression model that predicts closing prices of a chosen stock i am fairly new to machine learning and was wondering how these models could actually be useful so the test tests the model on unseen data and makes the close price predictions but i was curious how this can actually be applied to a realworld scenario the last data point of the predicted price is for yesterdays closing price so that does not have a purpose i am just wondering how a model like this once optimized can be of use i thought it would be able to predict say tomorrows close price but i assume i am wrong this is the model i am working from,ml for stock prediction,how do i go about building a model that predicts stock prices
184,i recently started watching mit is opencourseware course on linear algebra and i am having a bit of trouble grasping concepts like the spectral theorem and the singular value decomposition i get their application in stuff like pca but i only have a rough understanding of the underlying principles for something like the gradient descent i understand that it works by minimizing the error by looking at the gradient and finding the local global if lucky minima but if i had to code implementations to the svd or gradient descent from scratch i am not sure i could do it so i thought i would pose the question in the title to the seasoned veterans,how much linear algebra do you use on a day to day basis,question about the gradient descent theorem
185,i have been given an opportunity to learn a second programming language for free i am versed in r so which do you guys think is actually beneficial being able to code in both r and python would help a lot with when working with other data analysts and scientists and it has some hooks into hadoop excel is still and will likely be in the foreseeable future heavily used in all parts of the industry java is great for many things im just not sure what those things are what i do know is java can fully control hadoop which is beneficial since i inevitably want to work with hadoop spark ps i am not a data analysts yet currently studying to become one also i already know sql,r python vs r vba vs r java,what is the best free or very cheap way to learn python for data science
186,i am thinking of using imitation learning for atari games more like game or a gamesuch as mario or car simulator as a project for university now my questions are these how should i approach gathering data images or data such as position of player position of enemies action taken for every frame what algorithm should i approach and try to understand in such a situation dagger searn smile i have looked into dagger algorithm and i have got confused because of mathematics and do not seem to understand it that well maybe because i was not able to actually find an example of its usage what game should i try it for an atari game such as pong space ivaders pacman or something like tork now i get that those questions may bea bit stupid but i have got a bit confused after not understanding that much about imitation learning thank you for taking your time into reading this,some help with imitation learning,is there a name for this type of algorithm
187,hi im new here glad to speak with u is there any chatforum where i can ask doubts i have ended a math degreein eu this year im still yo and have a lot of time and enthusiasm to learn about this topic and obviously make it a job in the grade i ve learnt a lot about statistics and general mathscomplex analysis algebra numeric methods topology and i would like to apply it at least the statistic part i also dont undertand well the difference between the following terms data science data analysis big data machine learning ia i want to follow my studies with a master and they focus in one of this terms and dont know what should i choose is there any begginer guide or something about this ampxb thank for your time,i would like to know your opinion,i am a new data scientist and i have a lot of questions
188,hi everyone my name is ken and i have worked as a data scientist in the sports analytics field for the last years in grad school i was required to post one of my projects on youtube and i realized that i had a tremendous passion for creating informative content on the platform when i was starting out in data science i felt like there was a lack of useful content about how to get started and how to get a job as a data scientist as of now i have focused my videos on how to learn data science ml effectively and how to navigate the interview process this year i have decided to truly dedicate myself to improving my videos and i think an important part of that is honest feedback i would greatly appreciate it if you would take a look at my channel and let me know if there are ways that i could make it better specifically i would like to know how is the content would you like to see more day in the life stuff tutorials code reviews projects how is my delivery could i improve how i communicate my ideas how is the production quality do my editing and camera angles need work video topic ideas i love taking user requests channel link thank you,looking for constructive feedback on my machine learning data science focused youtube channel,how to get better at data science
189,for those that have achieved this in an analyticdata science field what do you think are some of the best toolsassets in your career that have allowed you to do so i currently manage a small team of analysts for the us corporate group of a large global company i only have three years of management experience but i have been in analytics my entire year career at different levels analyst senior analyst data scientist and now analytic manager i really would like to make the jump to a director level and while i could be on track at my current company maybe years i have started applying to external positions should i be more focused on my personal accomplishments driving results technical skills the way i have equipped analysts for success my ability to present findings to seniorglobal leadership something else am i too early in my career for such a lofty goal should i try to stay in my industry or do you feel companies are open to hiring someone who may lack some industry knowledge appreciate any advicediscussion,making the jump from manager to director,career advice
190,i have always looked down my nose at sas but now i may pick it up again for one feature its ability to easily query local files with sql and efficiently join with tables in a database with proc sql i can join local files with database tables as if they were both in the database and cleanly have the result in local memory ampxb by comparison python and r dataframes must be queried with their own functions and syntax numpy pandas tidyverse etc and joining with database tables involves either downloading the whole table querying for a piece of it and loading it local memory or writing a table definition and uploading the dataframe into the database when uploading a data file into the database sas can even automatically generate column names and data types ampxb to me sas seems like the superior analytical tool for ease of use when the job requires lots of sql and munging though i would love to be proved wrong here,is sas really the best tool for sql joining local tables with database tables,how do i use sas with python
191,hi everyone so i am in my final year of undergraduate in business administration and i came across business analytics recently as it was a new course introduced in my university we were taught statistics concepts such as hypothesis testing anova multiple linear regression logistic regression etc we were also taught how to use data visualization tools such as tableau and spss and a more focused use of excel i genuinely enjoyed learning these topics and the more i read about this field the more interested i have become into pursuing it as a career my conundrum is that i am not a math wiz i just view numbers as a representation of real life situations and seeing it from that perspective makes it easier for me to understand business problems i have done various internships but most have been non analytical in nature and have been more marketing related i do intend on getting one solid analytical internship before i am done with my undergrad i also intend on working for a year and then going for a master is in analytics i know i can learn almost everything i want online but i need a good master is program to elevate my profile to the next level my main worry is that my lack of programming knowledge and a non technical background would be a hindrance while applying for a master is in science my grades are good and my gmat score is but i am still not a sure if i should pursue a career in this field any advice would be incredibly appreciated thank you,is analytics for me even though i am not a hardcore math nerd,is it worth getting a masters in data analytics if i already have a job as a business analyst
192,over the last few weeks my analytics has shown a huge increase in referral traffic from facebook sure traffic increase sounds good but when i dug into it i found a bunch of my paid traffic from facebook coming in without a utm so it shows as sourcemedium facebookreferral instead of facebookcpc i checked all my ads and the utm codes are set up correctly i previewed all my ads and clicked on every damn learn more button which took hours and the utms are all showing up correctly in my browser from the preview but i have pages that you cannot get to outside of my paid ads that are coming into analytics as referral traffic it is happening with multiple pages on both mobile and desktop i cannot identify a single ad that is affected i contacted facebook support and was not surprised when they told me they could not help so can anyone point me in the right direction on how to start trouble shooting this,vanishing utms,how do i track facebook ads in ga
193,i am currently working on a project remotely to gain experience in machine learning i have been given some tasks to perform but as i am new to thisfield of expertise i need help for the same the problem statement revolves around building a recommendation system for an amazonlike website which will be deployed in madrid it is basically a budget mart to tackle the problem of inflation it will provide the users the cheapest commodity available around their locality and offer recommendations based on the commodity which they buy based on previous purchasing experience of the current user and the other users as well can anyone help me withthis what all should i be knowing and can i refer to something to carry out this task,help with implementing a recommendation system on a website python based flask,i need help with a recommendation problem
194,so i am finishing a master is in computer science with a specialization in data science initially i was really focused on analytics statistics machine learning etc and i still love it but i later found that i really liked infrastructure databases data pipelines etc as well i do not want to work purely as an infrastructure engineer but i would love to work as a data scientistengineer who both extracts data and builds models to analyze that data in essence a fullpipeline data scientist is this a reasonable expectation for the kind of jobs i can find it seems like the majority of jobs are either for pure analysts often from statistics physics andor economics backgrounds or infrastructure engineers who excel in programming and traditional cs i know that jobs that are looking for a wellrounded data enginer exist but they seem to be the minority,working in data analytics vs infrastructure,is data science a good career for me
195,i am a recent mathphysics ungraduated with some coop experience as a software developer data entry a year of work as a barista and currently working at a restaurant i am experienced using windows sql excel python c and powerbi right now i am looking for a remote job as a data analyst but feel like my options are very limited most positions are looking for years of experience i still apply to them but i doubt i will get any of those jobs i am not sure i could be a software developer as my coding skills are only intro level and i do not want to be a teacher i would really like a remote job within the next few months so i can move to from new burnswick to toronto and afford living there without it taking up all of my free time it is only been applications and a few weeks into my search i know this is not a lot but i am bad with taking on projects like this that can go on forever is this in the realm of possibilities and i just need to keep going at it or should i try something else here is a copy of my cover letter and resume with my personal information removed,chances of getting a remote job as a data analyst as a recent grad with little experience,is it worth getting a masters in data science if i already have a job as a software developer
196,i am working on a gan from scratch in tensorflowjs and after several day of unsuccessful results on various datasets and hyperparameters i decided to verify it could overfit to a single image and all results have been negative even at epochs i am not even getting anything more than mostly blurred colors my model architecture is below what should i try next to see if i can get better results i feel like the model simply does not have the capacity needed but i do not know what is worth increasing discriminator input is blocks of convd kernel stride batchnorm and leaky relu features go from to dropout then flatten and dense unit with sigmoid generator input is latent and into a dense of units then blocks of upsamplingd x convd kernel strive features go from to batchnorm and leakyrelu final convd converts it back to channel and uses tanh images and latent space are normalized to mean standard deviation training set is anime pictures currently both train about equal although shifting either way made no real difference thanks for the help and i can provide extra details as needed,my gan cannot overfit to a single image,how to deal with overfitting in keras
197,i have about years of experience as an implementation analyst if you know excel i can maintain and make changes to vba macros and build basic macros myself i can handle large spreadsheets k rows with rate analysis data manipulation formulae and pivot tables and i can manage large projects from a financial and implementation perspective ampxb however the salary with my current job role seems to have stagnated at k in london i realise data scientists make much more and since i am still relatively young i am willing to learn whatever i need to to pivot to a career that has room for growth and data science seems to be quite similar for context i have a bsc in mathematics and msc in mathematical finance where would you suggest i begin what things are the bare minimum i need to learn before applying for roles any resources paid or free that you would reccomend ampxb any help much appreciated,i am a year old implementation analyst i do data stuff in excel i want to pivot to data science how transferable are my skills and where should i begin,is it worth getting a masters in data science if i already have a job as a financial analyst
198,hello all i hold a bs in maths with a minor in informatics and a ms in statistics i have some knowledge about python r java oop relational databases and nosql databases machine learning algos neural networks mlp cnn yolo lstm hypothesis testing network algorithms operations research reinforcement learning but i have no knowledge about software development in turn i feel everything i know is useless i cannot create a data warehouse put models in production never worked with aws azure docker zero knowledge about dashboarding and web app for data visualization i am currently a research assistant but soon i will need to find a job data science seems more suited for cs students than applied math ones am i right has anyone felt the same i feel that i am not prepared for a data science job since i cannot create software best regards thx,ms in statistics need advice,i feel completely unqualified for a data science job
199,hello ds community i have started looking into learning ds since i have been unable to find jobs in cae for sometime now i hold a masters in mechanical engineering and some experience in cae i have used analytical methods and programming to solve design and optimization problems both in academia and at internships so i feel ds would be best suited as a career and also since there are more jobs in ds where i live what i can do turn engineering problems into mathematical models solve mathematical models using code and visualization verify and validate models solve linear and nonlinear system of equations code in python numpy pandas matplotlib cc matlab fortran ampxb what i can not do database management or programming statistics machine learning ampxb i learn best by working on problems and studying by myself so please let me know on how to go ahead please tell me about online certification ds interviews junior ds job expectation etc ampxb also if anyone switched careers to ds please tell me your story,need advice on how to get started with ds i can code and previously a cae engineer,how to get into ds with no experience
200,ampxb my project is to predict the ranking of the english premier league the image above is my final predicted rankings using different methods in addition to the true rankings this is a d plot showing the relative order of the teams the values are not really important but the order is in the plot above i just used seaborn is scatter plot and modified the points itself my problem with this plot is that the lines are not clearly distinguishable and the text overlaps and is a bit confusing it just looks a bit unprofessional ampxb so my question do you have any ideas about how to make this look better any recommended libraries or methods or even different types of plots,any ideas on how to better visualize this,how do i cluster my data
201,would not it be cool for other people to use your nlp research and modules without requiring additional work both those that are doing data science and those that are just looking for additional insights on a text like writers and translators i am looking for feedback on whether other data scientists would use this and why i am working on a tool called writealyze that provides a simple framework for creating nlp modules that can be connected combined and edited python notebook and allows you to see in realtime how well things are working and how the text is affected at each stage of your machine learning pipeline then complete systems will be so easy to use that translators writers and students can get helpful text analysis without knowing what text analysis means and data scientists can have users test their work and get rewards for winning leaderboards on certain nlp tasks and for sharing highly rated modules please signup at if you are interested thoughts,visual nlp notebook tested by writers,nlp for data analysis
202,i recently started work as a data analyst my team works regularly with my company is data science team i am also about to start a data science masters and hope to transfer to the data science team in a year or two the work that i did before this job was entirely unrelated to analytics data science so this is my first real job in the field i was updating my old resume to include this new job and realized it pushed my resume to pages so i figured it is a good time to consider starting one fresh that is just a pure analytics data science resume i would like to get some perspective from you guys if that is okay do you have any recommendations on when to throw older irrelevant jobs off a resume do you have any recommendations for resume templates my current resume includes sections for education certificates amp licenses job history and skills is there anything else you think is good to have on there,when to get rid of old jobs on resume,resume critique for new job
203,so i just completed a multivariate regression based on a little over million data points using fifteen blocks and five treatments with some solid results theres clearly a top three choices and bottom five ones to avoid but other than a graphical analysis how do you generate reports the client never actually said how they wanted the outcome and i usually have very specific deliverable examples samples or requirements but this guy has a masters degree in stats from a major school and i want to make a good impression right now i am going to deliver him a colorized rendering of the actual regression a simple spreadsheet some of my python code and a pdf of probably a page or two explaining the findings how would you deliver a statistical analysis and the explanation that goes along with it in laymans terms i mean is this just like one of those dual column research papers that i read on arxiv and produce this in mla format,how would you deliver a briefport done on a statistical analysis of million data points,how do i go about building a regression model from scratch
204,hello i have a finance background and currently work at a bank performing regulatory work a lot of what we do is review models done by data scientist to detect fraud and other things i noticed it was interesting and looked into masters of data science programs in my state the top programs seem to be ucla uc berk stanford usc and ucsd problem is i have zero programming background and also i never took the calculus classes that are recommended is it even possible to switch your career to data science with no programming background the two close schools to me are ucb and stanford and i know theyre the top programs which is incredibly intimidating it discourages me from even trying additionally you have to apply by december this year to get into the program next fall,is it possible to get into a data science program with no cs background,is it worth getting a masters in data science if i already have a job as a data scientist
205,i tried eli but maybe this is a better place i am not a computer scientist but i have been enjoying reading this ai wiki the one thing i cannot find an answer to is how the results are evaluated so as to be able to say to the network nope try again i mean an adversarial network makes perfect sense to me one network has the ability to evaluate results and provide the feedback another network has the ability to generate results and the two challenge each other but what i do not understand is that without a gan and without a human being to evaluate results whohowwhat tells an unsupervised algorithm that the error is what it is from the quoted article usually the initial guesses are quite wrong and if you are lucky enough to have groundtruth labels pertaining to the input you can measure how wrong your guesses are by contrasting them with the truth and then use that error to modify your algorithm thats what neural networks do but what if you do not,how is error evaluated in an unsupervised neural network with no gan or human intervention,what is the proper way of evaluating a neural network
206,i am in the early stages of thinking of doing a masters in the overlapping areas of data sciencemachine learning part of the motivation is to at some point apply for phds should my aptitude and enjoyment be sufficient unfortunately due to circumstances i would have to complete any masters course online and parttime i know there are obvious advantages to studying in person and on campus but my question is would the drawbacks of studying online be sufficient to prevent potential phd supervisors from taking me seriously as an applicant for context my undergraduate degree was a taught masters in mathematics with a focus and dissertation on pure mathematics i also completed a fulltime oncampus postgraduate research masters in cognitive neuroscience which involved some regression pca and programming in matlab as part of this i completed a research project which was computationally heavy using algorithms to make calculations on physical aspects of the brain in matlab i am currently teaching myself to program properly in java with a view to moving to python when i feel ready,question for academics how would an online masters be viewed by potential phd supervisors,is a masters in data science worth it if i already have a job as a data scientist
207,i would love to be told i am wrong here but it seems that the ability to track events in ga is a largely useless feature if you have a pretty cut and dry website meaning i work with a lot service businesses contractors electricians plumbers etc who have websites with the following a homepage an about us page service pages testimonials contact etc with that said the pages that do the selling do not really have much on them in terms of what i believe are trackable events there is copy sometimes a video and a link to the contact page clickable contact info is always present in the headerfooter but beyond that there is not much going on that leads me to believe that delving deeper into events will not do me much good am i correct in this assumption or am i misunderstanding ga,is ga event tracking useless for service businesses,is there a better way to track visits to a website with google analytics
208,i am struggling to find a scalable solution that will allow me to make predictions for several hundred response variables using a common set of predictors using keras in r since i am pretty new to nn and dl i simulated a small toy dataset that consists of five dependent response variables and a set of k predictors and fit some very basic multioutput nn with keras in r the plan is to build on these nn and to apply them to a real dataset consisting of k predictors and response variables the code for my very simple nn is input lt layer_inputshape dimtrnxrr namet_in layer_t lt input gt layer_denseunits units_m activationlinear kernel_regularizer regularizer_lk output yhat_t lt layer_t gt layer_denseunits nameyhat_t yhat_t lt layer_t gt layer_denseunits nameyhat_t yhat_m lt layer_t gt layer_denseunits nameyhat_m yhat_m lt layer_t gt layer_denseunits nameyhat_m yhat_y lt layer_t gt layer_denseunits nameyhat_y build model model lt keras_modelinputs input outputs cyhat_tyhat_tyhat_myhat_myhat_y gt compileoptimizer rmsprop lossmse metricsmae model_fit lt model gt fitx trnxrr y listtrnys trnys trnys trnys trnys epochs epochs_m batch_size verbose validation_split coding the output layer for each response variable is not great when you have response variables is there a better way to do this i have seen multioutput code in python that is much more efficient see the first chunk of code under model building here,scalable multioutput nn with keras in r,how to deal with a very unbalanced input
209,i am going through a rather large data set and with this many tb to start i recognize a familiar feeling there has to be a more efficient effective and economical beneficial process for this it kind of hit me one day that while there is a pemdas for the order of operations in algebra what is there for algorithm choice when doing data science work there is pemdas for the algebra stuff efficient since there is sciem for the statsdata stuff xxx efficient since there is crispdm for the mbaish stuff xxx efficient since there is myprocess for a smattering of all three x efficient over years is there a unified theory for all of this and my initial findings is that there does not seem to be a single obvious nor one that is unified theory for data science yet pemdas was drilled into me by the schools and this is computationally totalitarian dictator enforced and there are no dissidents allowed i walked across sciem which stands for split test misc cleaning impute missing values encodescale and modeling the data has a locus of for math or algorithmic model for data processing then you have crispdm which is for business understanding data understanding data preparation modeling evaluation deployment has a locus of process for mbaish data management while i have years working in finance as an advisor we used heavy amounts of analysis to understand the customers goals risk tolerance event horizon analysis and how much time or effort they wanted to put in we had a heavily defined process that came from regulation and we have millions of case studies showing that this specific process was heavily weighted in success i mean it was so ridiculously displayed in the data that it was practically newtonian in the reliability that it looked familiar but i could not quite recall where i saw it first it was so effective that those of us who just followed this process and logged it independently in excel noted a simple wave pattern emerged and the frequency became quite obvious it was logarithmic so when we met clients we had an incredible amount of confidence in our probability of success so clients frequently said yes we gathered data asked a trainload of questions ended that meeting scheduled the next and went to input data subsequently we used heavily modified monte carlo and hmm plus a smattering of other algorithms but always there was a process that blackrock software had us enter the data in then we progressed to the next step check our assertions vs a backtesting application and then go back into optimization in a sort of hybrid efficient frontier the output of all this was incredible and i never had one client come back to say they had gotten a better analysis by schwab da davidson lpl fidelity prudential vanguard jp morgan allianz but the constant outlier that amazed me was goldman sachs every freaking time they had an additional edge tweak or an ensemble of things and we almost always had a less effective model in their gt assets projections so i said all of that to show that in some fields they absolutely have found a process or the process and deviating from it was economic suicide or at least a glutton for punishment is there a process to all the algorithms that we use in data science in general,how value relevant or absolute is sciem in the data science process,is there a more effective way to analyze a data set
210,these dictionaries are compressed as well so they take up far less space than the regular json or pickle objects pip install dikt here a little example import dikt obj key_ stri listrangei i for i in range dump dictionary to a diktobject you can compress from to but you will get slower reading time diktdumpobj objdikt compress instant loading data diktloadobjdikt very fast lookup printdatakey_ the dictionaries must be a mapping that takes a string to a homogeneous type of data dict float int lists dikt is useful when you only need to grab some data once and very quickly without loading the whole json which is very slow and exploding your ram i use it mostly to allow gcp cloud functions or aws lambda functions to map data or vectors or idlookup really fast without using any database it is still in beta so be warned complete documentation is coming tell me what you think guys link to the project,python i opensourced dikt a library to dump and read dictionaries out of memory thus allowing you to access values without loading large files in memory,how do i use obj files in python
211,hi everyone i have an idea for a side project which will depend on making a speaker identification system but i do not know how to start building such a system i do not have a background in machine learning so i do not know from where to start or what i should read or learn what i did till now that i searched on the internet and i found some people gratefully shared their models on github but i do not know how those models work and i do not know about their performance and i would like to take the opportunity to write the model by my hands to learn more very few tutorials i read two of them one used siamese networks and the other used gmmubms a lot of published research papers and i tried to read this paper that i cannot say that i totally understood but i helped me to gain a basic insight on what i should make in the system also i found about aliz and marf which are open source frameworks but i have not tried to use them the last thing that i found is a statement that i read the statement says that ivectors and gmmubms are the currently used techniques so this is what i found till now and i do not know what i should read or learn now i hope that you can give me any tips and i am very grateful to your time and your help thank you,i want to learn how to make a speaker identification system,how do i know if my model is ready for production
212,i know python works thats it originally learned it because my friend recommended it as a useful skill i recently completed the udemy course data science az by hadelin de ponteves and kirill eremenko and started their deep learning course my question is what are some comprehensive resources to continue my journey here what are all the things i should be learning and where is the best place to learn them after the data science az course i feel i have good basic understanding and am looking to grow further i have a pure maths degree and think ive stumbled across my favourite thing ever as a career cant wait to become proficient in this,hi data science noob looking to learn the field any advice on skill sets i should work on,what is the best way to learn data science
213,hi i am new to machine learning and stuck on this problem for quite sometime i have searched over the internet for it but still do not understand how exactly do o implement the solution so what i am trying to do is given a sample of data i want to find the best distribution model that would fit the data and then use that model to sample more data from it i am only allowed to use numpy library so this makes the problem more challenging i have found the optimal model parameters for each of these distributions gaussian uniform and laplacian using maximum likelihood estimation how do i proceed from here any help would be appreciated thank you,finding the best distribution model to fit my data,how do i use a model with a uniform distribution
214,these past weeks i have been working on an ml web app as a side project being a data scientist i decided to take on this project for two reasons first it would make for a good experience for the things i am not very comfortable with like designfrontend and deployment tasks second as i found most of the materials lacking i thought i could gather some useful information to write a blog post about it i made a web app that tracks the sentiment on twitter towards the leaders of the top political parties in spain it works more or less in realtime the site is live here some things went well others that i could have done better and others that at this point i am not sure haha eg how much traffic would it handle i thought i could share those things before getting to work on the blog post i will start with the things that made my life easier endtoend machine learning app this is a great resource it goes through the full process of building a machine learning application in a realistic setting most of the materials you will find out there will skip deployment or work with simple data sets this one goes from scraping to deploying in aws a few days ago i also read this one which i also recommend dash i compared streamlit and dash and went with the latter for better documentation and a more significant community the deployment part was especially painful so proper documentation was critical to get the job done hugginface is transformers if you are working with nlp tasks in languages other than english check huggingface is repository of community models furthermore it is relatively easy to integrate into an inference service built with pytorchflask abhishek thakur is tutorials and kaggle notebooks for finetuning bert fantastic resources that saved me a lot of time especially when using those ideas with a pretrained bert in spanish from huggingface is transformers more generally i benefited from keeping the toolset simple i used powerpoint when i started designing the app sqlite as a database and python instead of javascript now the things that i wish i had done differently contain the scope i started with a straightforward idea and then started adding stuff that just made my life harder most of the time i think it was because i felt the app was not complex enough for publishing it deployment ha the only good thing about it is that it works right now it is a painfully manual process i should have gotten to a better deployment process from the beginning by the time i started deploying it felt like too much work sacrifice code quality i wanted to ship this quickly so the code is not dry it is more like cry yourself to sleep refactoring is among my top priorities now model it is not great right now it only gets the job done i did not dedicate that much time to labeling data for finetuning the model this is also a priority for me right now finally there are many things for which i do not know if i was following the best practices in particular setting up nginx and gunicorn felt a bit hacky sooner or later i guess i will find out,things i learned while building machine learning web app,how do you deploy models
215,first and foremost sorry to ask such a basic question its probably been answered numerous times i tried clicking the wiki link in the sidebar but nothing happens using the apollo reddit app on my phone and it wont let me copy the hyperlink anyways a quick background im a software engineer i have scratched the surface of machine learning and worked on small scale personal projects some years ago i feel like ive probably forgotten majority of what i learned since time has elapsed i also know basic probabilitystatistics calculus etc although i probably need to brush up on those as well my goal is to get a deeper understanding of ml and to actually learn and implement the various algorithms approaches i would like to stay clear of libraries that already handle the heavy lifting for you what books or online resources would you recommend that would best fit my background and goals thank you very much in advance,introductory books resources,what are some of the best resources to learn about machine learning
216,i am looking to move into the field learning r and python for people analytics purposes and my current hardware is most likely not going to cut it so i am looking at options that can allow me to get a head start on things i currently have a dell latitude e with a shitty processor i rd but decent ram gb and about to get a ssd wd blue which i am guessing will do as i learn the ropes if you do not have a specific equipment in mind just mentioning what kind of hardware i would need to make this work is also helpful i am planning on saving up around to for a decent upgrade later on and i would like some suggestions from people in the field some notes it has to be a laptop mobility is a must for me and relative independence from the power grid on occasion power outages and power surges are somewhat frequent in my country i can get it in the us and ship it in since most of the products available are bought and shipped similarly and it would not make a material difference i can wait out until supply becomes more readily available i tried rsuggestalaptop and got some valuable feedback there but i wanted an opinion from people in the field as to get a sense of what i would need requirements wise and googlequora is a bit all over the place thank you if you read this and i hope you have a great day,suggestions on a starting laptop to get into data science hris,laptop for data science
217,professionally take it job descriptions or practically do you need to know and be able to apply every deep learning modeltechnique to get hired cause every subfield seems quite vast and requires mastery in and of itself should i dive deep into the mechanisms of every popular architecture there is including supervised unsupervised autoencoders gans hmms that sorta thing or just know how these work and have an intuitive understanding of them but continue to thoroughly know what my interests deem best for me thats personally deep reinforcement learning sorry if the question feels opinionated but thats what i want from you people i have no friends or family that bear knowledge of this field that can guide me through so here i am thank you in advanced,to anyone who is a professional mldl engineer or works in an equivalent field i have a question,how do i go about learning deep learning
218,the data years of monthly invoiced sales history in addition limited length of history my data has some added variation due to the fact that some invoices land in the month after the demand signal because of transportation issues the h forecast that comes out of our exponential smoothing based modeling engine is very jagged and over fit in my simple opinion i would like to explore other ways to capture the seasonal signal which we know should be smooth between months most techniques i read about for seasonal forecasting treat each interval within the seasonal period independent from others this works fine when you have lots of data say decades of economic data but i have only cycles of data i want to make the assumption that demand is related to adjacent months februaries are related other februaries and also other januaries and other marches my instinct is that this could be done with a seasonal decomposition that assumes smooth smoothness between months is there a deseasonalizing approach that would work can my assumption of a smooth seasonal patten be incorporated into a model somehow maybe seasonal arima an arimax would produce a forecast based on lags is there a way you can bend it to include lags amp any help is appreciated thanks,modeling help need help finding a technique for seasonal forecasting that assumes smooth pattern,time series forecasting with seasonal patterns
219,im an undergrad majoring in data science and ive been considering taking an elective course in low level programming is it worth it where do you use this info as a data scientist btw heres the course description this course is conceptoriented not specialized to a particular operating system and not trying to teach how to code the kernel of an operating system after reviewing a number of system programming issues it examines the basic components of modern operating systems in terms of their function domain design principles and implementation techniques use and impact on systems programming it describes and uses in programming homework two modern operating systems unix and windows nt design and implementation of a number of concurrent programs is examined hardware support for operating system functions is discussed performance issues are considered through the course,is understanding os and computer hardware helpful as a data scientist,what is the best way to learn data science from scratch
220,i am working on this shared task which is just a twitter sentiment analysis since i am pretty new to machine learning i am not quite sure how to use both training data and testing data so the shared task provides two same sets of twitter tweets one without the result train and one with the result i current understandings of using these kinds of data in machine learning are as follows training set we are supposed to split this into training and testing portions training and testing maybe but the existing of a separate test data kind of confuses are we supposed to use the result that we got in the test using the portion of the notraining set and compare that to the actual result notesting set can someone correct my understanding,using training data and testing data in a shared task,how do i use twitter data for sentiment analysis
221,hi reddit turning to you as i am really conflicted about an offer i have signed the employment contract for recently for context i am a ds with years experience based in a country with few ds opportunities my first years was being the sole ds doing full stack data engineering and data science at a startup and am now part of a small team at a large corporate doing more data science than engineering i am not too excited about my corporate job i do not see myself staying here for long and would quit given the right opportunity the right opportunity would look like learning both engineering and ds skills so the work of an mlai engineer being paid well enough to live comfortably really for my experience level the equivalent of k usd in my country having good worklife balance and working for a company whose product i believe in i am not in a rush to climb the career ladder and would rather comfortably gain skills to become a full stack ds and not burn out i dont mind staying at the corporate job and actively look for the right opportunity as well that said i have recently signed the contract for an ai engineer role for a scaleup i was headhunted for after so much back and forth with my current manager and the hiring manager at the scaleup even after this whole back and forth which lasted a week i still have doubts about the role i have signed formainly with the work life balance i would have whether it would be too senior for my experience level and whether being a scale up i would learn more ds than what i am learning now at the corporate there is no doubt i would learn more engineering in this new role but in terms of ds the corporate is quite dsmature applying mlops model observability bias and fairness productionising models easily with cicd etc the ai engineer role at the scaleup also has less welldefined responsibilities it was tailored to me and was initially a prinicipal ai researcher role which suggests that they would be hiring an ai engineer as a title but expecting some principal duties out of me apart from the doubts i have just mentioned it ticks everything else in my definition of the right opportunity above it is a role i would take if i had no fear however the fear of failing and underdelivering is crippling me right now any advice or thoughts on my situation would be so so appreciated,help deciding whether to renege an offer or leave,is ds the right career for me
222,suppose you are training a random forest model for a standard supervised binary classification problem suppose you have data from the past years standard kfold cross validation would use randomly selected samples from this data over the past years suppose you perform kfold cross validation on this model and the results turn out well for a safety check would it be reasonable to adittionally train the model with years of data and make a test set with data from the most recent year just to get an idea at how well the model fits the most recent data sort of a way to test how well your model adapts to concept drift if concept drift is present if this is also successful you then retrain the model using all years of data and submit the final model i have heard that adding more data generally does not result in overfitting overfitting is generally the result of model adaptability and model complexity is my analysis correct thanks,time dependent vs time independent cross validation,how to handle overfitting of a model
223,i am looking for some conversation data to test out some chatbot ideas for predicting what comes next in the sequence of a conversation can someone point me at stuff out there basic level daily conversational would be ideal nothing too jargonish i need not just random sentences but utterances in order is important the reddit datasets may even work but they do not seem to be threaded the daily dumps also often do not have the parent item so it would take a fair bit of reconstruction there was a corpus of pairs like questionanswer based on movie scripts but i cannot find that now however the conversations were not that natural as i recall this kind of stuff would be ideal actually this is actually for a learn chinese conversation bot i am working on as a side project i will just machine translate the material thanks,sequential conversation datasets,i am trying to build a conversation reconstruction model but i do not know where to start
224,i have a strong background in computer vision and i believe if i look at some tutorials that simply show how to set up a cnn in code i can figure out most of the theory along the way i have also studied a little bit about neural networks and some introductory theory about how convolutional neural networks work i googled and also searched on youtube but could not seem to find a quick tutorial that showed me how to set up a cnn in code by quick i obviously do not mean minutes but i simply cannot wait for hours of explanation that goes too deep into the idea behind cnn i am confident i can learn that along the way in short i am looking for a tutorial that tells me exactly what software to download how to install it and how to start training an image classifier straight away from that basic tutorial i can work my way to more advanced stuff but i cannot seem to find that basic tutorial can anyone here post a link to a tutorial which they believe is beginner friendly to those who have never worked with cnns before but have a strong computer vision background and a somewhat ok understanding of neural networks thanks,tutorials looking for a quick crash course in convolution neural networks,how do i set up a cnn for deep learning
225,i just started a part time masters program in business analytics i am currently a credit analyst with a psychology ba long story i am very fortunate that my work is paying for most of this but before i get too far into it i want to know from those already in the field how reasonable this would be for me to continue to pursue i have done very little in the realm of analyzing data really just some excel equations for reports i run for my boss but there will be classes i take in the future that will teach me r python ect but i do not currently use them for work i know by the time i finish i will have more experience under my belt in general been with the company a little over a year now but with no other data background how likely would it be for me to get a job in the field should i need to my company is on a contract that would end around the time i finish my degree in ish years i do have a genuine interest in the field but i am concerned that having a masters but not the experience might put me in a tough spot should i need to find another job when the time comes sorry for the long spiel any advice or insight would be greatly appreciated,getting into the field of data science,is a masters in business analytics worth it if i already have a job as a data analyst
226,hoping to get some insight from someone who understands the data acquisition industry my business has access to a fairly significant amount of realtime or near real time transaction data from australian brick and mortar retailers this data contains near everything pertaining to the transaction amount product payment method etc my estimation is transactions daily in varied industries i have realised that this data might have some value to industry researchers and data brokers and that there exists a potential startup opportunity however i have absolutely zero experience in these domains could anyone provide any insight on how data brokers and industry researchers typically acquire their data and how much such data could be potentially worth i have anecodetely heard of businesses in australia being paid c per transaction for similar data but this seems inordinately high,how valuable is arealtime brick and mortar transaction data,how do i find the best data for my business
227,hi i graduated with ms in business analytics last year and have been working with a bank top largest banks in the usa in the credit strategy team my work mostly consists of analyzing data and building strategies models i love to code but i am not swe i can solve easymedium problems on leetcode hackerrank i am usually on kaggle if i find free time won silver medal so far i want to broaden my skillset and move to a more challenging role so i thought of the following options to spend my time on learn aws get cfa certification build profile using kaggle i am not sure what to pick from these and how much they will help me in the future can someone please guide me on what to do next thank you,looking for career guidance,i am a new grad and i have a few questions
228,the authors of the paragraph vector paper describe pvdbow with gt paragraph vector without word ordering distributed bag of words gt gtthe above method considers the concatenation of the paragraph vector with the word vectors to predict the next word in a text window another way is to ignore the context words in the input but force the model to predict words randomly sampled from the paragraph in the output in reality what this means is that at each iteration of stochastic gradient descent we sample a text window then sample a random word from the text window and form a classification task given the paragraph vector i have a couple of questions why do you need to sample a text window before sampling a random word to create a batch why cannot you just randomly sample from a list of the form cat sat mat humpty dumpty wall where the first item in each tuple represents the paragraph if hierarchical softmax or negative sampling is used is stochastic gradient descent still used to update the weights in the network or are these optimization methods themselves,how pvdbow works,question about wordvec
229,hey i am soon to start writing my masters thesis and i am currently looking into how to solve a specific problem i am basically tasked with finding a solution to what could be considered floor planning for a warehouse i am not looking at shelves and single items within these shelves but large objects which are restrained by a other objects and b certain other factors such as availability of certain in and outputs think gas water electricity etc which are only available at certain areas in our warehouse in short where is the best place to put an object large objects often bigger than x meters in a warehouse xm with having restrictions in mind we have data on the positioning of other objects from the past years as in dimensions positions and required mediums now i was wondering what the best approach would be to analyze the data we have and suggest possible locations for new objects in our warehouse would this actually something ml would be useful for i am thinking that it sounds like something that would be possible using ml as we have data to train our model and have relevant data available think a abstract representation of the warehouse when it comes to judging how good a suggested position actually is then again floor planning and optimization has been done for quite some time before ml was even a thing i also figured that many relevant aspects and maybe correlations of objects placed in the past could easily be found using statistics as all the data is available as a big spreadsheet i do not want to say i solved my problem by using ml when in reality it is just glorified statistics my question boils down to is this kind of problem suited to be solved with ml or would i get better results by looking into classic floor planning thank you,is ml suited for simple floor planning,looking for a data warehouse solution
230,this talk is an introduction to deep learning with pytorch lightning we will briefly overview of deep learning fundamentals and then learn how to easily implement various deep learning tasks including computer vision and natural language processing all while leveraging the scalability and flexibility of pytorch lightning ari bornstein is head of developer advocacy atgridaiand pytorch lightning previously ari scaled microsoft is aiml global advocacy efforts as an open source engineer ari is computer science masters research at barilan university concentrated on ai and nlp with an emphasis on multidocument semantic representation summarization and coreference resolution he also holds dual degrees in history and computer science from goucher college follow ari twitter pythiccoder,virtual meetup intro to deep learning with pytorch lightning,free deep learning with pytorch ai
231,hi so i am really interested in getting into machine learning i am in my last year of studying an undergrad degree in history and am predicted a first i have been spending most of my free time getting my math and programming ability up to an undergraduate level having refreshed my college level maths i am now just starting linear algebra calculus and stats at an undergraduate level using online resources such as books and mooc is while also doing online courses such as dataquest and some courses on pluralsight edx and coursera andrew ng is ones etc i am deadset on doing this as a career and have really loved learning everything but having looked at some of the masters in machine learning in the uk most require a technical undergrad degree such as computing or maths i am still in the process of researching universities in europe canada and the uk but it does not look promising so far so are there any courses any of you are aware of that do not have these prerequisites if i can build a big enough portfolio and have enough relevant mooc certificates will this be useful in an application are bootcamps a viable alternative to a masters i am going to email relevant university departments but i thought i would ask here first lots of questions but i really hope you can help me answer them thanks in advance,how can i get into machine learning with a undergraduate degree in a nontechnical discipline,is it worth getting a masters in data science if i already have a job
232,these links about crosswords have all crossed my path fairly recently noah veltman made some interactive tools with the nyt clues and answers from michael donohoe charles kurzman and josh katz recently wrote what years of crossword history says about the language we use xwordinfocom which has the unofficial nyt box set crosswords and counting i tried to get the raw crosswords for myself to play with but they are a total pain to scrape and clean for analysis i am actively practicing my data preparation skills so i put a lot of work into making this a sweet little setup and i would like to share it with people who can do better analysis than i can in total i found about crosswords freely available online by my estimation is maybe of all published crosswords here they are organized and cleaned and reduced to their utter essence in a carefully designed bulk text format edit links removed please pm me for the dataset xdfilepy has a parser for the format and xdstatspy shows some example queries duplicate puzzles most common words the cost to download is one comment i would appreciate any praises or critiques you might have while exploring this data please share your scripts and discoveries no matter how small or whimsical maybe we can set up a script that generates a web page of statistics and outliers and other fancy stuff enjoy,dataset published crossword puzzles,can someone help me with my data set
233,trying to read through the tracking events guide by ga which is a bit confusing but thought i would check first to see if it is at all possible i want to track what sections users are clicking on a website like this content is categorized by different themes so firstly ga needs to track this i would like to see a pie chart of these themes views content is further categorized by content type article media book etc so once i have filtered ga by a theme i can then see the breakdown of content type views within this theme i would also like to see a breakdown of content types regardless of theme to give a complete overall view hopefully some of this is possible can you give me any pointers as to how this can be achieved,is it possible to do this,how can i track content based on ga analytics
234,gttldr see example notebooks below i am happy to announce that i finally finished cleaning organizing creating baselines and developing an automated collection pipeline that collects minutebyminute market data for cryptocurrencies it updates on kaggle every day and will keep doing so until the competition is over maybe even more the whole project took me a lot of time to develop and is not easy to maintain so please if you find this of value your feedback amp support is highly appreciated the competition as some of you know there is crypto forecasting competition is running on kaggle gresearch crypto forecasting in this competition we need to use machine learning for forecasting shortterm returns of popular cryptocurrencies such as bitcoin ether dogecoin we are provided a dataset of millions of rows of highfrequency market data dating back to which we should use to build our models on once the submission deadline has passed the final score will be calculated over the following months using live crypto data as it is collected autoupdating kaggle dataset to make things more interesting i created an autoupdating kaggle dataset that collects highfrequency market data for multiple cryptocurrencies updates daily on kaggle available for anyone to play with also i also released starter notebooks each demonstrating a different model or method for forecasting future returns this project was meant to be for the currently running crypto forecasting competition by gresearch however since it is publicly available i assumed many others would like to also have a look mimics reallife better than typical datasets this is a unique opportunity to work in a much more reallife setup than usual kaggle because the datasets update daily so if you mess up and overfit you see it tomorrow anyway this is an ongoing project that is also beginnerfriendly since it is highly documented many more time series financerelated notebooks will be released in the future so this can also serve as a first stop when studying time series analysis baselines amp starter notebooks cv modelhyperparam optimizationtime series modelsfeature engineering neural network starter ae analysis lightgbm starter analysis catboost starter written from scratch series agg xgboost starter supervised ae janestreet st ae janestreet st engineering transformer is volatility features reinforcement learning ppo starter about the validation grouptimeseriessplit in the making fork them as you please enjoy yourself auto updating full price datasets i created an uptotoday auto updating dataset which contains the full historical data for all assets of the competition so you can easily build models that utilize it the datasets are split to each asset since they are much heavier than the competition data the datasets have also been labeled as described in the competition overview and had been organized in a way that they are at the exact format of the competition data the goal of this is to provide a dataset that contains the full history for each asset currently the competition data goes back to this dataset contains data from even earlier auto updating daily due to the high volatility of the cryptocurrency market we should train our models on the most recent data available these datasets have a backend pipeline for collecting formatting and reuploading to kaggle they are scheduled to be updated daily every single day until the end of the competition preprocessed the datasets had been ffilled to overcome any missing values issue that is present in the original competition dataset the datasets binance coin bitcoin cash bitcoin cardano dogecoin eosio ethereum ethereum classic iota litecoin monero maker stellar tron gtbonus dataset i have also uploaded a dataset containing the most powerful source for predicting cryptocurrencies movement elon musk is twitter it is simply an updated dataset of all elon musk is tweets i must check if elon musk can help us win you can play with it yourself here technical details about the data for every asset in the competition the following fields from binance is official api endpoint for historical candlestick data are collected saved and processed timestamp a timestamp for the minute covered by the row asset_id an id code for the cryptoasset count the number of trades that took place this minute open the usd price at the beginning of the minute high the highest usd price during the minute low the lowest usd price during the minute close the usd price at the end of the minute volume the number of cryptoasset u units traded during the minute vwap the volumeweighted average price for the minute target minute residualized returns see the prediction and evaluation section of this notebook for details of how the target is calculated weight weight defined by the competition hosts here asset_name human readable asset name indexing the dataframe is indexed by timestamp and sorted from oldest to newest the first row starts at the first timestamp available on the exchange which is july for the longestrunning pairs enjoy yourself and thank you in advance for your support this is not an easy system to maintain,i created an autoupdating kaggle dataset that collects highfrequency market data updates daily related trading notebooks,looking for a mentor for our crypto market forecasting project
235,for my nd semester of my current uni year i was given these as an option for an elective course and i want to hear more perspectives or experiences from others in data science from what i could see regarding course information derivative markets and discrete time finance syllabus introduces derivative securities forward and option contracts in risk management discusses use of derivatives in investment strategies concept of arbitragefree pricing the fundamental theorem of asset pricing in discrete time pricing on the binomial tree following up from the course i did in semester portfolio theory whereas ordinary differential equations introduces linear systems of odes laplace transforms discusses boundary value problem as well as phase planes following up from the course i did last year linear algebra ampxb derivative markets also gets a followup next year for continuous time finance which strictly requires me to take derivative markets this semester from what i roughly gathered through a bit of research odes seem to be in this middle ground for application some have said that they do not really come into application that much some have said that the more advanced followup of partial derivatives equations are very useful when it came to optimization i also do find it odd that odes is only exclusive to the program i have selected statistical data science and that actuarial science students cannot select this topic and are forced to select derivative markets is the choice as simple as do i want a finance course or not or is there more to decide when it comes to making a decision between the two of these,which course will be more beneficial for an aspiring data scientist derivative markets and discrete time finance or ordinary differential equations,is it worth spending a semester learning about probability theory for data science
236,hey everyone i want to become a data analyst and then down the road transition into a data science career i have an applied economics bachelor is and a supply chain management master is i have learned r and python during school and also javascript on my own i have javascript frontend apps projects is my bachelor is and master is combination a good combination for this path field i started learning sql power bi tableau python on my own at freecodecamp is there a roadmap or anything for becoming a data analyst also my previous javascript knowledge and projects would help me in any way getting my first data analyst job a last question a company reached out to me with a supply chain analyst job should i accept it or just focus on the general data analyst path sorry if i am asking stupid questions,how should i start,data analyst career path
237,hi i have interviews in quant tradingresearch with a few trading firms and they have asked me to prepare for data science machine learning as well can you please guide me a single website that is a really good for interview preparation in data science i am asking for websites as i have only a few days and dont wanna spread too thin i am appearing for akuna capital and going by their hackkerank test they had questions pca linear regression k means clustering for ex for getting into sde at faang leetcode is awesome coz of the interview is dsa remaining os system design networking and programming language specific questions are the remaining of the interview,websites for data science interviews prep,data science interview prep tips
238,hi im not a data scientist so im hoping my fellow redittors can help me out here tldr want to compare lead data we buy from rd parties to our total website visitors all sources we believe that with that we can say something about how the market is behaving as we dont cap the leads we but and how popular our service is in a certain month with that we want to see how well our websiteonline marketing is performing so i said im not a data scientist however for my boss im reporting on seo data on a monthly base during one of our last meetings we had a discussion about the leads they receive on a monthly base from third parties my boss wondered if we couldnt do something with that number could we use the total amount of leads received to say something about the general interest in their service and could we then also compare that number to the total amount of website visitors to say something about our overall performance compared to the general interest in their service so question is is this the right data to find the answers to these questions if so question would be how would i report that in a graph just put the two next to each other and compare over years if not what are things we could do with the lead data more info about the lead data their are several websites where we buy leads from we do this on a monthly base and the offered leads are not capped in any way so from that weve the feeling that it indicates how the market is behaving in a certain month and how high in demand our service is that month this is an assumption we work with and cant really validate final remarks weve got yoydata im looking for a direction of what to do with this data i know we are working with an assumption but im curious to see if we can find a relation between the data points thanks in advance for your helpthoughts,help comparing leads and visitors,how would you approach this problem
239,i am interested in how chartio works under the hood as i would like to offer a migration service if you are an sme or cluey individual with a chartio implementation i would like to work with you on your migration to see how it is done pm or reply on the thread and we can then talk further i offer years of bi and data engineering experience that should help you get to where you want quickly i also know a slew of the bigger tools really well feel free to pass this on provide more suitable communities for posting or let me know where i should be hanging out to meet like minded chartio people,looking for an sme running chartio to help with a migration project pro bono,how do you guys feel about data engineering and analytics
240,i am making a regression model in r where the target variable is zeroinflated and continuous with a large variance i also have a credibility column that is continuous and is used as the weight all of the variables i am working with are categorical or binned ordinal categorical data right now i am bound to using a glm as i need to extract the coefficients i also need to explain why coefficients are removed to people with a non technical background ampxb the dataset has rows with being nonzero there are variables but total categories some of the variables have na ampxb currently i have been running a loglinked glm with a tweedie distribution and letting the glm do all of the encoding i have tried including all the variables and then testing removing one variable at the time the model with all of the variables performs the best in terms of gini aic and residual deviancenull deviance ampxb but looking at the summary of the model a lot of the categories within the variables are not statistically significant i have done a chisquared test for independence on the variables and it always comes up that they are dependent it makes sense that there would be some interaction between the variables but i do not know how to detect it with categorical ampxb should i create dummy variables for all of the categories before running the model and then do a pca or should i do an elastic net ampxb ampxb ampxb ampxb,what to do when you only have categorical predictors,how to deal with missing data in r
241,so i know this sub is constantly flooded with advice threads but my situation is different i think and pertains mostly to choosing a grad school i have finished an undergrad degree in physics and applied math from a big state school and have the following options to choose from these are programs i have already been admitted to rutgers msds stats track upenn mse data science simon fraser university ms big data canada i am currently an international student in the us and immigration is sort of a big deal for me canada is significantly easier to immigrate to once you have a canadian degree and the sfu program is also significantly cheaper almost half the price of rutgers or upenn i am really confused about which program to choose the rutgers and sfu programs have the advantage of a practical work component built into the program but upenn is just a better school overall canada is easier to immigrate to but does not have as many job opportunities as the us does anyone know anything about any of these programs or any advice in general i am pretty confused and have less than weeks to make a decision thanks,grad school choice advice,is a ms in data science worth it if i already have a job as a data scientist
242,hello i dont know much of anything but i do know i love data and information theory ive been jumping up and down with subjects and i decided to just double down and finish this computer science degree one lucky introduction i had was to tableu and data storytelling i dont really know if that is niche or not but telling stories has been a passion of mine using data to do so might be that route of selfexpression ive been searching for right is there any opportunities for a young southernafrican like me as far as i see it when you become a stats expert here you either work and stay an employee as a large chunk of your career making someone else richer or you work for insurancebanking idk do you think its a valuable career worth pursuing what if i want to migrate later on in life and lets say with a partner is data science a career employers are willing to hire someone from overseas for my dream is migrate to the netherlands with my gf im a first year though so far i like where im headed is data science worth it,data science for africans,is data science worth the financial burden
243,i am working on understanding vaes mostly through video lectures of stanford csn in particular lecture tackles on this topic and i think i have a good theoretical grasp however when looking at actual code of implementations such as this code from this blog of vaes i see some differences which i cannot quite understand please take a look at this vae architecture visualization from the class specifically the decoder part from the way it is presented here i understand that the decoder network outputs mean and covariance for the data distribution to get an actual output ie image we need to sample from the distribution that is parametrized by mean and covariance the outputs of the decoder now if you look at the code from the keras blog vae implementation you will see that there is no such thing a decoder takes in a sample from latent space and directly maps its input sampled z to an output eg image not to parameters of a distribution from which an output is to be sampled am i missing something or does this implementation not correspond to the one presented in the lecture i have been trying to make sense of it for quite some time now but still cannot seem to understand the discrepancy,question on variational autoencoders,why do we get such a big discrepancy in the vae
244,i see this all the time these days on linkedin and when you click the person has just finished up a data bootcampcertificatemasters etcalmost without fail the fact is these toolsskills are pretty universal and expected for entry these days so including them in your headline does not differentiate you as a candidate in fact it may have the opposite effect of making you appear that you believe knowing these tools is all it takes to do the job when in reality it requires a lot more business acumen presentation breaking down difficult concepts for nonexperts providing recommendations problem solving knowing how to learn new things fast etc plus it also draws attention to the fact that you arent currently employed in a data role because if you were your headline would more likely say data analyst at x so a recruiter sees that and doesnt click on your profile because they figure youre just another bootcamper trying to break in remember folks are always looking for experience the bootcamps give you some initial skills on which you can build but its crucial to sign up for upwork or do some volunteering or something to get that real experience that you can talk about and even better then your headline can say freelance data analyst or something that demonstrates you are developing experience thats what will differentiate you and in this oversaturated field these days differentiation is key,advice for newbies trying to break inremove the data analyst sql python r tableau from your linkedin headline,how do you know if you are ready for a new job
245,dear redditors could you please recommend some online course or material to build my maths base for ml obviously i need to cover the following topics linear algebra calculus statistics probability the problem i have faced so far is that almost everyone here recommends mit open courseware for these or some world renowned authors book for stats and probability which are amazing and i understand why but why is not there anyone in academia who is just targeting ml specific maths for online students i for one have only basic understanding of maths i have long forgotten whatever i learned in high school maths classes a decade ago would not it be great if someone could make me understand the above mentioned topics just the right amount for ml in an intuitive way so that i would not have to go through all those topics as if i am supposed to invent them learning ml with a black box of algorithm does not feel right and learning each of these math topics in deep scares the hell out of me is there a middle ground by the way programming is not an issue python is fun and easy i wish i could understand the libraries as well and not just tweak the hyperparameters with my fingers crossed,maths for ml,is it worth spending a semester learning calculus and linear algebra
246,i am a high school data science enthusiast i am having trouble coming up with extracurriculars that deal in the field of machine learning so far there is not many posts on drivendata a platform that hosts wouldata science competitions to build a better world how would this compare to kaggle i heard drivendata competitions are way more practical than kaggle for example drivendata hosted a competition that dealt with how to predict the spread of dengue disease which could obviously help a lot of people in thirdworld countries i want to further my education at a good computer science university like uc berkeley mit stanford or cmu so that means having strong extracurrics is drivendata or kaggle a good place to spend my time,drivendata vs kaggle,is it worth getting a masters in data science if i already have a job as a data scientist
247,i have a data set that i am wanting to do a certain type of analysis on as list of numbers in each row is given i basically want to group each number in different categories and then store the category in a counter type collection here is an example of what i am talking about now what i am wanting to do is categorize each number in each array in the digit range it occurs in so the first array would look like i then want to store that in the equivalent of a counter class in the collections module to keep track of similar occurrences in the data set then i want to also do the same thing except record if each number is prime or even what i would also like to be able to infer is the number of times throughout the data set a number appeared in the same array with another number histogram of sorts would it be possible to do this with not only another specific number but a range like when the number occurs it gets listed with a number in the range or amp of the occurrences i am using pandas to load in the data set would i need to use sci kit learn to do this type of analysis,new to pandas data science with python question on how to go about analyzing a data set in a certain way,best way to store a subset of a larger data set
248,tldr ball only ranged probably rigged and influenced by player market more explanation it is like a lotterybetting hybrid the more you bet the more you get you can buybet on any count of numbers you can bet on all but that will not be profitable rigged and nfluenced by player market the number least bet on by every player will be chosen for maximized profit for the house my dad is been playing this for decades and now he wins times more than chance i got decades of scraped data roughly data points or days as they draw daily i think someone with a math degree specialized in statistics and probability can totally do this i am looking into keras to build a model with input of integer ranged and an output of another integer or better integers ranged for the chance of each number being drawn,can my simplified version of lottery be predicted by a neural network,is there a name for this type of model i would like to use
249,i am from india and there is been sudden increased need for data scientists data engineers analysts and so on the stream has got so much prevalence in the last cour of years that universities are now providing masters in data science i am a petroleum engineer and seeing how the oil and gas industry is becoming more and more data driven i would really like to be a part of it as a data scientist or analyst but i have no idea where to start from should i consider a taking a masters or should i learn from online courses also please recommend softwares and programming languages that i need to get good at i would really appreciate it,education guidance,data science in the oil and gas industry
250,i am performing sentiment analysis using this dataset and i headed to kaggle to pop open a kernel and do some analysis but after searching kaggle i was unable to find the imdb movie reviews dataset actually i think i came across a few but they were not in a friendly format so i decided to upload this dataset myself here is a link to the dataset on kaggle no need to unzip and stuff the path is inputaclimdbaclimdb and this contains the train and test directories and all other samples and files that come with the dataset go pop up a kernel link to original dataset hope you find this useful my first post here great community love it here,imdb movies reviews dataset on kaggle,looking for feedback on my first kaggle project
251,hi all i am wondering if i could get recommendations for a data science degree or certification program i am using my workplaces educational assistance benefit program for this and the requirements are that it is less than over a twelve month period it results in an approved degree or certificate in data science personally i would prefer it to have as flexible hours as possible as working my full time job is still a priority i am based out of toronto but i also do not mind doing an online program as well if anyone has any recommendations it would be greatly appreciated please let me know if any more information is needed even just advice on how to search and filter for the right program would be helpful too thanks,selecting a data science degreecertification program,is a data science certificate worth it if i already have a job
252,i recently started at a digital publishing company working in ppc advertising my title is technical analyst for now but i see my end goal becoming a data scientist i worked as a mechanical engineer in hvac for years i did not like any of it and made the switch to tech a few months ago so my education is not directly relevant to the data science path i want to take so far i have been working with excelgoogle sheets to pull some metrics about our campaigns i built a keyword suggestion tool with python to help with our research and a little google analyticsdata studio as well i am planning to use sql with our data warehouse to get even deeper with reporting i am wondering if any of you are in the ppcdigital marketing field and what you have worked on in terms of data science i just want to set myself on the right path from the start and i am curious what contributions a data scientist can make in a company like mine,data science in the digital marketing field,data scientist to data engineer
253,posted this on rlearnprogramming with no replies so i figured i would ask here i have some data that i am currently collecting by scrapping a website each document is dated but they are all different times of the year they are roughly yearly updated but sometimes they are updated more than one a year also the yearly updates sometimes happen before the year starts which can lead to gaps of more than a year my question is what would be a good way to go about dealing with the gaps and having multiple documents in a year i am using python and i am trying to organize the information by yearthis is my first attempt at dealing with data i am having a hard time wrapping my head around how to deal with the data wrangling part there are k documents over years for every county in the us i am just looking for pointers on how to start not full blown solutions,need help with dealing with some data,how do you organize your data
254,hey all as part of an interview challenge for a analytical role i have been tasked with a scripting challenge using python end goal is to know what organization and location had the best results after they joined our company as a client i have csv files file contains organization_id organization_nameorganization_start_date file contains location_id organization_id location_start_date file contains invitation_id organization_id invitation_sent_at location_id then there is a folder with csv is containing reviews for all locations columns are review_id rating publish_date location_id organization_id invitation_id i know i will have to do some joinsmerges to get everything into one dataframe but i do not know what to do with these csv is seems excessive if i could get some guidance on what they would like to see that would be great i am going to be assessed based on technical soundness and depth business applications and insights curiosity structure and organization thanks for your help,whats the best way to get familiar with this data job assessment challenge,how do i find the best data for a job application
255,i have been accepted into a very good university to complete a masters of data science my aim is to work towards a career in automation this can involve machine learning movements in ai as well as a backup in an area like asset management my background is in mining is this a good move i am strongly considering it my hesitance largely based on having to go back to school at it seems like a degree my strong math ability will aid with in sticking out within my course it is hard to have a question does anyone have in comments on whether this is a smart move or other things i could consider doing alongside the course,following up a masters in data science after a chemical engineering bachelor,is a data science masters worth it if i already have a job
256,hello i just started studying statistics and i have accidentially taken a masters course in statistical programming in this course i have to code a linear regression in python but i cannot use any packages such as scipy scikit or panda numpy and random is allowed though i merely know how to calculate a simple linear regression by hand and know i have to code one with specific requirements i do not know if this is the right subreddit for something like this or of anybody is able to help me but if somebody was kind enough to give me at least some clue where to start at i would be very grateful the assignment goes as follows write a class my_reg for linear regression ie yxbetae for initialization of a new instance should take a matrix x of covariates and a vector y corresponding to the dependent variable as input and a keyword argument intercepttrueltbrgt the class should include methodsattributes for obtainingltbrgt fitted valuesltbrgt the resiudals ltbrgt r ltbrgt a summary of ttests for the coefficients and an overall ftestltbrgt methods for plotting the fitted values vs the residuals and fitted values vs standardized residuals ltbrgt a call method for predicting y given a new x vector of covariates,linear regression in python,how do i go about fitting a regression model to a specific variable
257,hi i have been searching through this community for different reviews from different course providers can anyone recommend anything in terms of learning sqlrpython ideally as a whole course i have found some stuff on coursera but majority of people on here wrote that it is heavily outdated so far the most decent stuff i have found is on dataquest and datacamp in general i would like to self study in my spare time for at least for an entry data analyst role from searching through job adverts lower grade jobs only asking sql stuff how much i will earn at the start is not relevant to me just want to learn decent base skills from reputable platform and work my way from there i am mech engineer by trade but trying to quit this route and do something else i have it background so i understand basic sql and python ampxb thanks,data science courses for beginner,how much do i need to know to get a job as a data analyst
258,i am currently a mis student it is not called mis where i lived but it is basically business degree with some it and like java and sql classes i was a computer science student before but it was back when i did not really care about school and dropped out because there was too much work now i am really motivated and i keep trying to find what i wanna do in life each day but afte a lot of searching i think i wanna go in data sciencebi or database administrator should i go for a master is in business analytics or business intelligence i read online that it is a lot better to go with mathstats or another quantitive field to get into data science since i am finishing my major soon i consider to go in the business analytics masters to go more technical and have a easier time to get into data science and also learn programming in my spare time i cannot to a masters in mathstats or etc because i do not have a stem undergruate degree but business analytics accepts people from a business degree is it a good idea have any advices for mei like math and i feel my major lacks math so i am kind of lost on what to do next i am willing to put a lot of effort to reach my goal,need career advice for datascience,is a data science masters worth it if i already have a job as a business analyst
259,hi there i just posted something similar in rgradlife but i figured i might find some more help here i wondered if anyone has any insight into msba programscareer paths vs mba w analytics concentration programscareer paths im about to graduate with an undergrad degree in business analytics the major is in our universitys business college so ive taken all of the general business courses accountings iii intro to finance marketing management etc while my major coursework has mostly focused on learning the basics of using python sql sas em and r for data analysis ive also used tableau for data visualization i definitely want to pursue more education involving analytics and im unsure which type would be a more valuable experience given my skill set im not as business savvy as say a finance or accounting major but im not as tech savvy as a computer science major i fall somewhere in the middle that being said im more interested in a path on the analytics side than strictly the business side and i enjoy the problemsolving aspects of coding and interpreting data the most any opinions advice or career experiences with msbambaanalytics degrees would be greatly welcome and appreciated,advanced business analytics degrees,is a data science masters worth it if i already have a job as a business analyst
260,i thought this would be an easy question with an answer accepted independently of the particulars so silly my particulars i have a relatively simple object detection task with about annotated images only a single category i do an split and even when i augment just x for each training image hv flips small rotations brightness changes gaussian blur motion blur the network is learning fairly well given all my other parameters i am using fasterrcnn with resnet backbone my next step is to add more augmented images per training images i had always though was a good number but now that i think about it this is sort of arbitrary and as i research it online i realize it is not really based on anything any advice suggestions for good literature or sites or simulations to look at about this i thought this would be easier i have a feeling i am using the wrong search terms or something,how many times to augment each image in training set,how do i train a cnn to recognize different lighting conditions
261,i am going to be doing unstructured data processing from pdf extracting data elements and classifying the data i am supposed to be leveraging a tool another team made in python i have since come to find out that it is all vaporware hacky code that probably has very little reusability i will mostly have to develop my own code the team that originated that code is telling me to do it in python they mainly used tensorflow tesseract and pdfjs i have never written a single line of python code unless you count printhello world lol i am comfortable with r and i see that there are r interfaces to tensortesseract what is the marginal return of using python for this project instead of r and is it significant enough to warrant the time investment to learn a new language to be clear i am not trying to get out of learning python i want to minimize dev time,r v python does the language i choose matter for this project,what is the best way to store and model a large amount of data
262,hey everyone i am one of the creators of sieve and i am looking for general thoughts on this problem part of what we are trying to do is build easy ways for software engineers and data scientists to interact with rich data imagine making queries and aggregations on videos in the same way you might with numbers and text right now the way we are thinking about it is to turn videos into something that works with the structure of a database like mongodb everything in an image or a video is an object even the frame itself is an object with a large bounding box and each of these objects has some attributes and can be tracked over time with some form of object tracking given that the objects are tracked they can each basically be returned as a timeseries of each of the attributes associated with that object a separate part of our api is a system that automatically allows one to define entities like people dog car cell dirty kitchen or any other object by making api calls in which they are basically providing labeling data that automatically trains a fewshot classifier on these objects our longterm goal is to build a general index over visual data and we think building a great query language great ways to define entities within the query language are important this can be the simple abstraction such that anyone can process and understand visual data such that they do not even need to know computer vision or deep learning for that matter ampxb find all intervals where a person is walking slow get all parts of the video where motorcycles are entering the intersection with speed greater than find all intervals of video with a clean kitchen,building an api query language for rich data like images and video,how do you deal with multiple objects in a database
263,i have a new site up till now i was doing adwords express only and per ga on th december i had organic search session visits there was no acquisition data for paid search on th i created a google adwords campaign and linked all the accounts up starting yesterday th december now for first time i see paid search in acquisition data paid search is at while organic search is at only looking at the campaign data it is now showing data from both adwords express and adwords here is it possible that till now adwords express search visits were being count under organic search my site itself is not really in top search results right now because the keywords i am targeting are very broad,jump in paid search sessions organic search sessions dead,is there a way to track only paid search traffic in google analytics
264,hi all i currently work at a mid sized bank london in their data governance programme this is my first job and have been on the programme for months i am looking for some advice around what i should be trying to get out of this job which skills i should be trying to develop and ultimately any insights around a data governance career in the mid term future i am sure the majority of people here will have exposure in a positive or negative way to data governance so was hoping to tap into that experience some programme background the programme itself does not require a lot of coding i can code in r python and sql and have automated some reporting tasks but this is largely on an adhoc basis the bulk of the job is sme stakeholder management and data governance implementation in terms of deliverables we are massively overhauling how data is handled in the company from implementing dq monitoring to creating data stewardship to streamlining data flows from front to back office the initiative has a lot of csuite buy in and i regularly run working groups at the executive director level questions and thoughts what skills experiences would you be trying to maximise how do i make this relevant outside of finance i would probably like to work at a smaller firm at some point with impact on wider data strategy transformation not just governance i am rarely working at full capacity maybe day a week how would to you use this time should i be trying to seek out more work to do in perhaps adjacent business areas i do not think i really need to upskill in coding anymore as i am at the stage where i can solve most issues i would face or figure out through googling what to do i am by no means an excellent coder but appreciate i am not good enough at maths to do anything too advanced so happy being good enough for majority of tasks in a non cs ds department this is a one year programme what sort of job should i be trying to line up with this experience general thoughts and opinions on data governance as a whole really appreciate any advice,career advice for data governance position as first job,how do you manage your ds projects
265,hi im currently working in bi at a startup that due to the nature of our service have a very seasonal use depending on some circumstances some of our clients will heavily use our product for a couple weeks and go dormant after that for a time thats not much of a problem for some of the charts and analysis i do such as use and conversion of our features but im having a hard time adapting others charts due to that seasonal nature of our product for example im trying to figure out the stickiness and retention for our various features due to the seasonality of use it seems like we have a very low retention and stickiness rate when in reality its just those dormant clients crowding the data i tried looking online for hints and ways to deal with that to no avail so if anyone have any hints or insights in how to best deal with that i would very much appreciate,how to circumvent seasonal use in data analyses,how do you deal with seasonality
266,hello all i hope you are all doing well i apologize in advance for any typos or areas in this post that seem poorly worded or organized i am on mobile and writing this post as i walk home some background on myself i am an undergraduate student entering my fourth and final year as a statistics major with minors in data science and american studies with the as minor being nonrelated to my professional aspirations i currently have two internships internship a for which i am employed fulltime this summer and internship b for which i am employed it is unpaid parttime during the school year internship a is a more data science position with my tasks including collecting data cleaningorganizing the data doing some eda on the data and some modeling with it as well for the purpose of causal inference internship b is more of a personal interest being an analytics intern for my universitys baseball team it is still dataoriented and i do a good deal of data collectioncleaningedaing but i would say my baseball knowledge is depended on more so than my analytics knowledge as for what i want to do for my career well aint that the question and i acknowledge it will be difficult to answer the question posed in my post title without a definitive answer here but ill do my best to be completely honest i dont really desire to do any more education past undergrad not that i dont enjoy learning i am just eager to get out and apply my skills and get a better understanding of what i do and dont know in the field i also dont aspire some big fancy ds job where im working long hours for a massive paycheck id much rather take far less pay to apply my skills in a concentration i enjoy as for what i enjoy i do particularly enjoy sports as they have played an immense role in my life a position as a data analyst or something similar for a sports org would be amazing though i dont have much experience with health care or really anything medicalrelated that realm excites me as well as i feel it is a great field to apply my analytical skills in a way that will benefit others in general im not looking to be rich i know ds and similar fields are great avenues to achieve that but thats not why i chose it i chose it as i always felt and still feel as if it is an amazing way for me to combine my personal and professional passions i do want to live comfortably obviously so compensation is still a big factor in my decisions all that said do you all think it would be necessaryworthwhile to get a masters degree i am confident i dont want to pursue a phd but i am very open to getting my masters if it will open me up to good opportunities i know it is possible to get an entry level dsrelated job with just an ug degree and work your way up to more prestigious titles but also know it is probably quite difficult to land a good first job with just that ug degree i appreciate your time spent reading this and welcome any and all input,what degree do i need for what i want to do,what are your thoughts on data science as a career
267,hey all i am hoping some of you can help me with a potentially sensitive question i am in the late stages of interviews at a firm for an analytics manager position i know it is not true data science but it is close it would involve a small number of direct reports it is a large fortune based in the se us i am not natively an american but i tend to pass for one i have noticed that all and i mean literally all of the folks i have met in my interviews up down and lateral in the analyticsdata teams are all eastern asian or indian i do not care about working with different cultures but it seemed a flag to me that there are no americans there should that concern me that working conditions are poor ie americans would leave under those conditions or is that typical in expanding analyticsdata science teams at this point,joining firm company culture concern,data science in the us vs europe
268,drug discovery includes looking for biomedical connections between chemical compounds drugs chemicals and protein targets drugs interact with biological systems on a fundamental level by binding to protein targets and influencing their downstream action predicting drugtarget interactions dtis is crucial for identifying therapeutic targets or drug target characteristics understanding and forecasting higherlevel information such as side effects therapeutic mechanisms and even innovative insights for drug repositioning or repurposing can all be aided by dti knowledge sildenafil for example was originally created to treat pulmonary hypertension but after its adverse effects were discovered it was repurposed to treat erectile dysfunction polypharmacy has also become a viable method among pharmacists because most human diseases are complex biological processes that are resistant to the activity of anyone drug drugdrug interaction ddi prediction and validation can sometimes identify possible synergy in drug combinations allowing individual drugs to be more effective continue reading paper github,researchers from nankai and stanford propose deepdrug a python based deep learning framework for drug relation prediction,research ai for drug discovery
269,i trained a ml model for binary classification on the test set observations i got the following results the binary class in the test set is distributed accuracy kappa sensitivity specificity pos pred value ppv neg pred value npv i think these results are good i think the sensspec is more important than ppv and the npv values given that the sensspec is decent the way i see it suppose there is a math exam with questions i only answer questions of the i answered i got correct my ppv could be seen as but my overall grade on the exam was only clearly the second piece of information is more important is my interpretation correct,can someone please comment on my model results,question about schoenfeld residuals
270,hello to start with a background description i am a college sophomore majoring in computer science and in a week or so if things go well adding in a mathematics as a second major in a university wellknown for my perspective majors computer science and mathematics classes that i have taken in college including current ones so far are data structures computer architecture operating systems algorithms research in computer architecture series sequences and multivariable calculus matricesmatrix calculations linear algebra probability differential equations with linear algebra and two classes of discrete mathematics one under the computer science department focusing more on graphs and another one under the mathematics department for my second major in mathematics focusing more on sets just last month or so i have picked up a high interest in data science because i wanted to do something that relates to both computer science and mathematics online i took several courses in data camp through the data scientist with python track but i feel that learning through a textbook would be better for me especially if i need something to reference to when i am doing practical applications i have a decent background in python though not my strongest language my strongest language is java but i also want to learn r as well especially when it is the most common language in data science from what i heard given my background what are some good books reference books textbooks that yall recommend for learning more about data science probably leaning more towards beginnerintermediate level since i have had programming experience with python but not much with the real data science part and no experience with r whatsoever please let me know as soon as possible thank you d,good books for learning data science python and r,what are the best resources for learning about data science
271,hey everyone i work in a bank and i am really sick of the way the banks use some of their strategies to sneak money out of the customers pocket i would almost like to classify that as stealing first of all i think a banks purpose should be to support a person financially however just because the company is profit driven money comes first and customer last the specific example that i would be using is around credit cards banks use low interest rate offers with the hope that some customers fall into this trap of becoming a revolver i have actually sat in conversations where people have said this they want to make sure that the information for them is not fully transparent so as to sneak in some fees or late payment fees etc anyway given how accessible information is these days i was wondering why there is no credit card app which would basically create a monthly forecast for you based on your real time purchases and budget to make sure one does not go overboard with spending the purpose of this app would be to make sure that people are more aware of their purchases along with the forecast telling them where they would hit their budget overunder based on history just wanted to hear opinions on what people on here think about this idea,credit card app,how would you go about building a predictive model
272,hi everyone so i have recently dived into ml and pretty much a newbie i am taking a course on machine learning this semester and halfway through andrew ng is course and reading islrintroduction to statistical learning with r on my own the one single thing that is bugging me is the extremely bipolar arguments when it comes to mathematics needed to become a successful machine learning engineer in the industry not in research let me elaborate that with examples my ml professor literally crushes and throws at us every piece of math and stat there is in ml whenever he is explaining an algorithm and that would involve threefour blackboards of proof i clearly see that such level of expertise would require at the bare minimum a year sequence of honours level real analysis several advanced probability and statistics courses and perhaps graduate level econometricsfor some part seems like only honours math and stat students are capable of digesting such level of mathematical rigour in the undergraduate level even honours engineering students do not take that amount of mathstat andrew ng and couple other online courses seem to assure that being able to have a shallow understanding of the ml algorithms is ok as you would be writing only couple lines of pythonr anyway right this kind of analogy confuses me further because anyone with a decent amount of coding skill would then make a good ml engineer but we clearly do not see that trend in the industry perhaps the best way to summarize everything said above would be asking the question for those who have read the books of course where do i draw the line between the books islr and eslr in the pursuit of becoming an ml engineer so far i am skimming through islr and not having much difficulty understanding the topics presented is it enough for my background i have taken linear algebra multivariate calculus a few elementary and intermediate probstat courses that uses calculus and taking one graduate level econometrics course along with the ml course apology for the big post but the confusion is driving me nuts tia,how much math really needed for machine learning engineers in the industry,is machine learning the right choice for me
273,hi in my job i need to single data source with all sales info about all the stores but my problem is that the website wich recolects the data when i am trying to export the excel with the info i need to download files for each store available the second problem is on the files the exact data that i need is paymen type and amount which are contained on file and the other data needed is cancellations offers and courtesies which are contained on file at begining i thought yo use visual basic un excel to join all files and extract data but i am stuck with this idea then i thought that maybe using tableau prep could be an option to clean files also i am stuck with this cause this files only contains info about a single store and totally are aprox stores and it means that daily cause this process i need to do it everyday i will need to download files is there a way to optimize this process please help me i am stuck whith this,help with automation process,need help with data cleaning
274,i am just starting out on the journey to becoming a data scientist and beginning to realize how long this journey will take i am encountering a catch though without experience i cannot get a good data science job or be accepted into good university programs without those things its hard for me to meet and work with other data scientists expert or novice when i do not work with other data scientists its hard for me to get better so as a result i am stuck with learning all of this on my own in my house this feels like the wrong approach i know i learn much better with other people how do i get around this what should i be doing instead especially to meet others interested in data science,what is the right way to go about progressing in a data science career,how do i get better at data science
275,i am bsms electrical engineer who has taken subjects such as statistics adaptive filters linear control nonlinear control c mysql and other general electrical engineering subjects year experience in embedded systems but i hate it i have a sponsored phd projects in big data machinedeep learning i have always wanted to switch to software flexibility of schedule remote work freelance with higher salaryearning so i want to be a data scientist correct me if my reasoning is not correct my expectations of being a data scientist are gather data especially in database try to model it if required find the patterns or predict future not much coding required i can do but i prefer not not much graphics involved i am bad at gui i am good at data analysis and modelling though,prerequisites of data science field,how much do data scientists get paid
276,hi all i am looking into product performance between august december for my company through some sql queries and tableau viz i have found that there are specific products that overindex for the miami region my next obstacle is figuring out why why is it that these products are overindexing so well in our ecommerce sales for miami but not nearly as much for our ecommerce sales in houston i have got all this data at my finger tips but being a pretty noob analyst i need some help as to how i can identify more details about my customer what can i look at in our order history that would signal something to me using order history data to build this analysis for more context it is a particular jacket that is performing very well compared to our total ecommerce consistently does well through december especially in august for some reason was not purchased on any discount various colors and sizes no significant differences excludes bulk orders any help in terms of what data i should look at would be greatly appreciated i seriously have so much of it its a bit overwhelming ampxb thanks,retail analytics why a certain product for a certain region overperforms,how do i go about identifying products based on their sales history
277,hello everyone i am a young undergraduate and i am a beginner in computer science getting to my question which is more hypothetical than practical imagine you have an unimaginably oh the irony complex neural network with billions of neurons and a strong enough computer to process it is it possible to achieve human accuracy on image object recognition only by randomising the weights and biases and thus skipping the training part to my knowledge this would imply getting close to that global minimum which is technically impossible through backpropagation this randomisation process is fairly similar to the bogosort and its kinda interesting to think about playing an odds game with a potentially great outcome thank you for your time and i apologise if my question does not make any sense,question about neural networks,how do i train a neural network to recognize objects in an image
278,looking for suggestions on how to define the following nlp problem and different ways in which it can be modeled to leverage machine learning i believe there are multiple ways to model this problem deeplearningbased suggestions also work as there is a good amount of data is available for training will evaluate different approaches for the given dataset please share relevant papers blogs or github repos thanks input given a sentence s having words w to w s w w w w w w w w w w the sentence has some syntactic and semantic patterns but it is not exactly freely written natural language but it is in english these are words can be punctuation ampxb output should be something like this label w label w label w w continuous semantically related means words w w inorder are assigned a label also okay with solutions that do not output inorder label w w label w noise w w means words w and w independently are assigned a label label w ampxb need to solve the problem looking for researchthoughts on how this problem can be defined in different ways to exploit different patterns in the structure of sentences looking for similar tasks which are already defined in nlp such as token labeling parsing which can be used would be really helpful to get the suggestions to the latest research on solvingdefining this problem,need helpadvise phrasetoken labeling,how to deal with word embedding in wlp
279,unique situation here im in the military and was accepted into a program that sends me to a prestigious graduate school for either an mcds or mismbida degree i believe we will be taking some sort of placement test to determine which the interesting part is that i dont have a math or science background whatsoever so i was floored that i was even accepted i studied german as an undergraduate and have never taken high school included calculus or statistics i have little to no understanding of what data science even is or what a career in it would look like as i browse this subreddit i feel like im reading a foreign language at times and not german because i know that one can you learn data science from absolutely ground zero can someone who tends to struggle with math subjects still succeed in a data science field what do i need to knowlearn on my own before starting this program i fear that im going to get thrust into classes that i will simply drown in because i dont have the background any advice is appreciated,help im going to school for data science but dont know any math,i have been accepted to a data science program and i feel completely unqualified
280,hey yall hope you are doing well so my background is in marketing just graduated a year ago after graduating i realized my degree was useless and experience means everything i got an internship doing general digital marketing learning about google analytics tag manager tableau etc and later got a job doing ppc ads i am starting to realize that it takes a long time to get to the top level in marketing and i do not want thatfrom the small taste of analytics i have gotten i really like it i did not like math in school bc it was sort of like accounting but i am realizing i really like logic and thinking strategically codingapplied stats seems to be something i am genuinely interested in and the fact that it is going towards something actually tangible to help people to get a position like that i would have to first learn pythonr and stats and use it in my current ppc job are there any people who have done this and can give me tips on what you specifically use your technical knowledge for for example there is someone that said they use bayesian models for keywords and monte carlo simulation for conversions i would want to start off at a more basic level but you get the point lol thank you,using statisticscoding in my ppc job,is it worth getting a masters in data analytics if i already have a job as a business analyst
281,i need some help with a unique job posting i am working on posting a job for a very wellfunded and successful firm that does sports handicapping currently all handicapping is done via manual process and excel sheets they are very successful but want to try and modernize and automate their workflow using whatever tools are available i am assuming some sort of machine learning or something we are talking web scraping data warehousing modeling analysis you name it my question is does this seem like the sort of thing that is doable by one person i realize that is probably hard to answer without knowing all of the details i feel like the job should be titled machine learning engineer but i am not certain how accurate that actually is,can you help me with a job posting is this reasonable,how do i go about building a data warehouse for my company
282,hello everyone i am currently a phd student in economics however reading page of research paper almost every day and writing is not my cup of tea i could finish the phd but not doing this as a career for the rest of my life also for personal reasons i do not see myself pursuing an academic lifestyle and after doing some brief internet search lurking in the background of some forums i am planning to pursue data science in a serious manner i had intensive training in econometrics and did some projects using large data gis but with very basic coding in r nothing fancy and systematic i was just relying on brute force of the computational power at work i absolutely love working with large data and coding in general i have access to any courses offered at almost all universities in switzerland including ethz and epfl so i am planning to take classes every year for the next years in data science i have signed up for machine learning deep learning big data what are the skills that you would recommend me to obtain what kind of projects that would be beneficial to me to develop as a side project during this time thanks everyone,phd in econs to data science,is it worth spending a semester learning r or python
283,hi i am working as a data engineerbig data developer currently with just months of experience if the field i work with scala spark and hive esentially in one of the fortune top companies i have always wanted to be a data scientist but felt that i can switch after i gain some experience dealing with large volumes of data as well how can i make the switch to data science in the next months i do not want to take a pay cut my salary currently much above an average fresheraround th percentile of those with less than yoe i have some experience on kagglenotebooks expert what else can i do to make my transition possible,transitioning from big data hadoop engineer to data scientist,how much do data scientists get paid
284,hello i am studying recommender systems and have questions about contentbased and contentaware recommenders usually examples are the following there is a database of movies where genres are assigned to each movie and users rate the movies then itemprofile and itemprofile are created usually with tfidf or something similar and predictions are made based on this but what if there are several parameters for example there are restaurants with parameters cuisine where restaurants provide several types of cuisine and customers may like several types of cuisine and a lot of parameters with discrete values allowprohibit smoking parking dress code and so on how parameters with discrete values can be used simply filtering hotels beforeafter prediction suppose there is more information about customers age race weight etc what is a good way to use it use this information as features for classification,need advice on contentbased and contentaware recommendation systems,how to deal with missing values in a recommender system
285,i have a factory process where there are several sequential process steps and each step has an additive impact on my metric for that product i am looking to build a good predictive model of this process to estimate the output metric knowing which process tools were used at each step so say the two red dice r and r have different distributions the two blue dice b and b have different distributions and similarly there are different distributions for the green dice g and g for each roll i know which dice were rolled eg rbg for the first roll rbg for the second roll etc and i know the sum of all three dice without knowing the individual value any single die rolled i want to build up my best estimate of the distribution for what number r will roll what number r will roll what number b will roll etc how would i go about building this model i might have some idea of the possible distributions eg i might suspect certain dice might have a distribution that is the sum of two normal distributions with different means but i would like to be able to evaluate the possibility of several different types of distributions rather than assuming the same distribution shape for each die i should also note that the data i am trying to model is actually continuous i just thought it is easier to visualize using dice as discrete examples your thoughts are greatly appreciated,new to machine learning i have got weighted dice two red two blue and two green each roll i pick one of each color and know the sum of the three dice but not the individual result of any one die how can i determine each die is weights,how to deal with missing data
286,hi im a year old graduate student living in boston i have a house here and i study biostatistics and epidemiology my career goal is do data science for help solve health disparities and use big data to help inform clinics and hospital systems about cancer treatments and teach classes on the side im at a crossroads as to what i should do next i finish my degree in a year and am wondering if i should do a fellowship or do a phd in data science the pros of the phd are that i love boston a phd would help me with my ultimate career goal but the cons are that it would be a significant investment of time and emotion the pros of the fellowship are that doing it would be really really cool and would allow me to be mentored but the cons are that im not sure if i can move to maryland because i love my life here and im not sure if i can be accepted i was wondering what this community thinks,do i do a fellowship for the federal government or do a phd,is a phd necessary to land a job as a data scientist
287,hi everyone just reaching a year into my apprenticeship with year remaining at one of the follwing ibmamazonmicrosoftgoogle i have begun thinking about next steps in terms of career being slightly confused where i stand applying for jobs in the future my role seems to more ba rather than da as i have had very minimal contact wtih sql i am very proffecient in exceldata visualisation having got the relevant certificationsbusiness application of the two yet the lack of sql is making very concerned applying for da roles in the future is this going to be an issue moving forward as i do not plan to stay with said company akward location for travel what would you say the most relevant skills needed are going forward that i should work on going forward what are the key differences between someone who is a junior analyst in comparison to someone with a couple years experience thanks ampxb ampxb ampxb,apprentice data analyst at a multinational organisation in terms of next steps for my career where do i stand,is it worth getting a masters in data science if i already have a job as a business analyst
288,i am looking for german datasets that include different subject categories with to questions each that refer to said category i want to test a text analysis module with larger datasets aiming for categories something in the lines of category ticket sales questions referring to that category where can i buy tickets can i cancel my ticket purchase how many tickets can i buy at once can i print my purchased tickets at home standard category answer for more information about ticket sales see website xyz i am only finding small faq datasets with one question per category thus far i do not mind paying for the datasets if they are wellstructured and machineready,looking for german datasets with thousands of categories and multiple related questions,looking for a dataset that contains all ticket sales data for the past few years
289,context i am trying to do a job switch in the next months i got an analyst job out of school last year at a small firm and as the only technical headcount you can imagine that i am learning and doing a lot i want to work on a team so i can continue to build on other skills working on git writing clean code etc since i am so early on in my career the firm has said they cannot add any more technical headcount for a few quarters so i cannot wait for that to happen my game plan is to sharpen my sql skills workpost projects on a blog amp connect with people on linkedin at firms i am interested in this brings me to my q i thought the new google data analytics certificate might be a good addition to my plan it looks to be mo and afterwards i can use it as a springboard to connect with more companies through their hiring consortium does this sound like a waste of time i understand that certifications do not get you the job which is why i am focusing on the first three things i mentioned i like courses because i feel like you do not miss out on anything that is super important and i still feel like i am in a stage where i can be learning a lot the main draw to me is the job board background bachelor in business with a concentration in ds know r tableau and currently learning sqlpython if you are more biased towards free content i would also like to know that in your response i typically am like that too but i know that some things can be worth the money,interested to hear thoughts on the new google data analytics certificate for a job switch google hiring consortium,is it worth spending time learning r or python
290,i am trying to build a candy sorter and my strategy is to measure a photoresistor is value when different colors of light are shined on a candy i am thinking i would shine some combination of redgreenbluewhite lights so my input would be between one and four photoresistor measurements integers between and my output would be bits that would map to outputs possibilities i am thinking this makes for a very simple neural network that would be a good learning experience to architect my own my question is what are some good resources maybe a tutorial to follow that i can adapt for architecting a very simple nn or what other types of ai maybe a clustering algorithm would be a good application for my problem above thanks,resources for architecting a simple neural network or other ai concepts that may be better for my application,how do i go about building a neural network that can detect different lighting conditions
291,hello rlearnmachinelearning i am a beginner at deep learning and i have a question regarding to loss function i am using sentiment twitter dataset which contains mil samples and after each epoch the loss only decreases a little bit something like x or maybe even x decrease per epoch is this small decrease normal or am i doing something wrong this is what my architecture looks like model sequential modeladdembeddingvocab_size dim_size input_lengthmax_len weightsembedding_matrix trainablefalse modeladdcudnngru return_sequencestrue modeladdbatchnormalization modeladdactivation arelu modeladddropout modeladdcudnngru return_sequencestrue modeladdbatchnormalization modeladdactivation arelu modeladddropout modeladdglobalmaxpoolingd modeladddense activation isigmoid if use_existing_weights modelload_weightsfilepath opt kerasoptimizersadamlr modelcompilelossbinary_crossentropy optimizeropt metricsaccuracy earlystop earlystoppingmonitorloss patience verbose modeauto checkpoint modelcheckpointfilepath monitorloss verbose save_best_onlytrue modeauto callback_lists earlystop checkpoint modelfitx_train_enc_pad y_train epochs batch_size callbackscallback_lists here is an example of what the results looks like epoch s usstep loss acc epoch loss improved from inf to saving model to weights_besthdf epoch s usstep loss acc epoch loss improved from to saving model to weights_besthdf epoch s usstep loss acc epoch loss improved from to saving model to weights_besthdf epoch s usstep loss acc epoch loss improved from to saving model to weights_besthdf epoch s usstep loss acc epoch loss improved from to saving model to weights_besthdf epoch s usstep loss acc epoch loss improved from to saving model to weights_besthdf epoch s usstep loss acc epoch loss improved from to saving model to weights_besthdf epoch s usstep loss acc,how much does loss function can decrease per epoch,why do we save the loss function for later use of the model
292,hello it is a bit of a rant here because i couldnt complain outloud and had instead to thank every single person i interacted with for this great learning opportunity because who knows what opportunities it might lead to but to be honest while it wasnt that bad i am a bit concerned context i had a paid summer internship this year penultimate year of master the pay was the minimum allowed by my country and it was a remote internship so in the context of covid i couldnt really cancel it despite knowing the drawbacks the internship was offered to statistics students this internship was one in which i had to build an app using pythondash and use it to visualise data there was also a couple of statistical tests that were used to notice abnormalities now i am not saying i did nothing but it was really far from master level statistics and the only real reason they got someone from a stat school to do it was because of the statistical tests but to be honest they could just pick up a bachelor level stats or dev student and have him learn what he was lacking this led to a situation where i learnt absolutely nothing sure i had to interact with people to build the app they needed but it doesnt mean i needed an internship to do that i am a fairly extroverted person and i can totally communicate and keep in touch with people to make sure i am building the thing they are asking for without needing any internship i acted professionally and they seemed fairly satisfied of both the result and the process i wish i had instead had the opportunity to work on some statistical models but it clearly wasnt the priority while i could take advantage of the internship to do it it would have been unprofessional as it clearly wasnt what the user needed in priority now this isnt that big of a deal but now i am really scared of ending up in a similar place where the most technical thing i can do is a logistical model for my coworkers it was their reality and they appreciated it i am not afraid in the sense that it is bad after all you get paid for doing something rather easy but rather that it would lead to stagnation this is especially true considering the unlimited amount of things i believe i have yet to learn that i cant use yet ulmfit for instance or other arxiv papers applications ampxb any tips would be welcome,i am frustrated i didnt learn anything during my internship,i feel completely unqualified for a data scientist role
293,hello ive read a lot of posts about people comming from different majors that want to get into data science a lot of those people arent sure about what steps they could take in order to maximize their chances at becomming a data scientist in this post i want to share my journey as someone with probably the worst major ever to become a data scientist note this is my journey your journey could be completely different this post just showcasses a way a person with a wrong major could work hisself into the data science field year psychology had no idea what to do passed all classs but nothing more st half of year psychology halfway year i came to the conclusion that i was in the wrong major wanted to quit my major and start another major in computer science study advisor told me id better finsih my bachelor go from a premaster to a master in data science at this point i was completely freaked out and doubted everything about my academic career every minute i spent on psychology felt like wasted time so i had to do something about it i decided it was time to take learning into my own hands and to not just learn the subjects my university major suggested me to take nd half of year psychology after a massive search online for what was needed to become a data scientist i decided i needed to learn python i followed and completed an online udemy course in python in my free time summer before rdyear prepared myself for calculus i wanted to take next year rd year of psychology started a minor in computer science learned sql and some basic data science algoritms in python the online course helped so much followed an elective matrix algebra followed an elective calculus followed an elective vector calculus th year planning to do a master in data science altho im still behind i think my journey could send a sign to companies that im willing to learn right now im doing a minor in computer science where i learn sql data mining in python simple regression amd classifocation problems and some introduction course for java im also taking extra courses in matrix algebra and calc,my road as a psychology major to data scientist,is it worth getting a masters in data science if i already have a job as a data scientist
294,dear community i will be as concise as possible i have been looking for work for the last two years and i have not been able to attain a decent job i got my master is degree in political science at an american university where i learned how to conduct analysis with r since i graduated i have been tasked to do a couple of side gigs where i had to use r and they pay more than what i currently do journalist i want to exploit this trait more but i feel that most of the jobs in the us canada and europe demand a data science background do you have any suggestions of what i can do to take advantage of my r programming skills should i arbitrarily undertake another postgraduate stint with a data science specialization thank you in advance,what to do when you know how to program in r but you majored in political science,data science career advice
295,hello all i was wondering if i could pick you guys brain regarding getting into a data science career path i am a cs degree holder currently working as an administrative assistant at an international organization i am one of those whose been in the us under a nonimmigrant visa which allowed me to go to a us university while working as an administrative assistant not the same organization mind you this also means that i was not able to qualify for opt so i graduated with a cs degree with years of admin experience and needing an hb which made it very difficult to get a job in the field fast forward to now i was blessed enough to have a manager who would like to utilize my cs background whilst being an assistant during our recent checkin she mentioned something about data science and how much it is in demand within our organization she said that i should look into it as it could be a path for me to jump to a different ladder this made me very interested in data science as i really want as i feel like this is my opportunity to finally utilize my degreebut unfortunately i do not know where to start currently i am taking some online training for stata which is a program that we are using for a project i am involved with with her and other people we have a research assistant within the team that takes care of the data but i want to be able to step up and act as a backup in case she is not able to take care of the data also i am set for a couple of online training for python and r is this too much i guess in my attempt to look like i am interested i am trying to do everything i also looked into the data science specialization through coursera but wondered also if that is worth it or too muchi do not know i would just hate learning something and not being able to use it just like my cs degree anyways thank you all for your time and i look forward to you guys feedback,advise on how to proceed towards a data science career path,data science bootcamps
296,i know the general jist of this question is asked somewhat often so i will try and be as specific as possible for my situation my background is a bachelors in finance from a state school no masters or phd i have been working at a hedge fund since graduation with a minimally analytical role i have been teaching myself coding concepts casually for a while now in a hobby type way however i have decided i would like to revitalize my career and find the data science field particularly interesting and a good merging of my interests at first i was considering an online bootcamp so i could keep my job while getting immersed in the field with some career help i have since come to the conclusion this is probably not the best use of money and i should probably dedicate the same time i would have to free resources let me know if you disagree with this assessment my new and improved plan is to spend hours per week for the next to months studying across datacamp udemy coursera and others to build up my skills eventually i would like to switch career paths i am aware that my educational background will be limiting to my options but this is fine i just need a foot in the door of the industry and can work my way into other roles but to get started what are some roles that i could look into and eventually apply to without getting my resume thrown out on the spot i would like to know what i am aiming for while also being able to look up job postings and making sure i am learning things that match up with what is being sought in my area thanks in advance for any help,what are my options within the data analysisscience field details inside,data science career advice
297,resume hello everyone i realize resume review might not exactly be allowed on this sub so please excuse me if this is the case i would really appreciate some critique on my current resume as i am about to be reentering the job market and looking for my first serious data analyst position i think it is passable but i would love some input from everyone here to help me take it to the next level some notes about my backgroundresume i feel as my formal education is largely irrelevant i graduated with a bachelor of arts in an unrelated field filmart business studies and have been selflearning python software design machine learning calculusstatisticslinear algebra etc for the past few years i am not entirely sure how i should explain how i am self taught on my resume or whether that is even worth mentioning or leaving to my cover letters that being said i am currently enrolled in a night studies certificate to learn more about stats big data technologies etc i have hyperlinked text in the pdf to github repositories showing my code for projectswherever its mentioned is this common practice if anyone would like to give me feedback on my github work i would gladly dm you so you can take a look i am applying to data analyst positions that are a match to the technical stuff i want to be doing python sql but i am also interested in any entry level data engineering roles as well how does my resume fare for those as far as programming languages go i only know python and sql but i know them well is a lack of r or any other general purpose languages a glaring omission in anyone is eyes any advice for landing a data analyst position would be greatly appreciated i know there is no way i could land a data scientist position yet at any decent company anyways so i am not even shooting for those thank you,please critique my resume self taught applying to entrylevel data analyst positions,data analyst resume critique
298,i was sitting waiting for one of my classes to start and began to wonder about what entailed data science and why it is always a complex debate i am not asking us to debate what data science is in a normal sense but i did have some questions that came to mind what is the fine line of a programmer aiding operations of a business by developing systems to improve efficiency is data science more about taking a scientific researcher mentality to numbersdata and organizing it in such a way it is easier to assess and analyze if i take publicly available data and develop an algorithm and plot this data in a meaningful way where is the line between being a statistician and being a data scientist or what about being just a data analyst i have posted before in this subreddit and i love all data i have been doing information analysis for the military for almost years now and love every minute of it i cannot wait to apply my personal experiences in a more data oriented way thanks,a fine line of what data science is,is data science easier now than it was a few years ago
299,this felt a little long to post in the weekly thread hope its okay to make a standalone post anyway here goes i started as an analyst on a data science team at a nonfaang tech company several years back most of what i worked on was descriptive analysis studying churn and anomaly detection i never built a ton of models and did not productionalize any of my work i really wanted to move fullon into a data scientist role but i did not see a good path on that team due to management etc i then moved into a specialized area of techengineering that i love and have been in for about years i continued to do analyticsheavy work in this domain when i could and my work mostly bordered on what i would call data science i have gained a lot of experience both in this domain and have worked to further my data skills grad school projects etc and just landed my first actual data scientist position doing work in my area of speciality i could not be more excited but i am also absolutely terrified it is a small company and i will be their first data scientist i am worried i am in over my head and that i will not be able to deliver results i have successfully built out and been a tech lead for a small team in my area of engineering so i am fairly confident in my soft skills and ability to help push projects forward but i am very worried i will not be able to wow everyone with data magic or do really complex modeling as i am ramping up i have come to prefer simpler models anyway but i am worried my skills will not be up to par for being the sole data scientist has anyone been in a situation like this what can i do to ensure the best chances of success not only for myself but for data science as a whole at this company,first data scientist job after experience in other engineering field how to succeed,data scientist to data engineer
300,so i do not if these kind of posts are appreciated but i have seen some questions about starting a data science career and i thought it would be helpful if i share my experience and hopefully provide some insights please excuse me for my bad english it is not my main language also this is from someone who worked in several countries in europe so let is start with how i became a data scientist i do have a bachelor degree in biology and during one of my internships i had to learn r to analyse large amounts of data i took a course online from coursera and followed some youtube video is this was in btw and worked my way to a degree after receiving my degree i started looking for biology wouldata jobs and found out there was actually lot is of interest in wouldata people in other fields i started at a small company doing some basic analysis and to be honest it was there that i found out that i seriously missed a strong statistical background after months this company decided it was time to cut people out due to reorganisation leaving over of the people without a job including me somewhere i did not feel bad it was clearly too hard for me i learned basic ml principles from coursera course and i just started with python but i knew i did not had a future there i decided to move to a bigger company where i spend three years i did etl work doing some data curation and visualisation to be honest it was not a challenge they called me a data scientist but i was not even close to a data scientist i survived for three years and quit my job to start at a position where i could grow as a data scientist i applied at a bank which promised me loads of data science stuff but it was way too corporate for me i was nowhere near data science only doing data analysis very simple data analysis and waiting meeting waiting meeting etc the salary kept me there for a year when finally a real data science position was offered to me i joined this company years ago so this is the big problem with becoming a data scientist by following courses i was too skilled for some easy data manipulation and etl work or let is just say i found that very boring and i am not skilled and knowledgable enough to apply ml techniques i mean i could easily build a ml pipeline in python deploy it to production but the job asks so much more one simple example is picking an algorithm it is easy to pick an algorithm but tuning the algorithm and explaining why is something different and that is a very simple example i was lucky to have three senior data scientists with me who explained everything but to be honest it was very difficult i just miss a statistical background so this leads to the biggest problem thinking of new products and making and impact on a business without that knowledge i could not think beyond isimple stuff i was not skilled enough by now i followed more courses even a shitty data camp course read a few ml books but it was not enough one other issue is my role in the business beside the whole statistical issue there was also my personality i am really introvert or shy whatever and find it difficult to confront people or to be rude in meetings in most corporate companies you have to chase your data it is easier said than done for me even deploying to production environment requires chasing and lot is of talking it was very difficult for me when i make an overview of my work last two years it is meetingstalkingchatsemail data gathering requirementsdiscussing new products programming i think less tbh i concluded that a data scientist in a bankcorporate business is more of a business guy not a programmer which i wanted to be so i decided to quit my job and i am without a job by january i am walking away from a k salary and going to zero and i was not even fired so you might understand how difficult it is for me to be saying to myself that i am a data scientist for five years and finding out i am not good enough i hope this story helps with people starting a career in data science i want to provide some tips courses help you gain basic knowledge but please open statistical books first there are several posts on reddit and google ofcourse with great books but please start with statistical books master it do the exercises and study the books pythonr will come promise remember it is business first a few people care about the algorithm but if you do not have value for a company it is gonna be hard learn how other data scientists created there architechture how to deploy develop api etc it is essential if you want to be a value to your company when applying to a wouldata science job make sure it is not just the title you receive and look beyond the job description what are they actually doing with data already can you be valuable or do you have to set it up is it really data science or business intelligence plus looking at kaggle helps a lot i enjoyed programming in notebooks and stuff like that but you have to learn how to implement code in a production environment once again look up on how to deploy your products learn how to communicate being a data person requires clear communication it is not just writing an email it is how to behave in a company and you have to become the person who get things done that means communication and i would advice to read some books on how to do this obviously motivation helps for me i got demotivated after a while because it is was too hard also data work was not very tangible i google the word tangible so i hope this makes sense simple but i came from nothing i learned everything myself and went to a very nice salary imagine what you can do if you are motivated sorry for long text all the best,failed data science career,i feel completely unqualified for a data scientist position
301,i am a final year bsc compsci student that wishes to develop skills that can be shown to employersmsc admissions dsml i have narrowed down my final year project options to the following options but am struggling to decide on one i would really appreciate some advice kaggle guipreparing entries to kaggle machine learning competitions importing dataset trainingvalidation subsets preprocessing amp extracting features classify depending on domain statistical significance test eval data visualisation modelparameter settings amp saving capability sentiment analysis twitter feeddocument positivity etc thought about politicsmedia but read articles warning about inaccuracy provides a lot of scope imo building a reallife arecommender system eg amazon movie reviews sites build system to perform against alternative implementations with solid software engineering ppssible to test it on real users eg plista is api some context rd party packages amp libraries allowed i study nlp algorithmic game theory information retrieval amp network security as part of my course beneficial if topic has a lot of current material as can be used as research i want to make something robust we have to present it tldr kaggle guisentiment analysisrecommendation system,which project would you choose if you were me,is it worth spending a semester learning machine learning
302,hi reddit i work at a startup where we want to provide model training as a service we use sagemaker and s for our model training and datamodel artifacts saving we can even automate the whole pipeline with sagemaker project but for data model training or deployment we want to provide it as a webservice where users can use their data for training i am not a backend engineer and a very junior data scientists want to see if you have some insights or experiences on the right approch for learning sagemaker i found it is quick complicated with so many different ways to do the same thing sometimes and hardly any good practice and friendly to beginners how long does it take you to get comfortable with sagemakerwhat resource would you recommend i just bought this book learn amazon sagemaker thanks for all your help in advance,how to enable ondemand model trainining with sagemaker,best practices for training and deploying models
303,hoping for some advice if anyone has experiencedsolved this problem we use segment for everything tracking events on the website and sending to ga fb pixel etc i have tried a number of things and i cant get ga to report accurately on transactions or revenue it counts transaction ids and order values multiple times so for example a order might be counted three times so ga says its a order ecommerce is set up based on the segment order completed event not on a destination url so users refreshing the confirmation page shouldnt be the cause of this segment is also not sending the events multiple times as all segment events are sent to bigquery and theyre not duplicated there any insight or advice would be appreciated thanks in advance,google analytics amp segment,how do i track multiple events on google analytics
304,i am learning timevec embedding reading seminal article from kazemi et al it says for a given scalar notion of time  timevec of  denoted as tv is a vector of size k and mathematical definition so tau is a numeric value to express time more precisely time since a starting point in any scale seconds minutes days weeks but when i read examples like it seems to me that they use data as input to time embedding this is if data is ampxb timesheightcm the examples use height values to calculate the embedding and i think it have to use time column q am i right that embedding has to use the time column in posicional embedding for transformers the posicional embedding have same length than text embedding so both embeddings are added q how can i combine raw data height column with time embedding i can imagine the concatenation of time embedding lets say of k length and height data of lenght so the result it will be a k length vector perhaps adding to each item the measurement i have not found an explicit example about this q how can i combine multiple data ie several sensors read at same time with time embedding if concatenation is the answer then substitute time stamp by time embed and later concatenate the rest of data in same vector example ampxb timesxcmycm t gt time embed eg input vector or like in transformers with textvec adding value into embed and repeating for each column used input vector ampxb thanks,understanding timevec,time series embedding
305,natural language processing is pretty much exactly what it sounds like its an umbrella term thats used to refer to the ability of machines to process and understand language as its written or spoken by human beings while it would be nice to think that our languages make logical sense and follow basic rules of grammar and punctuation we all know thats not always the case we use slang proper nouns abbreviations and acronyms and not everyone can string a sentence together like stephen king or j k rowling thats where natural language processing comes in loosely speaking its a form of artificial intelligence thats all about trying to analyze and understand either written or spoken language and the context that its being used in a basic example of natural language processing in action is the predictive text that we see when we use our smartphones as we type our messages the phones operating system uses ai and natural language processing to try to guess at what we might be typing and which words might come next natural language processing isnt perfect as youll have seen if youve ever used a tool like google translate but it is pretty powerful and getting better all of the time it can even be combined with machine learning to create a system that can not only understand whats being said but which will also continue to improve the more its used a great example here is google assistant which gets better at understanding and responding to the commands of individual users this can come in useful if you have an accent or a speech impediment and its all made possible by a combination of natural language processing and machine learning ampxb source,an introduction to natural language processing,what is natural language processing and how does it work
306,i am using sklearns tfidfvectorizer and i want to make a tfidf in order to capture the essence of some wikipedia articles this means i want to obtain only the meaningfull words while dropping the rest the corpus size is k documents while i am aware of the principles around document frequency i was curious what would be some good max_df is and min_df is amounts my idea so far is that min_df should be around of the documents and max_df around i am leaning towards this scheme because i want the essence of the document not extraordinary terms nor garbage terms but with those amount i am getting pretty terrible terms but i am not using a stopword list either because i would like those terms to be removed by the df filters but i am considering using one in any case any thoughts,while building a tfidf determining a good balance between max and min document frequency,how to deal with large amounts of tfidf
307,i was wondering if people had recommendations for nontechnical books ie not a programming manual about data science something along the lines of signal and the noise by nate silver i just finished weapons of math destruction by cathy oneil in the book she outlines the roles that modeling and forecasting play furthering inequality among other things she uses examples of models certain data points like credit scores are increasingly used in every aspect of our lives she walks through a digital lifetime of elementary school college career and health that bad models have the potential to impact she also discusses her view on how modelers can be more just and improve with transparency i thought it was an interesting read and would recommend it,nontechnical books about data science,is data science for me
308,ive recently come across something which im not sure what to call and i was curious what people think it sounds like data leakage the scenario is something along the lines of the below hypothetical you are trying to model a future dollar value of people people who go to college vs people who dont go to college have such different values on initial data exploration that you decide to make two models one for people who went to college and one for people who did not lets say just hypothetically that the expected value is x different between the groups you use only data that is available when people are except you partition on if people ended up going to college if people ended up going to college is a future day value and would not be known to a model when you run an year old through it when they are in reality lets say you are only able to assign if a person will attend college with accuracy by using human judgement outside of the model the assignment to a college or noncollege model is done with only human judgement thus you do not aways use the correct model this seems like leakage as your model was privy to future data it should not have had namely if a person ends up going to college which at the time of being you only know with accuracy im curious about learning more about what this is and how to work with it even though this sounds like bad model building and cheating if it performs better than model without the college partition is it still ok to use are there any ways to mitigate issues like this,could a model built with leaky data still be ok to use in production,how do i go about building a model that is neither too dumb nor too sexy
309,i have a single layer cnn to perform binary classification done in keras i want to see what the regular pattern that is separates the samples that have a label vs a label sample label sequence convolution modeladdconvdrepeat_lengthstridesstridepadding isame input_shapeshape activation arelu i have plotted the bias of the convolutional weights that have been learned i am told that this is a good way to see the pattern that is being recognised and distinguishing vs labels however i am told that i must make sure that the weights of this convolution are normally distributed so i have plotted a histogram for all filters weightsmodelget_weights weightsmodellayersget_weights printweightsshape weightsweightsreshape fig pltfigure ax figadd_subplot y weightst mima for w in y mimaappendmaxw mimaappendminw x nplinspaceminmimamaxmima for iy in range offset iy nnphistogramyiynplinspaceminmimamaxmima axplotxnoffset lw zorderiy axfill_betweenx noffset offset lw zorderiy pltsavefigweightspng ampxb imgudgnop can i assume that from this graph that the weights are normally distributed and hence that plotting the bias will be a good representation of a pattern in the data,checking if convolutional weights are normally distributed is the bias representative of a trend in my data,how to train a cnn with a nondifferential distribution
310,hi everyone i am currently a sophomore in college having a bit of a midcollege major crisis i went into college intending to major in cs and have been through a fair amount of the curriculum my problem is that i realized that i do not want a job that is just programming and that i maybe needed something that placed more emphasis on math and data that is where i came across my school is data science major the good thing about the data science major is that it seems like a nice middle ground for me and it actually sounds interesting unlike a software developer job and other things in that realm although when i search the internet i tend to see skepticism towards the idea of a ds bachelors although i cannot find much discussion on it at all additionally the major was freshly introduced in the fall so there are not any people who have been through it that i can talk to i could also go for a statistics major with a cs minor which i already have the classes for but it would set me back quite a bit in comparison to the ds major which shares more early requirements with cs due to the programming portion of it i am not sure if that tradeoff would be worth it but that depends on whether the ds major is of any decent worth in it is own right so i figured that i should ask some people with actual experience who may provide further insight than any sort of college advisor i can talk to if you are interested in taking a look here is the major requirements,what do you think of a data science bachelors,is a data science major worth it
311,hello boiz ampxb im done with my masters and im starting to get into job market again so im looking forward a position in data sciencedata engineering as my country is a small one so we do not have huge gaps between those two professions and most of the time specialists do a bit of this and that i have basic knowledge of sql select simple queries simple subqueries case statements joins and i also did few courses on intermediate sql correlated subqueries stuff like that but i did not learn much from intermediate i just got familiar with it few questions a does sql language work the same on different programs sql server mysql apex sql etc b is my knowledge enough to pass the interview or i should dive deeper into idk text splitting crazy big queries and stuff like that c where i can learn some good intermediate sql i have datacamp access im working on course fundamentals in sql anything else ampxb thxxxx,landing a job with sql,how do i know if i am ready for data science
312,i am sorry if this is not the right place but hopefully wondering someone can help i got a ms in developmental psychology my adviser left the phd program i was in and left me high and dry no one else wanted to advise me so i left after getting no help with my dissertation i have stats and methods skills that i have used with my research and i have also done gsr is with these skills and my employers were very happy with my work for them well i have tried to apply to about jobs in the last couple months stating my skills and i have not even gotten an interview could someone help point me in the right direction as what to do my stats skills are pretty much univariate and multivariate stuff little r and little python both basic mostly used spss i am not expecting some k salary right now i just need something to help me start my life and start paying back my loans anyall advice is welcome life has been really hard lately i work door dashcook in a kitchen thanks guys,help with jobcareer please any advice i would love tyvm,data science career advice
313,i get why dsml folks at faanginternet companies are interested in general algorithms it is just data with a low cost of being wrong selling wrong ad is not too big of a deal so i imagine these folks are not as interested by the domain but for other industries where the cost of being wrong is high medicinepharmaenergydefensefinance you need to know more than pure mlds at that point i feel it is about augmenting the underlying domain problem with data than a pure black box approach some consequences of this not as up to date with the latest mldsai research gt harder to get into an internet company if you wish to make the move harder to change into another job bc you are too entrenched in your domain and point lower pay analyticsds will never be the main focus unlike faang domain experts might view you as it gt political battles tech at those companies might be really poor you really have to enjoy the domain and willing learn more about it otherwise it will never work currently i am enjoying my domain but faang pay makes the opportunity cost hard for me to ignore how are the rest of yall thinking about this,how import is domain to a data scientistml engineer,is data science for me
314,i want to build a simple book recommender using surprise library and purchasenot purchase as rating value instead of the classical to my problem here is that i want to train on my whole dataset so i can get predictions to all users so i was checking this surprise example examplestop_n_recommendationspy from collections import defaultdict from surprise import svd from surprise import dataset def get_top_npredictions n first train an svd algorithm on the movielens dataset data datasetload_builtin amlk trainset databuild_full_trainset algo svd algofittrainset then predict ratings for all pairs u i that are not in the training set testset trainsetbuild_anti_testset predictions algotesttestset top_n get_top_npredictions n print the recommended items for each user for uid user_ratings in top_nitems printuid iid for iid _ in user_ratings my doubt here is if it trains on the whole dataset why is it building an antitest how can i get recommendations for all users and at the same time train the algorithm on my whole dataset,get predictions for all users with surprise svdpp algorithm,how do i train a model that learns to ignore outliers
315,greetings i would like to ask for advice from this community i am entering the world of ai and while i am not completely new to probability programming or automation i have a lot to work on luckily there is alot of online content to help with studying but time is limited so i have to focus my efforts obviously i should learn ml algorithms and libraries for python only right now but i believe there is more to it than that what i would like to ask i do not come from a cs background the most i have done is programming some microcontrollersvectorial calculations with matlab is it beneficial to invest time in some software engineering course to make it easier to develop scripts or is it overkill as a ml engineer it would be a significant time investment is it possible to start a career in ml without data manipulation tools something like sql spark i intend to get to them when feasible after starting to work but is it a necessary precondition for the job i have not been able to find a conclusive answer by just looking at job ads or kaggle is python used in the industry or are other languages preferred i only really know c but i am not even going to try with it i want to thank everyone who takes the time to read this and even more those who answer,seeking advice for learning path,is it possible to get into data science without a degree
316,so i currently work as a data analyst but at a fairly basic level ie looking at trends and patterns using excel and process mapping but there is no progression in my current department a new role was advertised yesterday for a data manager at a much higher salary than i am currently on i doubt i will get it but i have to apply anyway as it is either this or looking outside my company i have used spss at uni and have a basic grasp of sql and python is it possible to learn data mining in a short space of time reasonably and if so what resources would you recommend there is so many out there i am struggling to pick one,is it possible to learn data mining in a week,what is the best free or very cheap way to learn data analytics
317,i have a bit of an unconventional background got my ba in english literature and classical studies a while ago i worked as a teacher for a few years managed to get a novel and a book of criticism published run a literary website but have spent the last couple of years just trading crypto and forex from home have a bit of hobby experience in web development did the front end nanodegree from udacity and some in python and more recently became interested in mql for automating my trades currently building a volatility bot to see how well i gauge particular market movements anyway not sure how long i will continue trading it is tough psychologically so i am gonna spend the next months learning to code and do a bunch of projects i have been meaning to test out and maybe get a job in the field given that my biggest interest in life is the arts i am gravitating a lot towards nlp i would love to explore for example whether great literature can be recreated from other passages with nlp training in particular since i define great literature differently from most i am also interested in constructing chat bots that serve various needs mental health etc and lots of other things that play up to my strengths as a writer here are the courses i have found to be taken in an order that makes sense to me coursera is intro to machine learning with andrew ng fastai is practical deep learning for coders fastai is cutting edge deep learning for coders am i now ready to tackle books on nlp there are a few recent ones nlp in action nlp with pytorch applied text analysis with python that look good to me especially since some are for nlp beginners i would probably finish these textbooks back to back doing all the exercises while working on my own projects as i pick up more and more knowledge also i plan on learning more math as needed should i be looking at anything else though more theoretical courses like andrew ng is deep learning specialization or the stanford csn lectures more formal math thank you,what is the best path for me if my endgoal is nlp here are a few resources i have found that i would like feedback on,is it worth spending a year learning deep learning if i already have a job
318,well guys its been a good run but my laptop finally crapped out on me and for a while ive been considering building a desktop pc mainly for freelancinginternet browsing and it seems like cost effectiveness of replacingupgrading parts is much better than buying a new laptop i dont do a lot of machine learning mostly just sql querys r and python compiling im recognizing that this could change towards more machine learning and would like to have a system that can be upgraded depending on my needs in the future has anyone made a build and could give a few pointers on what to not skimp on it seems like rbuildapc its focused exclusively on gaming pcs and i havent been able to find any good info on building something for data analytics,data science pc build,laptop for data analytics
319,ga is reporting spam referrals even though i do not have the tracker id script loaded on my website which is currently under development site a how is this possible i do have one other site site b which is tracking but not that one that is receiving referral spam not even a week ago i updated my htaccess on the other site site b which is ga tracking and that list is up to blocked sites i have more to add because these are not even on my current list the list can be found here spammerstxt please note these new referrals do not appear on site b which is ga tracking only my site which is currently under development site a also note that site a does not have an htaccess list of blocked referrals because it is still under development below are the new spam referrals fjgofawbr fwxwffvkwfunet lokyfltgcn lsbxpgcom ocdkllpmau,ga is reporting spam referrals even though i do not have the tracker id script loaded,can someone explain to me why i am receiving so much referral spam
320,hello there everyone i started a new job a few months ago as a senior data scientist at a large financial services company i previously was in a small fintech consultancy and a large consultancy firm before that this is my first leadership position and i am struggling partly due to remote working i have identified the following problems in the team notebooks are often not readable making it very hard to review other people is work production code is written procedurally and is very very coupled therefore it cannot be reused think a piece of code that is so coupled to the xgboost dmatrix that it cannot be used for non xgboost projects code is very coupled to a particular cloud provider general lack of software skills i have been tasked with making changes and getting people to join my vision but i am struggling due to people thinking i am a maverick for setting standards a feedback comment was that someone had said there are too many standards i cannot do this anymore but that person had also said they hate reading other people is code and tries to avoid it people upset that i am rejecting their prs for production code almost all the time people not understanding why decoupled and extendable code is good and saves time i am finding things are a bit slower to progress and my manager has made a few comments about how i am not implementing these changes quick enough ampxb has anyone got any pointers or experience thank you,struggling with leadership role,how do you handle bosses that do not understand your work
321,training extremely massive deep learning dl models on clusters of highperformance accelerators necessitate significant engineering effort for model definition and training cluster environment specifications and typically necessitates tuning a complex combination of data operator and pipeline parallelization approach for individual network operators automating the parallelization of largescale models could speed up dl development and deployment but due to the intricate structures involved it remains a difficult undertaking to address this problem a group of researchers from uc berkeley amazon web services google shanghai jiao tong university and duke university proposed alpa a compiler system for distributed dl on gpu clusters that can automatically generate parallelization plans that match or outperform handtuned modelparallel training systems even on the models for which they were designed continue reading paper,researchers introduce alpa a compiler system for distributed deep learning built on top of machine learning parallelization approaches that automatically generates parallel execution plans covering all data operator and pipeline parallelisms,research google ai and huawei researchers propose a deep learning clusteroptimization approach for distributed training
322,i was reading a paper on electric load forecasting and trying to understand their methodology the equation they use is here the part i am struggling to understand is underlined they describe their process as in the estimation each equation is initially estimated ignoring the movingaverage error terms and the regression residuals stored the equations are then reestimated using the regression residuals from the previous step as observed moving average error terms this process is then iterated until convergence can anyone eli how this calculation process is being done my understanding is that the first time a regression is done without the moving average error terms then with training entry you add a variable that is the residual from the entry day ago h d and days ago h d these will be used in the next regression and both get a coefficient i cannot subscript apparently so sorry then you also add the actual error h d somehow this does not get a coefficient so i am not sure how this is different from the interceptkept separate also when it comes time to forecast you can see the forecast and predict using your model you could calculate the h d and h d however i am not sure how you would calculate the h d to incorporate into the model since you will not have an actual value any thoughts on this full paper,how do you use stored regression residuals as movingaverage error terms and then forecast,question about time series forecasting
323,hi everyone i am new here and after skimming through the faq i could not find an answer that quite captured the question i want to ask so here i am but first a bit of background i currently hold a msc in biological engineering and a phd in neuroscience with a heavy component in next generation rna sequencing i used r mainly and i am looking into moving towards ds why because science funding in my country australia is shrinking while the people being awarded phds has exploded competition for funding has become an absolute hellhole and on top of that my career is slowly but surely becoming one in which you are behind a desk outsourcing the science to your students while you spend everincreasing periods of time just writing grants to get funding in a ridiculously inefficient system needless to say that is not what i signed up for when i enrolled into science so i decided i want to move into another field and ds sounds like the right move it is much more flexible ie it can be applied to many more areas than neuroscience and its demand is increasing i am also quite happy while producing analysing organising and visualising data so i think i am on the right track here when i started looking into ds via google many ads offered masters in ds diplomas in ds and so on some with eyewatering price tags attached to them and i have been mulling the question for a while is it really worth having yet another degree when i already have two postgraduate degrees one in which i could argue relates to quantitative data it is not that i do not want to learn the hard skills of course i want to learn more of r python sql aws and more i do not shy away from upskilling however i do shy away from spending ridiculous amounts of money now more than ever since i am the sole breadwinner of a household of people therefore i need to make the move as financially efficient as possible and for that i would like to know about the intrinsic value of the qualification read the piece paper with the rubber stamp from the universityinstitute compared to the value of the skills which is what the employer is actually looking for if the value of the rubber stamp is not worth the money i will do what i usually do and selfteach all the necessary skills so far that is how i learnt r for rna sequencing analysis and i managed to successfully publish my analyses in top tier scientific journals so i would love to pose some questions to you guys if i may if you are an employer how much would you penalise an applicationcvinterview with a candidate that does not have a specific degree in ds but that can demonstrably show she has the skills required for the job eg via a portfolio where she shows hisher work or something along the lines if you are an employee how much would you say not having a specific degree in ds affected your chances of getting your current position in ds if having a specific degree in ds the rubber stamp from a uni is indeed important which degree would you go for and why are there any institutionsprograms you are happy to recommend i have only browsed a couple of brochures from unis here in australia and in the us but they seemed pretty different in their content however they were both online and self paced which is good for someone like me who has another job at the moment for reference i am more interested in data manipulation organisation visualisation and getting insights and conclusions from datasets than into deep machine learning stuff or software programming skills or app development although i would not shy away from learning some of those skills if they are necessary but i do not feel like working in such areas i am definitely more an analyst scientist than a package coder if that makes sense at all would you mind sharing your thoughts with me thanks in advance,while transitioning from another field what is the inherent value of a specific degree in ds,is it worth getting a phd in ds if i already have a job as a data scientist
324,hello first let me apologize if this is not the appropriate place for this question i am trying to create a model to predict a decision based off of customer data the data take the following form ampxb namemonthdecisiontransactions andy andy andy beth beth carol ampxb i am attempting to model the decision based on previous transaction history as such i would like to have each row of my data contain a vector of previous monthly transactions that is ampxb namemonthdecisionprev_transactions andy andy andy i cannot figure out how to do this at least not without slowly iterating over the entire dataframe i am not at all an advanced user when it comes to pandas i am hoping there is some built in dataframe functionality that can help me the trick is that i have a variable number of records per user for some users i may only have one or two months of data for other users i may have many dozens so naturally that prev_transactions vector is variable length which leads me to my second question will treebased ml algorithms handle variablelength vector features,feature engineering building a feature of previous transactions from monthly transaction records,how to deal with missing values in a pandas dataframe
325,hi trying to do a little project of predicting the time of the sunrise given a month and a day my process thusfar has been scrape years of sunrise data feature engineer the data so i have month day and sunrise time which i have converted to seconds from midnight split the data for traintest in chronological order important for time series analysis used xgboost algorithm trained model tested model i am getting about accuracy and am not really sure how to iterate in order to try to get better results should i try another algorithm do i need more features my margin of error is pretty small and when my model is incorrect it is not off by much i feel stuck but want to improve the model as it is something which should be extremely predictable any advice is much appreciated,predicting the sunrise,sunrise time series forecasting
326,hey so i was experimenting a bit with cafe with python and wrote a little bit of code to read some information from my network lenet mnist i am defining my solver and the layer i want to analyze with solver caffeget_solversolver_prototxt layer conv and read the feature maps and batchsize with numfm solvernetblobslayershape feature maps batchsize solvernetblobslayershape everything works fine and produces what i want feature maps images in the minibatch but i was trying to change things up a bit and see what happens when i change stuff up in my network for that i changed the lenetprototxt from name lenet layer name data type input top data input_param shape dim dim dim dim layer name conv type convolution bottom data top conv param lr_mult param lr_mult convolution_param num_output kernel_size stride weight_filler type xavier bias_filler type constant to convolution_param num_output kernel_size stride weight_filler type xavier bias_filler type constant so i changed the feature map number from to but after saving and running my code again i still get as number of feature maps any idea what i have to change,change in prototxt does not translate to a change in the network,how do i know if my model is correct
327,so i am trying to draw a correlation between the median or average household income per regioncountyzipcode or whatever from or metropolitan cities i was thinking nyc and houston for now and covid rates this is for a final project in a stats class i am actually quite interested in doing the analysis by myself and thought it would make a great project but i cannot find the data i tried looking by zip code but the results seem to be very limited often to only a few zip codes per metropolitan city i tried by county but the best data i found for houston said the income was by race which made it hard to interpret the singular column of data and then the best i have been able to find for covid is the google stats i am a novice and have next to no experience finding information like this i could use some guidance do you know of any place i could find the datasets i am looking for any help is appreciated even recommendations of other trends to study that may facilitate the datagathering part of the project,help finding income by county and corresponding covid rates,looking for data on per capita household income by city or zip code
328,hi i am looking to become better at deep learning not for my job but just out of personal interest i have basic knowledge of the theory behind it and the various toolsframeworks but as with many subjects with me practice is needed and some probably simple questions need answers that i could not find in the litrature as well as some math background my background is classic software engineeringarchitecture and i have been a principal engineer on various projects for the last years so general programmingalgorithms etc come natural to me i also have experience in over programming languages and can for example write custom cuda kernels so the lower level aspects are taken care of i usually do not learn in a conventional way frontal teaching was a real chore for me but rather learn through practive and one on one explanations among peers that is why i am looking for an accomplished machinedeep learning engineer that would be able to help me with my problems of understanding certain topics and maybe work with me on a practice project that is not something like minst or similar eg develop a fully custom model for some task i have a special interest in computer vision and neural rendering i would think about hours of time remote of course and i would like to pay by the hour either good english or german would be needed for for communication anyone interested hit me with your hourly rate and we will talk,looking for a paid personal teacher,how do i go about learning about deep learning
329,hi guys i have a polymer science phd with years of industrial experience as a research scientist and have come to the point where i absolutely need to make a career change having no intro to data science at all i started off with the programming with python course on udacity and the machine learning course on coursera because it i wanted to dip my toes in the water so far im taking to it well im enjoying learning all the new things and have been fairly good at it too wondering if anyone else has successfully made a transition what could my future options be are the entry level jobs for someone like be really saturated am i acquiring the right type of skills any advice is appreciated,career advice science phd,is it worth taking a data science bootcamp if i already have a job
330,hi everyone i am starting my ds journey and now i know what skills i need i am now putting together a plan to acquire said skills however a question popped in my mind how much of each skill should i be learning before i apply to the ds positions i want and well i do not know so i am compelled to ask what would you say are the things that someone at intermediate level would you expect to be doing with the skills i mentioned in the title this would infinitely help me gauge how much of each i should be learning and how much time i should be putting aside weekly to meet those milestones the aim is of course to learn as much as possible from here on but i need a goal to reach to devise a plan of selfpaced learning that is doable in the years i have for my plan thanks a lot,what would you say is an intermediate level of proficiency in rpythonsqlmlpowerbitableau for someone aiming for a job at little bit above entrylevel ie when the job description asks for someone with demonstrable experience in these skills ie not entry level,what are some of the best resources to learn about data science for someone who is completely new to the field
331,i graduated years ago with a degree in biomedical engineering my work involves using data analytics towards developing medical devices interpreting data from a sensor and writing software algorithms to monitor the system i have been trying to move towards a more data focused role but i am having a hard time making the transition what are some good skills i could highlight to help with a career switch into data from a data standpoint what are key skills recruiters look for when filling data roles and how could i match that with my work experience i am actually even considered going back for a masters in cs but i had some tough times in undergrad and my gpa is just below the cutoff,transition from engineering to data science,data science career advice
332,author partha deka and rohit mittal ampxb automation in industrial manufacturing todays increased level of automation in manufacturing also demands automation of material quality inspection with little human intervention the trend is to reach human level accuracy or more in quality inspection with automation to stay competitive modern industrial firms strive to achieve both quantity and quality with automation without compromising one over the other deep learning for quality inspection to meet industry standards quality inspectors in manufacturing firms inspect product quality usually after the product is manufactured its a time consuming manual effort and a rejected product results in wasted upstream factory capacity consumables labor and cost with the modern trend of artificial intelligence industrial firms are looking to use deep learning based computer vision technology during the production cycle itself to automate material quality inspection the goal is to minimize human intervention at the same time reach human level accuracy or more as well as optimize factory capacity labor cost etc the usage of deep learning is varied from object detection in selfdriving cars to disease detection with medical imaging deep learning has proved to achieve human level accuracy amp better what is deep learning deep learning is the field of learning deep structured and unstructured representation of data deep learning is the growing trend in ai to abstract better results when data is large and complex deep learning architecture consists of deep layers of neural networks such as input layer hidden layers and output layer hidden layers are used to understand the complex structures of data a neural network doesnt need to be programmed to perform a complex task gigabytes to terabytes of data are fed to the neural network architecture to learn on its own sample deep neural networks below convolution neural network convolution neural network is a class of deep neural network commonly applied in image analysis convolution layers apply a convolution operation to the input passing the result to the next layer for example an image of by pixels has million features if the first hidden layer has neurons it ends up having billion features after the first hidden layer with that many features its difficult to prevent a neural network from overfitting with less data the computational and memory requirements to train a neural network with a billion features is prohibitive the convolution operation brings a solution to this problem as it reduces the number of free features allowing the network to be deeper with fewer features there are two main advantages of using convolution layers over fully connected layers parameter sharing and sparsity of connections convolution neural network look for patterns in an image the image is convolved with a smaller matrix and and this convolution look for patterns in the image the first few layers can identify lines corners edges etc and these patterns are passed down into the deeper neural network layers to recognize more complex features this property of cnns is really good at identifying objects in images convolution neural network aka convnet is nothing but a sequence of layers three main types of layers are used to build convnet architectures convolutional layer pooling layer and fullyconnected layer these layers are stacked layers to form a full convnet architecture image source the below image clarifies the concept of a convolution layer the below image clarifies the concept of a pooling layer average or max pooling following is one of the original cnn architectures processing img uygrlandl visualizing cnn following is an image of a crack on a plain surface two layers each of conv one x filter relu and max pooling x similar to lenet architecture are applied to the crack image above it can be seen below that the cnn architecture is focusing on the blocks of crack area and the spread of it throughout the surface case study to maintain confidentiality of our work we are presenting an abstract use case below problem statement detecting bad quality material in hardware manufacturing is an error prone amp time consuming manual process and results in false positives detecting a bad one as good one if a faulty componentpart is detected at the end of the production line there is loss in upstream labor consumables factory capacity as well as revenue on the other hand if an undetected bad part gets into the final product there will be customer impact as well as market reaction this could potentially lead to irreparable damage to the reputation of the organization summary we automated defect detection on hardware products using deep learning during our hardware manufacturing processes there could be damages such scratches cracks which make our products unusable for the next processes in the production line our deep learning application detected defect such as a crack scratch in milliseconds with human level accuracy and better as well as interpreted the defect area in the image with heat maps details of our deep learning architecture to describe things better we are using an example image of a circuit board with an integrated chip on it below our first approach we adopted a combination of pure computer vision approach nonmachine learning methods to extract the region of interest roi from the original image and a pure deep learning approach to detect defects in the roi why roi extraction before dl while capturing the images the camera assembly lighting etc was focusing on the whole area of the circuit example images below we are only inspecting the chip area for defects and no other areas in the circuit we found with a few experiments that dl accuracy increased substantially when neural networks focus only on the area of interest rather than the whole area  first extract region of interest roi with computer vision nonmachine learning methods here we go through multiple processes on the image such as gray scaling transformations such as eroding dilating closing the image etc and eventually curve out the roi from image based on use case type product type etc the basic idea of erosion is just like soil erosion it erodes away the boundaries of foreground object dilating is just opposite of erosion it increases the size of foreground object normally in cases like noise removal erosion is followed by dilation opening is just another name of erosion followed by dilation it is useful in removing noise closing is reverse of opening dilation followed by erosion it is useful in closing small holes inside the foreground objects or small black points on the object gradient transformation is the difference between dilation and erosion of an image overall these steps help in opening up barely visible cracks scratches in the original image refer the figure below  secondly detect defects using deep neural networksdeep neural network cnnbased models using proven cnn topologies such as inception netaka google net res net dense net processing img ozahusll some other areas where experimentation was necessary to find the optimal architecture  data augmentation we have few thousand unique images labelled as defects and few thousand labelled as good ones augmentation is critical to avoid overfitting the training set we did x random crops and y rotations original image results in xy augmented images after augmentation we have xy thousand defective images and xy thousand good images referring one of original cnn papers in this context  initialization strategy for cnn topologies we replaced the final connected layer with our own fc layer and sigmoid layer binary classification as shown in the figure below rather than random initialization of weights in each layer we considered imagenet initialization for each cnn topology our dl accuracy have increased substantially when we used imagenet initialization than random  loss function and optimizer cross entropy loss crossentropy loss or log loss measures the performance of a classification model whose output is a probability value between and crossentropy loss increases as the predicted probability diverges from the actual label so predicting a probability of when the actual observation label is would be bad and result in a high loss value a perfect model would have a log loss of sgd and nesterov momentum sgd or stochastic gradient descent is an iterative method for optimizing a differentiable objective function loss function its stochastic because it takes random samples from the data to do the gradient descent update momentum is a moving average of the gradients it is used to update the weight of the network and it helps accelerate gradients in the right direction nesterov is a version of the momentum that is getting popular recently our second approach critique to first approach while extracting regions of interest it requires rewriting code whenever there are changes in product types circuit board typechip type in case of our abstract example camera setups directions etc this is not scalable solution we built an endend two step dl architecture in the first step instead of a cv approach we used a dl approach to predict the roi itself we manually created a labelled dataset with a bounding box tool amp we let train a dl architecture to predict the roi one downside of this technique is that the labelled dataset has to be explicit and extensive enough to include all product types etc circuit board typechip type in case of our abstract example for the deep neural network to generalize well on unseen images refer the figures below  cnn roi generator loss function we initially used a squared distance based loss function as below ampxb processing img clvnmql after training a resnet model for epochs we achieved the following validation metric average missed area and iou on the validation set ave missed area ave iou intersection over union at least we want to improve the iou we came up with an area based loss please refer the figure below to get an idea of how we use basic math to calculate the area of intersection between the ground truth and the predicted label in the loss function we want to penalize both the missed and the excess area ideally we would want to penalize the missed area more than the excess area the loss function above is differentiable so we can do gradient descent optimization on the loss function  cnn roi generator augmentation we simply added margins both left and right margins during training time and test time on our predicted rois  cnn roi generator results we used resnet imagenet initilization toplogy and sgd nesterov momentum optimizer with penalty term lamda missed amp penalty term lamda excess in the area based loss as described above after training the resnet model for multiple epochs we want to minimize the avg missed area and maximize the avg iou best iou is after training for epochs we achieved the following on the validation set ave missed area ave iou intersection over union with area based loss and augmentationdescribed above we improved our validation metric on missed area and iou experiments amp benchmarks  experiment total of images few thousand images data split toto split using unique images only framework used pytorch amp tensorflow keras weights initialization pretrained on imagenet optimizer sgd with learning rate using nesterov with momentum loss cross entropy batch size total of epochs image shape xx except for inception v which requires xx criterion lowest validation loss ampxb benchmarks our benchmarks with both the approaches are pretty comparable the results with cvdl first approach are little better off than the dldl second approach we believe our dldl could be better if we can create an extensive and explicit labelled bounding box dataset ampxb following a successful completion of training an inference solution has to be found to complete the whole end to end solution we used intel openvino software to optimize inference in different types of hardware besides cpu such as fpga intel movidius etc ampxb inference intel open vino based on convolution neural networks cnn the intel open vino toolkit extends workloads across intel hardware and maximizes performance enables cnnbased deep learning inference on the edge supports heterogeneous execution across computer vision acceleratorscpu gpu intel movidius neural compute stick and fpgausing a common api speeds time to market via a library of functions and preoptimized kernels includes optimized calls for opencv and openvx refer the following figures on open vino architecture ampxb processing img yqofslfm two step deployment step one is to convert the pretrained model into intermediate representations irs using model optimizer produce a valid intermediate representation if this main conversion artifact is not valid the inference engine cannot run the primary responsibility of the model optimizer is to produce the two files to form the intermediate representation produce an optimized intermediate representation pretrained models contain layers that are important for training such as the dropout layer these layers are useless during inference and might increase the inference time in many cases these layers can be automatically removed from the resulting intermediate representation however if a group of layers can be represented as one mathematical operation and thus as a single layer the model optimizer recognizes such patterns and replaces these layers with one the result is an intermediate representation that has fewer layers than the original model this decreases the inference time the ir is a pair of files that describe the whole model xml describes the network topology bin contains the weights and biases binary data step two is to use the inference engine to read load and infer the ir files using a common api across the cpu gpu or vpu hardware open vino documentation inference benchmarks on sample image processing img dhbpim it is clear that optimizing with software stack is critical to reduce the inference time we saw x to x improvement in latency time using openvino software optimization in addition besides intel cpu we also experimented with other intel hardware accelerators such as intel movidius and fpga ampxb visualizing cnn with heat maps often deep neural networks are criticized for low interpretability and most deep learning solutions stop at the point when the classification of the labels are done we wanted to interpret our results why the cnn architecture labelled an image as good or bad binary classification for our case study which area in the image the cnn is focusing most based on this research in mit a class activation map in combination with the global max pooling layer has been proposed to localize class specific image regions global average pooling usually acts as a regularizer preventing overfitting during training it is established in this research that the advantages of global average pooling layer extend beyond simply acting as a regularizer little tweaking the network can retain its remarkable localization ability until the final layer this tweaking allows identifying easily the discriminative image regions in a single forward pass for a wide variety of tasks even those that the network was not originally trained for following is a heat map interpretation using this technique on the crack on a plain surface image using resnet architecture trained on imagenet as we can see the heat map focusses on the crack area below although the architecture is not trained on such images ampxb summary amp conclusion with deep learning based computer vision we achieved human level accuracy and better with both of our approaches cvdl and dldl discussed earlier in this blog our solution is unique we not only used deep learning for classification but for interpreting the defect area with heat maps on the image itself human factor cannot be completely dissociated but we can substantial reduce human intervention an optimal model is always a fine tune between fpr false positive rate amp fnr false negative rate or precision vs recall for our use case we successfully automated defect detection with a model optimized for low fnr high recall we substantially reduced the human review rate with our case study we proved that we can automate material inspection with deep learning amp reduce human review rate references https,quality inspection in manufacturing using deep learning based computer vision,research a deep neural network architecture for object detection
333,so i was trying to build a softmax linear image classifier trying to find a matrix w that would classify the images correctly and i got stuck with the regularization parameter after finding my loss function i should add a regularization term to punish the model for complexity eg we want w is entries to have smaller values according to notes of csn we multiply the regularization term by the sum of the squares of the matrix is entries in python the pseudocode seems like this loss loss regularization_term npsumw but looking at the solutions of other people i see something like this loss loss regularization_term npsumw why do we have there ampxb secondly when adding regularization to the gradient this dw dw regw produces a smaller error rate than dw dw regnpsumw first why do we even have to add regularization term to the gradient second even if we add why do we add the matrix itself and not the sum of square of its entries,basic questions about the regularization term,why do we have such a large number of regularization entries in a neural network
334,i am learning about classification with ml data set is a bit nasty santander data set first i undersampled the data set because they are only values and aroun values and then run the sgdclassification algorithm poor precision and recall and if i plot precision vs recall i get a thunder like line i will copy and paste code so it is more clear what i did this is the code note eds is my custom package that i use so i have less to type in simple_class_model returns what is printed and cells that have eds means that i want to add that in the future but other than that it is nothing complicated,thunder precisionrecall curve bad results on classification data set,is there a name for this type of model i want to use
335,i have a cnn binary classifier that is trained on images cancer and a random forests binary classifier that is trained on clinical attributes sex histology etc i am predicting survival at a certain time point after diagnosis my rf gives an auroc of and my cnn gives an auroc of i have already tried combining them where i just concatenate the clinical attributes in the fully connected layer of my cnn however for some reason this achieves a lower auroc than the rf alone i have tried allowing all layers to be trainable and tried only allowing the fully connected layer to be trainable both yield similar results is there a better way to combine these two sets of data,how would you go about combining two classifiers one cnn and one rf,how to combine two different cnn classifiers
336,what is the ideal use cases for a neural network if you have rows variables half of these variables ar categorical plus the data quality is shaky missing values multicollinearity etc and suppose you dont have domain specific knowledge to even understand these problems is it still the ideal environment to apply a neural network i am leaning towards the idea that a random forest model will prove to be more versatile in this case its unsubstantiated i feel that neural networks would have more success modelling data like images or audio signals where the data is converted into large matricies with usually nonmissing and continuous data eg pictures can be thought of as a x dimensional matrix each entry in this matrix corresponding to a light intensity measurement is this reasonable,are neural networks being overused,what is the best way to deal with missing values in a neural network
337,let is say you want to optimize a manufacturing process to minimize defect by doing an experiment with different settings of a certain variable suppose for each setting you product parts and make note of the defect rate let is say your experiment is composed of different settings and after all it is done you make use of the setting that gives the least defect but is there a rigorous statistical test to truly tell whether the outcome did not happen due to chance and here is a related scenario suppose you want to optimize the current process based on the history of the previous parts made you know the defect rate is x you use a new process but due to expense you only make an experimental run with parts and you get a defect rate of y what statistical test can you use to determine if the new process truly had an effect thanks,anyone good at statistics or experimental design,question about statistical testing
338,i am trying to create a program when you can input an email and it will give you the structure of the email this is best explained by example let is say i input johndoecompanycom the algorithm should say that the structure is firstlast if it were j_doecompanycom it would output f_last and so on i am very new to this area feel free to check out my post in the career questions thread and there would be no way for me to write such an algorithm on my own just yet so after some googling i came across the stanfordner package which can be also used with python the issue with this is that it can recognize whether there is a person but that does not help me much i was thinking of perhaps finding a database of first names and starting from there but i am open to your suggestions how should i go about this,categorizing email structures text recognition,how do i go about creating a database for my company
339,i am working on some machine learning projects and every once in a while i get stuck and it takes a while to get unstuck for anything involving python programming i head on over to rslavelabour or rprogrammingtasks and get it done there within an hour however there is no such thing for very machine learning specific tasks someone mentioned to make it a collaborative since there is way more value in getting better at a process with a few bucks i decided to still pay out since it is my project and i will be benefiting but here there is no requirement to know exactly how to do it beforehand introduction so for this round the task using google brain is tensortensor library gttensortensor or tt for short is a library of deep learning models and datasets designed to make deep learning more accessible and accelerate ml research tt is actively used and maintained by researchers and engineers within the google brain team and a community of users gt features gt many state of the art and baseline models are builtin and new models can be added easily open an issue or pull request gt many datasets across modalities text audio image available for generation and use and new ones can be added easily open an issue or pull request for public datasets gt models can be used with any dataset and input mode or even multiple all modalityspecific processing eg embedding lookups for text tokens is done with bottom and top transformations which are specified perfeature in the model gt support for multigpu machines and synchronous master many workers and asynchronous independent workers synchronizing through a parameter server distributed training gt easily swap amongst datasets and models by commandline flag with the data generation script ttdatagen and the training script tttrainer gt train on google cloud ml and cloud tpus it is used in industry and was used in the following papers gt attention is all you need gt depthwise separable convolutions for neural machine translation gt one model to learn them all gt discrete autoencoders for sequence models gt generating wikipedia by summarizing long sequences gt image transformer gt training tips for the transformer model gt selfattention with relative position representations gt fast decoding in sequence models using discrete latent variables gt adafactor adaptive learning rates with sublinear memory cost gt universal transformers gt attending to mathematical language with transformers gt the evolved transformer gt modelbased reinforcement learning for atari gt videoflow a flowbased generative model for video task the specific task is we are doing summarization training over a new dataset they have instructions on how to do summarization training on a few datasets here but adding a new dataset is not as straightforward especially if the new dataset has a different data format participation amp payment this is tricky for me to figure out i initially wanted to pay out to whoever figured out the task but i was also thinking of accepting whoever wants to participate to join i was thinking when the task is figured out anyone who made a contribution no matter how small will get to vote on who gets to have the and i will give it to whoever gets the most votes or if anyone has any other suggestions lmk,anyone interested in learning use machine learning techniques programming frameworks data processing pipelines and deployments and getting paid to do it for small dividends for this round it is figuring out how to use google brain is very prominent tensortensor library,how do you deal with overfitting in deep learning
340,hello everyone i am finishing up my undergraduate studies on mathematics and my time is coming to decide what i am going to do with my life given that i want to get into data science a master is degree is more or less unavoidable the problem is that i cannot seem to decide between statistics or computer science for the following reasons statistics data analysis and the likes have always been my passion given that i survived a math major i feel like going towards that direction is my destiny so to speak i have taken courses on mathematical statistics and measuretheoretic probability theory and i did not have any real issue with them i have developed a need for understanding the rigorous mathematics of whatever concept i am studying which is the reason i dropped out of a physics major however a cs master is heck even a bsc makes you instantly employable i am willing and ready to go ahead and study programming on my own but i doubt the quality of education i will get will be even close to that of a cs graduate i really really enjoy programming the whole problemsolving part of it even bugfixing feels rewarding i can fail to run my code for a week and not burn out as you can see my problem is not that i dislike any of the two disciplines my problem is that i like them both way too much and i do not understand the implications of choosing on over the other there seems to be many conflicting opinions on employability hardsoft skills earned necessary for ds compensation distributions etc my current options feel free to propose something else are do a stats master is but try to find one which contains a lot of programming and applications has plenty of projects throughout the semester maybe university funded internships etc learn programming mostly on the side do a cs master is and try to force as much statistical theory courses as the program allows me to projects and internships for what i have understood are part of every decent cs program so what should i go for am i being overly optimistic about my options any similar experiences are welcome,statistics or cs msc for data science,is a data science masters worth it if i already have a job
341,i am currently a business analyst looking to improve more of data skills and i have been googling data cleaning as one of the premiere skills to have however it is a very broad term so i am trying to gain more understanding my question is what does this process look like so if your company asks you to extract data from their system or gives you the data what tools or ways do you clean it is it a process done in excel python tableau prep do you just go through the rows and columns and look for errors and then test the validation through excel additionally when there is large datasets such as billions of rows how do you clean or look at that i have heard people say they use sql to write queries to break it down but i have trouble understanding what that means i realize this is a broad questions but any tips or advice on the start to finish from extracting cleaning transforming and loading the data would be helpful,for data scientists and analysts could you explain from start to finish what is the etl process for big data projects what is the process of data cleaning and loading and how do you do this with big data,how do you go about cleaning up data
342,i read once something like google searches can be used to predict incidences of the common cold in certain areas im interested if there have been any projects to try to use data to determine which companies have high employee satisfaction and to have access to that data in real time like being able to tell in any way when a company is having problems vs when things seem to be going well what kinds of data are accessible on this topic as a hypothetical to make the scenario more concrete imagine you could just spy on everybodys phones and there were advanced ais that could understand text messages for example and figure out when employees were complaining to one another about something while this is not legally possible it opens the door that something along these lines isnt such a long shot so are there any ways of accessing similar data thanks very much,employee satisfaction live data,how do you deal with bosses that do not understand data
343,i am doing a master degree in mathematics with interest in data science and biostatistics during my master degree i have done courses in optimization regression analytics and visualisation my bachelor was in information technology and have professional experience in it in the field of banking remittance and payments i need advice to select preferred out of the following biostatistics topics for the master thesis most preferred least preferred and i would like to know which are the most beneficial for a future career in data science in order of preference taking into consideration that i would like to get a job in some industry and not a research job so the topic or the tools used could be of a practical use rather than research    multiple imputation methods for handling missing data    propensity score methods for performing treatment comparisons in observational data    developing prediction models and treatment comparisons in electronic health records    big data methods integrating multiomics platforms    survival analyses incorporating competing risks    methods for analyzing microbiome data    spatiotemporal models for mapping disease rates and disease clusters    causal inference methods    metaanalysis and network metaregression   advanced longitudinal data models   graphical models in medicine   hierarchical model applications in public health,which is the best master thesis topic for a career in data science,is a masters in data science worth it if i already have a job as a data scientist
344,hey guys i am looking to learn regression and trying to pick a type to learn and use within the financial industry i am considering using logarithmic regression because in business we always talk about strong growth periods followed by levelling offs as other companies enter the industry or whatever same for economics countries often grow fast initially then level off i am also wondering if learning logarithmic regression will sort of be more useful within small cap companies because of the super growth period and levelling off aspect or am i overthinking it and i should just use linear regression what do you guys think should i learn both or one do they have a lot of commonalities between them,linear vs logarithmic regression,what are some good regression techniques for a small company
345,i have a phd in a mix of computer science and statistics i currently hold a role as a statistics lead with my own team in a large company went from junior to senior and then to lead i applied for a senior data scientist role recently and went through a few round of interviews with coding tests i think i did fairly well and they were very complimentary of my code i was asked to do a text processing task something that was totally new to me still with little research i solved their problem it was obvious that models that they were building were slightly different than what i am used to but all the principles of model building and validation are the same i have worked before on statistical endtoend projects with clients it sort of feels like if i take this entry level offer i could have gotten in straight out of my phd and i wasted last years statistics is an important part of data science so should not that experience in managing and leading projects be enough for sr data scientist role i do not want my ego to get in the way so i am looking for outside opinions fair offer or lowballed,offered an entry level data science role after a decade of experience in statistics fair,is it worth getting a phd for a data scientist role
346,my situation i have been given a blank slate to come up with a wouldata science job description for myself and i would like to see some opinions on what this community thinks a data science job description should look like some background i have been an entrylevel data analyst in my department for years amp at the same company in a different department for another year this makes up the entirety of my areal world work experience i started teaching myself python and data science practices a little over years ago and have really enjoyed it i have enough freedom in my role that whenever i learn a new concept i am typically able to throw a project together that applies it i went to my boss to discuss a promotion and we both agreed i am definitely overqualified for a sr analyst role or at least on the topend of the roll this lead me to bring up the idea that we create a data scientist roll for me which he agreed to i have been currently asked to create a job description for this new role so my boss and i can pitch it to the decision makers in our department common trends i have seen on data scientist job descriptions something around manipulating large data sets cleaningproviding insights buildingdeploying algorithms to yield actionable amp accurate results ability to explain models and findings clearly to key stakeholders mentor and develop technical skills of analysts and senior analysts thanks in advance for any advice you all have ps any advice on how negotiate compensation in a situation like this would be helpful typical salary distribution i have seen is k with a mean around k does that sound about right,need some help creating my job description,how much do data scientists get paid
347,i work for a small content streaming company anytime someone watches a video or does not watch one they have the ability to leave a comment on the video each video belongs to a series and i would like to have a good way to flesh out what the most common content strings are whether they are positive or negative etc for each of these individual videos series or for the main actor in the video the data exists on redshift thoughts on how i could execute some sort of analytics strategy on this i gather that some analytics could be done using python but i have no experience in it just sql i work as bi analyst appreciate any thoughts you have on this,text analytics,how would you approach this problem
348,hi ranalytics i am the maintainer of miceranger an r package which performs multiple imputation by chained equations mice with random forests i have developed a package miceforest which does the same thing in python github pypi i am a huge fan of documentation so i have included a very comprehensive readme on the github which explains the mice algorithm and the details of the package i have recently gotten the package into a pretty stable state complete with docs mypy checks ci testing etc so i thought i would share the news what is mice multiple imputation by chained equations mice is an iterative method that allows you to fill in missing data using all of the available information in the dataset over a series of iterations every column in the data set gets modeled by the other columns and the missing values are inferred by the model stef van buuren wrote the book on missing data which details the algorithm here random forests are a good chaining equation to use because they do not need much hyperparameter tuning easily handle nonlinear relationships in the data can return oob performance inexpensively are trivially parallelizable can return feature importance for diagnostics what is it used for i do a lot of funnel modeling at my current position and mice has proven invaluable it allows us to eliminate bias in the funnel caused by missing data being less missing the further up the funnel you go which allows us to use all available information no matter the funnel stage create confidence intervals on our predictions more data filled out less imputed variance a more confident prediction this allows us to create more robust confidence intervals for our forecasts motivation i originally developed this package for r because all of the available packages were lacking in either speed or features as i start using python more i noticed that the available mice implementations do not provide the functionality i find myself using most often custom imputation schemas built in diagnostic plotting imputing new data,new library multiple imputation by random forests in python,is there a name for this python package i developed
349,i am toying around with image classification i found this article that is very good but the size of the data is too much for my pc takes nearly an hour to compile and train the model so i decided to tackle something smaller i got some images from the google quick draw dataset i downloaded the numpy files for cats dogs bees helicopter octopus and bicycle and converted them to x jpgs i changed the model in the article so that it can fit this multiclass data i changed the input layer is shape to be and the output layer is shape to instead of i also changed the loss function to categorical_crossentropy and trained for epochs i got a reaonable test accuracy of but when i wanted to predict some random images i mostly got all zeros as the prediction from this code load random images and print the output images for l in labelsvalues folder fquickdrawtestl images folder f for f in listdirfolder shuffleimages for i in range filename imagespop plt_img imreadfilename plot raw pixel data pltimshowplt_img cmapgray pltshow classify the image img load_imgfilename target_size x img_to_arrayimg x npexpand_dimsx axis pred modelpredictx printpred output for all of the images ampxb did i make some obvious mistake is accuracy even the right metric here,problems with output from keras cnn,how do i train a cnn to deal with a very unbalanced dataset
350,i am a chemist who has gotten quite tired of bench work and want to transition over to data science i have a master is in chemistry and i have learned some r to analyze dna microarray data but that was more looking online and seeing what other people have done and applying it to my own data i have started taking an intro to computer programming on coursera i also realize that taking some classes on algorithms is necessary too because i have very little formal training in computer science i have looked into trying to apply for one of the master is in computer science such as the one in offered at illinois or georgia tech so that i have some formal training what others classes would i need to take as well to prepare and get into these programs of course i think data structures would be necessary as well but a thorough list and how long it would take to learn would be incredibly helpful as once again i do not have a lot background in computer science,advice for a bench scientist looking to transition to data science,is it worth getting a masters in data science if i already have a job as a data scientist
351,i am a statistician by trade my entire academic background is in statistics including an advanced qualification i have done no statistics at my current job and i am at the end of my rope i have been at my current job since may it is my second job directly out of college i was laid off from my first job during the golden handcuffs period i owed them money if i quit before a year because they did not have any data sciencey work for me to do i was essentially a dba there even though id keep suggesting reasonable analyses and easy ways to make their infrastructure more data driven instead of heuristic i brought up my concerns about wanting to actually do data analysis when i took my current job which is at a small team in a satellite office of a main office my boss is a very smart person with strong statistical credentials he is also annoyed at the lack of the statistical work but is staying around because he expects it to show up this company is pretty early in the process of building serious data infrastructure the only statistics i have done are one quick demo analysis in the beginning and another that took a few months but was cancelled due to internal factors i had no results at that point at both jobs people are aware that i know advanced statistics but i have always been stuck doing other work i have been doing literally nothing but demoware and basic dashboarding since september i have done some coding tasks because oh you are the data guy and i am a senior guy do this vaguely related data thing that is not statistics i have been making mockups for pms to show at conferences the work i do is very high visibility but has no statistics involved which is why i am annoyed i do the work but i have been miserable because it has very little relation to what i want to be doing unlike my boss who has a considerable resume i have little experience actually doing statistics i had an internship as an undergrad where i had no mentorship and they didnt know what to do with me so they kept moving me from random task to random task and a statistics reu where i was literally one of two students who was assigned a nonstatistical project it is particularly frustrating because i like literally everything else about this company my boss is awesome my coworkers are super nice everyone is super positive and i can work remotely one day a week i am well paid honestly more than i should be given the work i have been doing and have great benefits i have a performance review next month i am expecting it to be fantastic given that i have repeatedly gotten compliments on my work there is a machine learning team that i talk to a lot outside the context of work that is doing a lot of work i am interested in like voice and image recognition i would like to leverage my positive performance review into being able to do more machine learning work because i like this company otherwise i will quit after i hit the oneyear mark and find a job that will actually allow me to build models rather than being a glorified dashboard and demo guy how should i best ask to move to machine learning when the dashboarding work i am doing is so vital if they do not let me transfer teams how can i leverage my current experience into a new job where i am doing actual data science rather than making and maintaining dashboards for other people i have done some coding here and have good sql skills but i have found that my background in those areas has made me a ripe candidate for code things that manage data and do basic bi stuff roles rather than the more technical advanced statistical roles i am interested in my current thought is to emphasize my statistical background make it clear that i want to be doing analysis work and to point out that i was able to handle high visibility high impact projects that require talking to stakeholders in the past,at the end of my rope in my current position any advice for getting out of it xpost from rcscareerquestions,i feel trapped at my current job and i do not know what to do
352,i have to translate this text into a enhanced entity relationship diagram this database is used to be able to persist train stations a train station is uniquely identified by a name eg ypres in addition for each station also a unique coordinate pair is stored consisting of the latitude and longitude a distinction is made between internal national and foreign stations in the sense that for foreign stations the national code of the country in which the station is located is stored eg fr for france and not for domestic stations for domestic stations the unique name is always displayed in dutch but may be several translations of this name this does not apply to foreign stations a translation of a station name logically consists of the translation as well as from the country code of the language to which the translation belongs eg ypres is the fr english translation of ypres for each country code a maximum of times translation the nmbs also has different types of trains available with a unique generic name eg ic p bus each of which refers to exactly one category of connection hear eg high speed regional these train types can be placed on several routes each trajectory has a unique name and is linked to all train types that travel this route for example the trajectory with name blankenberge gentsintpieters linked to the train types with name ic and it a trajectory is carried out one or more times a day the implementation of a route in which a train of a certain type stops at a fixed sequence stations stops at a fixed sequence of times is called a trip every first of all trip has a unique code a maximum capacity of travelers that can take place on this trip and a collection of dates on which these trip is performed in addition it is necessary to save before every trip at what time regardless of the dates a train arrives and departs a specific stop with the exception of the first stop which has no arrival information matie and the last stop that has no departure information of course you can trains only depart from a stop when they have arrived there first additionally in this case it is necessary to indicate whether this is an arrival and departure time falls on the day of the original departure of the train before midnight or on the day after the original departure of the train after midnight like a train arrives at a stop after midnight it also departs after midnight conversely a train will certainly arrive at a stop before midnight if it is there too leaves before midnight because the departure and arrival times are not necessarily unique for a trip but the order of the stations must be known every stop where a train is stops a unique stop number per trip with the first stop being numbered the order of the stop numbers per trip should of course be consistent with the arrival and departure times of the same trip this means that the arrival time of a train at a stop must be same or later than the departure time at stops with a lower stop number and the reverse should also apply for ie other stop on a trip for which departure information is known ie all stops except the latter an expected passenger occupancy should also be stored of course this expected occupation may never exceed the maximum capacity of the trip exceed ampxb this is my third iteration of my eerd,help with eer diagram point out mistakes andor what can be done better ill delete this post if this is not allowed in the subreddit,is there a name for this type of model
353,cross post from rcscareerquestions i graduated with a masters in computer science specializing in data science about a year ago i intended to work with ml or ai right out of college but the couple of interviews i had never panned out i had to take up a job as a backend dev i have been working at my current company about a year and a half i am planning on moving into a career in data sciences my resume right now looks like a software dev resume most of my data sciences related projects are from college i did work on analytics project in my spare time but that is about it i do not get any callbacks from any positions i apply in this field how do i gain the necessary experience that gets me a callback how do i break into the field would work at a startup help any information or ideas helps really,breaking into a career in data sciences,how do i go about creating a data science portfolio
354,i am interested in setting up simple http endpoints sometimes with forms or just to handle json processing messages from queues batch processing and easily listening to streams of data from social media and rss feeds also the more features that can be added on like creating dashboards from data is a plus has anyone used both and have opinions on how node red and apache nifi compare i have been testing both of these for the past two days and it feels like node red is easier to use but apache nifi has marginally more processors node red seemed to have a lot more fun toys out of the box but apache nifi processors seemed to have more configuration options in case scaling ever becomes a priority node red is message passing the the msg json objects was really intuitive and even though it is only been a few hours working with nifi i still have not really figured out how to read manipulate and write flow files or how to set up an easy debug console to debug flows as easily as node red i have been doing some research on node red vs nifi for the use cases i mentioned before and i have not seen node red mentioned on this subreddit before it seems most people who would fall in the big data space use nifi so i would like to like it too but now i am skeptical if that is the right choice since node red was ridiculously easy to setup install and make something productive within minutes any thoughts appreciated,node red vs apache nifi xpost rbigdata,how do you set up your local ml cluster
355,hello guys i am from india and i am trying to switch my career in data science for that for the last months i have been learning data science through various online courses the famous ones which i can list are andrew ngs deeplearningai specialization all courses completed sentdex is machine learning tutorials basically i have covered svmknn neural netsdeep neural netscnnusing keras all these are basics but i have developed the apis from scratch with the help of these courses do you think i can get an entry level job at least with these and if not then what else do i also need to learn to get a decent job with a decent pay tiy,what kind of data scienceanalyst jobs i can get in india with my current knowledge,can someone help me understand what i am doing wrong
356,polarization powerful billionaires and the eroding effects of inequality rahaf harfoush ampxb rahaf harfoush rahafharfoush is a digital anthropologist bestselling author and speaker researching the impacts of emerging technologies on our society and is focused on deep and often hidden behavioral shifts that are taking place within organizations and individuals in this digital era she also teaches innovation and disruptive business models at sciencepos masters of finance and economics program in paris and is the author of hustle amp float the decoded company and yes we did an inside look at how obama used social media to win in rahafs also the executive director of the red thread institute of digital culture a thinktank and special projects agency focused on the intersection of technology and culture ampxb today we discuss the polarizing problem of social media and sharing why inequality is such a big deal what obama and trump did effectively in their campaigns the reason add is killing creativity why social medias perfect for information warfare how billionaires are breaking the world why protesting and media mobs may be the new norm how to think about worker rights whats wrong with the gig economy and where it heads how privacy is eroding faster than we realize why ai and automation could ruin society,polarization powerful billionaires and the eroding effects of inequality rahaf harfoush,is data science the next big thing
357,before i delve into the problem of which has been plaguing me for a while now i would like to address what i feel may become quite apparent as one reads the question i have to offer here my incompetence in regards to the field of machine learning and artificial intelligence in general i have no formal education in regards to the field of machine learning and artificial intelligence in general and all of my knowledge on the subject comes from a small set composed of personal readings such as hinton is a practical guide to training restricted boltzmann machines and youtube videos such as the ones to be found on channels such as google developers and deeplearningtv thus any patience you have to spare would be greatly appreciated and i should like to thank you in advance for any guidance of which you choose to offer having recently gained an interest in machine learning i have been toying around with edwin chen is simple rbm implementation as a means of familiarizing myself with restricted boltzmann machines one thing i of which i quickly afterwards became intrigued by was the implementation of supervised learning into an rbm larochelle is and bengio is paper classification using discriminative restricted boltzmann machines offers two algorithms of which i wish to utilize to solve this problem however their usage of terminology confounds me for example i understand that h refers to a list of hidden variables but what would a h denoted with a hat symbol refer to furthermore i am aware that u refers to the connection weights within visible variables but i had originally thought that in an rbm none of the visible nodes are directly connected to each other and thus there exists no weights between the nodes of the visible layer in general i suppose i am looking for someone to assist me by walking through a hypothetical implementation of one or both of these algorithms explaining to me as one feeds a set of training data into the algorithm what happens along each step i expect myself to gain from this a more complete understanding of said algorithms than just staring in a confused manner at its more symbolized form or not i guess in general any clarification in regards to how to implement these algorithms and how they function is appreciated once again thank you in advance for any guidance the first of the two algorithms can be found here where the essay previously mentioned is organized into a tidy chart the algorithm specifically can be found under the heading contrastive divergence for both algorithms look to the original paper here,on confusion in regards to classrbms,is there a name for this type of algorithm
358,i started with andrew ng is machine learning course on coursera last year but quit by week due to school and not putting in enough time i have decided to start again and have enrolled in the course again i was thinking that having a discord to discuss each week is content would be helpful since that would be a study group apart from the discussions forum on coursera which i do not really like let me know if any of you are interested and we can discuss on connecting through discord and setting up regular meetings we can set goals and be accountable for the group is progress trying to reach deadlines for discussions,discord for ng is ml course coursera,looking for a mentor to help with a project
359,hello i have a database with tables and i would like to see if any of you have some thoughts about the issue i am having main tables customersurvey and customerreview both of this tables have a free text field where customers can put some feedback regarding different topics that is the only thing the tables have im column we are running some analysis on the content of the text to get key phrases what is the customer talking about and key entities company eg microsoft person eg john smith etc we have a table that records the results so for example the customer survey table has one record and key phrases and entities can have many records for each parent record one to many relationship same thing for customer review what i am trying to find is a way to see which customer reviews have a match of at least of key phrases or key entities in the text we get from customer surveys kind of linking them together to understand if somebody in the reviews is talking about the same things in the customer surveys i was reading about graph dbs could be of help to link the data but then i also read about python algorithims to do this type of matchlinking but i have no clue where to start anybody has some thoughts on what would be a good approach to tackle this thanks sooo much in advance,question about linking records,how do i find the most similar words in a text field
360,hello i would like to hear some critique of my resume for seeking data scientist data analyst roles i recently graduated and got math phd from an r university with no internship experiences my research is about numerical modeling to save computational costs and i have years experience in python before doing math phd i was a financial technology consultant for almost three years i mostly self taught statistics and machine learning knowledge also do webscraping as hobby i am targeting to data scientist role but also open to data analyst or internship since i have very little luck on job hunting after trying few months thank you all in advance and i would be happy to hear any comments or critique,resume critique recent math phd seeking data analyst data scientist positions,data scientist resume critique
361,i have been working as a data analyst for a year now at a tech company and i am in a very lucky position where my company gives me a budget for learning amp development so i am looking for a data science machine learning course that i could use that money for i find it quite difficult to figure out which ones are the best value for money since there are so many in pre corona times i would probably use it for inperson learning or conferences i work mainly with sql amp excel started to learn python recently i do not have the traditional background so i definitely lack some knowledge in statistics amp maths so a course focusing on that would also work for me appreciate any help on the above,data science machine learning courses advice,data science bootcamps
362,hello i definitely believe that what goes around comes back around and i would like to mentorhelp someone on a regular basis me i have been doing machine learning for years and i am employed as an ml engineer for a space company my code is currently in use by top companies like pepsico bmw ebay and godaddy let me know who you are and what you need and i will help you in any way that i can ampxb someone recommended i start a slack group for qampas so i did feel free to join ampxb ampxb edit yes you can dm me ampxb edit oh dear lord i was not expecting it to blow up like this faq is for those interested how to get a job tech companies usually will not talk to you unless you have years of professional experience but that is for the big software companies that are advertising those mlds jobs my advice and what has worked for me is to go to nonsoftware conventionsi got my current job by meeting people at a space convention and posting your resume on craigslist you want to get in with a small company that has few or no other coders and charge less than you are worth that way if you make mistakes or take too long they will still want you because you cost less than any other options what do study if you have no coding experience take intro to python courses on datacamp or codeacademy after that this is where i learned literally everything i know about ai the course is free unless you want certificates which do not really matter i studied it an hour per night nights per week for a year if you want techniques on selfmotivation i suggest reading willpower by kelly mcgonigal some really fun ai projects to start off with ampxb a lot of people are asking about andrew ng is ai class on coursera i have not taken it but i have heard only good things about it,does anyone need a machine learning mentor,is it worth spending time learning python for data science
363,hello my name is moses and i am head of marketing and sales at data ampxb data is the first company to bring virtual and augmented reality to the world of data science offering various chart and graph types the goal is to give users the ability to easily create visualizations and analyze their data sets faster than ever before as a company we have been trying to figure out what exactly data scientists and analysts look for in the software that they use currently we have the tech and functionalities to rival larger companies like tableau and qlik but we are a much younger company years and utilize tech that has not been fully adopted by the mainstream yet here is our current website ampxb any must have features that we should showcase any things you think would be cool and would like to see as part of our advertising ampxb please be as honest as you can be one can only grow through criticism ampxb thank you all in advance i look forward to your responses,advice needed,data science in the digital age
364,i am a molecular microbiologist but wanting to gain more skills in data science a lot of my work is dealing with huge amounts of data generated from next generation sequencing and i feel that the programs we use only analyse the bare minimum i want to learn ways to analyse the data better and potentially implement some machine learning ideally this is something i would like to pursue as a career path i want to take an online course but i have noticed they either teach in python or r i know python basics but unfamiliar with r i know that once you know one well it is easy to learn another but i would prefer to start out with a language most commonly used in my field of interest anyone know which language that would be tia,data science for biomedical research and genomics python or r,is it worth spending a semester learning r or python
365,i have a couple data collection apps that are required to be running the apps are either scraping website data or retrieving data from an api every x minuteshoursdays currently some of these apps running locally that are storing the data in a postgres db and the rest are being written to csv files however i would rather not run these apps on my laptop since it is not always on and running however i am looking to run these apps from a cloud service and store the data up there as well an example would be running the apps from an ec instance on aws and storing the data in s ec s is currently what i am leaning towards but i wanted to see if there was any bettercheaper setups for this the apps collecting the data do not necessarily require a big server but that could be a potential concern depending on the data storage type there may be cases where i need to check if data exists already so i may need to read it all into memory there are work arounds for this though another option that seems viable is using aws lambda i am just not sure how efficient this is for scraping data i have not done too much research into it i am open to all cloud service providers awsazuregoogle thanks,best cloud setup for always on apps that scraperetrieve then store data,what is the best way to store aws data
366,hi i have a project which includes iot devices with smaller data frequencies data for every min what is your advice for selecting algorithms suitable for anomaly detection based on single sensor data which algorithm should i go with it needs to be unsupervised since sensor type varies temperature humidity pressure energy flux etc so it is impossible to know what is system is normal nature in advance it is mainly very clean data since we know where the data is coming from but occasionally null data or lack of data happens due to inconsistency at the sensors also algorithm needs to be cpu friendly since it will run also in low capacity hardware like arduino or small pcs thanks in advance cheers,best algorithm for anomaly detection unsupervised time series data,what is the best way to store sensor data for machine learning
367,lots of posts on how to enter data science what technologies apply what methods are most efficient and practical etc all that bring answered what data do you care about the most not necessarily what data do you work with responsible for or has the greatest influenceneed but what data do you care about personally i find myself on the cdc website monitoring covid data as it relates to my sons demographic i also check out wow subscription data when its available its usually not i also think financialmarket data for specific companies is important to review in contrast i could care less about most types of internal business data mainly because it doesnt seem to provide much practical use like the ltvcac metric its usually tampered or measured towards a internal political agenda or lets say customer churn sure its important but it can also believed that a low churn correlates to a superior product but in my experience its because of the hassle of changing platforms and not superiority what data is most important to you what data do you care about,what data do you care about,data science is not just about data
368,so i am an electrical graduate and there the only thing we have learned was matlab now have completed some basic data science courses stats prob and r and enrolled myself in ms ds i had some hands on practice on matlab and till now it is my start i can manage any analysis on it although python is a lot similar to matlab but u know remembering functions is the most tedious task of learning a programming language and then there is a practice i know a lot of analysis and statistical tools of matlab and searching for same for python is boring although i have not cover my ml yet but i have heard model training on matlab is simple i know python for ds is mandatory and if matlab is good enough then learning a nd tool would give additional benefits so i was wondering why the demand of matlab for data science is not that high for real engineering applications like audio analysis drone design image processing and autonomous cars nothing competes with matlab yet and if we want to apply data science on these applications matlab also provide tools for that so why people prefer python over it is it because it is paid r is a separate case and best for statistical analysis and is like a good shortcut,how do u rate matlab for data science applications,what is the best free or very cheap way to learn data science
369,i have really wanted to implement reinforcement learning with cnn and see it play a game by itself so i thought why not try it on openaigym is simple cartpole game i had tried my code with a simple network that employs what i feel is reinforcement learning previously and have achieved really good results so i tried moving on to cnn and started taking screenshots of every frame and feeding it to my network i ran my cnn code for hours and i achieved an average score that was lesser than that of my network playing randomly i then went onto reddit and stackoverflow for help and followed the suggestions tweaked my code and ran the algorithm this time for hours and the results exactly the same as before but with slight improvement in average score i cannot find any reason why my network will not work and hence i think i should just stop trying to implement cnns i have already gone through a couple of courses for cnn and i am still clueless what to do i have followed the general structure of cnns can i train it to play a game using some other network or algorithm,should i just quit,question about cnns and reinforcement learning
370,i am currently trying to solve cartpole using the open ai gym environment in python using deep q learning i have a working script but something weird happens my network will learn the close to optimal policy typically within iterations and then if left to keep training the performance plateaus and will not get higher than a run of if i keep this running for episodes the pattern will happen or times has anyone had this problem before i am not using a target network as i was under the impression that for a simple problem like this then it is not required so i am quite stumped as to what the issue could be i have uploaded to git the script and a pdf of the runs so you can see the problem and inspect the code if you want to thanks,issue with solving cartpole using deep rl,running out of memory in deep qlearning
371,i need help gathering data from boxreccom for boxing bout data i posted this on rwebscraping as well but figure this community will have a plethora of knowledge i need help with methods of not getting blocked i have a perfect script that works everytime my iteration runs with ease i have set up multiple ways to to ease this struggle proxy ip addresses random agent for each requests match request header fields add a random seconds in between each request all i can think of is that i am doing a pattern but i do not know how to set up random clicks i am in no way barraging their site as i wait seconds for each ip address so there are not calls flooded from one ip i want to use this data to train a ml model to try to predict boxing bouts if you want to chat about this i can show you my script and see what is going on thank you,trying to scrape boxing bout dataset,how do i use ml to predict a fight between two boxers
372,months ago i have started a junior data scientist role in a company which exist bot on mobile and on web i was separated from the whole team and i was sent to be data scientist on web and currently i am working with such tools as google analytics fb pixel amplitude and other data scientists are working on another more advanced tools which are suitable for data science and analytics my big frustration is that i am feeling you are not able to become a good data scientist when using google analytics or similar tools as they are more trivial you cannot do your own ab tests using statistics etc i am seeking for an advise should i change my team refuse to work with those kind of web tools or do something else sometimes i feel that i am not even a data scientist or an analytic as i am not doing complex queries using advanced i am not able to create predictive models etc,seeking for a career advise in data science,i feel trapped in my current role and i do not know what to do
373,this has probably been asked a lot but wanted to get some confirmation and a peace of mind i graduated from an ai bach and masters and ideally wanted to get my first job along the same path ds with focus on predictive modelling utilizing mlnlp and keeping up with the trends unfortunately these sort of things are not so popular in my country nz at least at an entrybased level i have instead landed a job again as a data scientist however i am getting the impression that it will be more related to data engineering data in the cloud bi and still some statistical modelling although not so much ml i realise that these are all still great skills to have and learn and i am very excited about my opportunity i do however wonder if this will set me more on this bi path rather than the mlai side of things i would like to work on in the future in your experience do people like me as their first job get ignored later on when applying to more ai based jobs thanks in advance for any input,do more aiml related ds roles tend to ignore people that have had a more data analyst role as a starting career,data science bootcamps
374,i have been assigned a case study assignment where i need to discuss my approach to implementing top custom dimensions metrics and events for a large ecommerce site i am google analytics iq certified and i have taken the google analytics academy courses for enhanced ecommerce and tag manager but i have no real professional experience with google analytics my experience is limited to the demo account i was given as part of the google analytics academy courses therefore i have been limited to reading blog posts to find ideas for custom dimensions metrics and events this has given me some promising ideas but i would be interested in hearing this sub is ideas as well if any of you have worked with large ecommerce sites what custom dimensions metrics and events have you used that you found to be indispensable thank you in advance,most common custom dimensions metrics and events for ecommerce sites,google analytics ecommerce case study
375,when we talk about comparing different policiesplans what we do is basically compare the expected reward of a state now i am confused as to how it works consider this problem let a be the start state g be the goal state and x be an intermediate step between a and g such that a gt x gt g the expected return for each of state be a x g g does not matter case suppose according to one policy reward x at state x is suboptimal but by the same policy the maximum of the reward propogates to a good path xgt g bad path agtx case in another policy reward x at state x is optimal but by the same policy the rewards degrades a lot as it reaches a bad path xgtg good path agtx in this case how can we compare which policy is better simply on the basis of expected returnreward i do not understand please help,confused on comparing policies how reinforcement learning,how do i deal with a policy that does not align with my expectations
376,hi everyone i have been working as a data analyst for more than years now primarily working in sql r and sometimes python for small data engineering tasks recently i have been exploring jobs in the data science realm i have an interview coming up it is a hr technical interview and i have no clue what to expect all they shared with me was that their ds role works in sql and python and after the technical round i will be tested on product metrics any advice on typical ds interview question it is the python part that is getting me anxious but considering that the role sounds closer to a product analyst job i do not expect anything more than the standard data libraries like numpy and pandas and perhaps some statistics and math questions as well any guesses or advice is welcome and please let me know of any good resources to study from thank you,interview advice please,data product analyst interview questions
377,about me im a bsn grad from a developing country who is currently working as a medical coder im interested in data science due to the ability to work from home with higher pay im also interested in the application of data science in mental health amp dermatological research which have been something of an interest to me i always enjoy reading research studies which i sometimes do for medical coding when necessary i am not the best at math i did well in algebra a but okayish b in statistics there was no calculus when i went to college honestly ive forgotten a lot of math stuff already my job doesnt use a lot of math so im not sure how id fare with heavier math topics i know html and css learned on my own the former was easy and fun the latter was more challenging and enjoyable i know hcpcs cpt amp icd cm amp pcs codes questions based on my background would being a data scientist suit me how do i know if im cut out to be a data scientist what are the most important softwareprogramming languages to learn where do i start,im thinking of possible transitioning to data science but i have a lot of doubts about the feasibility,is it worth getting a masters in data science if i already have a job as a data scientist
378,hello everyone i am from venezuela and i have started to teach myself some ds skills but i noticed that some of the best ways of learning stuff and at the same time generating some experience is with internships any south american friends that could give me some advice on where should i look for internships and what do i need for laying one of these i have just ended high school and i have not started the university yet so i have literally zero background only online free sources and youtube tutorials d i am specifying because i think that advice from people from closer countries to my own might be more relatable to my current situation than full developed countries also if you could give me recommendations on universities that might offer majors in cs or data science it could be very helpful if you are from a developed country and want to give advice you are welcome as well thanks for reading,looking for advice on internships and universities specially if you are from south america like me d,advice on where to start
379,hi i am working on a project to automate a few monthly reports my work is pulling currently we move data from google analytics gt spreadsheets gt tableauall manual it is pretty painful i have seen a few guides on doing it through google spreadsheets but we are not allowed to store data on google docs for security reasons so i was trying to figure out the best way to set up these api pulls i have the option of using datasheets or box or a sql server in the middle so it could look something like this ga api gt sql box datasheets gt tableau if anyone can recommend the best way to get data from ga to tableau automatically i would appreciate it,syncing google analytics to tableau,best way to store google analytics data
380,data scientists handle time series data on a daily basis and being able to manipulate and analyses these data is a required part of the job sql window functions allow you to do just this and is a common data science interview question so lets talk about what time series data is when to use them and how to implement functions to help manage times series data what is times series data time series data are variables within your data that have a time component this means that each value in this attribute has either a date or time value sometimes they have both here are some examples of times series data the daily stock price for companies because each stock price is associated with a specific day the daily average stock index value over the last few years because each value is mapped to a specific day unique visits to a website over a month platform registrations each day monthly sales and revenue daily logins for an app lag and lead window functions when handling time series data a common calculation is to calculate growth or averages over time this means that youll need to either grab the future date or previous date and its associated values two window functions that allow you to accomplish this is lag and lead which are extremely useful for dealing with time related data the main difference between lag and lead is that lag gets data from previous rows while lead is the opposite it fetches data from following rows we can use either one of the two functions to compare month over month growth for example as a data analytics professional you are very likely to work on time related data and if you are able to use lag or lead efficiently you will be a very productive data scientist a data science interview question that requires a window function lets go through an advanced data science sql interview question dealing with this window function youll see window functions commonly being part of interview questions but youll also see them a lot in your daily work so its important to know how to use them lets go through one question from airbnb called growth of airbnb if you want to follow along interactively you can do so here the question is to estimate the growth of airbnb each year using the number of hosts registered as the growth metric the rate of growth is calculated by taking number of hosts registered in the current year number of hosts registered in the previous year the number of hosts registered in the previous year output the year number of hosts in the current year number of hosts in the previous year and the rate of growth round the rate of growth to the nearest percent and order the result in the ascending order based on the year approach step count the host for the current year the first step is to count hosts by year so well need to extract the year from the date values select extractyear from host_sincedate as year countid current_year_host from airbnb_search_details where host_since is not null group by extractyear from host_sincedate order by year approach step count the host for the previous year this is where youll be using the lag window function here youll create a view where we have the year number of hosts in that current year and then number of hosts from the previous year use a lag function for the previous year count and take the last years value and put it in the same row as this years count this way you will have columns in your view year current year host count and last years host count the lag function allows you to easily pull the last years host count in your row this makes it easy for you to implement any metric like a growth rate because you have all the values you need on one row for sql to easily calculate a metric heres the code for it select year current_year_host lagcurrent_year_host over order by year as prev_year_host from select extractyear from host_sincedate as year countid current_year_host from airbnb_search_details where host_since is not null group by extractyear from host_sincedate order by year t t approach implement the growth metric as mentioned earlier its much easier to implement a metric like the one below when all the values are on one row this is why you perform the lag function implement the growth rate calculation roundcurrent_year_host prev_year_hostcastprev_year_host as numeric estimated_growth select year current_year_host prev_year_host roundcurrent_year_host prev_year_hostcastprev_year_host as numeric estimated_growth from select year current_year_host lagcurrent_year_host over order by year as prev_year_host from select extractyear from host_sincedate as year countid current_year_host from airbnb_search_details where host_since is not null group by extractyear from host_sincedate order by year t t conclusion using window functions specifically lag and lead allows you to easily manipulate time series data to solve questions like finding growth rates or yearoveryear rolling averages these questions and problems are what data scientists and business analysts deal with every day for more information about window functions and you can head over to the video to see the approach to solving this problem live,handling time series window functions in data science interviews,how do i calculate the value of a time series
381,hello all first of all please ignore my lack of knowledge as i did not have a use case to run aws before i am using a powerful desktop at work for my personal toy projects where i am working on data science and machine learning which laptop to get does that matter i even thought of running an aws instance from work computer but for privacy isses maybe it is best to get a personal laptop on my own i am considering a thinkpad t and run a dual boot with linux and i am open to laptopdesktop suggestions to run aws on my personal system to summarize how can i learn more about aws i am on free tier but my account was just charged even i have no ec instances set up yet do you see any disadvantage running my personal aws project on a company work machine in terms of privacy if yes could you recommend a laptopdesktop thanks for your patience regards passionate newbie this message is cross posted to aws community as well,which laptop for aws for data science and machine learning,how do i setup aws for personal use
382,i am in an odd situation and any input is helpful ive been working for years as ds in a quite large and extremely popular company based both in europe and us we are around data scientists working in different teams due to some restructuring i saw myself and my projects migrating to a new team focused on pocs and new datadriven products i am quite happy for it i was teamed up with two other colleagues that are in senior positions and with more company time than me the problem is that i have no clue about the work they have done in the past one was actually my teammate in my previous team he got assigned to a project manager role last year but the project never left the ppt prior to that i have started a project with this person in my first year and after two months of weekly meetings where nothing was done i asked my manager to work on it by myself both of them have never demonstrated any individual capability or willingness to show the outcome of their work focusing only on discussing ideas and what not for instance we have an enterprise solution for version control and all our projects go there yet they have accounted for contributions in the past year i know this is not a great measure of work and effort but cmon my question is then how do i approach this situation i have two concerns they wont contribute to anything concrete and i have no idea how to collaborate with them given that i cant find examples of their collaboration with others in the past on concern number is there a polite and political way to figure this out from their former collaborators or should i bring this up in the team and cut the bs thanks,advice about teammates,how do you deal with bosses that do not understand your work
383,hey everyone hope everyone is having a good day so far i know as of right now that my goal is to break into data science but i do not know exactly what industries i want to work in just yet so my plan was to reach out to alumni who were working as data scientists in a multitude of different industries of my university amp set up informational interviews so i could get specific tailored career advice from them but i am having a tough time identifying the exact people i want to be in contact with that fit the criteria i am looking for especially when searching on linkedin i just finished searching for hours amp hours only to find one good linkedin profile that fit what i was looking for ideally i want to be able to have like a large excel sheet of contacts that have their name email specific industry their working in as a data scientist amp linkedin profilepersonal websiteportfolio i do not want to have to search for hours amp hours to get this done so what can be the best way for me to get this process either automated or outsourced,networking for data scientists on linkedin properly,looking for a mentor
384,hey everyone i am looking for a partner or partners to work on python projects i thought on first working on a kaggle challenge to gain some experience and start our own projects in the future which may bring some additional income in the future at the beginning i am dedicating a few hours a week to it for the duration and increase depending on how it works out about me i did my masters degree in medical informatics and now work on my phd a computer visiondata science project i am most experienced with python and also know cc but did not become a friend of r i look forward hearing from you edit i am quiet flexible with the work we do so feel free to tell me i just want to start some interesting project beside work which may turn into something bigger in the future,looking for a partner to work on python projects,looking for a mentor
385,hi everyone i am an intern at a healthcare company and this is my first actual data science internship with only a couple of classes before this so i do not have much experience the company i am working for keeps track of patient data and we have some duplicates due to things like misspellings and adding hyphens in last names on the flip side since we have so many patients in our database about k there are also just patients with very similar names who are completely different people the company wants me to find a way to merge the duplicate patients but they need me to be pretty much sure the patients are the same person since if we mess up and merge the incorrect data there could be hipaa violations i was wondering if any of you had experience with a task like this i was looking up methods to do things like this and found something called fuzzy matching but i am really worried about the accuracy and i was wondering if any of you had experience using it and could speak to its accuracy thanks in advance,super accurate duplicate matching,how do i track the accuracy of my first data science internship
386,see the tldr at the end for the brief version hi rdatascience i am an undergrad cs major taking a course on big data comprised of mostly masters students the course has a final project where we use big data toolsframeworks spark hive etc to perform some sort of analysis on a large dataset for this project we are allowed to do it on our own or join a team of up to students as an undergrad junior looking for data science roles i was wondering if it makes any difference whether i join a team or not on one hand doing the analysis on my own makes me more familiar with the entire analysis and has me write it all conversely working with a team can show github workflow skills general responsibilitypartitioning etc those who have been in hiring manager roles or have had this experience what do does it matter at all thanks tl dr undergrad taking masters big data course final project right around the corner we can work in teams or on our own does it look better if i do it all myself or work on a team am i overthinking this,group vs solo final project,what does a data science manager do
387,i am currently a second year cs student planning on doing a formal masters in data science in the future however i would like to have a solid foundation before persuing that ampxb currently i am planning on doing the johns hopkins coursera specialization course on data science using r and i would like to complement that with a good math heavy stats course can anyone help me make a good decision on which course to choose and how to go about it i have already started the imperical college maths for ml course but i have not been able to find a good enough stats course the one offered by stanford university seems a bit lacking in content,need help choosing an online course,is it worth getting a masters in data science if i already have a job
388,first of all i am not sure if i posted this in the right place but i am breaking my head over this problem so would be more than happy with your help i am kind of new to the data science field so please be gentle for my dissertation i am researching the effect of international trade on income inequality at the industry level i gathered data for the income inequality measurements at the industry level implying industries for countries for a time period of years see attachment for overview furthermore i collected the international trade variable at the industry level as well however my other control variables cannot be find at the industry level but at the country level instead eg education implying the following regression specification regression the subscripts i j and t respectively represents sector country and wave timewhereas iiijt denotes income inequality hence the ginicoefficient mean log deviation theilindex atkinsonindex  and the pp ratio alpha indicates the intercept xijt symbolizes the vector of variables reported at the industry level including the main independentexplanatory variable for international trade industry exposure to international trade next zjt is the vector of the other independent variables which are reported at the country level eg economic growth education and inflation rate next d reflects a dummy variable which are the incidents eg china entrance wto shocking model mu signifies the sectorbycountry fixed effects and theta the wave time fixed effects and epsilon the error term as a beginner in data science this creates a few problemsquestions for me first how can i combine data at the industry level and country level in my dataset see attachment divide the country level variables by or just give it the same value for each industry second how do i construct the panel dataset in stata using xtset industry year or xtset country year third how do i analyze the effects on income inequality in one regression thus let stata run the specified model and fourth how do i generate the sectorbycountry and wave time fixed effects in the model thank you very much in advance from a very stressed economic student ampxb ampxb wave overview attachment ampxb dataset attachment,creating a panel dataset with time country and industry helping out a very stressed economic student,how do i calculate the effect of each variable on the following year is economy
389,some background i am months out of undergrad with a bachelor is in finance my experience is all financial analyst work at a bn hedge fund investment research platform startup my schools investment management fund aum k and tutoring work throughout all of college i was unemployed for the last year due to the pandemic and about a month ago i was doing some reading on the data space data science and data analysis seemed to take the parts of financial analysis i liked and applied it in a wider variety of ways ampxb i decided to make the career switch because finance seemed too dry for me and i wanted a different worklife balance and company culture anyways i just landed a great data analyst role at a startup that has been growing like crazy for the last few years i start on monday and i will begin my training i will be learning python and sql with basically zero prior knowledge of either my math skills are okay but they are not great as a financial analyst i never really had to apply complicated mathematical principles to my analysesi am feeling a little nervous about starting and being able to keep up with the high demand of the job efficiently my job will be creating specialized data reports which are the main revenue generating part of the company and my workinsights will directly be used by clients and implemented ampxb does anyone have any general tips for someone just starting out in the data analysis and science industry are there any books i should be reading on my own time after work skills i should be learning concepts i should be mastering extra things i can do to grow as much as fast as possible the job has a system of bonuses and yearly raises that could make the position lucrative if my results are good so i want to make the best impression possible besides just wanting to not get fired for poor performance any help or insight would be appreciated,starting a new data analyst job soon one year out of graduation and worried about keeping up,is it worth getting a masters in data science if i already have a job as a data analyst
390,the setup let is say i have a meme that i want to get to the entire population of the world each individual node has x_node modes to get the meme to their contacts it takes t_node time for the meme to get to that individual at least once it takes t_modes time for the individual to get the meme at least once per node as a natural course of the life of the meme an individual stops sharing the meme after t_indiv time or because they lost capability to send the meme for some reason death broken phone etc as a natural course of the life of the meme each mode stops sharing the meme after t_demode time due to all contacts via that mode being reached or the mode is not working for whatever reason consider the rate at which an individual is modes are contacted at least once the node saturation rate and the rate at which all individuals are contacted at least once the network saturation rate consider the rate at which an individual is nodes stop sharing the meme the node desaturation rate and the rate at which an individual stops sharing the meme the network desaturation rate all you have are these rates the question how would you evaluate the likelihood of success of the meme to reach everyone in the world based on these alone i have an idea myself and i will comment with it but i would like to hear new ideas as well my own concept has some issues that i need to figure out so help would be appreciated there we also want to minimize saturation times and maximize desaturation times so a way of noting how that is going would be beneficial further assume that we want our favorite celebrity in country y to see the meme at least once and we have set a goal of his getting it in t_celebrity time any delivery to the celebrity is considered a success but we want to maximize the chances of the celebrity receiving it so we want to know how close we were to them not getting the message,comparison of saturation rate vs desaturation rate of a meme,how do i track how many people are using our site at the same time
391,i have been working on this job for over a decade it is a data analysisconsulting job but it is really low tech data analysis i look at survey data monthly sales data and some other metrics do some basic analysis in excel significant test some pivot table etc and provide insights report i left the company as a midlevel manager with a small team and client account responsibilities i have no prior csprogramming experience if anything i have some exposure of sql but very little like a handful of commands with no real life application after a few days of thinking i now decided to pursue a ms in ds the plan is to do it onlinefulltime now ideally i would like go with those big name institutions with reputation but i found it challenging for a few reasons listed below my ultimate questions are how different are these programs from institution to institution is the difference really so big that worth all the troubles if i just finish a mediocre program and land a ds job can the difference be made up by work experience laterself learning on the side by the way i understand this is an industry that requires perpetual learning and i have no problem of doing that fall admission even some spring cohorts deadlines are passed my favorite the omscs at georgia tech does have a spring class but the deadline was july so unfortunately that is also in the past i will have to wait for another year to get into a lot of those programs no spring chicken anymore i want to start relatively quickly bar is pretty high for those programs some of them require gregmat that i do not have my bachelor was acquired outside of us so some programs need a toefl score my gpa is only below the minimum of of majority programs so it will take me some effort to make up the gap in gpa and get a good score in those exams is it worths it i have no previous programming experience i do plan to learn from bootcamps before the program starts but if i start applying now i do not have any on my resume cost seems to be really high for those reputable universities thanks for making this far if you know a good program will suit me i am open for suggestion too,educationcareer just got laid off and looking to get a ms in ds seeking for advice,is it worth getting a masters in ds if i already have a job as a data analyst
392,i am a complete beginner using freelancers for expertise but i want to learn from this community i am starting a weekly newsletter sending a list of data containing real estate listings rows with columns which new data is being added approx new rows every week the scraped data will have to be personally managed adding missing fields removing etc my question is what is the best database to store manage amp productize scraped data is there anything else to consider when looking to build a newsletter using data i am tied between using google sheets or excel when looking at what is the most simple way to manage the data and to present it to colleagues this is out of my depth due to my inexperience but would love to read your feedback,best database to store manage amp productize scraped data,how do you organize your data
393,i have had two sites that used google analytics one was created in and one this month i was surprised to see the new dashboard was pretty comfortable with the old one but upgrades are always welcome my big question is if we have a real live view anymore the dashboard would track in real time extremely well i had accurate counts of people who were on the site and when a user would leave the count would change within a minute or two the new dashboard seems to have replaced that with a minute window is there any way to see the older style data my big issue is that users on my new site tend to stay there for longer and often do not interact with the page the page does its thing it has the users attention but theres no interaction from the user because of this a lot of the metrics i have found do not really show what i want to see current user count i added a couple lines of code to my server to show me this but thats less than optimal my code often shows x the users currently on the site vs googles minute roll am i missing something in the new dashboard i would like to have everything in one place,questions on the new google dashboard,how do i track users who have visited a certain section of my site
394,hi all happy thanksgiving to those in the us i have a small project that i have been asked to give a rate for its not data science but i thought someone on here might have good advice the project is to create a dashboard on google sheet the users will be my clients customers who will put in their budget and transaction data and the output will be multiple charts and tables that show a bunch of different things that the client has requested im experienced with google sheets but i have never created something of this type i have lots of experience w data and a phd not sure if thats relevant but im just trying to figure out an honest hourly rate i feel like charging an expert rate isnt fair because i will probably be kind of slow and having to look stuff up along the way other relevant info i live in a very high cost area in the us coastal ca i dont have a full time job so it would be great to take on something like this also cool for resume finally i dont want to charge per project in case there are things i have to do that im not even aware of thank you for your input,not sure how to charge,how much do you charge for your data
395,towhee is a flexible applicationoriented framework for running machine learning ml pipelines it is a python project that aims to simplify the creation and deployment of complex multistage ml tasks allowing everyone from beginner developers to large organizations to deploy complex pipelines with just a few lines of code neural network models have become the cornerstone of data applications within the industry with embeddings being seen in all fields whether it be in product recommendation copyright flagging data management security pharma finance insurance etc despite the concept of embed everything being abundant in academia and industry there still hasnt been an easy implementationsolution for everyday users the idea of the towhee project is to sweep out those obstacles and make mlops significantly easier for all github,how to create and use open source machine learning pipeline,what is the future of data science and machine learning
396,we have found both in college and in the workplace that sometimes people find git intimidating to use because of all the commands you need to remember gitutor is a command line application that wraps git and provides beginner friendly versions of git is commands it makes git easy some of gitutor is features create local repositories and link them to github in one command you can easily undo changes interactive menus that make your life easier have a cheatsheet right on your terminal learn what the commands do behind the scenes to learn more git you can check out the tutorial and installation guide on our website and the github repo right now the project is in beta if you find any bugs or would like additional features please email us at supportgitutoriomailtosupportgitutorio,hard time remembering git commands try gitutor,learn git and r with our free beginner to advanced course
397,so i have an interview at a higher level position in a different field than i currently work at in my company which is going to be in a entry level business analytics position i have knowledge of some of the tools they use in their depart such as tableau and sql and some minor python experience under my belt i have not really used those programs in a real world situation but i have analyzed data to increase performance in a real world situation for example i would analyze my performance in games like wow by using data from damage parses to see where i stood among the majority of players what errors i would make and what trends the top performers were doing to get a better idea on what improvements i would need to make to increase my performance and tweaks needed to optimize my equipment to parse higher and to better perform next time there are other examples in other games but i feel if i had to use information that i know most about it would this should i utilize this information and real world example in my interview,so i have an interview for a business intelligence analytics position coming up and debating on using my real world experience in the interview,i have an hour interview scheduled for my first data analyst position at my new company and i feel completely unqualified
398,this might be more fitting in reconometrics but i will try here i am a master student in economic history and as such a bit lacking in statsknowledge although i have taken a few semester of both statistics and econometrics sadly my department is a bit weak in quant so i do not have a lot of people to ask in my department i am trying to understand what models to use to model time series i am reading up on arima and dynamic regression models in hyndman is but i fail to understand the use of these models yes i can fit a curve to the data very nicely and both ar and maprocesses make a lot of intuitive sense but they only seem to allow for step ahead forecasts considering that they always need to be feeded with fresh data on the previous observation so what is the practical application in forecasting it just seems very limited dynamic arima regression models seem to be slightly more useful since they allow for an external regressor but still for forecasting you rely on that t datapoint am i wasting my time here what i want to do is to basically model a time series of word frequencies produced from tweets during months to movement data from the google mobility report i could just fall back on a simple regression model of the differentiated time series but it seems a bit boring and are these models actually used in forecasting thanks,how are arimamodels actually used in practice,how do i go about fitting a regression model to my data
399,in our saas company we have a sales team to drive the leads to convert once anybody registers they become a lead and our sales team would contact them for various reasons we can get in touch with only around of leads therefore there are two ways how a lead can convert with or without a contact with our salesperson when a salesperson contacts a lead who would purchase anyway it is an easy sell so let is not give a credit to the sales for that one therefore the question is is there a way to estimate the number of leads who were contacted but would buy anyway in other words how to estimate what would happen if we stopped all sales activities i could measure conversion rates for leads who were contacted or not compare these two segments and say that the uplift of contacted leads over notcontacted is thanks to the sales efforts but this does not seem to be convenient to me for several reasons one of the reasons is that leads who are being contacted are already somewhat biased towards purchase eg lead who provides false contact information is less likely to buy so in that case i would be comparing conversion rates for two different samples,how to estimate an impact of a sales team,how do i measure the effect of a lead on sales
400,dev colleagues this nanodegree program leverages the intel distribution of openvino toolkit to fasttrack development of highperformance computer vision and deep learning inference applications and run pretrained deep learning models for computer vision onpremise you will identify key hardware specifications of cpu vpu fpga and integrated gpu hardware types and utilize the intel devcloud for the edge to test model performance on the various hardware types use software tools to optimize deep learning models to improve performance of edge ai systems the three skillbased training moduleseach with a handson project include edge ai fundamentals with openvino project deploy a people counter at the edge hardware for computer vision amp deep learning application deployment project design a smart queuing system and optimization techniques and tools for computer vision amp deep learning applications projectbuild a computer pointer controller this program requires intermediate knowledge of python and experience with deep learning command line and opencv enroll today at much career success lawrence e wilson artificial intelligence academy aia,intel edge ai for iot developers nanodegree program,deep learning with python for computer vision
401,i am building a chatbot that will only handle faqs but these faqs are very specific to an organisation so i cannot use any existing offtheshelf solutions or connect to questionanswering apis ampxb i have a dataset which consists of questions intents and answers ampxb let is say there are intents which basically group questions into general categories eg fee_payment each intent has different specific answers eg fees are paid through the online portal or fees are due on the st of every month and finally each answer has sample questions eg how do i pay my fees or what is the procedure for payment of fees ampxb here is an example of the structure of the dataset ampxb intent answer question fee_payment fees are paid through the online portal how do i pay my fees fee_payment fees are paid through the online portal what is the procedure for payment of fees fee_payment fees are paid through the online portal fee_payment fees are paid through the online portal ltintent_answer_questiongt fee_payment fees are due on the st of every month ltintent_answer_questiongt fee_payment fees are due on the st of every month fee_payment fees are due on the st of every month ltintent_answer_questiongt fee_payment fee_payment ltintent_answergt ltintent_answer_questiongt fee_payment ltintent_answergt fee_payment ltintent_answergt ltintent_answer_questiongt ltintentgt ltintent_answergt ltintent_answer_questiongt ltintentgt ltintent_answergt ltintentgt ltintent_answergt ltintent_answer_questiongt ltintentgt ltintentgt ltintent_answergt ltintent_answer_questiongt ltintentgt ltintent_answergt ltintentgt ltintent_answergt ltintent_answer_questiongt ampxb i have started building the chatbot using rasa and have the nlu part trained to accurately classify any arbitrarily worded question as one of the intents i now need to explore what is the best method to take all the questions in the dataset under this intent and find the most similarrelevant one to the user is question ampxb what are the best options to acheive this would something as powerful as bert be effective here what are some other simpler lookupsearch based options or supervisedunsupervised mldl options or ampxb note i am doing this in english initially but eventually it will need to be languageagnostic arabic will be implemented next,options to find the most similar question in a dataset of questionanswer pairs,i am trying to build a data science chatbot and i do not know where to start
402,transformer model a deep learning framework has achieved stateoftheart results across diverse domains includingnatural languageconversationimages and evenmusic the core block of any transformer architecture is theattention module which computes similarity scores for all pairs of positions in an input sequence since it requires quadratic computation time and quadratic memory size of the storing matrix with the increase in the input sequences length its efficiency decreases thus for longrange attention one of the most common methods issparse attention it reduces the complexity by computing selective similarity scores from the sequence based on various methods there are still certain limitations like unavailability of efficient sparsematrix multiplication operations on all accelerators lack of theoretical guarantees insufficiency to address the full range of problems etc introduction to performer to resolve these issues google ai introduces theperformer a transformer architecture with attention mechanisms that scale linearly the framework is implemented byfast attention via positive orthogonal random features favor algorithm providing scalablelowvarianceandunbiasedestimation of attention mechanisms expressed by random feature maps decompositions in particular regular softmaxattention mapping helps in preserving linear space and time complexity full summary github paper,google ai introduces performer a generalized attention framework based on the transformer architecture,research google research proposes a new deep learning framework for tuning and tuning of natural language transformers
403,hey guys so basically i am a rd year undergrad engineering student who is interested in the world of big data i see two careers data science and data analyst i know that data scientists often require a master is or even a phd neither of which i am too sure i will be pursuing and obviously the former has a greater pay than the other other thing that i have found out from my research is that the former requires a decent knowledge in the field of mathematics which i am ready to brush up on and the other one not so much i do not want to waste my time studying something which i will not be able to get solely on the basis of the lack of certification required i basically want to get a job as soon as i finish my program could you help me to decide which path i should take,data scientist or data analyst,is it worth getting a phd in data science if i already have a job as a data analyst
404,hey first time posting long time lurker i wanted to get people is thoughts on what to do in the analytics career after you have been in it several years midsenior level as i feel at somewhat of a plateau my background currently mid is in southern california i have about years experience now working in analytics at various tech companies currently i have a manager role it is sort of a midsenior level at my company pay is about k bonus over the years my sql excel have gotten very good i have a strong understanding of reporting infrastructuresbi tools have a decent handle of ga web data and am very familiar with scenario analysis generating forecasts and ab testing i have an mba from a decent school most people in socal have heard of but studied politics in undergrad so my educational grounding has always been less technical ampxb my dilemma is this i currently work at a more old school though reputable company and am having trouble getting a position at more modern tech firms my statistics background i am starting to realize is not very solid in the past few years i feel as though a strong grounding in statistics has become more of a requirement in the field additionally i see more and more requirements looking for python which i am extremely beginner in ampxb we can assume there are little to zero learning opportunities at my current job outside of learning on my own as they have recently let go of huge swaths of the data science department and many of the people in analytics have jumped ship upper management did not see the value in them very old school thinking we can also assume there is no room to move up in my current company ampxb q at this point in my career would it be worth it to get some sort of statisticsanalytics bootcamp credential if so any you recommend it would not help in my current role but would help me sound like less of a dumbass in interviews i guess ampxb q have any of you taken lower titles for the opportunity to jump ship within the analytics field i am starting to look at analyst roles though am afraid my more extensive background scares off employers who are only looking for years of experience if so what was the experience like also what salaries are they offering for them in the marketplace at my company it ranges from kk doe ampxb q to those of you hitting your midlate is do you have fears of one day becoming obsolete when starting my career it seemed like sql excel bi tools ga could open a lot of doors these days that skillset is feeling more and more dated as the requirements seem to rise tbh this stuff never came easy to me and i had to spend an incredible amount of energy slowly picking it all up throwing another requirement python statsmachine learning on top just feels so daunting this field just feels geared towards younger people as i rarely run across anyone say years old doing it granted it is a new field so that may be expected ampxb anyway just wanted to see what people is opinions are as none of my close friends are in this field so it is very hard to ask for their opinions on it in a meaningful way ampxb thanks,what to do in analytics career mid level,is it worth taking a paycut to switch to data analytics
405,hi i am currently a stem masters student and i am learning ds online not just for school per se but it is one of the possible career paths i am looking at i understand that a single online course is far from enough but i have got to start somewhere i would like to know if there are some sort of practice exercises or even real world problem sets that have been long solved so i can apply whatever i am learning and see what i need to work on it is quite weird to just learn functions and methods and not use them anywhere tangible sorry if this has already been postedshared i am quite new here and to reddit thanks,practice exercises while learning ds,how do i start a career in data science
406,i am working on a project where i am analyzing survey data that asks a number of questions where the person can answer on a scale of at the end there is a question of would you recommend this product to someone else and that is the question that we are trying to understand using the previous questions what i want to do is determine which of the other questions drives that response of yes or no my ideas are to use decision trees and logistic regression to understand which questions are the most significant but i was wondering if there are other techniques i should look into as well i assumed that there would be a lot of multicollinearity issues with the data but when i ran a logistic model the vif was under for all questions any ideas from those who have done this sort of thing in the past,analyzing survey responses determining which questions drive the overall response,question about using logistic regression
407,my future goal is to land a data science mainly analytics and ml in the states or even canada to do this i have pathways get a masters from the states and apply for relevant jobs straight away thereafter i am in my senior year of bs in cs in my home country so i will be having zero full time experience after i complete my masters which i am guessing will make landing a job tough i have an offer from zs associatesillinois based consulting firm for a position of decision analyst in my country i contacted people in these positions and the work includes working with python r excel and all that for analysis and also some market research i can work here for a year and then do step to have a higher chance of landing a good job which one would you recommend planning to get a masters in csstats also is zs associates a known company,future plans are settling in the uscanada with a data science job currently have a relevant offer from a consulting firm should i get some experience before moving,is it worth getting a masters in data science if i already have a job as a data analyst
408,suppose you are on a data science team and are given a dataset and problem statement after preliminary steps you know you need to train for example a classifier what does this process look like if you are trying to follow a principled data science workflow and organize yourself according to something like cookiecutter data science the goal is to have a reproducible workflow that is transparent so that anyone on your team could see how you arrived at your results and do it themselves this process naturally involves a lot of experimentation with pipeline steps and model selection as well as hyperparameter tuning one approach i could think of would be to do all of the experimentation with interleaved commentsdiscussion in a notebook say experimentsipynb and then once i pin down the best pipeline configuration for my problem reproduce the entire pipeline in a script modelpy which trains a model from the raw data and saves it are there better ways to do this it is hard to find examples of professionallevel implementations of tools like sklearn amidst the masses of beginnerlevel tutorials out there links to example projects would be appreciated,what does a good scikitlearn workflow look like,how do you organize your data science workflow
409,hi this is my first time posting here i am currently working on my master is thesis which involves detection of certain diseases using the mri scans of brain tissue of individuals using spherical cnn i am dividing the brain into left and right hemispheres i have mri surface pialsphere and curve files for each hemisphere from free surfer i can get and create a d point cloud map using nibabel and opend for pial and sphere files the same files also contain the co ordinates for mesh triangles curv file contains a list of values whose number equal to the number of points in the point cloud map is there any way to display the surfaces that is read from the pial and sphere file so that we can display it like what is shown in the freeview part of free surfer to display the free surfer files or save the output from freeview in the form of numpy array that can be read in using nibabel screenshotzip,feeding mri data into spherical cnn d,how do i store a large amount of data in a database
410,sorry if this is an obvious question i am fairly new to tensorflow i have been training an object detector using the object detection api and trying to reduce the loss as much as possible this is for a school project trying to make a first person shooter bot use pixel data by recognising the enemy a dalek and aiming towards it then shooting i have had success implementing it but i am now trying to retrain the model to be more accurate it could not recognise daleks that were far away so i collected more data procedurally screenshotted from unity and labelled with a script that programmatically gets the bounding boxes and trained the model again but my problem is that i cannot get the totalloss below about i have been using the pythonprogrammingnet object detection tutorial as a rough guide and up till now thought that i should aim for about is there a number i should be aiming for or am i just worrying about nothing at this point however my main question is this after looking at the individual losses the localisation loss and the classification loss i realised the bulk of the totalloss is coming from the classification loss but i am only training to recognise one class of object dalek i do not really understand how it can misclassify this or why the loss is so high apologies if this is too long winded,tensorflow object detection classification loss with one class,question about object detection in keras
411,i got my new job in sept after my first job decided to have us all go back in person but i am thinking about transitioning into product management my reasoning is twofold first i have always been interested in starting a company myself but do not have the guts to do it yet so i figured i might as well learn how the whole design to launch process works as i grow my guts and secondly because i keep joining companies that promise guidance but i do not end up receiving any at my first job i was fresh out of college with a stats degree no coding experience and somehow the only data scientist on the team so i learned a ton of sql python and powerbi my current job has me work with alteryx and python no one else on my team codes or does machine learning so you can imagine how little guidance i have i am probably going to keep this job on my resume despite only being here two months because it is easier to explain than being unemployed so far i have only written one algorithm and it does well i also determined the tech stack as in i do my preprocessing in alteryx then bring the data into python and occasionally do visualizationsanalysis in tableau how do i say this sentence in a better way on my resume i also communicate with upper management a lot more and have done one relatively big presentation so far so my questions are what do i say when the pm interviews ask why i want to transition from ds to pm without sounding like my ds career was halfbaked and it was never really what i wanted to do will it matter if there is not a lot of quantifying on my resume for this current job since i have really only been here for months and have not gotten into the meat of the job if anyone here has transitioned from ds to pm can you please share how you did it,about to start applying for jobs months after getting my current job,how do you feel about your first job as a data scientist
412,i would say i am far from being an expert in statistics or data myself but because i know how to write a liner in python and do some simple regressions and correlation analysis they thought that maybe i should explain how i tackle working with data i think i can read myself into the most important topics but i wonder what they are the audience are complete layman which means that they are on a level where they know what a linear regression is but not ie a logistic regression or that a high correlation coefficient doesnt mean that the variables are dependet of each other etc how would you structure a minute presentation about data insights for this audience which topics or methods should i include,my team wants me to hold a presentation about data and the insights you can win from statistical methods how would i best structure this,how much do you know about data analysis
413,i have been working for a very small company for years that manages inventory that generates on average million dollars in annual revenue except this year due to covid my job title at my company is analyst and i am exploring my options of possibly finding a new job when i look at job listings there are so many job specific titles that i am unsure where i stand due to my responsibilities and experience at my company being all over the place since i work for a small company for example i have done regression testing and sprint acceptance my first months as an analyst at my company and then i helped introduce and implement that software application to our vendors and affiliates eventually i assumed the responsibility of managing our vendor who created the software application for us and help troubleshoot any issues regarding the software application and implement changes to our business logic onto the software application in relation to the software application above i also provide analyses on the impact of specific actions related to our inventory that our company must be in compliant in regards to a legal contract and ensure both parties are correctly compensated for i provide ad hoc analysis and run data models to help measure the impact of changes to our inventory and revenue projection this aspect of the job relies heavily on excel and sql queries to pull large amounts of data in addition i also helped improve and generate new standard of procedures for our operations team in managing and maintaining our inventory for example we are implementing machine learning and image capture technology to help speed up management of our inventory and i manage the team and provide analyses on performance and provide suggestions for processes and areas to optimize when i look at my job responsibilities i feel like i am a combination of a datafinancialbusiness analyst and have not specialized or heavily focused in one area how do i determine what route i go to that best fits my experience i have contemplated transitioning into a product managerowner role but i honestly feel i am underqualified and not ready to take that role yet,where do i stand as an analyst,i am a new data analyst and i do not know what to do
414,i have about m rows of data in my ab testing result the goal for the test is to see by changing some layout on the website if clickthru rate will go up in the test vs control group the percentage of different levels of the categorical variables are the same for example in the test group there are new vs old customers sameratio with the control group so no selection bias existed what i am stuckat is that overall my pvalue is lt however when i break them into segmentations for example new vs old customers or by marketing channels etc none of the subgroups has a small enough pvalue btw the number of rows is at least k for the smallest sub groupso the power is enoughi think so how do i interpret my result and how do i decide if i wanna make changes to the website,help with a statisticsproduct managementab scenario,how do i deal with missing data in google analytics
415,i am a social scientist who frequently works with data which is not digitized and is too poorly formatted to be ocred so my data pipeline typically involves an extra step of digitizing data my usual process for digitizing data is as follows create detailed instructions to transcribe my data hire two data entry firms and provide instructions write python script which checks differences between two csv files i only do this once run script on two firms transcription and manually correct the differences between the csv files several things could be improved with this workflow i would like to be able to directly write to a sqlite database i would like to be able to enforce constraints on what can possibly be transcribed entered into a field for example it would be useful to enforce a constraint that dates are properly formatted in some situations i might want a simple gui interface in which the data transcriber can see just the image to transcribe and some fields in which to enter the data my script to compare the two csv files requires the data to be entered in an exact order if for example one of the data entry firms accidentally deleted a row the error checking script would detect differences between every following row it looks like there are many different data entry software which might provide something like this functionality and it is unclear whether any of them are best or whether they provide my exact desired functionality additionally most of the software are proprietary whereas i would ideally use foss do you have any suggestions of desktop software or maybe some sort of web application which would be useful for my type of data entry needs i am a passable python programmer so if it turns out there are no such options i may end up making my own software,best practicessoftware for transcribing data,how do i go about creating a data pipeline from scratch
416,hi i have created a simple lstm model for the problem of prediction of the next word in a phrase and i am getting a rather strange result when i try the same thing with gru cell instead i use dynamic rnn to implement the internal ops of the neural net and use a lstm cell with state_is_tuple set to true as input after epochs with each epoch iterating over the entire dataset it gets accuracy i am still working on getting a better result but that is not the point i am running the model on a gtx however when i substitute the lstm cell for a gru cell during aprox epochs of training something goes wrong and one of the parameters is calculated as nan which subsequently makes all other parameters be calculated as nan too which ruins the training so what could it be could it be a memory issue i am almost sure it does not have nothing to do with cross entropy since i use the highlevel function sparse_softmax_cross_entropy_with_logits which handles log cases i really have no idea why it is happening another important detail is that i am not using tfplaceholder to feed the input but a tfrecord reader that inputs data to a k capacity random shuffle queue which in turn inputs examples to a padding fifo queue which dequeues zeropadded batches of elements to the model i also use a pretrained embedding layer for optimization i use adam,tensorflow rnn model works with lstm cell but returns nan with gru cell,question about overfitting with lstm
417,i am working on a pet project where i am trying to find scope of improvement in services of a telecom company and also the customer care interactions for a start i have picked all interactions on relation to changing rate plan customers can use any channel to change their plan web app call care support chat with an agent visit store etc i am looking for a way to measure pain in their journey while changing plans how much time did it take to browse plans and make a choice was the app experience so bad that the customer had to call care center were there any wrong expectations set or miscommunication that made the customer call back care after the change issues with billing device etc one way i thought made sense would be to use csat score find correlation with features like time spent number of calls or visits number of times channels was switched and try to come up with a way to quantify the pain experienced in each step let me know your thoughts on this does the above approach makes sense is there a better way to do this thanks a lot in advance,how do you measure experience pain points customers have in interactions with customer care,how to measure customer satisfaction
418,hi all i recently joined an analytics team at a global consulting firm think accenturepwc and am liking the role so far i came from an fpampa background i am an accounting majorcpa in ug and got interested in analytics after writing python scripts to automate my workflow during monthend reporting i realized that i enjoyed the quantitative nature of analyzing data and the challenge of writing programs to automate my workflow and joined this group to build that analytics skillset while also continuing to build on my business domain knowledge i honestly really like the rolegroup i am in so far even though i am on an analytics team my work beyond the usual etl dashboarding etc is fairly strategic in that our group is hired on to solve a specific problem for our clients ie how much of an impact did covidrelated business have on profitability while still allowing me to work with numbers and find creative ways of communicating our findings the one thing i am disappointed in is that our group is not as heavy in the technical stuff as i thought we would be i am not deep in python doing predictive modeling ml etc like i thought i would my typical project involves getting very messy data from a client using either python alteryx or powerbi to etl the data creating visuals using powerbi to understand the data building out question packs for management to discuss further and then producing some combination of a dashboard powerpoint andor excel workbook to communicate our findings to the client i still like the role because i am learning a lot about to analyze and improve businesses so it is actually building on the finance aspect of my background but i am worried i am not developing enough technical knowhow to move up in the analytics world my salary right now is great for my age but i obviously want to earn more and be a leader rather than just a lowlevel manager my question is how far can i realistically go in analytics with the very simple stack mention in the title deep business experience are there lucrative opportunities in industry just for doing dashboards and this type of work or do i really need to get into mlpredictive analytics to get the bigger paychecks thanks,how far can i go in data analytics with just numpypandas sql powerbi and alteryx,how much do i need to know to be a data scientist
419,hi friends i am currently trying to learn python and sql for data analytics i have made a little tool in google sheets to save records of a game i play with friends left dead and to analyze the results and create a ranking and stats for who won which map how often and how often different teammates won togehter you can look at the sheet here the match done button under amatch is a macro copying the results of a game played to history columns am though this is not important for this as i do not want to build the frontend in python what i want to do is only take history columns am in a csv and then build the amapstats noteamstats and ranking things as well as the player stats bottom right part of the amatch sheets in sql and python and maybe make a couple plots just to learn from it could you point me to a couple packages and functions that i would need to do this is all of that possible with just pandas and basic sql,analyzing game stats with python and sql personal project,how do i create a list of all sports games that have played in the past
420,hey guys i am a biology student doing my undergrad and i am looking to incorporate data science and programming into my career and i was wondering what certificates and training outside of my university are good to do to best prepare me and are attractive to employers i am currently teaching myself r using a really helpful youtube tutorial series unfortunately those do not give certificates and am really enjoying it i have also spoken with someone recently who spoke of the data science course through coursera and i am interested in trying that out but i am not sure what weight it carries from an educational and professional aspect thanks for the help,data science certificates what is the best,data science certificates
421,hi everyone i dont know if this is the right subreddit to post this in but i thought id give it a try i recently graduated with a bachelor of science in statistics and i have been looking for a job as a data analyst i did very well in school but i have struggled to find a job covid probably has something to do with it i have an interview in a few days and one thing i have been struggling with in the interview and job search process is how to articulate and talk about data analysis and statistics in general having graduated with a good gpa i obviously know the content but i seem to fumble my words and struggle to talk about data analysis and statistics that accurately shows my knowledge does anyone else have this problem and does anyone have advice for me thank you,advice on the interview process,how do i prepare for a data analyst interview
422,hi everyone thanks for so many comments and signups on my previous post here is this weeks post we have selected two articles for this weeks post these articles are from shopify and yelp engineering blogs tips for shipping data products fast moderating promotional spam and inappropriate content in photos at scale at yelp we hope youll find it useful whether youre trying to excel at a job interview or just trying to open your mind to new ideas from different implementations what are your favorite engineering blogs for data science let us know in the comments and we will include it in the monitoring list if you like these articles and want to be informed about future posts please sign up for the newsletter,data science in practice post,data science career tips amp trends
423,i feel like we should start calling data analysts data artists as i feel like it is more of an art than a science aside from using visualization tools such as tableau we also create nice spreadsheets there also isnt one way to do something as most of the stuff we do is based on stakeholder needs and each stakeholder is different data can be formatted and viewed in various different ways as well as it is highly exploratory data scientists on the other hand deal with predictive models and that is more of a science hence the name as they are dealing with advanced statistics that have hard cut rules what do you guys think,data scientist vs data artist,what is your data science superpower
424,hey guys i am currently working in academia as a research scientist and have a bachelors masters and phd all in physics related subjects i am hoping to leave academia for a data science job within the next months and was wanting to get some advice on what skills to learn before i apply i spend a lot of time programming in c matlab and python for work however i am struggling to quantify my abilities relative to a computer science graduate i have been looking at jobs and do not really know how to measure my ability against their requirements i am currently reading some machine learning books and trying to fill in the gaps in my language skills since i work for a university i am also planning to sit in on some undergraduate computer science lectures in the new semester just to summarise would my resume be able to compete alongside computer science graduates with experience in the field what skills would you guys say are essential to learn what lecture courses were particularly useful when you were studying how deep of a theoretical knowledge is required for most jobs thanks for readinghelping,seeking advice,what are the best resources for learning data science
425,hi i am being screened by a company and i am unsure whether the job title on my resume matches my actual job title well in my job agreement there is no specific job title instead i have a very long sentence describing my duties in very general terms in my current company i was assigned to a devops engineering team where my coworkers who do the same or very similar duties have devops engineering titles therefore i used the devops engineer intern title in my resume however i am not sure what my actual hr title is it could be a business architect analyst intern or etl developer intern or simply intern would that be a problem in the background check,job title and background check,is my current job title a data scientist or a dev
426,i have been doing some freelance web scraping for a few years now and thought it might be interesting to create a multipart tutorial on building a scraping project with a data science end goal i have had an interest in political rhetoric in the news lately so i thought it would be a worthwhile project to show how to go from basic news scraping to massive data analysis and nlp part is here if you are interested i would love to get feedback and answer any questions there is a lot of tips and tricks i have picked up along the way that are not explained very well if at all in most articles,my ultimate guide to web scraping,looking for a mentor
427,hello total noob here and also new to this sub i used to be in a robotics team frc a few years back and i had a thought the other day the data of every game that every team ever played is stored on a bunch of json files on an easy to access website can i take this data and predict in a game which alliance will win ampxb the game goes like so there are alliances red and blue in each alliance there are three robots for the first part of the competition the alliances are random so each robot playes most games with random two robots and against random three robots at the second part the eight teams that did best at the first part become the alliance captines and they get to choose who will be in thier final alliance the pick order is always the same and the sooner you get picked the better the rules of the game change from year to year but the data that i know about all the years is which robot played at which competition how many points the whole alliance made which alliance won who were the alliance members in what stage did the match took place in the random alliance stage or in the stage where alliances are set who got picked when if a robot was an alliance captin and the rank in which the robot ended up in at the end of the random stage based on who many ranking points the robot made on an avarge game which is related to if his alliance won or lost and did his alliance succeded in the special missions during the match ampxb the idea is to know which robot is better which robot will give you the highest chances of winning if it was on your alliance if i can know that i can pick the best robot out of my options and have the highest winning chances i never done anything like that before but i do have coding experience and i know python to some degree so this should be a fun project to get me started on understanding and learning data science i really need the help any tips on where to start and how to approch this will be greatly appreciated,how can i know which robot will win based on match data,i need help with a project
428,so for one of my final year projects at university i am trying to predict an age of death from a disease based on prior diagnosis ages and death ages for example i have records of people is ages when they were diagnosed with the disease as well as the same records for the people is ages when they die with the disease based on that information a user can input their age of diagnosis and get a predicted age of death output back to them so far i have generated all of the data with other variables that i hope to use later on using python and saving it to a csv file what is the best way to go about predicting thisis there any available information or guides to follow which does this simple task thanks,what is the best way to predict a value based off two variables,i am trying to predict the age of a person based on their prior diagnosis but i do not know what to do
429,hello i am an engineering graduate who is currently working on a masters in data analytics this is just my first semester but i am feeling a little restless about not having work so i have decided i am going to start looking the only problem is i have no prior experience my work experience has only been in engineering and ux and product design i am currently looking into internships but each place seems to have their own requirements so it does not make a lot of sense to me learn skills while i am already doing a masters the skills i currently have are basic to intermediate python r and sql tableau excel and then the models i am currently learning at uni only basics since it is the first semester i also have a couple of simple python and tableau projects on github data cleaning and data exploration would these skills be enough to score an internship any thing you guys would recommend i add,advice on how to break into the market while i am doing a masters no prior experience,i am currently in a data engineering masters program and i would like to transition to data science
430,hello i currently have an image classifier i made i was wondering though how others efficiently review their predictions and update their model currently i have run my classifier against a few thousand images my process right now is to save the prediction to my db then based on the winning prediction having my server move the classified image to a folder with that label this way i end up with folders that should mostly be right i then have to go through the folders and clean them up is this what others do i was also thinking about making a ui that would help do this as right now when dragging and dropping images to new folders i sometimes mess up which takes time to fix is there something out there already that can help me review the predictions thanks,question how do you review predictions and update models efficiently,how do you store your model predictions for future reference
431,im deciding to do full time devoting hrs a day on udemy courses and a bootcamp general assembly or springboard most likely for months atleast my stats are quite weak and as follows graduated from usc business undergrad only have months experience as a business analyst at a not very well known company years ago so im hoping to either apply to the junior data analyst positions as seen on indeed and other job boards since a surprising amount of them dont specify work experience and masters in stem and hoping i could showcase good projects that would weigh in my favor or do good work freelancing in the field to leverage the aspects i lack in realistically how hard is it for me to get that data entry job considering boot camps have job guarantees right thanks,what are my chances of getting a data science job after bootcamp,would a bootcamp be worth it if i already have a job as a business analyst
432,the current roster of summit sponsors includes citadel point marshall wace and ernst amp young the intention is to steer women towards data science jobs in the sponsor companies places on the summit are available and despite the dearth of female quants competition for places is already fierce women had applied by last thursday and more are likely before the deadline of midnight est on october rd applicants can be students or experienced female quants they will need to take a foundational skills assessment examining their ability to interpret charts and tables to answer basic probability questions and to respond to information processing and analysis questions places will go to female candidates who score highest on the assessment and who are looking for employment successful candidates will get to attend the summit and meet employers they will also get a mentor throughout the two week period and there is a chance your mentor will be female,women is summit in nyc,data science for women
433,hi if it is not a problem i would like to ask you for advice on a project that i have to submit for a university exam i have to analyze a dataset for example with one or two sample tests anova andor chisquare the dataset must contain at least observations and variables of different nature qualitative and quantitative the problem is that i cannot find and i do not know sites that provide datasets with multiple variables for free i was also thinking of creating a questionnaire to collect data by myself and to do a more personal job but i have no original ideas that can be distinguished from the possible works of my course colleagues so i wanted to ask if you could recommend topics on which to build the dataset or sites that provide datasets with multiple variables i hope that publishing posts of this type in this sub its legitimate and does not bother thank you very much,any advice for the project work that i have to do,need advice on how to approach this problem
434,i have trained a tensorflow model which takes my rtx several seconds per action in addition to seconds to initialize the model i have been looking into turning this into an iosandriod app running on tensorflow lite but apart from the technical challenge of converting the model into a tensorflow lite model and everything else am wondering about the feasibility of this running on phone hardware even on a reasonably modern phone with inbuilt gpu would this still likely be too slow for practical purposes can anyone who has built an iosandroid app with tensorflow lite where the phone is responsible for computation comment on performance and other practical considerations the only other option of having requests served by my own servers on aws for example would turn into a major expense if the app had significant use,feasibility of running an ml model on phone hardware,running tensorflow lite on ios
435,hello i am trying to get tensorflow setup and decided to update tensorflow to from because some code was out of date i believe i have cuda toolkit installed but also have cuda installed as well running nvcc version tells me cuda but nvidiasmi says cuda when i run dpkg list i see cuda amd cuda metapackage but also nvidiacudatool ubunt amd nvidia cuda development toolkit ampxb i get issues when i try to import tensorflow in my python code such as importerror libcublasso cannot open shared object file no such file or directory and i think it is related to above although i am not sure ampxb any help would be appreciated either a solution explanation or where to look for either of the two thanks,cuda and cuda installed ubuntu,how do i use udaflow with tensorflow
436,hey guys i just got a new job as an sales analyst and i want to further my career in business analytics before i go for a msc in data science i thought i can get some practical advice i am considering this course that gets me a micromasters credential from columbia university there are courses analytics in python data models and decisions in business analytics marketing analytics demand and supply analytics is this advisable to do anyone has done it before what is your advice pearson is offering an elaborated course with assistance instructors onsite lectures forums pearson portal and you get an acclaim badge it is triple the price please see edux is offering a general online version for the price please see between and what would you advise i am new to this stuff and i cannot assess the difficulty level either path would get your accreditation from columbiax and the micromasters credential,edux course in business analytics from columbua university micromasters,is it worth paying for a business analytics certificate if i already have a data science job
437,im not sure if this is the right subreddit to ask this question so forgive me if it isnt i am not a data scientist but rather work as a twomonthold analyst in an office of about that awards grants my primary role is to create newrevised processes to improve internal efficiency and projectprogram managers qol my question is what is the best format to guide an office of how to use a project folder structure out of the new folder structure i created it basically implies a refined milestone system that i will write a sop for in the future but first i want to make sure people understand what files to put where i personally do not like checklists as they either promote rigidity or people stop using them entirely because they feel pedantic ideally i want to visually represent a broad outline of how to store files with an ability to zoom in to find more detailed guidance this guide will be copied into each project file so is there a way to create a mock file structure that people can see a broad outline and then view more specific file examples and required documents if they wish what format would i use and what programs we only have ms office and then whatever inbrowser services thanks for any advice,best way to create office file management guidesprocedures,how do you structure your data projects
438,i have been building some pp software to provide a politically stateless and indelible public record of human activities in live d simulated cities i made a proofofwork that cryptographically hashes certain hidden activations of feedforward neural networks to prove whether computational resources were expended on the model to process camera frames correctly see diagram the last inference output from every node is hashed into a merkle tree at certain intervals by the network for data compression indelibility and consistency across the network current computational requirements are low as the network is model only detects and tracks people and cars now but that will increase over time the network is designed to be a form of inverse surveillance or undersight it is version so there is some assembly required but i am constantly updating it it is open source so feel free to provide fixes or updates if you want,tensorflow cnn mapbox d real life simcity,is there a better way to store latent code
439,i am a graduate student working on an analytic project that utilizes historical documentation i need to download approximately publicly available pdf from the us state department i could click through each one and save them individually but that would take forever is there any way that i can expedite this process at this point i just need to download the files and store them on my local machine in order to continue my project i am currently working from a windows machine but will have access to a mac in a few weeks if i need it i have included a link to the document set link so it is easier to understand what i am talking about thanks,downloading public pdf files from us state department for an analytic project any way to expedite the download,how do you store your data for future use
440,i am trying to implement a cnn in numpy so as to better understand its inner workings my architecture is as follows ampxb images with channel and with pixel rows and columns dimension xxx convolutional filters each with the dimension x dimension xxxstride first convolutional output with dimension xxx first max pooling layerstride first max pooling output with dimension xxx convolutional filters each with the dimension xx dimension xxx stride second convolutional output with dimension xxx second max pooling layerstride second max pooling output with dimension xxx first fully connected layer of dimension x second fully connected layer of dimension x output layer of dimension xsoftmax layer using backpropagation i have been able to calculate the error of the second convolutional output which has the dimensions xxx i need to calculate the error of the first maxpooling output this involves the following steps ampxb take the convolutional filter that connects the first maxpooling output and the second convolutional output this has the dimensions xxx rotate the rd and th axes by degrees in code that will be resulting_weight nprotnprotweightaxesaxes this results in the new rotated matrix that has the dimensions xxx do full convolution between the errors of second convolutional outputxxx and the new rotated matrixxxx i am unsure of how to implement the last step due to unmatching dimensions the full convolutional operation should result in a matrix with the dimensions xxx this is made possible only if the rotated matrix has the dimensions xxx should we reshape the rotated matrix to have the dimensions xxx or is my understanding of the degree rotation wrong,help required in understanding how the error of a convolutional layer is calculated when the filter and delta of next layer have differing dimensions,need help understanding the second dimension of a cnn
441,hello i am a phdstudent in germany researching on ai and for a prototype we are trying to have an ai compete against a human in a simple game in a way that induces stress we were thinking about something like vs tetris pong tictactoei thought i could ask around here maybe someone has a good idea about what game we could use what we are looking for in detail is the following vs competitive game where one player is a reinforcement learning agent implemented in python simple game that ideally everyone knows easy to implement playing induces stress in the human by making the game harder the better the ai is eg additional garbage lines or a speedup each time the ai clears a line ampxb any suggestion is welcome and thanks in advance,simple vs game to implement a rl agent,looking for feedback on a game we are working on
442,hi currently working in the construction field utility business as a supervisor i have a civil engineering degree i am planning to pursue my master is in data science and engineering recently got two offers within the company first one is another field position and second offer is a data analytics position i am thinking of staying in the field for another years and pursue my masters degree in data science and engineering the offers for both job are same but field position has ot opportunity and a great schedule after every weeks weeks off so i am guaranteed to make more shift differential for night shift and also travel around the world my plan was that after spending years in the field and finish my degree than apply for ds related position any advicesuggestions on how to get started for the masters degree would you do anything differently thank you in advance,need advice regarding data science and engineering field,data engineering or data science
443,long story short i am a psychology researcher with a ba who has experience doing a bit of independent data analysis with spss and excel correlation moderated regression descriptive statistics in addition i have over years of data management experience so i know how to work with data a decent amount i am thinking about switching careers to more data analysis jobs i have a lot of free time at my current job and was thinking about learning a new program or getting better at spss i have access to online classes tutorials at my institution any advice for what i should do should i learn more about spss should i learnt the basics of r or python can this even be done on my own,looking to get into the career of data analysis i have a history of psychology research with stats what program should i learn to make myself competitive,is it worth getting a masters in data analytics if i already have a job as a data scientist
444,not sure if this is the ideal place to ask but i have an idea for an app for hikers where a wireframe of mountains and ideally trails is overlaid onto the camera imagery by use of gps and compass data in this way it would be easy to identify peaks which could be useful for people who are lost or who are just curious about what is around them the only issue isi cannot find data sets to do this with google earth data is not so easily obtained and nasa is elevation profile data has some weird legal restrictions on access that i think would prevent me from making the app publicly available it would be free wo ads btw i imagine there is data out there for use by cad engineers but i have zero idea where to start my googlefu is lacking when it comes to this stuff any help finding this stuff would be hugely appreciated,elevation profile data for the entire earth,is there an easy way to track and potentially invest in data for public use
445,i have a dataset that contains couples xy for each sample x is a normal image y is the same image with the skin extracted what i want is some ideas on how i can use it to extract a general mask that could be used on any one of the x images to get the something close or identical to the y images the only idea that i have is using a cnn where x is the input and y is the output i know that i am supposed to tell you guys what i have tried before but to be honest i have no idea on how to start working on this project thank you,how do i find interval for rgb mask using an existing dataset,how do i extract similar images from a set of images
446,hey i am applying for a job soon which revolves around customer services and uses google analytics so i would help small businesses troubleshoot queries about analytics they have training programs as part of the job but i would love to get a headstart and try some handson training because i can read about google analytics all day but i would not really get it until i have played around with it myself is there a mock version i can access to get a feel for it i am looking now at the google training academy in analytics i feel like i am about to ask a stupid question but are those courses worth doing for someone in my position tldr i want to learn some fundamentals of google analytics and i learn best through doing without having to build a website myself is there a mockpractice version of analytics i can play around with,can i play around with a mock version of google analytics would really appreciate your advice,can i get a job as a data analyst without a degree
447,hi all i hold a undergraduate degree in geology i have been looking at masters in the uk for gisremote sensing and i would like to use the masters as a leap to something more dataheavy preferably a job with lots of analysis data management structuring etc somewhat like a data scientist the endgoal for the data does not really interest me but rather how the data is analysed and manipulated the programming should not be a problem i know python fairly well and i would be able to learn r or use numpy my question is has anyone done a masters in the uk for gisremote sensing and been able to lever this into showing people you know how to manipulate data if so where did you go andor your general progression to the above position if not possible through the means of a gisremote sensing masters does anyone have any ideas on how it would be possible any other comments are welcome thanks,suggestions for someone thinking of doing a masters in gisremote sensing,data science masters in the uk
448,hi i am a bachelor student who recently got his first job in data analytics it is not data science which i had a hard on for before but it is still fun and i like my job very much so i thought damn i really do not care at all what do i do as long as i have to think a bit talk with people a bit and my colleagues do not suck i am applying for masters right now eu so it is free and i am wondering what should i focus on where should my path lead if i wanted to base my decision purely on money is it the senior data scientists is it the big data architects is it the cloud architects or do i have to wait a few years to become a tech lead or a project manager and only then become the best paid any experience is welcome thank you all and i wish you a happy new year,how do i make the most money in this field,data science career advice
449,i created gainrankcom free to offer anyone with a website search engine optimization tools to help track and improve your ranking in the search engines there are several tools that offer data that can be useful to any of you who have a website here is a brief outline of some of the many things that are offered site audit this is a complete website analysis of your offering a comprehensive report of all improvements that can be made to your website to benefit your ranking in the search engines can be downloaded and white labeled site profiler we compile all api data points from other leading seo companies such as moz majestic and ahrefs to compile one list with all of the information rank tracker the best way to improve your ranking is to know what works and what does not to help with that we offer a rank tracker that updates your ranking once daily and tracks all previous rankings so you can see how your ranking has progressed over time vs the changes and work you have put in i think these tools are the ones that would best benefit those of you looking for data on your website however we do have many other tools as well we have support staff who can answer any and all questions you might have and a team of developers who are constantly working on new tools to help your website progress any suggestions or issues you find feel free to let me know here or simply create a ticket we are here to make your lives easier and your website rank the best it can its completely free no credit card needed simply sign up and get started you have nothing to lose yet so much to gain,perfect free data tools for anyone with a website,i am a senior data scientist at a leading search engine and wanted to help people who are looking for us data
450,i recently read an article that i can easily relate to pardon my emotions but i feel very sad about my developing data science career so far i am currently creating a data visualization web application without understanding the purpose of the app the data itself and the problems associated with the information that i am trying to present i have taken initiative to ask for understanding from my managers and they would just say it does not matter or something condescending like you will not understand i have even tried taking extending the visualizations by implementing my own machine learning insights only to be faced with having that labeled as a waste of time i am practically doing front end development using javascript with the false label data scientist as my title this had me searching for new job openings and creating new opportunities for myself i have been working on my personal project relating to semantic analysis on ted talks but find myself feeling discouraged due to how overwhelming it can be questions like what if my results are not good enough or is this really important to employers or even what exactly is the purpose of this continually run in my mind causing me to feel more discouraged in taking steps forward i have been doing a lot of selfstudy in natural language processing to prepare myself for some of the challenges faced in this project and even wrote a rough draft of the ideas that i would like to implement in my analysis so i have made some progress i have also been applying for jobs relating to data science of course the majority of the positions rejected me due to lack of experience of the few companies that gave me the chance to interview in the final inperson setting all of them had rejected me due to various reasons i have a masters degree in mathematics and the majority of my analytics experience machine learning python sql r etc is showcased through small miniprojects which i am honestly not proud of done through a data science bootcamp all of these rejections are contributing to thoughts like maybe i am not good enough to be a data scientist or companies probably want to hire the best of the best in the field causing me to feel highly unqualified in any other role that i want to apply for i feel really stuck and have not been getting much sleep due to this and i am feeling really unhappy ever since i was a little boy i grew up loving mathematics because i enjoyed seeing the parallels between mathematical concepts and realworld occurrences i have done mathematical competitions performed well in them wrote a mathematics academic paper received an award for my presentation in a national math conference and continued solving math problems in my free time i am struggling translating this passion in the data science field because it seems that no matter how hard i try i fail for various reasons anyone have any further tips on dealing with burnout data science is a really difficult field to get your foot in the door and each passing day feels more discouraging than ever,how to combat burntout feelings in data science,i feel like i am drowning and i do not know what to do
451,hi my school is in norway and durmstrang is one of the three largest schools in europe that specializes in the field of herbology and the arts the courses cover a lot such as chemistry economics and anatomy of different creatures we work with we cover a lot of mathematics but we do not cover much programming because computer subjects are not as prominent or suitable for the school professor igor karkaroff is a very notable teacher he mentioned that while many are admitted focusing on the arts some become biostatistics and analytics wizards despite his brush with the law he is now serving as a consultant in the uk for naming coconspirators in one of europe is biggest drug and weapons bust by a group called dark wizards our biggest competition is a school in ireland that sounds like a sick pig with skin disease we compete with them aggressively to be first in our subjects but they have been getting a lot of attention lately because they have a cohort of champions who are also not notrue people if you know what i mean would my program work in terms of finding work among muggles,can i be an analyst if i have a degree in herbology or better known as pharmacy from durmstrang institute,are there any data scientists out there that do not like their jobs
452,i made an anonymized version of the meetmindful leak no names gps coordinates ip password hashes emails because the remaining data age height dating preferences were still interesting to me so they could be of interest to others the full leak is actually about m entries not m as news articles would have you believe they just looked at the line count of the csv without realizing there are many multiline entries i restricted to the subset of rows for people in the united states m just because it is more familiar to me i dropped columns that were very sparse finally i added a boolean pwned column which is true if the email was found in the haveibeenpwned dataset of b emailpassword pairs mb csvgz file link or link a few cool sad insights users with gmail emails are young in contrast to those with aol emails boomers forget their passwords more often older more likely to be in the haveibeenpwned dataset short men tend to have a larger searchmatch radius same for tall women,anonymized meetmindful leak subset k rows,is there a better way to store large amounts of user data
453,hi there wondering if people have perspective on when is too late in a career to break into data science for some context i have software engineers and ees in my extended family who came up in the s learning stuff like fortran and cobol my impression is that they have really fought tooth and nail to retain their jobs as they edge towards retirement i do not have the full story because it is kind of awkward to ask but that is something that has always made me a bit anxious about high tech of course i know that is not synonymous with data science but this is for the purpose of discussion i am in my late twenties and i have experience in data acquisitionoperations but i would love to take on more data science work that would involve python and r that is not necessarily in my day to day i use a little sql but not a lot i am learning slowly in my free time and i know plenty of midcareer people who recently broke into data science through many different kinds of pathways thing about those people though is that almost everyone i know in that position had some kind of stem background in common that i do not have at all so i feel like i do have to market myself in a different way and would potentially have more ground to cover to break into the field not a lot of personalwork experience in etl experiment design statistics yet i know that getting started in my late twenties is definitely not late relative to how long most careers even last but i want to be grounded and realistic about my next steps if i want to follow this interest like i said my reference point is software engineering where i feel like getting a first software engineering job north of is definitely not impossible but i understand that is more challenging given that there is age bias towards recent college grads maybe i have really been fed a lot of silicon valley coder stereotypes and i might be imaging more overlap than there really is between data sciencesoftware and that colors my perceptions but i am wondering if there is overlap between that culture and data science appreciate any insights or experiences here,question about breaking into data science later in career,is data science a good career choice for me
454,hi were a group of friends and want to hear what you think about what were working on were super early so really want feedback if you want this to exist register interest on the best experiences we had when learning data science were working on projects and hackathons we also benefited from having a peer group eg at university the friends we made have often lasted delta academy combines these two elements live competitive coding games with a cohort of peers the cohort will be people its the format we wanted but couldnt find online so were creating it we would have to charge for running cohorts initially just to cover the prizes but havent figured out how much yet just want to know first if this is something people want really keen to hear feedback both positive and negative,friends and i are sick of online tutorials so were running a group for learning data science by playing competitive team games is this a cool idea,looking for feedback on our data science bootcamp
455,prof dirk helbing dirkhelbingis chair of sociology in particular of modeling and simulation in eth zurich and the scientific coordinator of the futurict flagship proposal he is also the principal investigator on futureict knowledge accelerator and crisis relief system a big data computing system conceived as sort of a crystal ball of the worldthe core of the system is the living earth simulator a computing machine attempting to model globalscale systems economies governments cultural trends epidemics agriculture technological developments and more using torrential data streams sophisticated algorithms and as much hardware as it takes the project currently competing for funding from the european commission of billionhe is known for the social force model in particular its application to selforganising phenomena in pedestrian crowds besides the slowerisfaster effect he introduced the freezingbyheating effect and the phase diagram of congested traffic states helbing also proposed a microscopic foundation of evolutionary game theory and has studied selforganized behavioral conventions recent work applies principles of collective intelligence and selforganized control to the optimization of urban and freeway traffic his current research activities focus on norms and conflict the role of successdriven motion for the establishment of cooperation among selfish individuals the science of science socioinspired technology and technosocial systems disaster spreading and crisis management in our wideranging conversation we cover many things including how science fiction impacts our worldview the problem with todays economic model and what we need to fix to find success why blockchain is incredibly interesting and has potential to transform society how artificial intelligence and human creativity can coexist and thrive why we need better governance and incentive systems to sustainably survive the coming years the problem with connectivity and monitoring why dirks team is focused on building a universal human brain the pros and cons of capitalism socialism and something else entirely how regulations help and hinder progress what a new world order could look like and how to get there the impact of iot and sensing on striving for a better future,building a crystal ball of the world unseating capitalism and creating a new world order with prof dirk helbing,what is the future of data science
456,just what the title says what do you love about data science what makes it fun for you i have hit a rut and i would like a little help to pull myself out more accurately i think i burned myself out a little backstory i have a problem with my career choices where i start off super passionate excited and motivated and then i get i psych myself out of it for one reason or another i am pretty deep into data science i have been studying consistently since however recently i saw a post on rdataengineering that asked if people regretted their going into the field a lot of people did i know de is hugely different from ds and there is a bias in the people who would respond to such a prompt i would just like to hear what you guys love for a little motivation,what do you love about data science,i hate data science
457,this is a bit of a hard question i tried googling and searching within this subreddit and think i am not asking the right way are there any standards or tools for describing data sets using easy and consistent metadata and then visualizing organizing browsing and navigating through them i work for a form that has many large datasets managed in various ways but have fairly static metadata described using largely project open data however i and many team members create small analytical subsets all the time for a particular question or joins or whatnot they are typically disconnected as the analysis is point in time sometimes they are built into database systems like sqlsrver that has it is own metadata and ways to search and describe the set however it is usually sas or r or csv or some relatively small file from mb to a few gigs however this leads lots of difficulty in keeping track collaborating with coworkers reusing someone else is work etc some folks compensate by describing the extracts using datapackages or wc or whatever individuals choose and storing the file where it can be indexed by an internal search engine usually solr i would like to find an easy or oss tool that can consistently store metadata and point to the source dataset and allow browsing searching visualizing stats like linkages user activity etc but that also works on an individual level to organize personal on individual collections that grow over time there are commercial data management products like collibra or socrata has some internal enterprise data products but they are expensive and require a central install and purchase i basically want github for data but cannot host externally,what standards or tools for describing visualizing archiving metadata for analytics data sets,how do you organize your data
458,i am trying to start a project where i do textual analysis of song lyrics similar to this project i would also like to later incorporate some type of nlp aspect as well still planning that out the artists i am focusing on are a multimember rap group and i would like to compare each of them on various things like most words spoken per album least words per song most common words used etc i plan on getting song lyrics through webscraping but i am not sure how to organize the data once i have all the lyrics i am not sure if i should separate their lyrics individually by song or by some other factor is there an optimal way to store and organize this data,data organization for textual analysis of song lyrics,how do i organize data for a rap lyrics project
459,ampxb i am glad to announce we have released hora an approximate nearest neighbor algorithm library which is written in rust and focus on the approximate nearest neighbor search field we have already implemented hnswhierarchical navigable small world graph index index ssgsatellite system graphindex pqivfproduct quantization inverted file index bruteforceindex and other indexes are coming and we use simd to accelerate the performance make it blazingly fast our slogan is hora search everywhere which means hora can be deployed in any os platform including already supported pc os linux mac os windows will support portable device osios and android and even will support embedded systemsno_std and we would support many language bindings including python javascript java ruby swift and r thanks to the llvm great portable feature we can make it happen github homepage python library you can easily install horapy pip install u horapy for horapy demo you can check our github here is our online demo you can find it on our homepage facematch online demo dream wine comments search online demo we think rust is very suitable for computing applications due to its zero cost abstraction and llvm backend and nowadays rust community also improve its simd support these days make our library can be as fast as faiss even we do not use something like blas annbenchmark is a famous ann benchmark framework here is our benchmark result you can see we are as fast as faiss and we do not use any other dependency like blas or openmp we use rayon instead d performant simdaccelerated packed_simd stable algorithm implementation multiple threads design reliable and productive rust compiler secures all code memory managed by rust for all language libs such as horapy broad testing coverage well documented elegant and simple api easy to learn portable support windows linux and os x no heavy dependency such as blas multiple languages support rust python javascript multiple distances support dot product distance euclidean distance manhattan distance cosine similarity we are pretty glad to have you participate any contributions are welcome including the documentation and tests we use github issues for tracking suggestions and bugs you can do the pull requests issue on the github and we will review it as soon as possible github,announcing hora an blazingly fast approximate nearest neighbor search algorithm library,rdatascience is announcing the release of hora an opensource python package for machine learning
460,hey everyone so here is the thing i am trying to accomplish user visits a specific page either through a landing page or a regular pageview it does not really matter i set up the following sequence basically it is landingpage contains x and is immediately followed by an event being triggered the event triggers a specific conversion on my page it is not possible to use goal conversions here since it was not set up prior to the analysis but somehow my segment still get sessions on a page where the event cannot even be triggered how does immediately followed by actually work in google analytics i thought it was hit gt event but it does not seem to be like that any ideas,understanding followed by and immediately followed by in segments,how do i track a specific page in google analytics
461,hi everyone i mfinishing my bachelor in statistics in italy and i would like to continue my studies with a master degree in a good university in europe in these years ive appreciate both the theoretical and the applied stuff ive met in university therefore im torn between applying for the msc in statistics and the one in data science either at eth zurich moreover there are some programs in statistics and data science such as the one at ku leuven nevertheless i think i can build an hybrid path as well doing either the statistical and the data sciences one considering the large amount of elective exams in conclusion i would like to ask you what should i do to really understand which is the the branch of studies i really want to continue in for istance under or postgraduate courses that better represent each field studies and work prospectives or any other discriminant that may help my choice thank you in advance,data science statistics or middle ground eu msc,is a data science masters worth it if i already have a job
462,i am training a convnet on cifar and using samples for validation at each epoch whenever i use early stopping though it stops way too soon this is because there is a pretty significant amount of variance in my validation loss even if i set it to be patient and wait for several epochs of no improvement it stops way too early usually around accuracy what am i missing here it seems like it is always best to let training run the full course i have it set for about epochs at the moment but will increase it when i feel more confident in my hyperparameters i also tend to see the loss and accuracy plateau rather than worsen in the later epochs is this normal behavior,early stopping for neural nets,why do we use so much convnet
463,hello i am a college freshman and am interested in going into a career in data science at my university we do not have a bs in data science so i am planning on pursuing that for graduate work but what undergraduate degrees are generally best for pursuing data science graduate degrees for me i was mainly looking at cs but the uni i go to has a really competitive major for cs so it is not guaranteed i will get in other majors i was looking at is math or statistics are those majors good for a career in data science or should i just stick with trying to get a cs degree thanks so much,best undergraduate degree for data science graduate programs,is it worth getting a master is degree in data science
464,i have been applying to a bunch of entry level data science jobs without any interest a refreshing number of straight up nos actually as opposed to just ignoring me i wonder if you all could give feedback on my portfolio it includes my resume side projects most important at etc a few questionsconcerns on my resume i put aspiring data scientist and software developer this is the truth but i have heard people say you are supposed to project more confidence should i just say data scientistsoftware developer rather than many small projects i have big side project the manga learn project linked above what are your thoughts on this project is it a good example of what i will need i learned one hell of a lot from it far more than i have from any kaggle competition it also reflects my work style i am really good at finding useful applications of machine learningdata science as opposed to just optimizing it shaving off loss points my location is in carpinteria ca this is near santa barbara a lot of the jobs i am applying for are in nyc should i use an nyc address how would this work since my current company is clearly in carpinteria i have some personal blog posts there as well should i remove these thank you for any feedback you have from how far away i am from getting an entry level job to what i can improve and also how to increase my chances etc,critique my resumewebsiteportfolio,data scientist to data engineer
465,i am thoroughly reading through deep learning and really want to understand the math i never had the motivation to understand math until my recent interest in machine learning and deep learning in general i have this mathematical notations page from wikipedia open on the side as i am trying to decode the formulas but am having trouble understanding them as a whole ampxb i am in the section of the book describing norms and how a norm is any function that satisfies three listed properties one of those properties is written as rfxfx ampxb my current understanding as i look at the formula is that for all numbers in alphawhich confuses me from the start because i found it means proportional to but it is being used as a variable is an element of the set of all real numbers and the function of alpha times vector x is equal to the absolute value of alpha times the function of vector x ampxb can anyone help me decode this into regular people words,math question from a nonmath person in the topic of norms,how do you deal with missing values in deep learning
466,firstly apologies if this is the wrong sub i could not find one that better suited my question i am currently working for a company that manages many different social media accounts and websites and it is part of my job to gather the analytics monthly and present them in nice graph form we are talking or so twitter and facebook accounts along with a handful of instagram accounts and websites so quite a large amount of data sources i was initially hired as an apprentice and as i was relatively competent at excel i spent a long time developing this very large excel document that incorporates all this data and has reactive graphs with drop down selections date ranges quarterly reports etc etc as you are all probably aware setting this up in excel and learning as i went was an absolute nightmare we are now we are looking at adding a few more accounts to the list altering data points and making several other changes and i really do not fancy changing all my code i would probably just rather recode everything from scratch at this point and i have convinced my manager to look into other programsservices we can use that are more user friendly the overall aim is for some nontechsavy staff members to help input some data i have done a fair amount of research and i really cannot find anything that suits our needs they all either cost a fortune i will not have a large budget for this or are missing some pretty essential features so does anyone have any ideas i do not mind manually inputting data into something if it can spit out some nice graphs and can do some of the more basic analysis but we would like something more userfriendly and easy to manage if possible tldr need to analyse a large amount of social media data excel is too complex and we would like something userfriendly that can spit out nice graphs that does not cost the earth any ideas thanks,excel alternative for processing large amounts of social media data,how do you organize your social media data
467,hi everyone i am currently thinking about an issue that seems to be undocumented at all in machine learning classification theory regarding making a decision based on the probabilistic threshold in ml classifiers let me use an example imagine a typical classification problem for instance credit loaning in banking the target variable is whether a customer will default or not when using a classification approach there are a couple of things we may want to do try different models and hyperparameters for those models and select the best combination based prediction quality on unseen data given that our classifier may output some sort of probability scores think predict_proba in scikitlearn we should decide our cutoffdecision threshold in order to decide which customers will be given a loan and which wont after that we probably want to asess the quality of our model threshold decision in a separate test set everything seems pretty standard so far however i am thinking about how to split the data in order to avoid optimistic resultsdecisions i have thought about the following approaches splitting the data into trainval using cross validation test where cv is used for hyperparameter tuning and test is used for threshold choice and estimate future results however the problem is that i wouldnt have a true final estimate since the threshold choice is performed in the same test data i am using for the final result asessment splitting the data into trainval using cv decision set test set where the decision set is used for choosing the threshold and final result asessment is done on the test set the problem i see with this approach is that we are splitting the dataset more times therefore we have less data in the other sets splitting the data into trainval using cv test where cv is used for both hyperparameter tuning and choosing the threshold while the test set is used for final results asessment however something tells me that using the same cv procedure for both model tuning and choosing threshold will yield illinformed decisions furthermore if i use fold cv for instance i would have to make the decision threshold choice based on independent experiments which could be cumbersome and unstable any ideas on which technique is better i have asked different people and there seems to be no closedform solution id rather not use the first approach but i cant decide between approaches two or three thank you,train validation test and decision threshold choice in classifiers,how to deal with outliers
468,i am currently trying to simulate this problem i am using r the strategy that i am using is roll till an a or a larger value is encountered in which case stop playing and collect your winnings this is simulated times for each value of a which varies from to by using the replicate function i maintain records of what value of a gave rise to what expected value finally i choose the entry for the maximum expected value to provide an example sided dice a dataframea for each value of a i run a simulation to check what the estimated value will be one example a die rolls in this case the player continues to roll till at which point they stop as is larger than a here and collect as their winnings actual gain step is repeated times each value of a gets runs the final expected value chosen is the mean of all these runs i end up with a data frame like a dataframea ev c from which i can see that the maximal expected value is xyz where xyz is the decimal part the problem that i am facing is that i cannot seem to be able to replicate the figure in the original link which is backed up by the theoretical calculation i have noted that increasing the number of trials from to towards takes the expected value closer to the figure in the link is this the only way to increase accuracy or am i overlooking something some other information i setseed to a fixed number at the beginning of the function this means that setseed is called only once for the entire function irrespective of number of trials,need help finetuning a simulation i am trying to run on r solving the sided dice problem,how do i deal with missing values in a model
469,abstract text contains a wealth of information about about a wide variety of sociocultural constructs automated prediction methods can infer these quantities sentiment analysis is probably the most wellknown application however there is virtually no limit to the kinds of things we can predict from text power trust misogyny are all signaled in language these algorithms easily scale to corpus sizes infeasible for manual analysis prediction algorithms have become steadily more powerful especially with the advent of neural network methods however applying these techniques usually requires profound programming knowledge and machine learning expertise as a result many social scientists do not apply them this element provides the working social scientist with an overview of the most common methods for text classification an intuition of their applicability and python code to execute them it covers both the ethical foundations of such work as well as the emerging potential of neural network methods,text analysis in python for social scientists with code free pdf through march,research a new type of data science called sentiment analysis
470,data governance is the management of an organizations data availability usability integrity and security according to gartner governance is the specification of decision rights and a framework for accountability to assure acceptable behavior in the value generation consumption and control of data and analytics why do organizations need it it guarantees that data is consistent and reliable which helps to avoid data inconsistencies or errors it helps in regulatory compliance that helps in ensuring that organizations are consistently compliant with all levels of regulatory requirements this is key for minimizing risks and reducing operational costs it leads to improved data quality decreased data management costs and increased access to data for all stakeholders which translates to better decisionmaking and better business outcomes dqlabs presents a data governance tool with the following features a greater data comprehension utilize a machine learningenhanced data catalog to streamline and automate the process of discovering inventorying profiling tagging and developing semantic associations between data assets as well as determining data quality traceback to the source using data lineage build trust in datadriven business outcomes by automating the process of data lineage to trace from the data source to data consumption ability to monitor and report data assets over time as well as many areas of data management such as trend quality sensitivity curation impact and so on minimize risk with proper access easy and simple but centralized data security and permissioning of information assets across data sources datasets and even attribute levels automatic identification of personally identifiable information across diverse information assets using semantic type identification to avoid revealing sensitive data check out dqlabs agile data governance for more details on data governance and how your organization stands to benefit from this service you can also signup for a day free trialand request a demo,data governance tool what to look for dqlabsai,dqlabs data governance best practices
471,tldr a mech engineer doing an msc data science course everything is way too interesting need the advice to hone myself into a weapon using the knowledge of experts in this field that have a bird is eye view looking for general career advice cannot add more to the tldr without messing up the main intentions read below i am currently enrolled in a yearlong msc data science program in the uk i am and have a bachelor is degree in mechanical engineering i have a real interest in creating value it might be designing a new kind of machine or algorithm i love it at this point i have already finished a semester in the univerisity with only semesters left i know that ds is a vague term for a collection of similar and interrelated professions i took up ds as a master is course because i had eventually come to terms with the fact that i had an interest in all things scientific but it turns unsurprisingly out that most ds jobs deal with trying to increase a company is profitability that in itself does not appeal to me i would love to work in a company that works on increasing the performance of a product or service rather than trying to increase the profitability of the company directly with a mechanical engineering background i like the idea of working in a company like tesla of course as a data scientist but at the same time i get lost in this breathtaking field of ds after some thought i managed to narrow things down a bit a computer vision etc is something that is general and can be used in multiple domains like medicine science governing etc b time series analysis this is again multipurpose and i am thinking about its uses in the financial industry the financial industry again is not something that adds value but at the same time i do find it interesting since i used to successfully day trade cryptocurrencies c nlp this is like the final frontier unimaginably interesting for me because of its proximity to general artificial intelligence but not sure if i have an easy career there that lines up with my end goals which i have stated below there are just so many wonderful things happening and so many possibilities that i am just confused there are two things that add to my confusion i need to repay the k gbp loan this is not a dealbreaker really in the sense that although i do not like being in debt with anyone i would not mind taking longer to pay the loan for the sake of my career my own company or initiative and this one is extremely important i want to do something of my own about the time the next years come to an end since i love all fields of expertise equally this can be in any domain for this sake i would love to have a lot of exposure which off the top of my head only a startup can give i am asking for advice on my options and how they compare with each other i do not mind moving to any other country as long as it increases my long term and preferably short term too career prospects i am hoping for a person with a bird is eye view of the ds domain to understand where i am coming from and answer my question accordingly i am sorry i cannot be more expressive about myself if nothing else please elaborate on how it is like working in various sectors of ds because as a person like myself who is new to this and who is going to have to pick a career soon this is really overwhelming i know that a lot of people would ask me to just pick a project and just try my hands with it i know that and i am already in that path but it takes time and i would like to slipstream behind the ones that have already done it or at least listen to what they have to say knowledge compounds when it is passed on i prefer not to try and reinvent the wheel at this stage i think the main reason it is so hard for me is that i am not someone who just casually picked ds because of the salary benefits so i would not enjoy working just for the sake of earning money i need intellectual stimulation and i also need to add value,a budding data scientist needs career advice,is it worth getting a masters in ds if i already have a job as a data scientist
472,i am trying to build a recommendation system using deep learning to predict whether a user will select a certain item based on his past orderselection history this is my first time trying to implement a recommendation system so i am struggling a bit and looking for any kind of advice and tips that could help my dataset has columns user id item_id item category and the binary target column which indicatens whether the user have chosen the item or not item_id item_category target user_id so far i have tried an embedding approach using keras where i embed the user and item ids take their dot product and pass them onto neural network vendor_input inputshape namevendorinput vendor_embedding embeddingn_vendors namevendorembeddingvendor_input vendor_vec flattennameflattenvendorsvendor_embedding user_input inputshape nameuserinput user_embedding embeddingn_customers nameuserembeddinguser_input user_vec flattennameflattenusersuser_embedding prod dotnamedotproduct axesvendor_vec user_vec out dense activation areluprod out dense activation isigmoidout model modeluser_input vendor_input out nameembeddings modelcompileadam binary_crossentropy modelsummary i have also tried just passing the input features directly into neural network without embedding them model sequential modeladddense activation arelu modeladddense activation isigmoid modelcompilelossbinary_crossentropy optimizeradam metricsaccuracy modelsummary the embedding approach yields high f accuracy on train set about and very poor f score on testing set about the approach without using embeddings gives me near score on train set and near zero f score on testing set i am looking to improve my test f score i am wondering if anyone has any tips or recommendations on how to implement a decent recommendation engine which model architectures should i use what were the flaws in my approaches that i have tried all suggestions are welcomed,any advice on implementing deep learning recommendation system,how to train a deep learning model on a single set of data
473,hi there i am new to machine learning and trying out a toy problem to give me something to play with i have some historical stock data i am trying to use to train an lstm model i have chosen this as it is an area i am familiar with i have a pandas dataframe with data which looks something like this resampled down to minute intervals datetime open high low close volume close_pct open_pct feature feature feature nan nan nan nan e e there are columns in total the examples and tutorials i am following all seem to presume that we want to predict all of the columns in the upcoming data i do not care about any of the feature columns i just want to predict what the high_pct change or low_pct change will be do i need to define a loss function i have a feeling i may be misunderstanding something fundamental it is probably not useful but here is the model i have started with so far model sequential modeladdlstm return_sequencestrue input_shapenone modeladdlstm return_sequencestrue modeladddense input_dim activation isoftmax modelcompilelosscategorical_crossentropy optimizerrmsprop metricsaccuracy modelsummary can anyone suggest where to go next with this or even just some keywords for the kind of things i need to be reading up on to help me understand better thanks loads for any help edit to add i am running the fit function modelfitx_train y_train epochs validation_split but i am getting nan for the loss score epoch s loss nan acc e val_loss nan val_acc e,how to tell keras which column in a pandas dataframe to predict,question about nan loss
474,hi i noticed that a lot of data folks in and out of this community are employed by companies either for fulltime or longterm contract positions i was wondering if anyone has done a data consulting business of their own fulltime or as a side hustle like finding your own customers and working with them for months projects here are some of my initial thoughts cons challenges basically any cons that you can find from having your own business finding customers marketing tax finance communicating your value propscompetitive advantage what is the difference between a consultant and a dataanalytics consultant do people actually want to hire a data consultant cannot companies just hire a data analystdata scientist temp how do you build your consulting package how do you decide on the price and estimate hours needed pros basically any pros that you can find from a generic consultant position flexible timelocationterms you can choose who to work with gain additional data experience besides your main job some extra income any thoughts or advice quick info about me i am a senior business data analyst have an mba not a top school total years of work experience incl years with excel sql some tableaupowerbi some python statistical analysis tldr advice for starting a data analytics consulting business as a side hustle is it worth it,what are your thoughts or opinions for someone starting a data analytics consulting business,data science consulting vs analytics
475,the way i have been going about it mind you i am self taught is the following training set is used to perform crossvalidation to narrow down the algorithms you wish to proceed with once you have selected or algorithms you fit them on the entire training set and test them repeatedly on the validation set validation set is being tested on repeatedly with different hyperparameters each time until the optimal combination of hyperparameters are selected for each model test set is used to test your final models and to select the best performing model results from testing on the test set should not be too different from your final tests on the validation set does this sound just about right or is there a better approach to utilizing the data splits,is there a standard approach for utilizing test validate and train sets when performing classification problems,how to handle outliers
476,hi all i am building a product which logs website visitor information i need to be able to look for specific patterns in this visitor data for example let is say there was a sudden spike in visitors tonight from pm pm i want my product to be able to recognise periods when there is a spike in traffic i understand i could write some brute force code which does something like counts the number of visitors in every minute period and compares the current value with the previous minute period value and then compares the previous minute period value with the one before that and so on for perhaps the previous ten minute periods and try to judge if traffic is increasing but obviously this is a horrible way to achieve this are there any common patterntrend algorithms or techniques or general best practices for this sort of thing also what is this area of study called is it statistics if so is this something i could hire a statistics intern to help with or is it too advanced sorry if these are stupid questions thanks for your advice,general advice on looking for specific patterns in data,how do i go about building a time series analysis
477,just started reading this deep learning book and they used a term which they have not yet defined here is the context they are trying to explain two ways of viewing deep learning here is the second view bottom of page on the link i provided another perspective on deep learning is that depthenables the computer to learn a multistep computer program each layer of the representation can be thought of as the state of the computers memory after executing another set of instructions in parallel networks with greater depth can execute more instructions in sequence sequential instructions oer great power because later instructions can refer back to the results of earlier instructions according to this view of deep learning not all the information in a layers activations necessarily encodes factors of variation that explain the input i have heard this term a lot a layer is activations what exactly is a layer is activation,question about terminology what are activations,deep learning activation instructions
478,heatmapgif gt we are currently in the process of officially partnering up with the korean cdc to bring more accurate and uptodate data and the most powerful tool to expedite the process is the sign of support from developers like you so if you liked our work please leave a star and share this with others your support makes our work meaningful thanks isaac covid korea dataset with patient routes and visualizer heatmapgif covid korea dataset with patient routes dataset components patient routes more coming patient age gender diagnosed date based on jihoo is dataset epidemics amp medical statistics dataset components major epidemics vaccines chronic diseases annual health screening results medical facilities population depression amp mental health life satisfaction multivariate amp timescrollable data visualizer gt coming soon key features displays infected patient route and regional patient count visualizes changes in the number of patients and route with time displays noncovid data as heatmap visualizergif upcoming official partnership with the korean cdc in progress more patient routes from nonseoul provinces dailyupdates on covid release visualizer more features for the visualizer more noncovid data,largest covid korea dataset with unparalleled patient details,new covid epidemic dataset
479,hi i am a newly graduated double major in maths and finance with a large interest in maths stats computer science etc but i have a small problem i live in an industry city in northern europe with a lot of companies within manufacturing and other conservative areas atm i work as a data analystscientist doing some machine learning modeling and some data visualization etc but i do not get the stimulation that i need also it is hard to get another job where i live since it is a fairly small city and the industry consists of large conservative companies not a lot of start ups etc investors etc i am thinking of in my spare time evenings and weekends set up some side business doing some analytics work or something but i have no idea how to start or if it is easy to get some customers etc online does anyone have any tips where to start looking and how to go about this thanks,set up a sidebusiness at home,how do i get started
480,hey all i have about years of analytical experience with a masters in business intelligence have coding experience in r sqlsas and applied to data science projects in the past past role and current are more descriptive analytics and my ds acumen is fading off still have extreme passion in the ds space i am very confident ill get an offer as a senior decision scientist role upcoming that is about coding data analysis and more so business insight application with the bonus potential i will probably take it based on comparisons to my current role salary and other ds roles i have explored my question is how to keep the passion alive and continue to learn in the ds space to merge back over im currently enrolled in some class for data engineering and python on codeacadamy any other suggestions thanks in advance,senior decision scientist job prospects against data scientist passion,data science career advice
481,for example with background in ee one day i was working with energy data i saw the data if a house has some power exceeding kw and the house does not have any electric vehicle the i immediately feel suspicious and double check if any problem with sensor or data synchronization turn out sensor problem also if the voltagecurrent waveform then i can think about impedance or admittance or phase or oddorder harmonics or transient could be the import features in fault study when the power line is grounded voltage then admittance will be infinite and it should not be a feature in fault study i am curious to see any other examples from other industries,what are examples from your working experience when domain knowledge is super important,is there any reason to have multiple time series data in a database
482,hey everyone i am a year old currently a freshman in a uni having economics as my major i have always been asked what i wanted to become and i was always unsure because i have love for both everything financial and everything tech too i was torn between taking a computer science major and an economics major decided to take economics later on i feel like data scientist as a profession fulfills my need for best of both worlds it gives me the opportunity to play with numbers as well as employ the magics of technology under my command fyi i have been studying computer science as well as economics in both my junior and senior year of highschool i have comprehensive knowledge of economics and i have learned to code in java c python sql some beginner level javascript and a bit of html and css i am willing to take a side professional course if it means that i can move closer towards being a data scientist here are my questions what are the skill sets i should have to be a data scientist is economics major going to help me out with it is it advisable to take on some professional courses in computer science like a minor would love to know your viewpoints as it will guide me towards the appropriate direction,a question,economics major to data science
483,hello i find myself needing to modify this so that i can call the generate portion repeatedly in a persistent framework and get a few predictions each time my current issue is that when i attempt to call it the second time it says it is unable to load the saved model even after adding a sessclose at the end rewriting this properly for my use case would enable me to skip repeating the preprocessing steps ideally and replace insession state values with new ones of what actually happened so therefore i need to understand much more about tensorflow sessions graphs running a session etc i am poking through the docs now but would very much appreciate an indepth tutorial or blog post,resources for understanding of tensorflow internals,how do you handle repeated sessions in tensorflow
484,hi all currently my dataset t consists of values i want to stretch it to a length of by doing this i would like to keep the shape of original dataset as you can see at the plot above the rescaled dataset with zoom destroys the original shape however as you can see below the rescaled dataset looks completely different than the original question so i got to know this dynamic time warping method which could be used for this case could someone explain how a rescaling process with dtw works with a simple example if i am wrong and dtw is not a suitable option which alternative would exist replacing the zoom function ampxb from scipyndimage import zoom import matplotlibpyplot as plt t resample_ratio lent resample array y zoomt resample_ratio pltfigurefigsize pltplotrangelent t labeloriginal pltplotrangeleny y labelzoom pltlegend,rescaling a dataset with consistent feature with dtw,can someone explain to me why i am getting such a bad rep
485,i am going to start my fulltime ms comp sci program at a top ranked us school in january and hope to graduate by dec exactly year because the requirement is only courses i want to pursue a career as a machine learning engineer afterwards i am aware these roles typically require a software backend background as well as a data science background i love programming softwareapps but also want to dive into the field of machine learning and computer vision so i figured ml engineer might be a fit for me these are my courses below does anyone think everything listed here will be sufficient to obtain a ml engineer postgrad internshipentry level role afterwards winter semester i am required to finish these foundation courses first before taking any electives algorithms computer architecture software engineering personal time gt java oop projects to build portfolio learn more python and stats etc summer semester data science gt overview and intro to ds intro to machine learning gt more theory related cannot use librariestools intro to database systems largescale database system fall semester applied machine learning gt covers ml librariestools and apply to realworld data from kaggleucikdd big data processing using hadoop information retrieval gt similar to data mining i believe personal time gt do own machine learning projectstry kaggle competitions to improve portfolio i do not want to waste moneytime taking unnecessary courses that is why i want more opinions on this any advice is highly appreciated thank you all,any ml engineers here i will be grateful for some academic advice,is it worth spending too much time learning python for data science
486,hey all i am trying to set up a goal funnel for an exitintent overlay that is coded with javascript into the backend of the website right now i am tracking the signups in parts and would like to combine the tracking into one easytofollow funnel the form pops up using javascript so it does not load a new page we are tracking that just fine as an event the problem i have found in creating the goal funnel is that once the user fills out the form they are taken to a thank you page ie it is a destination goal any advice on creating a goal funnel where the logical path is event gt destination or am i just wasting my time i only see a way to create a funnel where all steps are different page destinations edit if i track the event as a virtual pageview instead would that be suggested i would only lose about days of data by switching to a virtual pageview,creating a goal funnel,how do i track a user from page to page with google analytics
487,first lets take each word of the term individually and try to explain it artificial refers to something made by humans in contrast to nature made stuff and usually is a copy of something natural so artificial is about humans trying to replicate mother nature what about the meaning of intelligence well thats when the fun begins we call ourselves homo sapiens which in latin means wise man and we like to take pride in being so intelligent in comparison to our fellow peers from the animal kingdom but what does intelligent really mean some of us may think of iq tests while others may think of surviving i propose the following definition being able to learn and apply what was learned of course this is a simplified definition not a thorough one putting these together we may say that artificial intelligence is something made by humans that is able to learn and apply what was learned this is just a starting point because in real life things are far more complex the textbook definition of ai is the study of intelligent agents any device that perceives its environment and takes actions that maximise its chance of successfully achieving its goals truth be told there is no quite an agreement about an exact definition even among ai researchers so i think the best way to understand the meaning of artificial intelligence is to discuss about its pursuits even though you may have heard about it recently ai was founded as an academic discipline in and along the years it has experienced its share of ups and downs the history of ai will be discussed in a future article the longterm of ai is to eventually carry on any task that a human being can do it its more like reverse engineer our brain and then create an artificial brain that functions the same as our human brain since we havent yet fully discovered how our brain works thats why this goal is a longterm one in the meantime lets discuss about more approachable pursuits of ai that the reader may have already heard of there are more than those discussed here machine learning ml tagging people and objects in photos content recommendation google search what about them they are all examples of machine learning application the next video to watch showed to you on youtube is based on past data of your online behaviour on youtube same thing applies to facebook feed algorithm the more i click on real estate links the more facebook will show to me sponsored real estate pages when you search on google lets say java it can show you the first results about coffee or about the programming language depending on your search history this is all machine learning its about using data to answer questions finding and extrapolating patterns lets take a numerical example we have a couple of values for two number and the task is to find the relationship between them try to find it alone before reading the answer x y using machine learning we can quickly learn that the relationship between the two numbers is the following x y basically machine learning helped us finding a pattern in the numbers data we have natural language processing nlp siri cortana alexa these are prime examples of nlp at play natural language processing is about machines understanding what you mean when you are saying something to get the context of the conversation when you ask siri to play some rock you are referring to play some rock songs not to play with a physical rock thats the challenge of nlp to make a machine to be able to talk with a human being by understanding what is being discussed and to come up with its own opinions robotics selfdriving cars are an example of robotics a selfdriving car takes data from its environment process that data and makes a decision or take for example a smart vacuum cleaner robot what it really does is to take cues data from the environment your room process it and decide which way to move if is continuously bumping into your furniture then that wouldnt be too intelligent right another example of ai in robotics could be drone delivery the road from factory to destination is paved with obstacles so the ability to make the delivery is a matter of understanding the environment and make decisions accordingly computer vision coffee mugs inspection on a production line is an example of computer vision it looks at a coffee mug and tries to find any evidence of cracks if none found then the mug is ready to be packed and shipped to customers basically computer vision deals with making a machine to gain understanding from an image or video thats what happens when you use face id on your iphone the phone recognises you and unlocks itself this is called facial recognition and is widely used in china where cameras are almost everywhere and can track your behaviour on the streets it has the ability to catch you jaywalking information which will be used to lower your social score which is kind of a reputation score ai is comprised of quite a few number of subfields making it a complex and a universal field to be truly understood you have to see it through its numerous lenses thats why is so hard to come up with an encompassing definition however i will end by giving a shot at defining ai in my own view for me artificial intelligence is the field that deals with replicating every form of human intelligence with the purpose of creating a machine capable of acting and thinking intelligently i hope you find this article useful and it will get you intrigued about the ai field if i manage to do that then my goal is achieved if you liked this article and want to see more of these then follow me on twitter,my attempt at explaining what artificial intelligence is,what is the point of artificial intelligence
488,i just finished my junior year at a large top state school double majoring in statistics and economics and for the life of me i cannot get an internship i applied to over mainly data analysis internship positions that i met all qualifications for this summer got interviews that went fine but never any offers im doing well in school gpa on track to graduate magna cum laude i have r python and sql experience both from classes and from side projects so i really dont know what i am doing wrong ive worked manual labor jobs the past two summers and its looking like ill have to do that again this summer im really getting down on myself about it cause honestly i feel like im working below my potential and feel like im on my way to becoming a failure i have many friends who are doing significantly worse than me in school with awful work ethics and they all easily got internships some only because of connections their parents have i guess my main question is am i going to be screwed a year from now when i will be trying to get an entrylevel job with office experience if i cant even get a summer internship how am i ever going to get a fulltime job in addition if anyone has any idea on what i could do this summer to help me become a more attractive candidate next year that would be much appreciated as well,graduating with no experience,data analyst or data scientist
489,so i am a bit new to data science though i have been interested for a few years i am about halfway through obtaining my bs in data management amp analytics i already hold an aas in electricalelectronic engineering technology i work as a controls engineer but in the years i have been in my current position i have only created one controls project the majority of what i do is write c and delphi for legacy products recently i have been tasked with getting more involved in building web apps and interfacing with data stored in azure the desire is to get more into data and eventually write some machine learning code that said we ourselves are not the end users you see the company i work for manufactures asphaltmaking equipment and it is our customers that use the software and such that we produce so in getting back to my original question as i am entering the realm of analytics and data science i know python is a huge player my most recent project is to build a web app and i have decided to write it in python using flask but what else should i look into i am hoping to transition into a career much more software and data focused and a lot less on the hardware and engineering side what technologies frameworks languages etc would yall say are most valuable when looking at jobs i see a lot of python and some r but when combining data analytics with software development i see a myriad of js frameworks languages cloud services etc sorry for being so scattered thanks in advance for the help,starting out tips,what is your data science superpower
490,hello i have a problem that i thought people here might have some tips on how to deal with this the problem i have two datasets measuring different things about the same process let is say that dataset contains data on a per minutes basis while dataset contain data on a per minute basis their features are all different but to have some idea of size dataset is about k rows while dataset reaches k the question is i want to keep as much information as possible to eventually use in the machine learning model what should be the correct way to combine these information option would be to combine the minutebased data into the minutebased data thus improving dataset with more features matching the already existing time steps the resulting dataset would have k rows option would be to populate the big dataset with more information from the small dataset however every sequential min data points would have the same information coming from the the other dataset the resulting dataset would have k rows both datasets contain important features about the process any tips on how to approach this problem thanks in advance,question about combining two datasets with different time step measurements,how do i deal with missing data
491,hi all i am looking for feedback on our soon to launch partner program for gravityai we are a marketplace for algorithms targeted at larger enterprise organizations and government we hope to help data scientists monetize their creations while simultaneously helping enterprise companies leverage cool stuff you can check out a short explainer here and click on the play button below is the partner program specifics i guess what i am looking for is does it make sense is the structure of the pay and incentive appropriate would anyone be interested in learning more or participating in our beta the partner launch program at gravity ai we understand how difficult it can be for data scientists with valuable ip to package and sell their technology to big companies we simplify this process by containerizing your algorithm then adding a security layer thats often required by enterprise it and finally making your algorithm available to enterprise through a simple web interface as we prepare for public launch we are inviting data scientists like you to work with us in a few ways the marketplace is ready to begin seeding algorithms and we are actively building a select group of first sellers who have algorithms they own and would like to sell we are also adding curators who can help us find and assess opensource algorithms to package for the enterprise lastly we are expanding our team with data scientists who are willing to work parttime first sellersgravity curatorparttime what is it opportunity for data scientists who have developed and own algorithms they want to sell to enterprise clients on our platform were searching for algorithms that might be valuable to our clients in finance insurance healthcare and travel if you know these industries and know where to find relevant algorithms become a curator we need help vetting algorithms working with our engineers to upload algorithms to our platform and potentially training algorithms how does it work send us your algorithm as a zip file along with a detailed description and documentation we will assess your program to ensure it functions as described and is relevant to our clients after review we will work with you to get the algorithm listed for purchase in our marketplace review our list of high priority algorithms search online data science communities message boards github and other places to find relevant algorithms send us the list of algorithms youve identified we will work with you to define a statement of work that aligns with your skillset and available time what is in it for me our team will review your algorithm and you will be compensated in the following ways if your algorithm is on our high priorities list of programs you will be compensated after review and acceptance if your algorithm is pretrained on a high value vertical financial data for example then you will be compensated an additional after review and acceptance once your algorithm is listed on our platform you will be paid a percentage of the monthly fee our clients pay to use your algorithm in perpetuity our team will review the algorithms you find and you will be compensated in the following ways if the algorithm is listed on our marketplace you will be compensated a onetime fee of if the algorithm listed on our marketplace is pretrained on a high valued vertical you will be compensated an additional onetime fee of you will be compensated hourly with an opportunity to interview for fulltime roles ifwhen they become available,data scientist partner program,looking for feedback on our new data science marketplace
492,hello guys we are working on a greenfield cloud solution to be deployed on azure that has the following requirements ingest master data and transactional data from heterogenous internal systems we are talking about to different apisprotocols permutations per entity ex to different ways of ingesting a product from our master data systems depending on their release version and software provider some source systems were developed by us some are third party at the end of the day we are talking about several billion records terabytes of data per tenant transform that heterogeneous data into uniform relational data models perform basic checks ex uom currency etc deduplicate harmonize enrichment etc add some businessspecific validation then store the data and make it available to the entire ecosystem microservices serving business requirements and uis ml analytical dashboards etc my initial reaction was to propose the following source system gt middleware that will transform the source data into a uniform model on the fly gt rest api gt java microservices that perform the checksdeduplicationharmonizationenrichment gt data lake or data warehouse my problem with this approach is that it goes against the latest literature that seems to be putting the data lake at the front of the ecosystem for dataintensive applications source system gt raw data into the data lake gt data pipeline python spark etc that performs the transformationchecksdeduplicationharmonizationenrichment gt data warehouse and microservices i feel much more at home with approach but approach seems to be the logical one when it comes to hyperscalerbased data intensive applications you keep a journal or a checkpoint of your data which makes failover or recovery easier python spark databricks and so on seem so much more efficient data scientist friendly powerful and scalable than your typical middleware or java microservice to perform the data manipulations you are not restricted by the scope of domain of the rest api exposed by your microservice we know for a fact that our rest apis will evolve over time requiring more and more attributes or entities dumping the entire domain of our source systems as is into the data lake makes sure that our api evolution will not force us to initial load again every time data scientists also have more freedom to build ml on top of that raw data on the other hand putting our microservices and business applications at the end of the process with approach would probably introduce some latency for near realtime scenarios we can deal with a latency of to seconds but not minutes is this a typical use case any personal experience with these approaches and feedback ampxb thanks,data pipeline vs middleware javabased microservices for data intensive use cases,data scientists what are your favorite python packages for big data
493,hello im an undergrad student whose been working with my college team doing baseball analytics work current role with a few other students had been to look at their pitch sequencing data and to find insights i had an idea today that i was presenting to them and i made sure not to overwhelm them with technicals provided insight into methodology didnt state a value proposition which is where i probably messed up but as im going midway through my sec breakdown the professor cuts me off and starts talking about another students idea doesnt even let me finish i was pretty disappointed because i was pretty confident in my idea but he didnt want to continue listening my question is does this happen a lot in industry when presenting to management do they sometimes dismiss your ideas like this also maybe give me some advice on how to pitch something too i am planning on scheduling a meeting with those two professors again to give them a full run through of my idea and why its useful,professor cuts me off mid presentation and dismissed my idea how common is this in industry with management,how do i go about creating an analytics dashboard
494,hello would you please let me know what i am doing wrong i am trying to train an lstm model on a binary classification problem but the accuracy keeps being the same as if the model always guessed a or whichever occurs more in the label set this is one of my first models and i have spent the past few days trying to figure out what is not working but i am still missing something and so i am coming to you for some help the data is a daily time series split into windows of days with feature each and the labels are an array of is or is features labels model model sequential modeladdlstm input_shapeselfx_trainshape selfx_trainshape activation notanh modeladddense input_shapeselfx_trainshape selfx_trainshape activation arelu modeladdflatten modeladddense activation isigmoid my_metrics metricsbinary_accuracy precision recall modelcompilelossbinary_crossentropy optimizeradam metricsmy_metrics the questions i am trying to answer are is this the correct way to shape the data why does the model just keep predicting the most occurring label recall is always either or thanks for reading and sharing your notes,lstm data shape amp binary classification help,question about time series prediction
495,i am developing a questionanswer website where users have their as well the backend of the application is the rest api basic feature user is profile question answer posts search question users posts from the search bar now i want everything under analytics but i have never used any kind of analytics tools so far so what part of analytics should be handled directly by the frontend and what parts should be handled at the backendrest api also it is mandatory to put a search query into the url like if i programming here on reddit and press enter the url changes to is it required to put query params into the url if i need analytics on website is search though it does not matter my website is build using reactjsspa and javarest,google analytics at the frontend or the backend how to handle what a user is searching on my website,question about google analytics
496,in high school i taught myself python and some c currently i have a decent grasp of python though i remember almost nothing of c i took philosophy and economics in university during undergrad in hindsight i should have taken statistics and economics or computer science and economics but what is done is done i took every possible statistics and research class i possibly could classes of econometrics classes in research design and analysis classes of empirical research methods in the process of my statistics classes i became very familiar with spss and r looking at what the value of my degree and skillset is it seems like it is kinda close to what is required for data science the problem is that most data scientists seem have a statistics or computer science background which i lack on paper so my question is as follows do i absolutely need to go back and do a nd bachelor in stats andor computer science in order to be employable i feel like a lot that is learned in a computer science and math degree is not directly applicable to data science so if i spend year teaching myself whatever is relevant in csstats to data science i would save a lot of time and energy,so it turns out that i have accidentally went down the data science path i am looking for advice,what is the best way to get into data science without a degree
497,i am having trouble understanding the use of anchors in rpn from what i understand so far the final feature map or maps in case of fpn is taken as the input for the rpn rpn first runs a x convolution on the input resulting in a new feature map with depth of but here is where i get confused so a x convolution is performed twice at each pixel of this depth map once for the classification object nonobject and once for regression how do the anchors come into play in all of this how i understand it is that since the anchors are applied to a given pixel of this depth map the anchor can be reprojected to the original image based on the field of view of this pixel so the regression and classification of the x convolution on this pixel should output classifications and regression values for each of the anchors at this pixel how can each anchor get a different classification score though or a different regression score since we are using only a single feature vector of a single pixel in the depth map as input for the classification and regression how can we tell if one anchor should have a greater classification probability than another or how can one anchor get a different regression again because we only have a single feature vector as the deciding factor,how do anchors in region proposal networks work,question about anchor mapping
498,if you are a machine learning researcherengineer nowadays you should definitely be aware of einsum operations personally speaking i used to give up understanding git repos because of einsum operations the reason even though i felt pretty comfortable with tensor operations einsum was not in my arsenal long story short i decided i want to get familiar with the einsum notation since i am particularly interested in transformers and selfattention in computer vision i have a huge playground in this article i will extensively try to familiarize myself with einsum in pytorch and in parallel i will implement the famous selfattention layer and finally a vanilla transformer the code is totally educational i havent trained any large selfattention model yet but i plan to truthfully speaking i learned much more in the process than i initially expected link please feel free to express your perspectives,d understanding einsum for deep learning implement a transformer with multihead selfattention from scratch,what are some of the best resources to learn about ml for someone who is completely new to the field
499,i currently work full time as an ml and data engineer i have a bs although i am almost done with an ms to keep track of developments in ml i am consistently reading papers and articles online while i know a decent amount about ml i feel like my knowledge definitely lags behind my phd colleagues i took two ai and ml related courses for my ms both courses were not that good my ai course was essentially a repeat of my algorithms course with some ai and ml concepts introduced that did not fit together ml course did not teach concepts that well either an entire month is spent on linear regression gradient descent and knearest neighbors the rest of the course rushes through other techniques like multilayer perceptrons decision trees and tree ensemble techniques,is it hard to be an ml expert with just a bs or ms,is it worth spending a semester studying ml for a masters degree
500,i have a predefined decision tree which i built from knowledgebased splits that i want to use to make predictions i could try to implement a decision tree classifier from scratch but then i would not be able to use build in scikit functions like predict is there a way to convert my tree in pmml and import this pmml to make my prediction with scikitlearn or do i need to do something completely different my first attempt was to use fake training data to force the algorithm to build the tree the way i like it this would end up in a lot of work because i need to create different trees depending on the user input,is it possible to use a customdefined decision tree classifier in scikitlearn,how do i go about building a decision tree from scratch
501,i hope this post does not break any rules i looked for similar posts first i am in my first big data class at csus and our professor introduced us to the gdelt project which monitors the world is broadcast print and web news from nearly every corner of every country in over languages and identifies the people locations organizations themes sources emotions counts quotes images and events driving our global society every second of every day creating a free open platform for computing on the entire world direct quote from the website basically if there is a news story published after january anywhere on the planet it may very well be part of the project i am still learning how to handle the computing side of this but i have a decent understanding of statistics b s mathematics statistics concentration csumb i am exploring the site and learning more about how it works but i could not wait to share it here one thing that i am sure will make most people happy is that it is free and open and you can download the raw datafiles who does not love free data if anyone finds this interesting or useful feel free to share it with everyone,gdelt project,data science in the public interest
502,i have a client who added event tracking pixels using pixel caffeine a wp plugin in different areas on his website the pixels are to measure lead conversions from ads we will be running since there is no lead form thank you page on his site the only way to measure a lead is through site links that take a visitor to a pdf sign up sheet or to a contact us form fillout url of the four pixels triggers are link clicks on the website that take the visitor to different pdfs for different services the other triggers are page visits to a contact us form and an enroll now form when i go to the website i see that the chrome extension fb pixel helper shows a succesful installation of the code however the pixels are not in the client is fb ad manager can i add these pixels or do i have to create them in facebook first and send them to the client to add to the code this is what the client sent me,facebook pixel integration help is it possible to add pixels already installed on a website to a client is events manager on fb ie pixel helper,how do i track visits to different pages on fb analytics
503,recently andrew ng introduced the datacentric approach in which the model and its parameters are kept the same but the data will vary i wonder if we can apply the same principle for featurecentric to see which feature is important for example initialize a random forest model run a list of uncorrelated features like only feature a then only feature b with a that model and does not change any param rank best features based on the model metrics try to understand why this feature is most important test that model based on those features start with combining until the metric is saturated finally start tuning model or even testing other model types with those features rule try the moderatecomplex model not too much simple like linear not too much complex and black box like neural net try numerical features first try categorical features with categories or depends on data dimension the variable with too many or too few categories imo might be not so important for those categorical variables applying the same encoding method do not grid search or random search so it will be quick challenge vary on problems which thresholdmethod to decide features are not correlated which metric of model output to decide one feature is better than the others what happens if too many uncorrelated features should loop over all what do you guys think,can datacentric approach be applied to featurecentric approach,how to deal with overfitting
504,i have done a ton of searching through this subreddit but i could not find any real answers to this is it better to get an ms in analytics then supplement by learning programming on the side eg data camp coursera edx or to get an mscs and supplement with math on the side background i have always had some data analysis as part of my job and i spent about a year in my last job doing actual data projects ie writing sql queries and building dashboards part time i talked to my current boss about doing the same in my role now and he was fine with it once i have a better handle on python i will try to build some cooler stuff and work on building up a github i am currently going through python courses on data camp and doing a coursera course on math for machine learning my goal is to get a job in analytics of data science in the next years popular opinion from coworkers past and present who have or do work as analysts or data scientists is that i could get a job in the field now with my experience but i personally want a master is both for myself and to help my resume be more competitive my ba is unrelated english though i have a stats class at a master is level under my belt from when i started an mba hence the data camp coursera stuff in advance of applying to any programs originally i planned to do the analytics route i intend to apply to the georgia tech omsa from reading this sub it seems that a lot more people have an mscs it seems like that might be a bit harder for me to get into but if it is the better approach i am happy to do some more classes in cs before applying tldr masters in analytics or masters in computer science for data science jobs,ms in analytics or mscs,is it worth spending a semester learning cs for data science
505,im a data scientist at an earlymid stage bb startup since i joined all of the data scientists rolesscopes have been shifted around a lot beyond the typical multihat wearing projects tend to start with excitement from leadership and tend to end with a change of focus from leadership a lot of changewhich i anticipatedbut not at this frequency im a highly experienced fullstack data scientist and i know the value i bring to the table i thrive working on projects with direct impact to our customers and our revenue im customercentric and productlead i often coldcall customers to better understand their pain points i fall in love with the problem not the solution and im a firm believer that perfect is the enemy of good enough i can be scrappy and resourceful or i can be methodical and planned our data scientists here are high caliber however we say were productlead but we have no product leader our cto handles product we say were a data company and datadriven but we have no data leader some time ago our data scientists were transitioned out of product and into their own team and now more recently the team has transitioned into engineering with the onboarding of a pragmatic vp of engineering my observation is that data projects at this company have been stuck in limbo the data scientists dont appear to be and dont feel valued and are usually not asked or involved in communication to collaborate where it might be appropriate i think this is because the overall culture is not datadriven but hippodriven leading to shortsighted projects that inevitably dissolve because a new new and exciting idea took priority the vp of engineering has a massive data infrastructure project they want to tackle and as a consequence a number of existing data projects have been temporarily haltedprojects and product features that were rooted in solving customer problems and validated in driving valueto reresource data scientists i recognize the importance of improving our data infrastructure and i believe the completion of this task will only open up more capabilities once complete what im failing is grasp is why the company isnt capitalizing on the data science talent they have to build a stickier and personalized product with what we have in short it appears that were misappropriating data talent away from important customerfacing data projects to focus on internal efforts philosophically there are numerous trains of thought on how a team of data scientists ought to be distributed from decentralization to centralization to pod structures to everywhere in between usually this structure is dependent on the size of the company among other factors given that we claim were a productlead data company id expect we would embed data into product and partner closely with engineering i dont have full visibility into how or why these big decisions are made so id bet im missing some key elements we are in a productmarketfit stage and id imagine that may have influence on the allocation of talent im confident about this companys future and i keep a bright outlook for whats ahead i see great opportunity and potential for data science work that will drive value im posting here because i want to understand my blind spots and learn if this is typical for data scientists to experience or if this is just bizarre and if so how i can do a better job at educating our leaders,data science allocation at a startup,how do you deal with bosses that dont understand data science
506,hi all im currently working in data governance im a graduate so its all very new stuff to me im really curious about how influential this realm of the data world is and can be the company i work at dont seem to value it too much and it makes what im doing feel quite bland and unfulfilling i get the impression that governance is viewed as more of a burden across the organisation and people dont seem to recognise the motives for it theres also weak messaging around the incentive for good governance what are you personal thoughts on data governance as data scientists have you witnessed any major transformations where youve worked was the benefit noticeable or practically worthless has good governance facilitated more enjoyable and successful projects i look forward to hearing your responses,people whove worked at multiple companies how has the different levels of emphasis on data governance across those organisations influenced your enjoyment and success with ds projects,data science is not your only or even the most dangerous industry
507,the question is strange but im calling data scientist even tho data scientist comprend many things what am i doing i work for a videogames company every months the requests are different sometimes marketing ask you a list of customers that match some required criteria sometimes im ask to pull some data from an api elaborate analyze and make dashboards with data studio or tablesu sometimes doing dashboard analyzing the market sometimes making a clustering algorithm for our customers and making some dashboard unfortunately all the data i have is on sql server so i need to make a data flow that pull the data from it elaborate and then push them into big query is this a sort of data eng the problem is when i am asked to do some interview i do not know what should i focus to say i am doing i know to do many things but not too deep so there are pros and cons for this i know many ml algorithm but i rarely apply atm i should i be called is it correct saying data scientist or its too much someone in the same state thank you,who am i,data scientist is the most pretentious title i have ever come across
508,hello all just some background i have an ee bs and ms in fields and a bs in math i currently oversee optical fiber technicians while i love my job its not forcing me to learn anything i rarely use my degree after being rejected for a handful of places i got feedback saying they want a fields engineer who can program one of the things that piqued my interest and my old thesis adviser worked on was machine learning specifically in regards to optical sensors is there a simple guide to learning the basics of ml i found a great course but its too costly goes over a ton of stuff i already know and takes up too much time are their intermediate courses or books on integrating ml filter design and controls theory from a beginner understanding there might be some crossover with stuff like filters both standard rlc and microstrip and different feedback loops i might be completely off but controls theory is a huge part of ee and it would be nice to incorporate some of ml into it sorry if this is already answered i did not see anything like it in the search thanks for your answers,two questions where to start for the knowledgeable beginner is there any controls based machine learning,is it worth getting a masters in ml if i already have a job as a data scientist
509,im working on a nlp project at work where we have a dataset of open ended responses from surveys where people mention certain brands and we want to quantify the occurrences of each brand that interests us the problem here is the misspellings and that sometimes people use abbreviations for certain brands or dont mention the full name of the brand we manage to quantify the brand occurrences using fuzzy match to fuzzy join the responses with a list of brands that interest us however we find it troublesome since we need to set up aliases for common brand misspellings to improve the accuracy i am trying to research whether there is a better way to do it especially i would want to see if it would be possible to build a classification model around it all guidance would be appreciated im not too well oriented in this topic,model for classification of common misspellings,looking for a dataset of spellings of brands
510,ill give some background info graduated with a ba in history amp economics in and landed a job as a data officer at a startup the job role itself requires me to collect data using internal web scrapers cleanse the data and then provide it to the analysts ampxb the main tools i use are sql excel and some basic python and now and then i help the analyst with some analytical work however it is very basic analytical work moving cells to the right columns etc while the formulas and some machine learning software do most of the work ampxb i recently applied for this analyst position for a grocery company in their marketing division and got an interview i got rejected fortunately they did provide feedback they effectively said i lack the analytical knowhow during the interview they asked me a few questions about measuring campaigns and measuring performance a lot more analytical questions and was completely stumped i could not think of ways to measure performance on coupons they deployed and how to compare two groups one group had the coupons targeted and then the others didnt questions like these during the interview i struggled with and felt a bit embarrassed ampxb the question im asking is how can i be more analytical i want to get more into the analytical field and my current place now i feel its not the best place to stay due to high stress and long working hours what coursesbooks should i take and read to have a more analytical approach and mind ampxb thank you,becoming more analytical,how do i prepare for an analytics job interview
511,hi guys i am cashier in supermarket which means that i am good with numbers so i thought it could be nice to transition into data scientist i have read all posts in this sub and came up with the following pathway python haha what a funny name for language i think that i will start with automating some my boring staff first do you know maybe any booksmoocs that cover exactly that cheaper the better pandas haha another animal andrew ng is coursera course concretely his machine learning mooc personal project i love di caprio check out my reddit name so i thought about predicting some titanic shit who will die and so on it might be something that will make my resume stand out from other ai praticienne would you addreplace anything else cheers,help me to learn machine deep learning ai pls,is it worth getting a masters in data science if i already have a job as a data scientist
512,a little over a year ago i accepted a position at a mediumsized company building their data infrastructure from zero as a team of one it is the job you are never supposed to take but it is a good opportunity to grow my skills my time is roughly data eng analyst data vis and my own it support for my unique issues with the risk of building bad habits as there is no one to consult on best practices i am often asked to provide a solution that needs to be run ad hoc but i do not particularly want to oversee python etc installsupdates on several computers it would not manage either nor do i want a ton of recurring can you run this again asks a rough example would be grab a csv do stuff in pandas and io a db return data in smartsheet i have started using pyinstaller to give someone an exe and move on but i am not sure that this is the preferred or even a good solution is there a better way to handle this how do you deal with similar issues ampxb if there is a better sub to post this to let me know,distributing python tools as executables to nontechnical users,how do i go about building a data warehouse for my company
513,i reopened my kindle app on my mac laptop after many years of neglect to read some statistics pdfstextbooks i have laying about i actually like the look and feel of the app and the ability to highlight sections and take notes it is clean and crisp however the notes section does not keep the mathematical notation of the highlighted note which makes it pretty useless for anything but bookmarking are there better desktop apps than kindle to solve this free or paid does not matter to me i would pay for a good product i have found the kindle ebook to be subpar when reading textbooks especially with heavy math or stats content or color pictures but if people like other ebooks or ipads i would be curious i have an old kindle eink model so not sure if the paperwhite ones are better for this or not i do not like to use my phone for reading mathstats content but i am curious if anyone out there prefers this,desktop app for reading mathstats pdfs and taking notes,is there a good free or very cheap way to get started with machine learning
514,i am considering classes that is sleep yawn neutral fear and fatiguetired i am using alexnet model for classification we have collected around k images for all classes except fatigue class scraping method was not that successful with fatigue or tired keyword search as most of the images were sleep and yawn which will cause inter class confusion to the model i have seen drowsy detection datsets but did not find images which were much different from yawn or sleep i did not come across much papers regarding fatigue etc is there any other way i can tackle this problem that is collect fatigue images without affecting sleep or yawn class any leadsideasdatasets thank you,regarding inter class confusion for a classification model,is there a dataset with images of sleeping and tired people
515,hi experts i am not looking for direct solutions but rather concepts approaches and the right words i work in a company with several production areas and lines we produce between and products per production area an important part of our my businessresponsibility is an estimate every week of what orders will be completed in the next weeks the cycle time ranges from to working days per production area this projection is done very simply with the help of our data from the erp system which shows at which work step the respective order is currently now i would like to automate this process and base it exclusively on numbers data and facts but how what would be the process and concepts here ampxb i have experience from my university days with aspects of ml big data etc i am only missing a framework concepts and,manufacturing cycle time prediction,how do i go about building a predictive model for my company
516,stats link two years ago with a newly minted masters degree in stats and yoe of analytics experience under my belt i landed my first ds job in a hcol city and wrote about it here link at the time i was massively underpaid but i had naively hoped that with my first ds job it would be a much easier landing that second job with the pay i deserve as soon as i hit months in i started to apply elsewhere two years later i and probably many other ds realized the opposite ds interviews are a crap shoot and expectations unrealistic i didnt let that get the best of me and spent many weekdaysweekends prepping for interviews i finally landed my second ds role with a k increase in salary k base yearly bonus k signing bonus i wanted to write this post because everyone always talks about their first ds job but no one ever talks about landing the second and subsequent ones the breakdown months into the new job i started applying and unsurprisingly not a lot of companies took me seriously both screens said i should wait for at least a year and then apply i took that advice and in a few months started to get interviews unexpectedly there was a serious increase in interview difficulty from my first job i had naively thought just having a ds job is enough for other employers i was asked leetcode programming theoretical database statistical ml and product questions the range was baffling and i bombed them left and right after hitting one year and an extended winter break i decided to start applying again this time covid hit and i had half the response rate from precovid many places emailed me letting me know that they were on hiring freezes and later on found out that there were many layoffs i had a few screens but the number of people applying for jobs was in the hundreds and employers were able to be picky i ended up using this time to start seriously prepping for interviews doing leetcode refreshing my stats knowledge reading up about databases and picking up a few good software engineering fundamentals months into my job and with an economy that was starting to recover i started applying again this time i got hr screens from apps i knew my next step wanted to be at a tech company with an established ds team doing statsml and with the market seemingly picking up i declined to proceed with roles after the hrmanager screen i ended up with technical screens ndrdth rounds and ended up with offers my takeaways you dont need to be a unicorn however refusing to adapt will make your job search a lot harder i came from a stats background and noticed ds is becoming much more coding and software engineering heavy companies no longer want to hold the hands of pure modelers unless youre an expert the opposite also applies software engineers without good business senseanalyticsstats skills will create messes as an addition to the above being a python expert will open up more doors than being an r expert out of all my interviews only or wanted someone who knew r some companies still have no idea what they want and are looking for a unicorn i always got the vibe that these positions will end up with terrible wlb or interacting with data illiterate stakeholders if youre not at an intermediateexpert level of sql practice technical skills are only half of the battle as you proceed through your career being a great communicator and having industry knowledge are huge for my two offers i felt like i was ok on the technical portions but in both i received feedback that i was a great communicator and liked my enthusiasm for the industry,two years ago i wrote about my experiences landing my first ds job two years later and through one pandemic here were my painful experiences in landing my second ds job,i screwed up my first ds interview
517,i am just starting out with data science and have a question when it comes to life i tend to have a holistic approach i know that most people strictly separate their hobbies from work but my mind does not work that way i have a strong interest for art and lately was wondering if there is a way to somehow create art using ds tools i am aware of people utilizing machine learning as a means to do that but there are a lot of memes going around about how dumb these algorithms are in terms of actually creating something original and valuable is this true and if so do you think this will change in the near future,data science and art,data science and machine learning
518,im currently a rd year undergrad who is interested in machine learning deep learning and data science i really want to be a data scientist but most of the job listings i see require masters or phd degrees this was slightly discouraging because it seems hard to enter the field without a masters or phd i am currently pursuing a bachelor is in cs with a minor in statistics getting a masters will be tough considering i could barely afford my undergrad degree and i was wondering how i could make my way to the data science role without a grad degree could i start in data engineering and work my way into data science if so how long might that take,data scientist without masters or phd,is a phd necessary for data science
519,im working on a project in which i have a set of tweets labeled democrat and republican my goal is to make a model that can identify if a tweet is republican or democratic so far ive split the data into democrat tweets and republican tweets ive tokenized them and created a bag of words for eachone for dem and one for rep my question is how do i use these two bag of words to train a model to identify using occurrences of the word in each if a tweet is democratic or republican im pretty new to this so sorry if this seems too simple but im just getting lost at this step thanks for the help,how to combine bag of words,how do i cluster tweets based on sentiment analysis
520,i am currently in my prefinal year of bachelor is in cs i will soon be applying for masters and planning to get a job in canada or usa now i have a hard time determining what my career path should be should i go into data science development or software engineering i started android development two years ago so i have intermediate experience in it i only know the fundamentals of coding languages like cc but can learn more if it means more pay and finally i have three major research projects in deep learning with computer vision two of which are based on gans and i somewhat enjoy deep learning and computer vision based tasks more than development now i am highly money driven and super confused if i should brush up my coding skills to land a swe job or continue with data science in computer vision tasks i have heard that swe earn a lot but i have never heard anything about data scientist maybe because there are not many where i am from what is the market scenario right now for a new graduate who works in computer vision and deep learning,advice for career in deep learning,is it worth getting a masters in data science if i already have a job as a software developer
521,apologies if this is the wrong sub i am current looking for datasets where i can test the accuracy of my optimization algorithm in this case it is a particle swarm algorithm by trying to estimate the parameters of some function that aims to predict the data i was wondering if anyone knows of a dataset with the following attributes is relevant to physics particle physics in particular would be swell includes a function that aims to predict the dataset with some number of free parameters to be optimizedestimated ideally contains the true value of the parameters to which i can compare to the optimization of my algorihm as an example something that would just be a vector of xvalues a vector of yvalues and a function say a gaussian of the xvalues with some free parameters to estimate would be perfect note that i am aware that i could simply use a monte carlo method to generate data myself but i think real data would be more interesting thanks in advance and apologies again if this is the wrong place to ask,looking datasets relevant for physics that can be used for parameter estimation,question about gaussian optimization
522,i just finished a bachelors degree in statistics and computer science i am now doing computer science part time and working full time my current job is software development parsing data doing basic analysis on it a lot of backend stuff and business intelligence creating dashboards sql querying kpi monitoring my job was supposed to include a lot of machine learning but it is taking time since it is a huge company and new projects need to get approved by many higherups i have been applying to other jobs because it seems to be the fastest way to move up the ladder and get salary bumps i am sure i will get more offers within the next month or two but right now i have two offers operations research job at a big company jump in salary it is half business half analyst i would be applying very basic statistics and lightweight machine learning to internal employee logs to determine how much time and money each internal application saves the company machine learning month intern at a startup company cut in salary analyzing tastes building some sort of recommender system clustering customers for me the operations research would be a nobrainer but i feel like it is moving me away from data science whereas my other option is machine learning albeit in a small company i know there is no right answer but if you guys were in my position which would you choose,i have a few job offers i do not know which one will be best for a data science career,is it worth taking a paycut to get a data science job
523,i have recently been admitted to several ms statistics programs for this spring semester that i have shortlisted down to cal state fullerton csuf university of idaho uidaho and north carolina state university ncsu my primary reason for applying to these was that they could be completed online since i work fulltime however i intend on moving to the area they are located in to take classes inperson and seek employment around there sometime in the future these are my pros and cons of each program anyone familiar with these programs and can give their opinion on each one csuf pros ends up being cheaper of all close to los angeles good and bad curriculum is flexible in that i can do a thesis or not will accept the graduate statistics classes i have taken at another university as course substitutes shortening the time it takes to complete the program cons not ranked small university compared to the other ncsu pros ranked th in the nation for its statistics program research triangle and i have heard there are strong ties between the school and companies in that area department has been pretty quick in responding to my inquiries and emails cons i heard more attention from the department is given to their phd students program seems more of a cash grab will not accept the graduate statistics classes i have taken at another university as course substitutes most expensive out of all uidaho pros thesis or not curriculum looks good cons not ranked middle of nowhere degree is an ms in statistical science,ncsu vs csuf vs uidaho for ms in statistics,is it worth taking a data science masters at a top rated university if i already have a job
524,i will be working at a hft firm in august out of undergrad as a data scientist and want to prepare myself by studying time series analysis the company uses python pretty unanimously and it is also my preferred language so it would be helpful to have a textbook or some sort of resource that teaches both the theoretical fundamentals of time series analysis as well as implementation using python is there anything out there like this as far as mathstats goes although im decent at math i would prefer a book that is not too advanced if there is not a great resource out there would there be a good one for r that i can use more concerned with the theoretical steps than the programming since i can always google which libraries to use ampxb ps i took intro and intermediate level stats courses and was a ta for intermediate stats as well as practical linear algebra and probability courses unfortunately none of these covered much time series material other than some basic stuff like dw tests acf patterns cyclical seasonal etc,any great textbooksresources on time series analysis for python,is it worth spending time learning r or python for data science
525,hey guys i come to you in time a great need i am currently doing research involving deep learning on pytorch i currently have a desktop for it with dual boot to windows and ubuntu desktop spec ryzen x gb mhz ram rtx ti gb ssd for boot ampamp tb hdd i am happy with working from my desktop at home however i want a laptop that is good for accommodating the deep learning because uni told us that working from home will soon be over reading some threads apparently you can just get a cheap laptop and use google collab or kaggle i have never explored such clouds but willing to try if this is the case could you please suggest specs for laptop i can get be that be cheap gaming or professional if you think i should not get a laptop and just stick to my desktop let me know too thank you,should i purchase a gaming or cheap laptop for deep learning or not,laptop for deep learning
526,hello everyone i had an idea recently and i wanted to see what you guys thought about it baseball season is right around the corner and i was wondering if ml could be used to simulate games in a very fast way my idea is basically that you give some stats of the opposing pitcher some stats of each batter in the lineup against that pitcher and run gans on this with the output being the final game statistics hits homeruns stolen bases ect eventually this would give arealistic game simulations does this sound like something that might work a problem i could see is that baseball can be very random on the game level and it might have a hard time trying to find what a realistic game is ideally i suppose this system would also return a distribution of sorts and not a single expected value for the matchup let me know what you guys think,gans for baseball simulations,looking for ballpark data for final game of season
527,hi all i have just finished up andrew ng is classic machine learning course and i absolutely loved it i have an engineering background so the requisite linear algebra and calculus was not a problem it was the perfect level of difficulty and i have learnt an immense amount however there is a bunch of algorithms and techniques i see used in the industry i work as a data analyst have not done any ml but know plenty of people who do such as trees forests and boosting which were not covered i assume this is because the course is close to a decade old now can anyone recommend an equallyrigorous course which covers modern methods not looking for a plugandplay runthrough ps i am aware of ng is deep learning course in python i am looking to take this class next but my question is geared more towards methods outside of deep learning,courses as good as andrew ng is ml from recent years,what are some of the best resources for learning about deep learning
528,one of my clients wants to create an advertisement for their computer hardware which they aim to sell to data scientists and reasonably enough they would like the screen in the photo to show something related to data science rather than a generic swirlylines picture my suggestion how about a cat photo was not received well for some reason even though i had a willing cat model so i need an image to include that does not raise any issues of intellectual property the last thing i want to do is talk with lawyers i figure that the best option is an image of someone using an open source data science tool working on some sort of open data eg a nasa data set could someone indulge me it would be groovy if the real data science at work image looked sexy with a cool visualization or whatever but it is fine too if it is a screen shot of an open source tool chomping on data it is going to be in a photo in a notverybig pdf after all send me to imjur or whatnot and a private message telling me what the image is and that it is free for anyone to use besides i can imagine that a showandtell might be fun for the denizens here tldr could anyone give me a screen shot of a real data science project,request i need a screen shot of data science at work,is there a name for this kind of data science project
529,what is your routine if any or go to technique for feature reductionselection for example if my data has several thousand features i typically try things right away depending on circumstances ampxb zero variancenear zero variance using r package caret remove zero variance and nearzero variances then by using nzvpercentunique i may remove the bottom quartile of features depending on the range of percentunique is correlation to find multicollinearity i find the correlation matrix and remove values gt and remove i have seen others use correlations gt or but do not have any references for it ampxb boruta random forest love boruta package but it takes a while then use forward feature selection ampxb pca depending on the nature of the data i will try pca last if the model must be explainable then i skip this i may use several criteria error explained forward feature selection look for first orthogonal features,what feature reductionselection routine,removing outliers with pca
530,i am using the scikit for my linguistics thesis and i am running into an issue when trying to classify reddit posts in two groups i have about stemmed texts from a particular subreddit and i want to class them into two separate classes if i run the initial multinomial bayes bagofwords model i get accuracy score confusion matrix but if i run the program using scikit is inhouse tfidf transformer i get an accuracy rate that is lower total documents classified score confusion matrix but everything i have read states that tfidf should have higher accuracy if i run the models using svm i get the expected result bagofwords score confusion matrix tfidf total documents classified score confusion matrix so in svm i get lower general accuracy but the tfidf results are higher than bow which is expected does anyone know what might be going on in my scikit model my advisor does not have any experience with scikit and prefers to code everything by hand which i would like to avoid doing crossposted to rcompling,help with tfidf transformer,question about using tfidf in python
531,i accepted my current position in a small company because it had a nice sounding title senior manager of data science higher salary and i was going to lead a small team i am now getting increasingly disillusioned with the position it was nothing like i imagined my small team are all recent graduates from unrelated degrees and with no coding experience the type of data they work with are really simple and there is nothing beyond summary stats and dashboards that is required for any of the projects my team accomplishes this manually through excel and spss gui nobody has even heard of github or understand what version control is it is very frustrating i have sent them to r courses now and have started automating their excelspss data wrangling in r i am doing all the coding and when i give my team small r tasks they get stumped and basically pass everything back to me i think that coding can be learned but there also must be strong driveinterest in it which they seem to be lacking my bosses provide no direction i have send a few emails with updates on what i have done so far and they either do not reply at all or just reply with that is good most of all i have this sinking feeling that i will not learn anything here as i am by far technically strongest person and i am not technically strong at all i was expecting that at least one person in my team is a decent coder so that i can have bigger picture ideas that they will then implement but it seems like i need to have the ideas and i need to implement them and then i need to teach my team how to use my implementation they are happy with excel and spss any advice on if i should stick this out and try to make it work i have left my last jobs in just under years so i do not want to look like a job hopper maybe this is normal and i should just lower my expectations,started new data science position months ago and thinking of leaving,how much do i need to know for this job
532,my friend and i both want to head into data science i have landed a ds internship he will be pursing a se internship i am thinking about moving to a different part of the country and we were discussing how applying for jobs will look like in the future for us his thoughts were that interviews for entry level jobs are much more difficult than interviews for internships in terms of technical questions he said that coming out as a ds intern moving to a new remote location and trying to find a job in ds would be very hard since jobs are scarce for ds he also believes that it would be near impossible to get any good se entry level job coming out as a data science intern because you would never pass the technical interviews so ultimately his view is do se internship gain experience to pass the harder entry level job interview then transition into ds after a few years on the other hand i think that that entry level job interviews are easier provided you have any related internship experience i do not believe that entry level interviews will be as technical in terms of questions as internships unless you go for companies like faang of course this is because the interviewer already knows you were exposed to a real work environment worked on a big team and solved issues that come up everyday picking up a new programming language is not the interviewer is biggest concernit is whether you know how to work on a team and are fun to be around i go for a dsrelated job immediately after college however i will also apply for jobs like se if that does not work out in a timely manner based on my experience i would be a better candidate for ds jobs however i do not think that i am ineligible for se and i do not think it will be harder to get a se job provided i can show that i am adaptable and can transition into a new field after all i initially planned to do se but just happened to enjoy working interpreting and manipulating data more what are your thoughts are entry level jobs really much harder to get than internships if you have prior internship experience,my friend says doing a ds internship in college is a bad idea,how do i prepare for a data science internship interview
533,suppose we have three variables x predictor x predictor and y target we are interested in making a regression model y xx we have some current data and we make the regression model could be any machine learning or statistical model i just used regression for simplicity this model is working fine but now the question of concept drift arises how do we know that this regression model will keep working in the future what if the underlying process that is generating the data has started to significantly change perhaps it is time to retrain the model or to restart completely i understand that this is a very abstract concept and that there is no single answer to deal with this but here is an idea i had suppose we decided to compare all the marginal and conditional distributions for all combinations of variables for old vs new data if these distributions are statistically similar eg determined by the kolmogorovsmirnov test is there some grounds to believe that no major form of concept drift has occurred i understand this might not be the best approach converting the observed data into continuous probability distributions using kernel density estimation comes with its own statistical risk these continuous probability distributions might not fit the data well therefore the results from the kolmogorovsmirnov test might be deceptive what does everyone think of this approach for studying concept drift thanks would it be better to use the kullbackleibler divergence instead of the kolmogorovsmirnov test,using the kolmogorovsmirnov test statistics for measuring concept drift,is there a reason why we would not use a random forest regression model
534,hi everybody i guess i am looking to get into data science i was trained as a programmer and in the course of my career i have also been a sysadmin db admin network guy hardware tester and so on and so forth i am pretty good at all of it but every now and then i am given a big messy ugly dataset and told to extract something useful from it and i am really good at that just for example a while back i was working for the documentation department of a major hardware manufacturer and we were asked to take all the documentation the company had ever produced and put it all online for the first time this was three decades worth of pdfs covering thousands of products in thirtyodd different languages all of them had been scanned at some point and given xml metadata but the metadata had been handedited and was often incomplete erroneous or specified the wrong encoding and displayed as gibberish my team leada better programmer than i waslooked over it for a while and decided it was too inconsistent to automate the whole team would have to pitch in to check every document manually at a cost of some personhours all told i asked for a few hours to try to pick out just the entries that were complete and compliant to save us a bit of time in the process of writing that script i noticed that many of the errors repeated consistently and with a few reliable markers i could deduce what they were supposed to be eg if the metadata specified say chinese simplified gb encoding and produced gibberish usually it was supposed to be chinese simplified gb and it was easy enough to see if the text in the xml file looked like gb encoding i put in three hour days iterating and examining the results and iterating again finding and nailing down patterns and by the end of it i had a script that correctly classified of our documents this kind of work is enthralling to me and i seem to be good at it despite zero formal training i literally do this for funspreadsheeting data and analyzing from games is as much fun to me as playing i would love to find steady work like this but just saying that does not impress interviewers and i really do not even know what kind of jobs i should be looking for i have been calling it data analysis but i have also seen data science and data engineering among others so i guess my questions are how do i find work like this what should i do to market myself are there courses i could take to teach me standards methods and tools that i am not aware of andor certifications i could get that would look good are there any other forums where i should ask this incidentally i am going to be looking for work in the seattleredmond area soon,i am a programmersysadmin looking to get into data science where do i start,how do i go about creating a database for my company
535,debating on if a career change from it encourage desk to data analytics is worth it i currently have certs comptia and microsoft i was planning on becoming a system administrator but am more interested in the data analytics field the only thing that kept me from getting into data analytics was the difficulty of math and the time it takes to learn it i am already so idk if it is too late or if i will experience age discrimination i have been looking at going back for a nd bachelors at wgu either for cs or it which would be better it would be quicker i would not have to take math and i am more familiar with it cs everyone says it is more regarded but would take longer and be more difficult to do with working a full time job also is the career change even worth it or should i stick with it and what degree is better,it or cs degree for career switch to data analytics,is it worth getting a masters in data analytics if i already have a job
536,im interested in a masters program in applied data science right now i currently hold a degree in psychology with a minor in statistics i spent a lot of my undergrad involved in research projects that involved statistical analysis my stats classes also gave me experience using rstudio to analyze large data sets research was my favorite part of my degree but i did not pursue it because i was unsure of obtaining a doctorates degree which is almost ur only choice when it comes to psych due to time and money its been a few years since ive been out of school and ive felt lost with what i really want to do ive considered doing coding boot camps i know theres differencesto earn certifications but the idea has lingered in my mind for a while and now im playing with the idea of seeking a graduate degree im not sure if i just like the idea of it or if i will even be competent enough to get into or through the program i think i might need to do some more research as to where this career would lead to and if i fit in it but any advice pls b gentle with me im so lost,am i in over my head thinking that i can go into data science without having a background in it,is a data science masters worth it if i already have a job
537,i have been working in the ecommerce analytics and business intelligence space for almost years and there is one lesson that has held true throughout the years analyzing data is not enough it leaves too much room for error all too often analysts identify correlations that are wrong or worse decisionmakers draw wild conclusions from what they see in insights reports the truth is the lens we use to analyze data and draw conclusions is clouded by our experience beliefs assumptions bias knowledge etc what you know or want to believe may not be reality the only way to uncover the truth is to run an experiment and let the results confirm or deny any conclusions youyour analystyour partneryour dog drew from the data remove ego from the decision you may believe strongly that you are right and you may be but your patience and effort will pay dividends in the long run run the experiment and let the results make that decision for you not only will you have more confidence in your decision but you will also gain insights that you would have otherwise missed by analyzing the data alone,data analysis is not business intelligence,do you believe in the value of data science
538,i am new to data analytics field and started a job in the finance industry a few months ago in the risk management department after i graduated but i have always been interested in reading about different businesses and stocks the more i read about the same the more i wonder how i could get into that field after a few basic searches online i found a yahoo library to gather stock data but i understand its not just as easy to do some time series forecasting otherwise everyone would be doing that i was hoping to get some advicesuggestions as to how i can get started in the field or the path i need to take and what i need to study to do some personal projects first before i can move to that field,any suggestions on how to get into stock market analysis,how to get started with data analytics
539,i have a very small set of data that im trying to think of how to best interpret the data contains budget information for each budget year ie fy fy etc which is budgeted on a year basis i want to understand how the most recent budget year fy compares to prior budgets ive thought about mapempe but not sure how best to interpret this data i want to be able to say our new budget is x or x value bettermore accurate than our old budgets assuming that our current budget is the most accurate version since its the most recent and uptodate apologies if this is the wrong place just wanted to get some thoughtsideas screenshot of data,how to do forecasting accuracy for data,how do i interpret this data
540,with adding a consistent version system across all of the code the art of coding moved from craft to engineering the same thing will happen to data governance full article currently data governance teams attempt to apply manual control at various points to control the consistency and quality of the data the introduction of data version control dvc version tracking would allow data governance and engineering teams to engineer the data together filing bugs against data versions applying quality control checks to the data compilers etc platforms like palantir foundry already treat the management of data in much the same way as versioning of code within data versioning platforms datasets can be versioned branched acted upon by versioned code to create new data sets this enables data driven testing where the data itself is tested in much the same way as that the code that modifies it there also some open source options data version control project is focused on data scientist users delta lake project is a databricks version control system for data lakes with big data workloads,dataops vs legacy data governance and how is broken in the ml era,data lake version control
541,so there have been more than a few of these types of posts i think the most recent was months ago since this is reddit and not stackoverflow i figure its ok to post and solicit more advice ive been asked to do parttime consulting work basic bioinformatics tasks its all stuff i have experience with ive an earlymid career bioinformatician yrs experience in statisticsepidemiology yrs in bioinformatics ive never done bioinformatics consulting before and i also have a history of undervaluing myself im also quite seriously underemployed right now working with a government agency at an hourly rate of hr ive seen that consulting rates should be x your hourly fte rate that translates to hr but what ive yet to see anyone quote lthr on here i dont know what to do if i say hr people might think im not that good compared to those asking hr when in reality i am skilled its just that i was hired as a contractor for a government health agency and they underpay everyone any suggestions about this would be welcome as an aside i will take all your advice as basic career skills advice as i look for better fulltime employment as well no one around me talks salary its very hard for me to know what im worth i guess im not google materialim not some kind of computer maverickbut on the other hand i know hardly any bioinformaticians who understand epidemiology and statistics concepts that are actually really important to the work that we do so i occupy a niche i see the value in it because i see a lot of shitty bioinformatics work being done but im not sure how to connect with employers who see the value in it,consulting rates on east coast,is data science for me
542,i have programmed a maze solving game where the creation of the labyrinth is procedural dfs and backtracking the maze can be solved by the user or by a best first search algorithm with backtracking as well i wanted to add a sort of dataset containing for every match played only ai data the time needed to solve the maze the percentage of error made by the ai aka how many times the ai gets stuck and the backtracking function is called example to solve the maze the ai needed movements it got stuck times so the error percentage is the solving time was minute after n iterations of the bfs algorithm i want to predict time needed and percentage of error for different sizes of mazes what algorithm could i use linear regression i am new to this so i do not know how to apply it to this problem what variable is going to be b b x is linear regression good to this problem sorry for bad english it is not my first language if something is not clear do not bother to ask,machine learning for an error prediction of a best first search maze solving algorithm,how do i go about solving this problem
543,hello im an undergrad student who is the education director of my data science student org i will be running a text analytics workshop series which covers every elementary topics for beginners new to data science and text data it will be very basic and not really going into any advanced techniques for modeling using text data i want to know from some of you what the best way of structuring this would be and what would be the best way of organizing the content a rough idea i had was talking about how to preprocess text visualize text and do some light modeling with sentiment analysis and topic modeling clustering but again i dont want this to be too advanced mainly because my depth of knowledge isnt very advanced and i dont want beginners to be confused i just want them to be comfortable working with text data if any nlp experts would like to pm me that would be great or give your advice down below thanks,advice on how to run a nlptext analytics course for a student organization,how do i structure a text analysis workshop
544,im a data scientist for one of the largest energy companies in the us im financially secure but i dont want to go into an office anymore im interested in working remote even if it means that i take a pay cut i love doing ds work and am relatively young s so i dont want to retire but i dont want to live in houston anymore my heart is back in montana does anyone have any advice on finding remote opportunities my preference is to not do contract work as i dont want to have to deal with being a employee and all the headaches that come with that any advice is appreciated,remote data science work,remote work vs home
545,this week in our free news digest we reflect on microsoft is transformation into one of the leading ai powerhouses when you put the azure platforms reach and depth of ai solutions together with the amazing wave of ai opensource releases from its research unit as well as smart strategy of acquisitions microsoft starts looking like a front runner in the ai race do you agree how would you compare microsoft against amazon and google in terms of ai offerings and capabilities also in the digest ml research overview the main research papers of the week efficient nlp with minimum size by googleai dataflow approach to conversational ai microsoft research the magic behind the new alexa features by amazon cool ai tech releases highlight cool tech releases dynabench and kilt by facebook updates and releases from microsoft google cloud ai platform money in ai explore where the investment money went to this week very helpful to see the trends sign up to get thesequence weekly it is one of the most practical and nohype newsletters you can find out there,news the microsoft ai powerhouse and trends in ml,google ai latest research
546,i know naming conventions can be tedious and somewhat ambiguous or opaque but in your estimation what would you say are the key functional differences between a systems analyst and a devops technician or engineer from what i have heard promulgated within the stem community is that sys analysts are a liaison between the business and development departments and devops is a liaison between the development and it ops departments it seems as if the former deals more heavily with sql database implementation analyzing and clustering data predictive modeling and visualization and business intelligence whereas the latter focuses on automation pipelining api configuration and scripting and various other deployment workforce tools that assist the it department in more simplistic advantageous and feasible functionality,system analytics or development operations,is it common for data scientists to refer to their departments as devops
547,i am wondering which programming language should i learn to stay fresh to be honest it is been a while since i actually sat down and learned a new language and i actually like the process for obvious reasons i am looking for something new not exactly eager to learn vba for example with big potential to be used in data science machine learning big data as these are the areas with which i am strongly connected both professionally and academically ampnbsp i know python and r are the most popular i know sql is very useful to know i know javascript and software such as tableau are used to fancy up your visualizations before showing them to upper management ampnbsp but what is new i am looking at github stack overflow popularity charts seeing languages like rust julia or clojure and i have no clue whether it is worth learning any of those languages and if so which one even when it comes to scala although not that new and widely used in hadoop ecosystem i am not sure if it is worth a fuss ampnbsp before someone comes and tells me that it is always good to learn new programming language i guess i agree it makes you a better programmer in general but the problem with learning new things is that it takes time i do not have much spare time in my life right now and definitely not for learning things that i will not find useful later on in other words i do not have time for learning new programming languages just for the sake of it that is why i am asking you for advice to help me cherry pick the option that will be the most suitable for me,which programming languages except python and r would you recommend to learn for data science machine learning,what is the best free or very cheap way to learn data science
548,hello everyone i am about to apply for a job as a research assistant and im feeling a bit of imposter syndrome im currently in my last year of my degree in health sciences and have an interest in research i have done a introductory statistics unit a unit on epidemiology and two units on research methodology and projects i have gained a lot of skills through these units that i believe would help me comfortably do this job however when it comes to statistics using excel and analysing huge amounts of data i am not that confident even though i passed these units im still a bit uneasy with these things this job doesnt require too much more than what i have to offer but i still feel like an imposter its only part time so ill be able to do it while i finish my degree it specifically requires someone with relevant experience i have done relevant units but obviously no field experience at least a year graduate tick and competency in computer skillsmore specifically spreadsheets databases social media email word processing etc my question is basically do these jobs tend to require of knowledge on everything they list that the job requires do they tend to train you a bit further and build on your existing skills will someone be holding my hand for the first few weeks or will i be thrown in the deep end am i overthinking this,advice on jobs in research data and statistics,how much do i need to know to land a job as a data scientist
549,i have got a small project brewing involving a raspberry pi and a bunch of sensors that will mimic a fancy baby monitor i have got months to see if it will work my question is in regards to the motion sensors they are extremely sensitive as in it can rest on my desk and detect what i assume is gravity or some dark magic in the house for now i have some rudimentary thresholds that just ignore values that i decide is background noise but the noise is different on each xyz axis and it just feels hacky so i want to know if this is something machine learning can help with i am thinking along these lines train the model with s s of values of background noise from a csv background noise tends to just be values between and depending on the axis feed in seconds worth of motion data and decide if any real motion is detected that deviates from the learned pattern alert when no motion is detected so am i in the right place for this if so has anyone got a starting point for me or a python library that might help with this scenario thanks in advance,total beginner is pattern matching relevant to machine learning,is there a name for this kind of project
550,hi i want to know how subscription based services apply machine learning fo churn prediction a customer is supposed to churn out a point suppose the company started its service in and if i look at the dataset today it will have all users data but most of them have churned out in the past two years so the dataset has only active subscription as not churned and rest all as churned in my case the percentage of them is and respectively how do i approach the problem the stationary features like gender and location stay the same in the non churned month and the churned month so how is it going to help in prediction and also if i take tenureage as a feature the tenure changes everyday and the age also changes individually on the birthday of the subscriber so how do i do feature engineering and do i have to fix a timing window and how should i create the dataset,churn,churn prediction
551,i am yeshan and im a final year student of university of westminster enrolled in bsc hons computer science as for my final year project im researching and providing a solution for the detection of inconsistent online reviews on amazon ecommerce domain in which my main focus is on detecting discrepancy between user is review text and the star rating he submitted as for the solution i would be providing a solution using deep learning and nlp techniques and im in the process of evaluating and testing out various models for this problem simply i need to interview some experts for requirement gathering where i can get your opinions and thoughts on my research it would be great if you can help me out if your a data scientist or a ai expert i have been struggling to find experts to interview and if your willing to participate pls message me or email me at yeshsanthushgmailcommailtoyeshsanthushgmailcom thank you and i hope someone could help me,request for interview for my fyp,i am a year old and i need help with my final year project
552,hi all i have spent the last couple years working hard to better predict fantasy sports for daily fantasy purposes ive self taught myself basic excel functions lookups pivot tables sumifs and just cant build the algorithm i want last couple of weeks ive gotten into the stock market because lets be real its going off anyways began to do research and once again stuck decided i was going to learn python and better manipulate data so ive began using dataquest software and its awesome heres the question if i complete the data scientist program and honestly understand sql python r pandas git machine learning would i have enough skills to jump into the data world i have my business degree and currently am a closer at a car dealership doesnt really translate well to this but i definitely am loving working with the numbers and creating visualizations etc or i could just get rich quick trying to gamble lol has anyone finished this program ive searched this reddit and seems like those who have done it already have their doctorate masters or bachelors in cs and been able to enter this industry what steps did you take,success stories from dataquest,data science career advice
553,i love how supportive and inspiring the data science community is to newcomers especially as someone just starting to seriously research this field but no job can be perfect for everyone what type of person leaving work ethic issues aside as it is important in most fields would you encourage to look elsewhere if you had to say something like do not work in data science unless you are an x type of person or really enjoy doing y or consider yourself really good at z what would you say alternatively if anyone is working in data science and regrets it what do not you enjoy about it what fields do you want to try instead i just want to hear a devil is advocate perspective because everything actually sounds great so far good salaryjob safety getting to explore interesting issues many paths to entry tons of free or inexpensive learning materials etc,who should not go into data science,is data science worth the financial burden
554,i have been thinking about this for a while now but i cannot convince myself that my reasoning is right it is about propagation of uncertainty in labels i have a dataset with continuous labels that by themselves already have an error after training my model i get the model error for each prediction which i define as the absolute difference between expected and predicted value is this error correlated with the labels error in particular i suspect that i cannot achieve an error that is lower than the labels error so it is kind of a lower bound then this is the total error that includes also the labels uncertainty is my reasoning correct,error lower bound and label uncertainty,question about label reduction
555,i am currently head of studies of master student in a field heavily related with but not included in datascience some industrial from bigcompanies ask me to train my students with google cloud plateform on one hand i am highly hostile to make my students dependents of one cloud technology on the other hand the fields seems to get more and more involved with those platform my students are train to deploy and administrate vms for their project but they do not formally have a training in cloud or distributed computing they are not cs major but math major with cs specialization so i do not have a lot of time and resources to train them how hard is it for young datascientist to become familiar with cloud plateform should i invest training time in that or should i keep the training less tech dependent,how important is cloud computing for datascience students,how do i make sure my data science projects are relevant
556,hi i am writing up some reports about analytically services for my company we are getting ready to gear up for the new year when we roll out a new marketing campaign and i was told to primarily focus on two analytic services bitly and google analytics my company wants to track pamphlets with a shortened link from bitly but i have found through my research some not so positive things about the service such as lack luster rd party spam filer abilities the fact that twitter and google have their own dedicated link shorteners and some bad white listing services and i was leaning toward google analytics as the optimal road to track user data i was also looking at gnip and parsely i am about to take off but i will be back in an hour i was wondering which service would be able to track user data so we can optimize our reach and be able to tell what demographics our stuff appeals to and which service would be better if a link was placed on a physical pamphlet for people to go to our host website thanks collum mcjingleballs,question about analytic services,how do i track users in google analytics
557,in week of the sequential model course the trigger word assignment quickly breezes over how they actually build their training dataset which has been confusing to me i have got an approach in mind but i am not sure if this is correct ampxb here is how they explain how to create one training sample ampxb x y create_training_examplebackgrounds reddits negatives ampxb but x has a shape of approximately note mine is slightly different since i started creating training data for a different task ampxb now fast forward to the portion of the assignment where we actually train the model the shape of a single training example is to replicate this i used the following code ampxb x y for i in range x y create_training_examplebackgrounds reddits negatives xappendx yappendy x nparrayxreshape y nparrayyreshape ampxb with this i have got a few follow up questions is this the appropriate way to create such the training dataset is there a specific reason why the shape is instead of,deeplearningai how to build a complete trigger warning training data set sequential models week assignment,how do i train a neural network to recognize different shapes
558,hi reddit i currently work fulltime as a data analyst i am very passionate about predictive modelling and even statistics however i have very little confidence in myself to explain how or why these algorithms work beyond the two paragraph highlevel description found on wikipedia medium vague memories from statistics courses in undergrad and grad school etc because of this i decided to go back to school to take math courses i have completed a couple intro math courses and decided to formally enroll in a parttime statistics bachelors degree for fun i have came across several posts and experiences of you do not need to know math focus more on programming there seems to be more of a focus on writing production grade code or get a model up and running yesterday in data science on one hand in my opinion not knowing the math seems to be a situation of running before walking on the other hand i see people code these amazing models that go over my head yet they seem to know how it works despite coming from a computer science focused background i am questioning myself a bit on whether my decision to focus on math is the right one especially after reading this paper and reading tukey is quotes any advice would be appreciated,mathematics or computer science where to spend efforts,is it worth getting a masters in data science if i already have a job as a data analyst
559,hello looking to switch out of my field and captain my own ship i have peaked and cannot move up anymore got to make a move that scales better than where i am at was looking at and seriously considering a masters in data science looking at syracuse for now is this a good program is the job market as open as they say will this continue years from now might be free and inexpensive online courses and micromasters do these detract your value is there any relation to data management and ciscoserver systems i am mostly worried about getting saddled with a degree debt and a job that does not scale no way to pay debt not the pursuit itself hopefully doing my due diligence thanks ahead for your answers,looking to switch,is it worth getting a masters in data science if i already have a job as a data analyst
560,i am interested in learning machine learning as a hobby and maybe in the distant future as a career the problem is i have a graduate degree in a totally unrelated field and am a dunce when it comes to math i read the super harsh guide and quickly realized that elements is well out of my depth so i began reading the apparently easier introduction to statistical learning the material covered within is still somewhat beyond me are there any suggestions as to where to start for someone who knows very little math beyond basic introductory algebra i know it is a big ask and i am aware that i will likely never work at google brain however i am really interested in the topic and would like to become more educated for my own personal satisfaction i have been looking at the intro to probability and data course for introductory statistics and the mathematics for machine learning linear algebra and calculus courses for general math do these seem sufficient for getting into the intro book contrarily is this overkillshould i just read the introduction to stat learning book and glean as much as i can without any prep will i even be able to understand these courses with only a basic algebra background i know this is a text dump thanks for reading and please know that any insight is much appreciated,advice for a mathematical moron,is it worth spending a semester learning probability theory
561,hi i am following the chatbot tutorial for pytorch i am confused about this portion my main confusion is with the dimensions so i understand the dimensions of the input must be max_length x batch_size but i cannot understand how the dimensions of the hidden layer are n_layers x num_directions batch_size hidden_size so n_layers here refers to the number of rnn cells or is hidden_size referring to the number of rnn cells in the code they have commented initialize gru the input_size and hidden_size params are both set to hidden_size because our input size is a word embedding with number of features hidden_size selfgru nngruhidden_size hidden_size n_layers dropout if n_layers else dropout bidirectionaltrue so does that mean max_length of the input sequence is equal to the hidden_size this is very confusing even after i had gone through the theory for rnn the code implementation does not make sense here please someone explain the dimensions used here,questions about pytorch chatbot tutorial,question about hidden dimensions
562,hi there everyone i have been trying to get into machine learning and ai since the new year started i am an electrical engineer but i wanted to branch out and explore some new fields i finished the andrew ng coursera course a few weeks ago and am looking to dive into fastai next i like that it is a python course even though matlab really brought me back to my college days my question to you guys is which of the four fastai courses should i start with the first on the list at the top of the home page is practical deep learning for coders but a few lines down there is introduction to machine learning for coders i was planning on just doing all of these by but if there is an optimum order to approach them i would really appreciate it,which fastai course should i tackle first,what is the best way to learn machine learning
563,i am a high school student looking at pursuing a degree and career in data science mainly i want to know how much cs is involved in coursework and jobs i am strong in maths but have had no exposure to anything computer sciencerelated and i am not sure if for this reason a data science course would be suitable for me it is likely that if data science does not work out i will stick with stats hopefully focusing on the maths side rather than the computer side of it so how much cs is involved in data science and is succeeding in cs units at uni with no prior knowledge of coding or programming possible,high school student strong in maths weak in computers is data science an option for me,is a data science masters worth it if i already have a job
564,hey all im a medical student and super interested in machine learning in retrospect i should have probably studied cs instead of medicine but i am graduating soon so might as well finish it anyways my dream is to be able to combine my medical knowledge with the tools of ml and work on applying ml in medicine either in industry or research what you would recommend me learn of ml theory and application given my background i have always loved math and stats and dont mind diving deep into it but do not want to spend ages learning math before something else if there is a better approach would really appreciate any advice you might have,advice for entering ml as a medical student,medical student looking to get into ml
565,apologies if this is the wrong place to post this but i cannot seem to find a learndatascience or datasciencehelp subreddit for a project i am plotting the number of pointers made in the nba season by season since this is based on every team playing an game regular season so i am going to drop the data from the and seasons i decided that i want to use a model to predict the number of pointers that would be taken in these dropped seasons i was planning to put the season year as the x axis and the total pointers on the y axis is this the right way to approach this problem,can you use linear regression in this case pointers and years,how do i go about predicting the outcome of a game
566,hi all i am looking for relatively simple information having the total exportimport data between china and all partners countries since as csv for excel i looked at main website all wto and world data and others and more obscure ones but they often only offer graphicsresume and if they do have data its always only part of it only imports or only exports often by category or with only one countries however i wish to have two ways in us dollars of the current year thats fine and all i am confused about why it seem difficult to find a complete dataset of this very easily available information and if i am not looking properly somehow any tipsadvice thanks,best source for dataset concerning exportimports between china and partners countries since,looking for data on exports from china
567,someone recently asked me in a comment what skills i would recommend for data scientists looking to transition to ml engineering so wrote down a quick list and thought it might deserve its own post it looks like a lot but bear in mind that i learned all of these on the job to solve specific problems ie i didnt do any of these as independent study before getting my first ml engineering role so in terms of skills needed to transition i would actually say all you need is a hacker mindset and the ability to learn quicklyindependently my list htmlcssjavascriptreact data labeling apps prototypesmockups integrating models into existing webapps javacruby integrating models into existing backend services cc customizing amp extending opensource ml libraries dockerkubernetesaws deploying models jenkinsbuildkite automating model builddeployment pipelines kafkasqsdatadogelkbugsnag building amp debugging distributed applications technical writinguml documenting technical decisions getting alignmentbuyin from other nonml engineers are there any other major things ive left off,skills to transition from data scientist to ml engineer,what are some of your favorite data science libraries
568,i work as an urban analystconsultant which includes many data related tasks often geospatial i am pretty decent at getting and cleaning data building indicators and spotting relations trends insights however i need to get better at communicating and visualising these things it is not that much a matter of technology i know my way around ggplot which is what i use of the time and i am currently learning markdown but rather more at an abstract level make something our clientstakeholder will understand and that needs minimal input from our designer there is only one in a company of about people thus any recommendation of resources for that will be very appreciated thanks in advance,any recommendations for data communicationvisualisation courses,how do i go about creating a dashboard for my clients
569,hello i am looking to see how the areas that we have physical stores in differ from those that do not have a store by creating a segment for comparison when doing this i am only able to segment by metro or city when doing city it does not even tell you the state and there are multiple cities with the same name so this seems too vague does anyone know if it is possible to create a segment based on zip codes or if there is documentation on what exactly the metro area is or what cities are defined as ampxb i saw another post about using an api to track ip addresses and then layer it in but that seems complicated and a violation of the pii policy ampxb thank you,location specific segments in ga other than metro or city,how do i track the physical address of a city with google analytics
570,hi everyone my wife is going to be graduating soon with a phd in cognitive psych next year and she is looking to go into industry rather than staying in academia to be closer to family we are looking at either denver co or austin tx we have read a lot of articles about the best places to find a datascience job but it is tough to make a educated decision based on a paragraph of information from a slideshow of course we are going to send out resumes and line something up before we move but it would be nice to have a single city to focus on rather than spreading out the effort across two cities so do any of you live in either of those locations and would you be willing to share your experience finding a datascience job thanks ps i work in it so i am not worried about finding a job in either city,advice moving soon trying to decide best city for datascience jobs,data science in the west coast or austin
571,i am currently in the st semester of my data science bachelor and could use some help with an article i am writing for an austrian data science community the article will focus on describing what is widely considered a data scientist is core skillset and how well one can do with just those skills when it comes to finding a data science position i usually just come to this subreddit for the memes but i would really appreciate it if you could share your opinionknowledge on the following questions what is your background eg education experience what would you consider to make up a data scientist is core skillset eg r python sql would you say that nowadays it is hard to find actual data science positions rather than just ones in name have you ever been denied a relevant position for a seemingly superficial reason eg some companies only hiring ms phd for their positions are there any required technical specialisations you often encounteredencounter in your job search eg docker kubernetes feel free to share if you have something not covered by my questions love you and thanks cookie,i am writing an article on the necessity of specialisation in data science and could use your input,what are some of your favorite data scientist job titles
572,hello everyone i am an artist and i am trying to do some basic research where i may be able to find my target audience starting off with platforms they use i found similar web and the other night somehow got a day pro trial in tonight i tried logging in but am unable to looks like i have to enter a credit card for the trial which i had not done the previous night so i am guessing i got in by some glitch using google chrome thing is i entered a credit card and they could not confirm it i am assuming that it is because it is a personal credit card i am legally under the title of hobby and not an actual business so i do not have a business credit card or business checking account i am not sure if that is the issue going on here anyways i just wanted to look up a few sites for their audience demographics basically male vs female and what the dominant age groups are is there any other place i can look up this info as i said i am over my head so maybe this is topnotch exclusive stuff but i thought i would be able to find this info easily i suppose any other factorsquestions that i may want to consider or look into would be great too i already have locations by country and vaguegeneralized other interests news gaming tech etc any help advice of any sort is much appreciated thanks for reading lt,totally out of my league here but,looking for a mentor
573,hi i came across the federated averaging algorithm proposed in this paper would like to implement the algorithm on a few distributed clients with kerasunfortunately i cannot fully understand how the updating works i understood it the following way the clients performs one step of gradient descent in kerasafter that all the clients need to send there weights to the server can i literally use modelsave_weightsthe server performs the weighted average and returns the weights to the clients the newly calculated weights from the server are used in the next training round did i understand this algorithm right is it possible to train for a few epochs and then send the weights i think i am not really sure what is meant which one step of gradient descent in a framework setting like keras thanks for your help,federated learning with keras,how do i calculate the average of the weighted average for a client
574,i want to get some feedback on a script i wrote that helps me search through all my jupyter notebooks for code examples sometimes documentation for the packages we use is unclear or does not use practical examples i find myself looking up old code and documentation to recall some problem previously solved tools like find and grep are helpful but i wanted a more comprehensive and organized approach the program i wrote uses ipynb files json with tagged metadata along with find and jq to create a kind of cheat sheet generator like tldrsh for notebook files i simply supply a config file to point to locations i want to search now upon solving some nontrivial task eg joining dataframes on some key i tag the cell eg dataframe join and insert a short comment later recalling tagged samples related to joining dataframes is easy bash session gt kapitsa dataframe join i call it kapitsa __ the program outputs the code snippets tagged with dataframe and join along with the other tags and the path to the file where it was found i am opening this up to the broader community for feedback the script is not complicated it can support any language or framework eg python r scala julia that jupyter supports the goal is to increase efficiency and help with organization hopefully some will find it helpful it has helped me let me know of any features you would like or improvements you would make,searching code examples and best practices in notebooks,how do you organize your data
575,hi guys i am curious to hear your experiences with automatized data science let is say my input is a clean dataset with known data types ie i know exactly what kind of data it is and that machine learning classifiers are generally applicable in this domain but i do not know the specific dataset and i want a script that automatically selects a classification method eg regression random forests or neural nets fits models does parameter tuning selects the best model and then tells me what the best model is whether it is reliable and what variables had the most impact i think most of us would agree that this does not make sense when you do not know what kind of data you are getting and that the results would never be guaranteed to be perfect as you have to rely on heuristics but i think this approach could still work reasonably well if the data sources are known and clean after all nonautomatized data science is never perfect either some possible points for discussion what is your experience with these approaches any software that you would recommend eg ibm watson analytics google prediction api anything that works well with python or r and is open source what kind of classification methods do you think are suitable for this approach is it too soon to do this with neural networks you should probably set a threshold for the minimum amount of observations in the dataset before you allow this approach and maybe you do not want to allow data that is heavily imbalanced any other possible criteria like these that come to mind any experiences with automatic feature engineering there is a quora question on this topic here but i would love to hear more opinions on this,automatized data science,how do you handle outliers in a data set
576,some people say i am crazy sometimes they are right my goal is to catalog parse and analyze the properties of misinformation campaigns on the internet it is very difficult to address a problem if you do not understand the full scope of the issue i think most people are aware that there is a lot of misinformation out there but they think that its relegated to the crypts of the internet and they are not effected by it it is not it is everywhere and you have touched it i do not think blind censorship is the solution it is a quick fix that just creates a temporary inconvenience as parler has showed us and does nothing to stop the actual campaigns i will not lie to you and say i have the answer right now i do not but i do know where to start and that is with some good questions how many platforms are actually hosting and distributing this content what channels are utilized to reach users how is the content found by users how much of the content is organic vs manufactured how many people does this content reach per day the answers will shock you you may literally be electrocuted please check out my post on rparlerwatch if you want to contribute or get a list to mine yourself i am doing this manually at the moment to get a rough picture of the situation and could use your help i need to itemize things like subreddits facebook groups twitter tags news sites etc which serve to aggregate and disseminate misinformation content once i analyze enough content i can make tools to find and scrape more content like it and catalog the results,disinformation archive cataloging misinformation on the internet,how do you handle fake news and fake accounts
577,hello i have a list of countries with a number of measures and class labels corresponding to countries groups i would like to rank these countries using a calculated score from the most important features contributing to this classification weighted sum so my task is to select the most important features and assign weights using different algorithms to guarantee reliability and stability i found some papers doing this using filters with ranker they used in each run a different filter and rank features then calculate the average rank and then calculate weights accordingly i would like to do this using wrappers but i need some papers to justify my usage of this method therefore i would like to get some relevant keywords or sources thank you,finding weights to selected features,how to calculate weighted average of different classifiers
578,i have my first ds interview coming up in a few days here is what i have to expect during your minute interview the interviewer will ask you questions related to statistics and problem solving the goal is to get a sense of how you approach and communicate while working through a problem and to understand your thought processcreativity when presented with a scenario in which you do not have previous context i am guessing the statistics part will largely surround nhst and descriptive statistics i am not so sure about the problemsolvingscenario part most of the ds interview prep resources are focused on ml methods if anyone has resources related to more of the scenariobased questions i would love to understand the format my background is in cognitive science so i do have experience with statisticsds methods however i am not as familiar with industrytech interview protocols thanks,first ds interview,how do i prepare for a data science interview
579,so i have been tasked with analyzing sales data for my current employer i want to identify and show some trends around important release dates for our product to see how those releases impacted sales my first thought is to summarize the total dollar amount by day and then plot that however i think summarizing by day is too granular and there is a lot of daily fluctuations are the below good ideas to help paint a better picture any warnings about these approaches also any recommendations would be great summarize data by week instead of day i expect to get less natural fluctuation in numbers when looking at it by week but we lose the ability to see how we did on the specific day of the release focus on average dollar spent per customer rather than just the overall sales number continue to show the data by day but show the day running average instead of the total sales i think this will make it harder to see if there was a sharp increase on a specific day i dont know how common it is for companies to look at this type of metric i know the answer is probably to do all of the above and see which one provides the most meaningfulrelevant results but i just wanted to get my thoughts out there to see if anyone had suggestions thanks in advance,analyzing sales data,how do i track sales liftoff from a specific day in a week
580,hi everyone i am in unfamliar territory honestly but i have been given an opportunity to work on an nlp project for contract reviews and i would rather give it my best shot than anything else so here is what i can share i need to redline contracts where a prospective customer has violated one of our predefined rules prepared in a separate file i have a corpus of contracts that are standardizedmeaning paragraphs are numbered in order in a specific format the other of contracts are in an unfamliar format unique to that particular customer engagement however the content of interest is in there what i need to do is sift through these contracts and redline specific parts of the contract that violate the predefined rules ampxb here are a couple thoughts i have validate that the specific rules i have been given are actually representative of the examples in the corpusso that i will be looking for specific group of wordstext matches easy option try to segment the document into sectionseasy with the ordered ones little trickier with the non standard ones and then based on section identified looking for wordsfeatures of interest ampxb appreciate any insight or even booksarticles for further reading ampxb thanks,nlp for contract review,how do i deal with a customer that wants to use a certain type of database
581,hi all i have been invited to give a career talk at my phd alma mater is ds institute i got my degree from an unrelated department i am a data science director at a marketing consultancy and got here through the phd gt postdoc gt bootcamp route four years ago i have a lot to say about my experience on the market and in business but i suspect i am out of date on the contents and value of ms programs in data science engineering and what the job market is demanding for those who recently graduated with and ms in something data related and have been on the job market what advice do you wish you were given,advice for career talk,career advice
582,i am trying to decide between two offers i have at hand i am years old moving from another position graduated last year and here they are person startup where i would be head of aiml basically lead aiml engineer i have worked with this group for a while but i would be the only one having any inclination or knowledge of aiml here so not too convinced on the career development front pay is k no k but good health insurance imp because i have a kid and a wife a big consulting firm accenturepwceymckinsey where i would be a consultant l but working as a data scientist good benefits all around but pay is k with potential annual bonus increase later on in salary etc i do not really consider work life balance to be a deal breaker in this case just focused on career development and if the extra k is worth going to the startup the ceo of the startup makes the argument that working as head of ai at his company would help me further down the line with getting into big tech companies but i am struggling to see it esp as i am the only one in the company with any data scienceml expertiseknowledgebackground they do not plan to hire someone else in this space at least for the next months due to their funding round budget the startup definitely does deep learning ml but again its all up to me and me alone the consulting firm has an established ds practice so i would be surrounded by folks who would know more there but at the risk of less work life balance thoughts,startup with more pay or a big consulting firm with less pay but more opportunities,data scientist vs business analyst
583,i got this interview question today and was unsure how to go about it how would you have answered the following question a classifier outputs a sequence of letters possible classes in the alphabet you need to present to management the ten most common classes the naive way would be to just maintain counts and then rank order them to select the top ten but the twist is that you can only maintain counters not how would you go about this is this a type of problem i am not even sure what to google to explore how i should have answered this ideas i have include storing and updating the max of the top ten min of the top ten max of the bottom order of the top ten classes etc but i am falling short of a substantive answer any thoughts thanks so much,stumped by an interview question,how would you approach this problem
584,im interviewing for a temporary academic research position focused on ml in days the role requires expertise in python programming and with utilizing python libraries to generate simulated data based upon the approximated distributions of observed data experience with large datasets a plus the problem is im not an ml researcher im a mechanical engineering student ive used python and numpy for robotics amp decision making applications but i havent really touched the statistics side of python i do have stats experience with large datasets and sampling from distributions but all my work in that area has been done in matlab and jmp is this something i can get a decent understanding of in days im not expecting a super technical interview so even a cursory knowledge of how do work with distributions in python would be helpful any advice on what libraries to reviewhow to best review them would be really appreciated,last minute prep for research position interview,how do i prepare for a data scientist interview
585,in reference to the healthcarebiotech industry i have about years experience in lab automation roles specifically lims for those you might know it this involves laboratory data management and automation i want to steer towards data science roles in the healthcare industry and have been applying mostly to such roles unemployed for a few months now but i recently received a job offer in the lab digitalization and automation area good company good pay my dilemma is if i should take the job or wait for a possible data scientist position in future possibly entry level position will this digitalization role serve as prior experience for future ds roles or does it not matter at all,does a informatics scientist or lab digitalization role count as relevant experience if i eventually want to get into data science,would you hire me as a data scientist
586,a little bit about myself i got started in data science before it was called that so i have seen the crazy progression of the profession now i work as a director of data science at a retail company side note i also worked for a successful blockchain company back when bitcoin was a what inspired this post i have gotten a lot of my friends that are interested in data science hired at their top companies by giving them advice and steering down the correct path however i have been kind of conflicted about just giving the advice to only my friends so here is what this post is about who needs mentoringcareer advice help trying to get into the industry i would be more than happy to help,data science career advice amp mentoring,advice on starting a career in data science
587,i have just been given a new position and i need to balance our inventory essentially the goal is to make sure we have a minimum of weeks of inventory on hand or a maximum of weeks on hand right now to determine problem items we have to follow a spreadsheet and mentally calculate is this around weeks on hand it is tedious inefficient and inaccurate i would like to make a line chart that will easily show whether your inventory line is between two values i imagine this would look like a line chart with a max and min line and the area between is filled with a color the actual inventory would be a line that fluctuated hopefully in between is there a name for this type of chart could someone please provide a brief explanation of how i might make this i have struggled trying to do this excel cannot get it to quite look like what i want i have a hunch that matplotlib can do this thank you please let me know if this is not the right place to post this,line chart that shows whether you remain between two values python or excel,best way to calculate inventory inventory
588,hello everyone i come from more of a clinical background pharmacy but i decided that i had enough i still got a clinical master tho i decided to finally switch to do something i wanna do instead and i was wondering if i could do anything to have a better chance of going into this field instead i had built some projects like an excel sheet that pull data from morningstar now the service got terminated for fundamental analysis purpose with some degree of programming and whatnot i was wondering if there are exams or whatever which i could show my passion i would like to go to aus studying b analyst d analyst d sci master not sure if this is the best place to ask any ideas would be appreciated d,transfering to b analyst d analyst d sci master without prior exp,data analyst to data scientist
589,hello everybody i have a conceptual problem choosing the best strategy for training a neural network so let me explain my situation i have trained an autoencoder on a huge unlabeled dataset using train and validation split now i would like to extend the architure by fully connected layers to predict a small labelled dataset similar to the approach described here as input features to the fully connected layers the encoding part of the autoencoder will be used the parameters of the fully connected layers must be optimized for svm and random forest i would use nested crossvalidation to optimize the hyparameters using random or grid search or just one crossvalidation with default parameters with fully connected layers this is not a good options i think usually i would split the data into train test and validation set but my dataset consists only of points in class and points in class so train test validation split is probably also not a good option using nestedcrossvalidation and random search is very time consuming for fully connected layers moreover using crossvalidation i cannot observe the training and validation loss anymore and adjust the parameters acoordingly as i did for tuning the autonecoder so crossvalidation does not work for manual tuning the network what is the best strategy to optimize the fully connected layers in my case,optimizing parameters of fully connected layers,question about crossvalidation
590,i am using the r programming language i used the rpart library and fit a decision tree using some data from a previous question libraryrpart cartestframereliability asfactorcartestframereliability zauto lt rpartreliability cartestframe plotzauto textzauto usentrue xpdtrue cex this is good but i am looking for an easier way to summarize the results of this tree in case the tree becomes too big complicated and cluttered and impossible to visualize i found another stackoverflow post over here that shows how to obtain a listing of rules extracting information from the decision rules in rpart package libraryparty librarypartykit party_obj lt aspartyrpartzauto data true decisions lt partykitlistrulespartyparty_obj catpastedecisions collapse n this returns the following list of rules each line is a rule corresponding to the plot of zauto country in cna germany korea mexico sweden usa amp weight gt country in cna germany korea mexico sweden usa amp weight lt country in cna japan japanusagt however from this list it is not possible to know which rule results in which value of reliability for the time being i am manually interpreting the tree and manually tracing each rule to the result but is there a way to add to each line the corresponding value of reliability eg is it possible to produce something like this country in cna germany korea mexico sweden usa amp weight gt then reliability note i am also not sure why the countries are appearing as befgh instead of their actual names thanks,manually extracting rules from a decision tree,how do i get the best results out of a dataframe in r
591,looking forward to trying this out but i am going to wait until it is out of beta has anyone tried implementing it yet have any tips or thoughts i love the idea that custom definitions can be mapped i have always defined two arrays to manually do this myself is there a way to set these outside of a hit is parameters sometimes i like to set them in anticipation of whatever the next pageviewevent will be gtagconfig ga_tracking_id custom_map wouldimensionltindexgt wouldimension_name gtagevent any_event_name wouldimension_name dimension_value what about event tracking the syntax has changed for categoryactionlabel along with a handful of defaults seems kind of cool but it appears that they are introducing custom parameters see this example straight from the documentation gtagevent video_play video_title amy promotional video woulduration user timings appear to actually piggyback off the event syntax but the sampling rules remain the same still on the lookout for tasks in the new framework but you can now assign consistent values for all hits what other cool new features have others discovered,has anyone tried the new gtag framework in google analytics yet,how do i track a custom event on google analytics
592,hello i am working with temporal spatial data and am in a bit of design funk here is my problem for a given location i have both dynamic and static features that is measurements that change with time like rgb values and measurements that do not elevation i am designing a network where the first layer contains a fcn and a rnn i would like to pass just the static features to fcn and just the temporal features to the rnn my question is what would be the best way to parse the data i could just slice it during the forward pass because i know the static features are the last few columns but i feel like there might be a better option,deep learning help,best way to pass dynamic features in rcn
593,i have some background in analytics as i studied it to some degree while in college but my current job is offering to potentially purchase training in any area related to our current work as part of an ongoing learning process could anyone highly recommend online training in any of the following areas data modeling including sqlteradata use data visualization such as tableau spotfire etc data mining particularly related to algorithms i never had much development there anything related to statistics coding or any other topics you find to be pertinent ideally these would be offered at an intermediateish skill level certification is preferred as it offers greater justification as to why the training is worthwhile but it is not required this is just a rough outline any advicecourses you can offer at all related to data science would be appreciated thanks,looking for best online trainings related to big data data modeling data visualization big data algorithms etc,is a data science bootcamp worth it if i already have a job
594,i have a neural network that i have developed which classifies emails into either spam or ham emails and at the moment i have two datasets these two datasets are used for training the neural network and testing the neural network is accuracy i have just been reading up on validation sets but i am wondering if this is even needed since my neural network seems to be able to be trained simply using the testing set at the moment my neural network has around accuracy and is adjusted through the use of back propagating an error and adjusting the weights of the inputs based on the error do i need to provide a validation set for my network if i do how do i even provide validation i do not get the concept of a validation set at all,is a validation dataset needed when training neural networks,how do i set up a neural network for testing
595,the neural ode technique to my knowledge presents a neural network based way of solving odes efficiently which implies it needs an ode and an initial value in order to construct the evolution over time in one simple example they provide of the lotkavolterra model the forward pass evaluates dxdt for an arbitrary x thus assuming knowledge of the ode and solving it to obtain the evolution of x does the technique still apply if i wish to flip the problem given a small number of measurements predict the evolution in the future by attempting to model it as an ode for the above example in my case i do not know the underlying dynamics but have some initial data about x vs t,can neural odes fit an ode from just measurements,is there a name for this type of neural network
596,hello im currently in my first semester studying data science on a postgraduate level my bachelors is in accounting but i have a stem background and im trying to rectify the mistake of going down the accounting path to begin with and im currently working as an auditor im interested in bioinformatics and ml and thats what ill be focusing my thesis on my question is i want to exit the finance industry at least as far as being an auditor is concerned but i have no idea what other jobs to look for that are relevant to what my end career path looks like without having finished the master yet will a basic data analyst gig be sufficient any help is appreciated,relevant jobs to seek while completing masters in data science,career advice
597,hi i am looking for a dataset of images of cells something like this one the idea is that it has labels so i can identify the different types of cells and also is the image is big and has more than one type it has rois so i can identify the region where the cell is present or i imagine something like in the case of blood cells the categories red cells white cells and the subcategories of different types of white cells is great but i also image cells from different part of the tissue like neurons or different types of neurons neurons blood cels lung cells etc something like cells from the cell type but with different features such as age any help will be very much appreciated cheers,i am looking for dataset of cells with different features like type age,looking for a dataset of images of different types of cells
598,i have been restudying a high school algebra text book especially wrt logarithms one section fresh in mind is that off logistic growth curves the formula from my online textbook for these is i do not know how this will render i see no preview option yfraccaebx where c is the asymptote a the initial value at x and b is the scale example in r data lt dataframe x y c model nlsy sslogisx a b c data data plotdatax datay linesdatax predictmodel separate to this in my day job i have been working on life time value prediction for cohorts of app installs there are some data points from the logistic growth curve that seem pretty handy to the work i am doing and before suggesting it to my team wanted to bounce it off here first the output of a logistic growth regression contains the asymptote and the mid point fitting cohort revenue to a logistic growth model could one then use the asymptote as the predicted lifetime value the midpoint would be the time taken to get half of the cohorts estimated lifetime value which could be useful since some stakeholders have asked about velocity of payback are my two ideas isound if i go down this path how can i validate with regular regression i could keep an out of sample of eg and run evaluation metrics on that but in this case how would one evaluate a model i have years of data and we typically consider a week to be a cohort i am planning on fitting a model per cohort would i use historic data here or just fit a logistic growth curve on a cohort after n weeks and project out as i have never used this approach before i am seeking validation is my approach worthwhile how can i validate,use a logistic growth curve to estimate cohort lifetime value is this a common approach,question about time series forecasting
599,so i have been landed the task of organizing the strategies of a large number of similar but different organizations in a consortium each one is basically a project management contractor that implements various kinds of mostly government contracts globally each organization has a number of regional and subregional offices globally each of which has produced a narrative strategy document in moreorless the same format my job is to organize them draw out common themes and synergies spot overlaps and identify outliers that might not make financial sense i think i am going to have to go through them all manually identifying commonalities etc and organizing them in a spreadsheet but i just wanted to ask whether there is a better way thanks,tools for working with large numbers of text documents,how do you organize your data
600,shameless reposting from here as the title states i have an opportunity to share my figures with an executive team that is multiple tiers above me they have zero coding experience how do i package my figures here is a copy of the figure i want to use notime series with rangeslider the code import plotlygraph_objects as go import pandas as pd df pdread_csv fig gofigure figadd_tracegoscatterxdfdate ydfaaplhigh nameaapl high line_color wouldeepskyblue figadd_tracegoscatterxdfdate ydfaapllow nameaapl low line_color wouldimgray figupdate_layouttitle_text notime series with rangeslider xaxis_rangeslider_visibletrue figshow obviously i am not going to share my entire script that takes days to generate the csv and ask them to run it is there a way i could wrap the above into a exe or html thingy ideal scenario would be something i could attach in an email and they could just click on it,opportunity to share my interactive plots with executive leadership help python,can someone help me understand how i can use tflearn to create a python package that can be run locally
601,hello sorry to bother everyone and i am not sure if this a question that is fit for here but i am really stuck i tried to train a cnn for cat and dog classifier for a course i am taking and that ended on my laptop seriously overheating and shutting down so i cannot go on with the course to train my model i tried some cloud solutions but they are really inconvenient for me and if i am going to pay for the cloud instances then it is cheaper on the long run to get a computer fit for deep learning so my question is what is the bare minimum gpu that i can go with that would fit a beginner is need in deep learning i have seen most computer builds go for but that is steep for me so is there any way i can get a build for half that or something or is that not possible thanks in advance and i am really sorry for such a question here but i am really stuck and i cannot find anyone saying anything on google that recommends a gpu suited for beginners,a computer build for deep learning,what is the best setup for deep learning
602,i am an undergrad nd year student in electrical and computer engineeringi want to become a researcherwhat things i should do to become reseacheri heard to become a researcher you must read papers dailyi am little bit confusedi did some small courses on ml and dlso now how should i proceedshould i read some text books to have base knowledge and then read papers or read them in paralleland which books and paper should i readrecently i see lots of research work is happening in dlshould i first focus on dl or mlif someone answer these in details that would be really helpful i am new hereif i am making any mistake forgive me,can you please provide a roadmap and resource list to become a data science researcher,what should i read
603,greetings i am years old and i am currently in my penultimate year of school i am a russian citizen but am studying in an english school in malta i am interested in data science as of now i have a good command of python and a portion of the pydata stack numpy pandas matplotlib studying scikitlearn i know basic sql studying the necessary statistics and math and am planning to join kaggle competitions and build my own personal projects over the next years i personally have little desire to get a bachelors degree and would want to start working right after school also partially due to financial limitations the country of work would for the first few years be either malta or russia after which i plan to go work in australia for years to become a citizen there there is a chance i might need to get a bachelors degree to avoid getting drafted to the russian army what would your advice be for me in my current situation the only specific question i have is what kind of degree if i had to do one would give me the most of which it is hard to study on my own whilst obviously still being adequately related to data science,advice for a yo planning to work in ds,is it worth getting a masters in data science if i already have a job as a data scientist
604,hello there my partner and i both lead data scientist teams in the online travel sector we often hire grads and phds who have the technical skills and theoretical knowledge and then help them develop the additional competencies needed to become competent data scientists after doing this for many times we developed a pretty effective approach with a decent success rate recently we spent some time here on rdatascience and noticed that many people here face a similar challenge they have finished a data science book course or even online degree yet still felt that there is a gap between the technical stuff they learn and the skill they need to become competent data scientists if you are one of them we would love to have minutes of your time to answer a few questions here we are considering to develop a course to bridge this gap your feedback will be super valuable for us thanks for your time in advance,you finished a data science course now what,i have a data science interview tomorrow and i would like your feedback on my interview prep
605,hey everyone i was premed but after some deliberation i see myself more engaged in statistics r and sas health and super eager to learn how to code i was thinking of doing mph in epidemiology and learning coding and those statistical packages right now i am a junior in college doing public health but i mean if i want to learn those skills would just mastering in data science be better the way i look at it a data scientist given my health background as well can do the many stuff of an epidemiologist as is if i want to join that route or be like a pharma data scientist or something analyzing trials but a epidemiologist can not always do the job of a data scientist essentially i am saying that i think a data scientist is more general and i can apply to more different jobs,epidemiology gt data scientist ms advice needed,is it worth getting a masters in data science if i already have a job as a data scientist
606,right now i am training models simultaneously through colab for the same dataset ampxb obviously the training times vary based on these parameters and i wanted to ask something rather simple which should i choose ampxb the simplest one takes seconds per epoch but the losses are terrible ampxb the intermediate one is well in the middle ampxb the deepest one takes seconds per epoch but at the same time the losses are much much better and i am sure the results will be too ampxb ampxb for more detail it is a wgan i am looking at the same model for mnist was taking per epoch on my net and colab will not get into excessive details but the deepest one is so much better loss wise and i am just waiting to see the results ampxb ampxb beyond my specific case is there any usable information about losses overfitting depth training time and epoch count,deeper networks over fewer epochs or shallow networks over more epochs,question about overfitting in google colab
607,i am a newby at data stuff i hope this is the right place to ask questions i apologize if not i am trying to analyze some home heating data from logging thermometers problem is they are on different scales some are minute some are minute and a csv i downloaded of outside temps is hourly is there an easy way in a spreadsheet to add the spaces i need to conform these sets to graph together i guess i need to add rows to the outside temp file i might also want to make all of them on say a minute scale to reduce the size of the file so adding rows to the outside column and deleting every of and of respectively from my thermometers i have tried googling this question and not had a lot of success for a simple answer thanks for any pointers,help merging datasets with differing time scales,best way to store a large amount of time series data
608,this post is inspired by a post around hours ago regarding the necessity to specialise i have a bachelor of accountingmarketing a marketing mba and use sql python power bi every day in very much a data analystscientist role in the commercial arm of a big pharma company i want to specialise in commercialmarketing data science so i can really be that go to person for business performance improvement at any company i am also looking at a data science role in mampa at deloitte that requires you to be able to identify the key segmentsdrivers of a company it looks really interesting so i want to develop in this space what are some possibilities for specialising in ds to understand what the key drivers of performance in the commercialoperations sense and then using data science commercial acumen to develop new opportunities thanks in advance,specialising commercialmarketing applications of data science,data science in the commercial sector
609,i am a junior year undergrad computer science student from india i am suffering from cyclothymia disorder and had to take a year off after my high school and due to this i was admitted to a lowranked local engineering university i was doing software development and programming and became a good developer as a result i got selected for google summer of code during my sophomore year but with the beginning of my junior year i lost interest in software development and now i want to make a career in research i want to gain all the existing knowledge in my area of interest and begin working on my novel idea while working as a research internassistant that may lead to publications and a master of science phd degree in the usa i am ready to take a year off after my bachelors if it requires i have two questions is it late to begin with research provided that i have only year left of my bachelors i am unable to find my specific area of interest i have begun reading a standard book on machine learning and it got me excited but then i look at other people profiles on linkedin who are doing great as a phd scholar at the usa and i think that i am too late and maybe i am inclined towards aiml because of the hype sometimes i thought of taking a masters in physics as it used to be my favorite subject during school days i do not know what will happen in the future but i want to do wonder in my area of interest how can i decide it specifically i am at the end of my undergrad and thus lack of time,how to find my area of interest provided that i am a junior year computer science undergrad and want to do lifechanging research,is a data science masters worth it if i already have a job as a software developer
610,three days ago i made a video explaining how my nlp transformers course would be entirely free as part of a limitedtime promo i shared that video here and in a couple of other subreddits too rlearnmachinglearning and rlanguagetechnology being two three days and downloads later here we are i thought we would be lucky to hit k incredible response and very happy to be able to have been able to give so many of you an opportunity to access the course where some of you may not have been able to otherwise i am looking forward to working with all the students and helping you guys out just please do not all ask me questions at once thanks all truly humbled by the response it is really really cool it has blown my mind for any of you that are still interested i will leave a final discount link here thanks all,more than k of you downloaded the free nlp transformers course wow,free data science course for students
611,so at the beginning of this year i set out to learn about data science and i feel like i have done fairly well but i am still struggling a bit and could do with some help a little info about the project since i have a background in robotics i recently decided to try my hand at applying what i have learned there in case you do not know a common university project given to mechatronic engineers is to build a robot that balances on two wheels it uses an accelerometergyroscope to sense it is orientation and a deterministic algorithm to control motor output to achieve balance commonly a pid controller is used some will also include an encoder on the wheels so that it can balance on a specific spot instead of just trying to stay vertical i built one of these with a raspberry pi and it works very well i decided to see what kinds of learning algorithm can be used to balance it as alternatives to the pid loop i decided to use my original code to generate a data set of inputs to outputs and then use these to train a machine learning algorithm specifically the data is as follows inputs were the current angle error setpoint minus angle reading from the accelerometer the rate of change of angle from the gyroscope and the approximated integral of the angle over time calculated from the outputs labels were the motor power signals i used this to record about seconds of balancing wherein i bumped the robot around a little so that the data set included how the robot handles disturbances i fed this into a few different regressors in scikitlearn and found that random forest regressors performed the best lowest rms error i am now in the process of writing a new control algorithm that uses this model to balance just comparing the pid outputs to what the random forest regressor would produce for a separate test set shows that the two are very similar so i am fairly sure it will work this kind of traintestimplement methodology is ok but if i wanted to turn this into a reinforcement algorithm how would i go about it i ideally would like my robot to learn from its own balancing and get better as it goes there are some limitations which i am sure will prevent perfect balance one example is backlash in the motor gearboxes i just do not know how to start with this kind of algorithm i can start a separate thread in my python script that updates the model in the background as new information as it is collected but i do not know the practicalities of how i program in this reward and how the algorithm can know that it is improving instead of just changing i am starting to learn about qlearning but i do not think it is very applicable here thanks for reading when i get it working i will post a video if anyone is interested,beginner questions how do i introduce reinforcement into a random forest regressor to help my robot balance better,how do i go about creating a neural network with input from two different directions
612,do not know where exactly this will fit thought maybe someone here could advise i am a grad student in the cheminformaticsdrug discovery space because that is where i could get and i am working on models to help predict drug toxicity at the same time my personal interest is in modeling financial timeseries so that is what i am doing when i can however my team lead wants me to get back to the task furthermore i have a contact at a big tech firm and he strongly believes i need to get into nlp and is suggesting a personal project for me to develop in that space he also thinks the financial modeling is not leading anywhere oh and at the same time i need to keep my software engineer skills up to date and get an internship as a software engineer i feel like i am being pulled in a lot of directions at once and if i at least had some idea which is the profitable one it would be ok i am grateful to have wellwishing people around me trying to guide my career path but i do not know which direction is a waste of time and which i should focus on sorry for the rant i am grateful to be where i am and to have this kind of problems but i am still concerned that i will end up going on a wildgoose chase that leaves me in the dust,i am being pulled in a lot of different directions at once,data science career advice
613,hi there i am currently making a gan for a project i have been working for a while trying to get it to work correctly the goal is to generate pokemon i am using keras on a tensorflow backend my problem is that it currently does not change the produced images based on the latent space at all all images are nearly pixeltopixel copies of eachother the images of any particular set of latent variables also changes quite rapidly completely changing color and shape within iterations even after iterations for some reason the latent space changing seems to have pretty much no effect on the end result i am using rmsprop rather than adam and using no dropout in my generator to try to combat this yet it still will not work any help would be great thank you,gan creating no unique images,how do i use generative adversarial network in keras
614,hello world long story short living expenses car payment and apartment costs have crippled my ability to do much besides eat and work with students loans starting back at the end of august the situation is guaranteed to get worse was just curious to know if there any data scientists out there living out of their car or were considering doing so having been homeless as a child and been in an out of foster care i dont look down on people that are homeless or live in vans or cars but even contemplating this makes me feel pretty bad about myself in my circle of relationships im the only person i know my age that isnt about to have kids owns a house and is traveling to cool places every other month thank you for your time best gaborized,working as a data scientist and living in your car,is it worth getting a phd in data science if i already have a job as a data scientist
615,hey there is a work project that i am supposed to do and right now i feel like i am in way over my head i appreciate any help or direction the project is supposed to work like this show random word out of predefined list person says the word machine prints out a rough percentage of how close you are to nativelike pronunciation prerecorded spoken words there are words in the predefined list i was thinking of classification providing examples in the range of nonsense to excellent pronunciation and printing out how likely it thought the speech input to be the displayed word that is only because of my lack of knowledge in this area i would have just used google speech api and used a hacky way to do it but one version of it has to work offline in a stand somewhere so that is where i thought of training a model,audio comparison,i am trying to build a wordvec model from scratch and i have a few questions
616,im trying to explore a switch in career paths in order to make more money but searching for dads jobs has me nervous there seem to be very few true entry level jobs and the few i do see that claim to be entry level still require years experience at best here are my current credentials heavily summarized education bs in physics with a minor in mathematics years experience in python current job middle school math teacher curriculum involves algebra and statistics previous job quality assurance rep at a debt collection law firm spent time analyzing call data to identify patterns and compiled reports on various aspects of collector performance utilized basic excel vba in order to pull data clean said data and process it into reports for daily submissions to corporate office if i choose to pursue dads obviously i will dedicate my time to learning more skills necessary im not under the impression these credentials are enough to switch careers at the moment but will they help bolster my resume in years if i do decide to make the switch,would my work experience lend itself to a data analystdata science job hunt,is it worth getting a masters in data science if i already have a job as a lawyer
617,to what extent an entrylevel data scientistanalyst interview will touch on algorithm amp data structure questions i googled around and some say they have been asked basic coding questions as you would get from a developer interview such as easylevel questions in leetcode and those from cracking the coding interview basically used by interviewers to test applicant is basic cs knowledge ampxb but i feel like some topics in algorithm amp data structure are not very closely related to data science imho topics such as big o arrays sorting amp searching are useful but do i really need to know topics such as tree graph will i be asked for classical but notthatrelatedtodatascience coding questions such as shortest path dijkstra is algorithm other treegraphrelated problems just to give some examples so what algorithm amp data structure knowledge should i prepare for ampxb specifically what topics of coding problems should i focus on for a data science interview besides topics i mentioned above other common topics are bit manipulation strings oo design dynamic programming recursion,do i need to brush up on algorithm and data structure problems for a data science interview,data scientist interview prep
618,hi all im working as a reporting analyst mostly automating report generation producing reports but wanting to move into more of a data analyst bi role through networking ive managed to set up a couple of coffee meetings with some lead data scientists in my organisation id really like to make the most of out this time and would like to know some recommendations for questions or comments around what topics i should try to discuss ive got a list of personal questions surrounding feedback around my current development plans but i really would like to show that im interested in their work i guess for those who have beenare in a similar position what would you recommend asking about thanks for the feedback,questions to ask a data scientist,data science career advice
619,hello i am trying to do a little project about nlp and data analytics and i need to get the text from some whatsapp chats i know there is an option to send a chat via email as a txt but it is limited to k messages and this amount is not even enough for the small of the chats i want to use i thought about creating a javascript function to get all the text from but seems inefficient and it should be my last resource are there any ways to recover full whatsapp messages from backup or whatever without having to root my phone my phone is android if that is helpful in any way thank you,p obtaining full whatsapp chat,best way to store text messages in google analytics
620,at some companies data scientist is a person who creates monthly counts of customers and never works with machine learning even though the title is data scientist this really should be a business or data analyst at other companies a data scientist is a person who builds data pipelines along with data analysis reports even though that should be a data engineer and at other companies a data scientist is someone who reads academic papers and writes software to translate those papers into software production code that is used by other teams this should be a machine learning engineer but companies define it as data scientist this along with the large number of data science graduates every year is creating a huge supply of people who call themselves data scientists this makes it really difficult for hiring managers to wade through this supply of candidates to find the right person for the job,the term data scientist is so loosely defined by various companies and that is one reasonnot the only reason why there are an absurd number of job seekers,data scientist is just another title
621,so i supposedly work for the best place to work in my city due to a positive culture pay worklife balance etc etc but the culture around data science is not very fun maybe even toxic the company dates back to the late searly s and the average tenure is over years so it is so slow to change and largely run by what i call intestinal analytics i cannot really afford to leave right now because i made the mistake of living at my means and i have plenty of debt to pay down before i can move maybe a year and a half longer before i cannot afford a pay cut without dramatically decreasing my standard or living which takes a bit of time to liquidate assets ampxb they hired our entire team over the course of one year we are a team of and i am one of data scientists i was initially hired due to my abilities in r i did some of the advanced modeling work for a while which i enjoyed after a few months the higher ups decided to purchase tableau i was the only one of the team with prior tableau experience so i got moved over to tableau world at first that was fine because i had to refresh my memory and relearn a lot of things as well as train another team member now it is tedious and boring so now it is me and a coworker who live in tableau world the bad part is less the boringness and more so the fact that we are responsible for facing the company and building something presentable out of the modeling work that others can understand ampxb unfortunately the models show that the company is losing ground in comparison to competitors which for some reason we get yelled at over because the modeling cannot be correct it is they just do not like it keep in mind the profit margin for this company is over so it is a bunch a spoiled old people who throw temper tantrums when they hear things they do not like another thing is that when we do roll out a very useful tool or valuable information that is appreciated for about seconds then we get bombarded with requests to change colors to different colors based upon the person and no one is happy because they do not have their own individual view ampxb the culture attitude towards my one coworker and i has also been on a steady decline since the company decided on a salary transparency policy about a month ago during a reorg i got a k increase that i thought everyone else got apparently that is not the case only my cowroker who also works primarily with tableau did as well once that got out she and i have faced a steady stream of judgement because we are making more money to do what is seen as easier hr issued a statement saying that we got the increase due to the business facing nature and value tableau reports are adding to the company either way it has been uncomfortable especially when we need their help on something and since we are the youngest on the team ampxb my coworker who works with me on tableau lives the next street over so we carpool a lot and she spends most of her commute home crying about how much she hates her job i do not cry but sometimes i really want to we are both at the point where the money just is not worth being totally miserable to hours a week ampxb i guess i just want to hear your experiences and if you have any advise on how to break out of this is this what the culture around data science is everywhere,i kind of hate my job as a data scientist do you like your jobs any advice for me,is it worth spending too much time learning r or python
622,hey everyone i am a final year maths amp statistics with a bit of german uni degree student in the uk i know i want to do something to do with analysing data and coming to conclusions but i am not sure on the career that will allow me to pursue this i am taking modules in medical statistics data analysis and bayesian statistics which i enjoy all of i am pretty handy with rstudio and matlab but other than that i am not massively keen on programmingcoding although i would not refuse to do something like that i am however not keen on something that is solely finance based some careers that i have found have been data analyst data scientist market researcher and various types of statistician although i am not sure what best suits me i am sure it varies from position to position but i would like some advice any maybe someone to talk to regarding it if possible about where they think i would be best starting out as much appreciated,i am not sure on the specific career i should go in to advice much appreciated,data science career advice
623,so i am the lone data scientist in my company startup in the healthcare tech space like i imagine many here are last week i saw a linkedin post from the company is ceo flaunting how data we provided was used in an article published by a major news outlet i am omitting details here to preserve anonymity he said it was all thanks to our new product ltinsertflashynameheregt and our cuttingedge work with big data all caps ai and business intelligence the thing is neither this particular data nor this product are thing which i have even heard of now like i said i am the only data person in the company and we are not a large company at all so there is no way there is someone working on stuff like that without me knowing we are nowhere near close big data and there is very little ai stuff being done like in most startups the majority of my time is spent juggling data engineeringdata analysis demands and if i had to bet i would say this particular case was probably something done in some random excel spreadsheet by the productmarketing people at the last minute i know part of the ceo is and other execs jobs is making the company look good but sometimes the way they misrepresent the technical work the company is actually doing by using random datarelated buzzwords is really hard for me to overcome is this me being immature should i just learn to embrace this kind of thing as an inevitable part of corporate work,how do you handle marketing speak by execs and misrepresentation of yoursyour team is work,how do you deal with bosses that do not understand data science
624,i have a dataset of sales figures from jan to present i am trying to project sales out to the increase in sales is nice and regular starting at jan until we get to a huge anomalous surge in activity around march april may this year this is affecting the projections if i include this activity in the training data the projections are as much as higher than if i just project from february before the lockdown happened the confidence bounds are also much wider how should i deal with this how have you folks dealt with this because i am giving my manager two copies of every projection i have one that uses the lockdown as training data and one that does not i have framed it as here are projections that take into account continued lockdowns and customer uncertainty panic buying and here are the more sane projections that might happen if a virus is found tomorrow and everything gets back to normal however i feel like i should be telling them which one to use or what i have done to ensure we get the most accurate projections ps i am not even using python or anything complex for this just excel is built in forecasting tool which is pretty handy,how to deal with time series projections that contains covid lockdown anomalies crazy sales figures,how do you deal with sales projections that are not accurate
625,hi i am trying to match the output with the input of a restaurant software system here input means raw material and output is food items since there is a lag in the input time and output time how could i solve this issue for example if i input kg of flour this kg will turn into bread some days later so how do we match the bread to the flour it was made from my aim is to calculate the amount of bread made in a month and match it to the flour it was made from since there is a lag which i do not exactly know how long since this could vary with demand how would i go about this i could think of a way to do this such as scanning bar codes at every point such as scan the flour bag when the supplier delivers it then scan again when going production and again at sale this method would not be worthwhile if the company is small due to the additional cost time and less standardisation also this system would be quite difficult if there are many food items being used such as in a restaurant i am not sure even large food chains such as mcdonald is even use such tracing of inventory from stores to customer but they should be thanks amp best regards michael,matching input with output of a system food,how would you approach this problem
626,i am new to ml and tensorflow i started about a few hours ago and i am trying to use it to predict the next few data points in a time series i am taking my input and doing this with it x y what i thought i was doing is using x as the input data and y as the desired output for that input so that given i could get the in particular however when i run my graph with x as the input what i get is a prediction that looks more like x than y here is the code based on this post the result shown in this graph is a prediction that follows x rather than being shifted to the left and including the predicted points on the right as it should be to resemble y obviously the desire is for the red line to be as close to the blue one as possible i have no idea what i am doing with all this so please eli oh also my data points are fairly small numbers order of if i do not multiply them by say the results are so small that the red line is almost flat at the bottom of the chart why i am guessing it is because of the squaring in the fitness function should data be normalized before use and if so to what if i use normalized_points p min_point max_point min_point for p in data_points my prediction fluctuates more wildly as it progresses edit i am being dumb and only giving it one example to learn from not are not i so i should be giving it multiple point samples right,trying to use tensorflow to predict time series data,how to deal with outliers
627,i am offering free ti gpu instances for deep learning sign up at the instances have gb ram cpus cores and one ti gpu and you can run multiple instances in parallel instances run on customized jupyterlab images fastai pytorch tensorflowkeras and on cudnn you can access the command line and use it as a dedicated server for training our goal is to lower the entry barrier for deep learning so we will work hard to make sure we support the community we are inviting you to help us learn how we can better support researchers in the field of ai we want to improve the product and so we are exploring the community feedback we will be providing free gpu time reaching out to the registered users and asking for feedback if this sounds like something that would fit you sign up at contact for supporttensorpadcom,free servers with ti for deep learning,free servers with ti for deep learning
628,hello i graduated this june with a bsc in astronomyastrophysics in canada i really liked the material which is why i chose the degree but now it is obvious there are not really any decent jobs in this field i have had summers of research experience in computational astrophysics and data analysis and i am currently working as a data analysis technician at a university as well and this job is contract ends in december i am most experienced in python but i am familiar with other languages as well i thought about pursuing a masters in cs since i am experienced in coding but i probably do not fulfill the requirements of the good programs so i was thinking about masters of data science which i thought could apply to a variety of fields such as finance cs etc but my brother suggests i do something engineeringrelated i believe i can do good in either programming or engineering i just care about better pay so my question is the following what programs can i look into that have good job prospects in industry with good pay my research experience is all in academia which i do not want to continue in is a masters in ds worth it in the long run if there is any other advice or suggestions you guys can give that would be greatly appreciated as i am clueless right now and a bit worried i would like to mention that i got a few lt interviews for a data engineer role and junior dev positions but none of them worked out,masters in ds after impractical bsc,data science career advice
629,i am currently working on a project to diagnose medical diseases from freetext clinical notes i have done nlp on medical text and i extract clinically relevant terms and identify their coded term in a medical dictionary for example the term angina gives me a code of c what i end up with is a massive list of codes for each patient i am wanting to classify these lists into a type of disease which i have some labelled data for however i am having difficulties putting these codes into a numerical format to use in a simple ml algorithm probably a simple backpropagation network as a proof of concept if anyone has techniquestips or even algorithms that work on this type of problem would be greatly appreciated,preprocessing medically coded data into numeric data for computation,looking for a clinical dataset with ai
630,i have degrees in both biology bs and pharmacy pharmd i am looking to transition into a career in data science and was just wondering what everyone is thoughts were on whether completing a ds bootcamp could be a viable strategy for someone without a background in cs or a quant discipline to start a career in ds based on previous discussions that have been held in this subreddit on the topic most data scientists do not seem to have a favorable opinion of ds bootcamps but most of those discussions were held yrs ago and i understand that a select handful of bootcamps are held in relatively high regard so i am curious to get new input on the subject matter even though i am interested in pursuing ds or possibly cs as a career on a general level it may be worth mentioning that i have been told that combining my pharmacy practice doctorate with a data science skillset would make me uniquely qualified for positions with pharmaceutical companies that involve doing various types of statistical modeling having proficiency in something called r shiny was specifically mentioned to me among other things it goes without saying that the prospect of becoming eligible to apply for ds jobs after completing a month bootcamp holds significant appeal but at the same time i want to make absolutely certain that employers whether in the pharmaceutical industry or those who employ data scientists in more general positions will actually consider bootcamp completion to be a legitimate jobqualifying credential thanks,is completing a bootcamp a viable way for someone without a quant background to start a career in ds,data science bootcamps
631,still getting used to reddit and could not find the particular subgroup this should go in bare with me people thanks making the career field transition from gis to data sciencedata engineering i am a master is student at insert big engineering school name here in city amp regional planning i wanted this degree to give me more background for a career in urban analytics however i have become super involved in civil engineeringtransportation systems engineering because i work in that department and because most of the classes overlap with the transportation specialization i am doing in the city planning program i really enjoy applying my technical skillset heavy in gis i code but only a bit right now in r python learning html amp javascript to transportation problems whether it be public transit traffic or freight problems that need solving my issue is this i am burnt out from doing school straight through for my entire life i have been hustlingworking hard while doing school simultaneously for a long time yearsin addition i forced myself to complete a terribly difficult program in high school plus years totaling now because it was the only opportunity i had to get out of the rural town i come from so yes i am tired i also have asperger is syndrome so i completely obsess over new topics i get interested in such as transportation engineering or data science this often interferes with my ability to prioritize and make important career moves for example i should have learned programming years ago but i did not know how to get into it etc so i procrastinated until about a year ago i am at a point where i need to decide whether to pursue a master of civil engineeringtransportation systems only more months of school after my first master is graduation in may or just walk away with my city planning master is and start working in the field i am on the fence because i am really good at what i do and i think the nd master is would build upon my growing skill set and help me become someone who stands out and i think the title of engineer is more fitting to what i do do not get me wrong making a decision like this just because of a title is pretty stupid and i am tired as hell here is my degree trajectorycannot outline my various related jobs here but i have worked enough in the planning and gis fields in both publicprivate sector and i am only i have gotten a ton of gis experience from working in industries like tourism consulting economic development local county government software development transportation regional planning climatology and fluvial geomorphology if you happen to be an employer reading this feel free to hire me and drop me a line bachelor is double major geography geospatial information analysis and political science international relations master of city amp regional planning transportation specialization potential master of civil engineeringtransportation systems engineering would it even benefit me to have the civil engineering master is like i said it is only extra months i have no cs background but i have literally been teaching myself and i have been very successful not trying to sound like a knowitall i am conflicted also because i get a ton of job offers via linkedin in gis fields but none of them pay in the bracket i am realistically aiming for i have clearly worked my ass off to get out of the trailer park and into the white collar world lol i know my worth thanks all who respond,career move from gis to urban analyticsdatasciencedataengineering,is a data science bootcamp worth it if i already have a job
632,i am a sophomore in college right now and after finals ended i have been reflecting on what i can see myself doing after college currently i am a biomedical engineering major planning to minor in eecs focusing on ee i know i like the field of biomedical engineering but i am also realizing that some of my favorite schoolrelated things to do is to manage data look at statistics use excelpythondesmos to model situations and do things like calculate my potential grade managing lab data and other things that i think data science would be related to as well as browsing rdataisbeautiful lol also i recently finished a cs algorithms course that discouraged me from software engineering other cs fields but still open to ee related things can anyone especially those with experience in the intersection between biologymedicine and data science tell me what the field is like what further education is needed subjects within data science that are most applicable or resources to learn more on my own this is something i am only just beginning to consider but i do not know much about it so i want to learn and see if its right for me,biomedical engineering and data science double major,what are some of your favorite data science courses
633,hi everyone i need ur advice on my next step specifically should i study bachelor of data science or master of data science or any suggestion would be appreciated i graduated from bachelor of civil engineering in due to personal circumstances i wasnt able to apply jobs in my field and so just did some odd jobs however now i wanna get back to focus on my career as i reflected back i thoroughly enjoyed mathematics statistics and engineering modelling those few subjects in my engineering program and since data science can be applied in various industries this piqued my interest even more im not gearing towards being data analyst in engineering sector though im not against it if the opportunity comes my way,further study for transition from civil engineering to data science,career advice
634,i am a programmer who got put on a bigdata machinelearning project i have picked up the concepts i think but i am mostly relying on pandas scikitlearn and other tools and kind of treating them as a black box i have been trying to learn more and i am wondering what i should focus on to give you an idea of what i have done i wrote a neural network from scratch as a learning exercise in my free time but i had to do it like a simpleminded programmercreating a neuron class that contains weights and references to other neurons instead of piling all the weights into a matrix the book i was following had lots of as you can see this is the same thing as a dot product and but this equation would be much more concisely written if you think of it like a vector and then the steps that followed made zero sense to me and in the end i just had to copy the magical backpropagation formula so far i have been able to fake my way through i can probably keep running queries putting the data into dataframes and running offtheshelf ml algorithms on them but i am wondering what am i missing out on and how might i be better if i had a proper academic foundation in this stuff what is the most important thing for me to study or should i just trust that the phd is who wrote this stuff understood it and focus on doing my job,i picked up data science on the job what am i missing from lack of academic experience,how do i go about building a neural network from scratch
635,hello and good day to everyone i just wanna ask for an advice or recommendation regarding my current state im a gradwaiting computer engineering student and have been wanting a career path that is aligned with data scienceanalysis however my current knowledge for the said track is limited as i have only studied a couple of lectures regarding it preprocessing techniques such as imputing categorical data and some linear regressions through python on the other hand i am somehow confident with my knowledge in software engineering through asp net mvc i should also note that im currently in a state of financial crisis so i need a job as soon as possible my questions are the following should i pursue a career in net first and study ds at the same time or should i build my skillset in ds first before pursuing a career despite the financial problem are courses in udemy really worth the money time and effort do companies hire aspiring data analystsscientists with minor skillset in the said field to be trained thank you very much any replies would be very much appreciated,in need of advice and recommendations regarding my future,is it worth pursuing data science as a career
636,link when i was working at my previous job some queries were getting pretty big and ugly and i started thinking about some kind of tool that could make building my sql queries cleaner and more convenient i thought that there must be a better way to organize queries other than in a wall of text someone pointed to me that there were already some software like alteryx and knime that are visual but for my objective to just visually organize sql queries these were overkill and overbudget also their dark theme is either nonexistent or ugly as hell there are also other tools like chartio is visual sql and active query builder that are kinda visual but not the kind of visual that i wanted so i decided to create my own supports all modern browsers also supports tablets and ie dark mode by default light mode is not even a consideration do not know if it will be useful to you guys but this would certainly be a game changer for my past self i will keep refining this project over time so feedback is much appreciated,i built a free online tool that lets you visually organize your sql queries,is there a better way to organize your data
637,i have programmed a random forest algorithemit took month and bayes was pretty easy attributes are the words an operator inputs categories my team manually decides however i am running into the issue where my most popular categories doesnt work wrong department part broke dominate my random forest and bayes probability i see hints of classification where there is a noninsignificant value toward things like microphone broke how do i get more of nothose to show up here are some programming problems i am thinking may impact gtdepth of random forest trees items are classified rarely do they find a common attribute mostly they go through the false side until they get to an ending i have full control over changing parameters gtdata is bad only entries to mine and whoever categorized them picked the easiest wouldid not work too often gtneed more learning methods i currently use dumb conditionals dumb probability probabilitynoise bayes probability and random forest for my inputs dumb conditionals are the most effective unfortunately gtdo bayes on random forest this would supposedly get rid of noise i am pretty desperate for next steps any ideas,random forest and bayes are done but my predicted classifications still suck,is there a name for this type of problem
638,hi i got attracted to this wonderful field a few months ago i learned r and took a course on edx i found it much more interesting and exiting that my current degree humanities i read that to be a data scientist a degree is not a major drawbacks if one has a good portfolio but as i do not have eve a single project under my belt i thought that i wold take up an internship to get hands on a project but alas to get a internship in my region eghther you need to be a engineering student or have a good portfolio any suggestion on how to create a portfolio under such conditions ampxb thanks,questions regarding portfolio and projects,how to create a data scientist portfolio
639,some set up is needed due to my somewhat limited experience with time series data the question is also based off a meme lets suppose were predicting sales in a shop or levels of some chemical in soil suppose also you have a dataset which includes numerous relevant predictors for the item of interest numbers of competitors or soil type ordinarily you would just use some nice technique like regression or something fancier question suppose there is also a time component and that it is known that the item you want to predict could be treated as a time series supposing some technique again well just pick regression for simplicity is used there was a reference to correcting for time series error what is this actually digging at i sat down to think about the issue and came up with possibly using some relatively simple time series technique and combining that with the other predictors in some sort of ensemble model combining predictions from the time series technique and however the other data is utilised this makes some intuitive sense but i would not be surprised if theres a better approach good reads on time series data would also be appreciated,combined approaches with time series data,question about time series prediction
640,univocityparsers is an opensource project csvtsvfixedwidth file parser library in java providing many capabilities to readwrite files with simplified api refer to the following code for parsing csv file public static void readcsv throws filenotfoundexception read csv rows into dimensional array st config the csv reader such as line separator column separator and so on csvparsersettings settings new csvparsersettings settingsgetformatsetlineseparatorn nd creates a csv parser with the configs csvparser parser new csvparsersettings rd parses all rows from the csv file into a dimensional array listltstringgt resolveddata parserparseallnew filereaderexamplesexamplecsv public static void writecsv throws ioexception st setup the writer for writing csv file csvwriter writer new csvwriternew filewritertemptestcsv new csvwritersettings nd write the record headers writerwriteheaderscountryname capital rd write rows of data into the csv file collectionltobjectgt rows new arraylistltobjectgt rowsaddnew stringgerman berlin th add comment and flush csv data writercommentrowthis is a comment writerwriterowsandcloserows,univocityparsers a suite of extremely fast and reliable parsers for java,i am trying to implement a new dataframe in my caffe file and i cannot get it to work
641,so i have the latlong coords of companies abc and d physical store locations i want to perform an analysis to look at the proximity of of the companies abc in relation to of the companies d i have already mapped all the locations and done analysis such as company ab and c is average distance from company d stores but is there anything else you guys think i could do which would be useful i am using pythonpandasgeoplotlibseaborn i tried googling but not sure what exactly to search for i am sure there must be techniques for this kind of stuff but i am coming up blank apologies if this is the wrong subreddit,help analyzing store locations,how do i find a data set that is similar to a location
642,i am a year old man from bangladesh i have a bs in economics and an mba both from universities in bangladesh i am working at a retail bank branch as a universal bankercustomer service officer for years now the work life balance is horrible with me being out of home for work from am till pm five days a week office is from am till pm i want to totally leave the financial industry banking insurance financial institution and anything related to finance i am at a point in life that due to personal circumstances of having a fulltime job and caregiving i cannot afford to spend the time and money on a bachelors or master is degree at best i can do an online certificate course like the data science certification from google there are not many jobs in data in bangladesh and those that are only allows those with bachelors in cs to apply for noncs graduates you only get to be an mis analyst doing all the excel work and building report presentations my aim is therefore to aim for remote online data science jobs based in foreign countries that i can do remotely from bangladesh i am also looking for something that has a careertrackcareer progression now i was wondering are there any careertracksoccupations in the world of data that i can realistically switch to right now or i can switch to with a certificate ps by the phrase world of data i am referring to careers in data science big data analytics excel or anything related to data i hear that careers in data have huge demand and low supply of talent and it pays decently and has great worklife balance so that is why the interest also the key word here is realistically because there is no point in spending a thousand usd which is a lot in my currency for a course and certificate and spending hours and then finding out that my resume will be screened out the moment it is sent because i do not have a degree in cs,given that i have a bs in economics and an mba what careers in data if any can i realistically switch to with just a certificate program,is it worth getting a phd in data science if i already have a job as a data analyst
643,while i do not have formal training in data analysis i have been charting marketing and other internal performance data for my company with success i have working knowledge of pivot tables and basic analysis this week my boss asked me to start running reports and analyze some new types of data to increase performance this is where i am stuck i have compiled the data in to basic reports but i cannot figure out the best way to chart and summarize the information in a way that allows action to be taken are there resources online that i can use is anyone here maybe willing to point me in the right direction anything would be awesome for clarification the basic idea of the reports are we provide multiple levels of service higher tiers can service lower tiered customers but this is inefficient and much more expensive i have the occurrences broken down by date showing when we have used higher tiered assets for lower tiered incidents i also pulled reports showing all instances of lower tiered customers so now i can see out off instances over month we used higher tiered assets to service lower tiered customers times i am trying to somehow chart this so we can see possible trends and quantify efficiency somehow,just cannot figure out the best way to breakdown some data,looking for a data analytics tool
644,recently i have had a few datasets where it is not really feasible to classify all of the responses open text but a pure clustering methodology only works on about half of the responses is there a method that combines classification with clustering what would be ideal is for me to use the wss error to identify the of clusters and then go into the data and code responses into one of each of the categories finally use those targets to help improve the ability for the model to cluster into the appropriate groups are there any papers on something along this method that i could read or does anyone have experience doing this,classificationclustering ensemble method,best way to cluster data
645,machine learning has been possible partly due to the accumulation of data and within that data an important step is that of data validation may it be a data warehouse database or data lake migration all require data validations it mainly encompasses comparing the structured and the semistructured data right from the source to the target and subsequently verifying that they match correctly after every step in the process the data validation tool by google looking at the importance of data validation google recently released the data validation tooldvt this tool will primarily function as an opensourced python cli tool that would provide an automated and repeatable solution for the process of data validation the researchers have claimed that this tool would work in different environments with brilliant accuracy the framework that was equipped for this tool is the ibis this would act as an intermediary link between the numerous data sources like bigquery cloud spanner and so forth min read github ampxb processing img mohzuwmakci,google opensources its data validation tool dvt a python cli tool that provides an automated and repeatable solution for validation across different environments,is google data warehouse the right tool for this
646,does anyone in here have experience with image transformation networks i am working on mononuclear depth estimation and after reading plenty of research papers about what others are doing i am honestly surprised that their networks converge at all to me it looks like the commonly used ssim loss on a waped input image can only backpropagate gradients for pixels that were adjacent in the warp source image that would suggest that unless your training images have large continuous gradients training can very easily get stuck in a local minima btw that is exactly what i see when trying to replicate depth from videos in the wild for very small offsets between the target image and my warped source image the gradient will backpropagate through the bilinear coefficients and it will snap in place or if the training image has large gradients then throughout the entire gradient the color of the pixel that is closer to the correct location is more similar in color to the current pixel so again the bilinear coefficients carry the knowledge forward but for objects with uniform color and sharp borders eg a black plastic chair the ssim loss never backpropagates to affect the warp target location meaning the estimated depth is never updated,gradient for image transformation networks,how do you deal with missing values in a d image
647,hello i am a computer engineer and for one of my projects is ai detection for crime scene evidence analysis and for me to do that i need a photo or video datasets of crime scenes i tried searching everywhere i cannot find any database of crime scene photos does anybody know of anywhere i can find some photos or it forensic competitions that have such datasets i need it urgently please help a professor suggested using kaggle however i could not find anything plus i am not sure how i can use it the dataset does not even have to be real i just need anything to start working on my project thanks,crime scene datasetphoto and video database,looking for a crime scene dataset
648,hi i have a set of about million objects defined by features each the features are a mix of numeric and categorical variables i would like to cluster these objects with an aim of seeing whether particular qualities of these features group together in a way that enables me to better understand the population of objects trying to work out what the right clustering approach would be both from the perspective of yielding the most useful and reliable clusters given the nature of the data as well as from the perspective of performance since i understand that certain types of clustering methods ie hierarchical methods can be computationally very expensive i am running a relatively humble cloud based spark cluster any advice would be appreciated i am not up to speed on the latest thinking around big data clustering thanks,clustering techniques for exploration of large mixed data set,what is the best way to cluster data
649,hi all for the first time in my life i have reached a point where i do not know what to do i am a beginnerish in the data science industry i have a master is in computer science i completed a six month data science bootcamp did several ds projects on my own some kaggle competitions completed a four month internship at fellowshipai and worked as a ml engineer for two months building a recommendation system for a jewelry company i decided to leave my job after i had a major disagreement with my former manager and i thought i would land another job easily but i did not i almost got into an ai residency program but failed in the last round and then covid arrived and everything collapsed now i do not know what to do next should i go for a phd should i wait and apply next year for another residency should i keep applying for jobs i apply for jobs a week and nothing so far or is there something else that i am totally missing everything is an option now but i think i am stagnating and not moving forward as i said in the beginning i do not know what to do,what to do,i am a year old and i do not know what to do
650,hi i am the owner of kilos a search engine that indexes listings vendors reviews and forum posts from online black markets i am publishing some of the data i have scraped to see if anyone can reach any interesting conclusions from playing with it i have quite a bit more data which i will be posting in the coming days right now i have currently indexing forum posts listings vendors and reviews from markets and forums you need tor to download the dataset once you have the tor browser bundle installed you can find the data set here the data is in the format sitevendortimestampscorevalue_btccomment site vendor and comment are strings site and vendor are both alphanumeric while comment may have punctuation and whatnot line breaks are explicit n in the comment field and the comment field has quotation marks around it to make it easier to sort through all the data uses latin characters only no unicode timestamp is an integer indicating the number of seconds since the unix epoch score is for positive review for neutral review and for negative review value_btc is the bitcoin value of the product being reviewed calculated at the time of the review there are some slight problems with the data set as a result of the pain that is scraping these marketplaces all reviews from cryptonia market have their timestamp as because i forgot to decode the dates listed and just used as a placeholder cryptonia reviews score variable is unreliable as i accidentally rewrote all scores to on the production database to correct for this i rewrote the scores to match a sentiment analysis of the review text but this is not a perfect solution as some reviews are classified incorrectly eg this shit is the bomb might be classified negatively despite context telling us that this is a positive review there are a decent number of duplicates some of which are proper eg thanks as a review appears many many times and some of which are improper detailed reviews being indexed multiple times by mistake anyway if you can make any interesting inferences from this data let me know i am always looking to improve kilos display of datas right now i am working on using polynomial regression to detect when vendors have padded their reviews with fake positives to improve their listing in search results i would appreciate help with this if anyone can offer it,mb set of reviews from online black markets,looking for feedback on my project
651,hey everyone ampxb tldr if i built a source code search engine based off commoncrawl would you use it and would you share in the cost of itthere are real costs the cost to host the data alone is kmo i made a poll to see if people would use it ampxb not sure if people here are familiar with commoncrawl im sure alot of people are but its a copy of the entire internet every month i have known about it for a couple years and played with it but the problem is the costtime is too expensive like basically you have to pull down these super compressed files uncompress them and then search them and delete them because its like kmo to store terabytes the compute power required to crawl all the data too is time consuming and expensive i had a problem i was trying to figure out last night and realized i could use the commoncrawl data but was running back into the same cost issues as before but when i thought about it of the usecases are basically the same thing uncompress the data search the data and get results instead of all of us rebuilding the wheel we need access to the uncompressed data and to query that data ie search i found a cheaper storage hosting wasabi and i can host the uncompressed data for mo i can run a crawl every night for days that people can put whatever they want into the crawl for another mo for the ec instances ampxb what could you do with access to the data say you wanted to find idk every wordpress site alive you could do it you wanted to find every link to an xslx file you could do it you wanted to find every law website on earth you could do it i mean there are alot of usecases ampxb so the question is will people support this project i made a poll if you want to work with me on it lmk because one way or another i want to do this,making commoncrawl data truly searchable,is there a better free or very cheap way to store large amounts of data
652,i am and have a bba and a library and information technology diploma currently i work in academic admin and have my eyes in either moving to a junior business analyst position or one of their data analyst positions i meet all requirements for the data analyst position and most of the requirements for the junior ba one the one manager really wants me but the other hiring manager does not know me so a more qualified candidate got the job i am hoping another opportunity will come up in one of these soon i am going back to school for a bsc with a major in computer science after transferring my bba courses i will need about another years of school i am wanting to transition because my original idea of wanting to be a librarian is not really panning out while it is a field i am passionate about there are very limited job opportunities many of which are low pay i also feel like the work of a librarian is not actually something i would enjoy long term this is where i feel like data science comes in i enjoy working with data and the idea of turning data into good information is appealing to me i guess i like the neutrality of it and i would like to work in a position that involves more problemsolving however i worry that i am not smart enoughgood enough at math to do well i really enjoyed stats during my bba but in high school i failed precalc to be fair i feel that was more so because i did not show updo the homework and when i took it online selfpaced the next year i got an a but due to some bad experiences with a math teacher as a kid i feel like it is not something i can be good at or enjoy do you think there is any chance for someone my age to learn the skills needed for data science i worry that because i am just starting to learn programming and relearn math it is too late,do you think it is too late for me to have a chance in data science,is a data science masters worth it if i already have a job
653,i just completed my high school and i need some advice on which degree to take right now i have an offer from a college to do a bachelors in data science for years or should only do a year computer science degree and then do an ms in data science because to to do a year program i would have to wait for year due to some personal issues is a year cs degree more valuable than a year bachelors in data science or are the skills you can learn after a degree more valuable than the degree itself in the eyes of the recruiters how is the field of data science right now is it too saturated thank you so much for your time and help it really does mean a lot,heyy i am planning to do a years bachelors in data science should i do that or do a cs degree,how important is a degree in data science
654,i currently have an assignment where i have to use a specific optimization algorithm in this case it is a particle swarm algorithm on a dataset to estimate the parameters of some function that aims to predict the data i was wondering if anyone knows of a dataset with the following attributes is relevant to physics particle physics in particular would be swell includes a function that aims to predict the dataset with some number of free parameters to be optimizedestimated ideally contains the true value of the parameters to which i can compare to the optimization of my algorihm note that i am aware that i could simply use a monte carlo method to generate data myself but the aim of the project is to use real data from outside sources thanks in advance and apologies if this is the wrong place to ask,datasets relevant for physics that can be used for parameter estimation,how to calculate the optimal parameters of a model
655,so i want to create a word predict rnn that i am going to feed with the books from one authori want to capture his style so when i started thinking about the process i got confused by the following would training a rnn with one book at a time then saving it is weights for the next book and so on be the same as loading the same rnn with all of the books at onceif not which do you think would be better and why i am learning mldl since january and this question never occured me really it is probably very intuitive but i cannot get around it thanks in advance,a question about text prediction rnns,question about rnn
656,just to give a bit of background i did my undergraduate degree in mathematics heavily leaning into statistics computational mathematics landed myself a graduate job at a top accounting firm where i am currently on the verge of qualifying my original plans were to push even deeper into finance a move which is well trodden in the uk as several of my colleagues have already done this but to be honest i am a nerd at heart and i miss all the maths i used to do i have started refreshing myself on python and r as a starting point so from what i understand you have data scientists data engineers and data analysts and from my background it seems becoming some kind of data analyst is probably my best bet and honestly the one which i feel like i would also enjoy the most i have tried scoping out some job search websites and it seems like an accountant who can do data analysis is actually fairly niche on the one hand this makes it more difficult to find a suitable role on the other hand the salaries quoted in postings that specifically request an accountant with data analysis programming skills seem to be really good wanted to ask for some general advice or guidance please still a bit unsure about what my next moves should be,uk accountant wanting to move into the data science space any advice appreciated,is it worth getting a masters in data science if i already have a job as a data analyst
657,this is a part video series that takes you completely through arima forecasting in r from the beginning to the very end this is a complete data science forecasting project that uses atmospheric air composition data and it then looks at so sulfur dioxide levels and predicts future so amounts based on the data you will see that the analysis and forecast are thoroughly tested for maximum accuracy this entire process includes all the code and lots of helpful commentary on why data scientists and data analysts need to thoroughly test their data and it even tests several models including the auto arima models and default settings used by most reporting applications and then test for the correct fit of the data part exploratory data analysis part decomposition of the data taking seasonality trending and cycling into account part autocorrelations and choosing the order of the arima model part fitting the arima model part testing the arima model with a holdout set part further testing and final model selection,instructional arima forecasting in r how to do a complete thorough and very well documented forecast analysis,how do you handle outliers in your model
658,i am new to data analysis and data science i am trying to learn with a little project i have the data on the results of an emailing marketing campaign across years of time i have already calculated indicators of performance and everything is stored in the same file i would like to evaluate this marketing campaign is it getting more or less successful how are the different indicators affected by specified variables what type of emails attract more clients which key words in the campaign title attract more engagement i would like to use python and r since i have already used both in a few projects where should i start what other questions should i be asking should i be doing a segmentation predictive modelling,help me with how to start cause i am thrown in different directions,data science and marketing
659,sometimes you have a propositions or conclusion that is very well justified but you arent able to justify it though mathematical algorithms for example hamilton is battle plan for the battle of yorktown which involved spies and waiting for the british at chesapeake bay his logic behind that hunch was on spot but he has no statistical justification to back that up in other words you could see his plan adds up and works out to win the battle so its clearly very justified but it could not be justified through numbers and algorithms so my questions to you data scientists of reddit is have you ever figured out a conclusion or a proposition and had a knockout justification for it but got frustrated because you were not able to find a justification through mathematical algorithms that even came close to doing your proposition justice,data scientists of reddit how many times have you figured out a conclusion or a statement that which you had very strong evidence and arguments for but you were not able to translate it into numbers,is it just me or does data science seem like a bubble
660,hi i am very new to ds and am not even sure how to ask this question i would like to predict categorical variable binary or ideally even more from time series data to make this more concretely say that i have two events event a and event b for each event i have time series data of the probability of each event happening so at some point t i would have a probability of event a happening and at some point t i would have say a probability of event a happening then at some point tn i know the outcome of the experiment ie does event a happen or does event b happen i would like to know how can i predict which event will happen based on the fluctuation of the predicted probability hope that makes sense again i am very new to this so i am not even sure if i am wording this correctly,how to predict categorical dependent variable from time series independent variable,how to deal with missing data
661,hi there ampxb i have recently started testing google optimize for ab testing and am very impressed with everything until i started running an experiment live ampxb i only have experiment setup and all it does is updates the hero image by replacing it with another i am trying to do a comparison of goal conversion using hero a vs hero b ampxb my issue is that when the site loads the image update is quite visible i have installed the anti flicker script which is recommended by google optimize additionally my gtm script has top priority within the document ltheadgt tag ampxb any recommendations on what the issue could be ampxb thank you,issues with google optimize visible content update,google optimize is not showing up in google analytics
662,for a little context i did mathematics in leiden the netherlands and am now thinking about a new job i have worked for years in the offshore industry and now for a year at a bank i found a bank to be an amazing source of data but having really strict it and data regulations for good reasons the offshore industry had a lot of really enthusiastic technical engineers wanting to build awsome stuff but had a really old fashioned it infrastructuredata landscape the models you produce do not always have a very tangible result but can be really interesting your experiences are probably based off of a sample of one your company but i would be really interested to hears stories from the hugely diverse range of companies and industries you all work in,current data scientists how would you describe being a data scientist in your current industry,data science in the financial sector
663,if at all how do you use twitter for learning purposes i am not a social media user but i finally decided to create a professional twitter to be used only for learning growth professional development i started following some people that i knew did work in areas of interest which led to more and more suggestions i am currently following people all of who seem to be very active in sharing work techniques visualization etc i am at a loss on how to use this app how do you extract anything meaningful from it there is no way i can read through all the posts short of spending all day scrolling through it and by the time i have reached the bottom there are more tweets it is been hours and i am already exhausted i definitely want to try to make it work because i have already found many missed and upcoming opportunities that i would not have found otherwise and i can see that people are forming genuine professional relationships in a way that you cannot do on linkedin,learning from twitter,how do you use your social media data
664,sometimes i get test accuracy of and sometimes i am getting so i cannot understand how can the results be so extreme when i am literally not changing anything i am compiling the same python code multiple times edit i am using the basic classification code available on the official tensor flow site but instead of using the fashion mnist dataset i am using my own dataset import scipyio import numpy as np import matplotlibpyplot as plt import tensorflow as tf from tensorflow import keras mat scipyioloadmat amatlabmat mat scipyioloadmat amatlabmat training mat notraining testing mat notesting class_training matclass_training class_testing matclass_testing training npascontiguousarraytrainingt testing npascontiguousarraytestingt model kerassequential keraslayersflatteninput_shape keraslayersdense activationtfnnrelu keraslayersdense activationtfnnsoftmax modelcompileoptimizertftrainadamoptimizer loss isparse_categorical_crossentropy metricsaccuracy modelfittraining class_training epochs test_loss test_acc modelevaluatetesting class_testing print notest accuracy test_acc,voltatile test accuracy,why does matlab always perform worse than caffe
665,i have been a lurker here for quite some time but the time is coming when i will need to make a decision about which career path to choose i am finishing up my undergrad with next year being my last i am dual majoring in computer science and economics i have been a part of a few projects and am now interning at a large company as a qa engineering intern originally i wanted software development but after they told me they no longer had positions open for the software development team i decided to go with this just to get my foot in the door regardless i am loving everyday of it my dilemma is that after this summer i may have the opportunity to apply for their program for graduated students to somewhat test drive a full time role i would probably apply for software development but i am also interested in data science especially after taking my advanced level econometrics class in which i wrote an entire statistical analysis on income inequality in the us i enjoy collecting data and playing around with it to discover what it can tell us i think my ideal plan would be to get a full time job as a developer and go to school part time and get a degree that would allow me to combine my love for cs econ and my curiosity of data science i know of a few good data science programs but i am afraid i may not have the grades for uc berk cmu etc could anyone recommend some options or paths that i could consider i was looking at a couple programs specifically boston university is ms in statistical practice and northeastern university is ms in business analytics does anyone have any sort of advice regarding these programs whether or not they would put me in the right direction or not or even if data science is right for me thanks for your time guys and sorry for the long post,is this the right field for me,i am a year old and i do not know what to do with my data
666,i am a software developer but my passion is data analysis and machine learning i have been learning and practicing these skills in my free time for a couple of years now currently i am working on a little project analysing my job is company database trying to gather some information on correlations between different types of objects that we store i have done some regression analysis on easily labelable data with not much success most likely because i had to filter out majority of the available data that could not be labeled now i am trying to work with a much larger dataset however assigning relations between objects is something i have been scratching my head and googling for a while with not much success to expand the size of the dataset i am gathering the features that i have chosen have one to many relationship within the dataset so each object could have to few category labels assigned to it and there is no way to prioritise them as all of them have comparable importance each of these parent objects have a long list of related child objects each of which also have one to many relation to the same category along with some metrics which i am planning to use for training my model here is a simplified and generalised example of source tables i am working with parent object table parent object idcategory category a category b category c category a category d child object table child object idparent object id fkcategorymetric category emetric value category bmetric value category emetric value category ametric value category bmetric value the categories in both parent and child object tables are the same category where category a of a child object equates to the same category a of a parent object as my knowledge in this area is still quite limited i am struggling to figure out what types of algorithms would suite this problem and how to structure this data in a way that would allow me to either run some regression analysis trying to identify what category correlation results in highest metric value or trying to cluster that data to find relationship between what child category groups have stronger relation to what parent categories it is quite hard searching for solutions or advice to this problem maybe my definition of it is too vague but also it is not something i encountered in any of the courses or articles that i have read so any help or suggestions about what to do or just pointers in the right direction is greatly appreciated thank you very much in advance ps i hope this does not go against rdatascience is not stack overflow rule as i am just looking for general guidance or pointers for how one could approach a problem like that apologies if it does tldr how could i approach analysing relational data with common category labels where each object can have to few categories assigned to it,clustering and regression on relational data with multiple and varying number parameters,looking for advice on how to approach this problem
667,hello everyone im years old and will be going into my rd and final year in university in the uk im majoring in accounting with a minor in law but after much soul searching ive decided i want to be a data scientist originally i wanted to take a gap year before i went to university so i could decide properly what degree to pick but i lived in an abusive dysfunctional household so my parents picked my degree for me and forcedcoerced me to go to university even though i did not want to now that im older amp no longer under anyones control i wonder how can i go about becoming a data scientist as i know that im a disadvantage because i do not have a stem degree ive also been teaching myself python and im starting to really like it any advice would be appreciated thanks,how can i successfully pivot from an accounting amp law degree to becoming a data scientist,advice for a career changer
668,i have been following this guide and i came across a point that confuses me so the author states that there are two assumptions we need to make about the cost function in order for backpropagation to be applied the first one confuses me gtthe first assumption we need is that the cost function can be written as an average c n _x c_x over cost functions c_x for individual training examples x gt gt where the cost for a single training example is c_xyal gt gtthe reason we need this assumption is because what backpropagation actually lets us do is compute the partial derivatives cxw and cxb for a single training example we then recover cw and cb by averaging over training examples screenshot of the excerpt so i understand why the cost function can be an average of c_x the cost for individual training samples that makes total sense to me but the part where i am confused is when he says that back propagation only lets you compute the partial derivatives for a single training example does someone know why this works like this the following statement also confuses me where he says gtwe then recover cw and cb by averaging over training examples how does he find the partial derivatives with respect to the weights and biases by averaging over the training examples,help understanding one of the assumptions for back propagation,why do we need to use partial differential equations for training
669,i have been working as a data amp compliance coordinator for a year now in our marketing department though i do not have a relevant degree surrounding data analytics i am willing to take courses and training to get myself up to speed my job role usually requires me doing the following work with it teams stakeholders and campaign organisers to determine organisational goals clean and prune data to discard irrelevant information analyze and interpret results using standard statistical tools and techniques pinpoint trends correlations and patterns in complicated data sets identify new opportunities for process improvement provide concise data reports and clear data visualizations for management design create and maintain relational databases and data systems triage code problems and datarelated issues support investigations into gdpr breaches where required i have a good understanding of excel and power bi and our master database we use at work is microsoft dynamics ax which i am confident in using as i have only been working in this field for a year my manager is not interested in training me any further and i worry there is no progression in my role can anyone advise what would be the best next steps to take i am f from uk so any advice on training courses maybe in london or anything similar would be great much appreciated ampxb,best training seminars online courses to take for data amp gdpr,how do you deal with bosses that do not understand data science
670,hello i have a dataset containing around observations imgsoziul it is a dataset collected via a survey each row is a dataset filled with information re diet habits physical activity the fact of taking supplements or not personal goals type of medication if any taken and so on majority of features are categorical aka factors except one item_total which is the amount each user spent on some product my objective is to cluster these questionnaires based on the available features i use the r language for performing this task my current approach is i calculate gower distance via daisy package aka dissimilarity matrix gowerdist lt daisydf metric cgower where df is the dataframe i use agglomerative hierarchical clustering agglclustc lt hclustgowerdist method complete i find the optimal amount of clusters via silhouette method i would like to check other clustering techniques out keep in mind that the features are mainly factors so kmeanlike techniques woulds be underperforming if not impossible at all to apply any suggestionssources i would need to check out thanks in advance v,cluster categorical data survey data,how to cluster a dataset
671,the purpose of your content is not to feed the content beast or the empty space in your website but to reach connect and convert your target audiences to your business as content marketing and intentdriven micromoments evolve defining your organization is buyer personas and then strategically creating content that is aligned with one or more of those personas provides a path towards the most effective content the main reasons for this strategy are that you can create content that is written for specific audiences tailored for them and their situation highly tailored content will perform much stronger with the target audience than generic content as you speak their language to their needs you can evaluate how you are connecting satisfying and converting individual personas and compare them to other personas or the site average once you are using personas for your content creation the next step is seeing how the personas perform and gaining actionable intelligence from those metrics to see how your buyer personas are performing in google analytics we are going to use a littlediscussed featured called content groupings to get us there keep reading to learn more about measuring your content effectiveness through buyer personas and content grouping in google analytics,aligning buyer personas with content groupings in google analytics,how to measure the impact of content creation on sales
672,do not have anything else lined up this summer and it pays well it is getting late for internships and i feel like maybe the work experience and quantitative element of the job might look better than nothing i know they are also offering the data science internship next summer and this could be a foot in no idea why they offered this to me they said they really liked me for the software but i did not quite make the cut so they emailed me about a month after with this should i just take it for the work experience or should i chance it and keep trying to get a data sciencecs type internship,got offered acturial internship at fortune company in place of data science internship applied for advice needed,is it worth taking a data science summer internship
673,i did a double major in computer science and information systems from a not so prestigious university as compared to those locally i then proceeded to do a bootcamp in data science from the more wellknown institutions due to the lack of substantial projects back in uni as of right now i am on a job hunt and while doing so i have discovered so much about how i lack the skills to even take up an entrylevel data scientist job i refuse to believe any data scientist who convinces me that you dont need indepth knowledge of statistics to succeed in the field i have not done mathematics and statistics in a long time however i am also not one that is afraid of hard work i could put in a lot of effort to learn the math and stats to be a better data scientist but will i ever be a better data scientist despite all that i have been thinking about data engineering instead not because its the secondbest option but because i am interested in programming engineering in building something and being part of something i know how difficult it is like i said i am not afraid of the hard work the true dilemma i have right now is all the time that i were to spend on learning math and stats and all the other stuff to be a data scientist and be better at it i could channel that time and energy towards become a data engineer and being better at that instead i could also leverage the knowledge from my degree and data engineers do know some level of ml which i believe is at the level of the bootcamp i did i feel that the bootcamp has put this false expectation in my head that being a data scientist is easy and possible in months when its truly not i am seeking advice from professionals in this field for a long time and to confirm this suspicion i have that i would indeed need much more than just what a bootcamp could offer and that perhaps data engineering is a more realistic path,seeking honesty about future in this field,is it worth getting a second bachelors degree
674,i am buidling a handwritten word recognition system using cnndblstmctc i have trained the model on the iam dataset about words where i split the dataset train validation and test the network trained for epochs on batchsize now i have gotten a pretty consistently descreasing training loss but the validation loss has been pretty unstable during the training see attached graph ampxb the average editdistance is about and the accuracy is number of words it got perfectly on the test set while the accuracy is not very high meaning the words are not perfect the results it gets on the test set are pretty good it is mostly off a character or two which i consider an acceptable result considering the problem and given it is my first time doing something like this my question is should the behaviour of the validation loss worry me given that the predictions the model gives are pretty good i suspect that the validation set is too small and that is the reason i am getting these results but could this mean there is a different problem with the model,unstable validation loss,question about batch normalization
675,digitmg is best training institute in machine learning course in hyderabad offers handson practical experience on live machine learning based projects and in depthunderstanding of machine learning along with assistance the machine learning course hyderabad you will be trained under the best industry experts with a record of over students trained from the digitmg machine learning malasia popular machine learning modules that you need to learn for batter job opportunities this course equips the student with a strong foundation in python r and r studio specifically the use of r studio to develop statistical software is highlighted the student then develops algorithms for skewness and kurtosis box plot hypothesis testing parametric and nonparametric test correlation analysis linear regression multiple linear regression logistic regression multiple logistic regression supervised machine learning knn naive bayes decision tree random forest ann and svm enabling unsupervised learning and reinforcement learning with python and r is also dealt with students are trained to develop compelling data visualizations using python and r this is the most comprehensive course on machine learning with python and r,machine learning course hyderabad,r vs python for machine learning
676,hey guys i studied chemical engineering at university however i did a few internships regarding mathematical modelling and data analytics and i enjoyed it now i am applying to entry level jobs in data analytics and data science and i have a few questions given that i did not study data science would they expect me to still be able to answer questions concerning data science specific ie types of machine learning models since the job descriptions i am applying to say they require any stem degree my first company is a consultancy so i am not sure if that changes anything how should i prepare for these interviews should i study data science concepts and statistics etc as well as preempting questions on how i did my internships which is more important in your opinion do you have any other advice for someone in my position any help would be greatly appreciated,advice for data science interviews for someone who studied something else at university,i have a few questions for you guys
677,i just completed my bs in healthcare business i know i want to work in the realm of data analysis in this industry i have great internshipwork experience for someone coming out of college but i do not have any technical experience whatsoever my plan so far has been to take the gre and do well my undergrad gpa is pretty mediocre due to my own laziness but i know i am good and standardized testing and apply to some online data analytics certification programs that are about credits that way i can try to find a good entry level job in the area i want next year would the gre help in my chances of getting accepted to this type of program is there an alternate route i am not aware of any feedback is appreciated thanks,how helpful is the gre,data analytics bootcamps
678,hey i am currently finishing up my math phd i have realised academia is not for me so i am looking at industry in particular data science ml positions i am currently trying to work on my programming skills having done a bit at undergrad but not so much recently as well as my stats skills and learning about machine learning data science learning python seems like the most obvious first step and i have almost finished the machine learning az handson python amp r in data science on udemy but i am not finding it that useful in terms of picking up indepth knowledge i find the exercises a bit too copy and paste is dataquest a good next step the syllabus looks pretty comprehensive and i have heard that the python exercises require you to make the algorithm yourself before using premade packages which sounds ideal for really understanding them i expect being able to properly explain amp compare algorithms would be a massive plus at interview also is it also worth learning another language in addition to python c seems to appear fairly often in job ads and i feel like having recent experience in both a lowlevel and a highlevel language will boost my programming skills amp my profile but on the other hand i feel like i may be better off just focusing on python so i can build a portfolio amp get a job sooner thanks for reading and any input would be appreciated,pure math phd transitioning to data science,i am currently in a data science phd program and am considering a career switch to machine learning
679,hi all i did a bs and ms in biomedical engineering and been working with medical technology companies as quality engineer and regulatory specialist for the last years ive been considering switching tracks and becoming a data scientist i was wondering if a masters is required or if there are any certifications i can complete thats equally valuable as the end goal is to find a job as a data scientist i want to make sure i pick the shortest and most efficient path to get to that i would really appreciate some advice on what i need to make myself a competitive candidate to find a job in that field thanks a lot,do i need a masters to break into data science field,data scientist to data engineer
680,if i sound like a complete novice please bear with me i am trying to extract keyvalue pairs from invoice pdfs such as invoiceto addressofvendor tablesthis seems tough to implement and receipt images such as vendor subtotal date etc i have tried to ocr the reciepts and nonsearchable pdfs while i am getting good results with tesseract spacial information such as for tables is getting jumbled up how do i find the keyvalue pairs what could be the dataset for the machine learning model would named entity recognition be enough from unstructured text i think with only nlp i might not be able to detect tables i am trying to construct a general purpose pipeline so i can use a minimum of rulebased matching or templatematching i am open to any more ideas,invoice data extraction,how to deal with missing data
681,i have to find the eigencomposition of matrix a ampxb a ampxb with nplinalgeiga i get the vector of eigenvalues and a matrix of eigenvectors  eig_val v eig_vec ampxb i am supposed to prove av_i_iv_i but i do not get the same on both sides how do i calculate the original matrix like a vv  is supposed to be the diagonal matrix but again i get the wrong answer ampxb my code for av_i_iv_i aeig_vec which gives array eig_valeig_vec which gives array my code for a vv eig_vecnpdiageig_valnplinalginveig_vec which gives array ampxb can you please tell me what i have done wrong and if you have time show me the correct way of doing this,please help eigencomposition,how do i calculate the vector of a column in a neural network
682,gslides is a wrapper on top of the google slides amp sheets api that simplifies the creation of charts amp tables in google slides amp sheets with python while providing flexible customization options the package is perfect for data folk who need to create elegant company branded visualizations for stakeholders who are comfortable in google slides if interested checkout the following full docs a notebook detailing basic usage a notebook detailing advanced usage heres a sneak peak of what you can create ive been testing this package for a couple months worked out some bugs and have integrated it into my workflow quite nicely if you have any comments questions or bugs feel free to reach out to me cheers,gslides programmatically create charts tables and slides in google slides,i have been working on a google analytics package for years and im finally ready to give it a go
683,i am not a data scientist by any means i mainly consider myself a data engineer who used to work alongside very talented and smart data scientists this is something i have been saying for the past years ampxb gtwith the increase of ui choices such as dss datarobot ho and even pure cloud solutions such as azure ml the emphasis on coding skills python r is decreasing there is a decreasing reason for a company to have data scientists code everything from scratch with numpy scikitlearn etc when models can be built with a simple click of the button on these ui tools the bar to entry to be a data scientists is also lower with the less need to be proficient in a programming language thoughts comments disagreements are welcome thank you,is my overall perception of ml ai accurate tools and languages,is data science a dying field
684,i have been doing analyticsds for a while now and i do not know why but since the start of the pandemic i am beginning to question why i liked ds in the first place i am even in the middle of earning my ms in analytics i have been in this field for more than half a decade now the compensation in my current job is really good but dealing with the analytics immaturity politics hype and bullshit in every stint i had makes me want to explore other jobs not related to ds i always have this impression that ds would always be second class citizens since the business is the primary driver of most companies i cannot imagine being in this kind of subservient role for the rest of my life i have always been a tech guy more than a stats guy and it shows in my stints where i was the one who implemented automated processes and ml algos i am more fascinated in implementingengineering side of analytics this made me wonder why i am always in a ds position i know that ds could mean a lot of things but again i do not know i think i am just tired from the bullshit taking some days off work did not help either and just made this thought more apparent every now and then are you guys experiencing the same thing sorry for sounding off as if i do not know what i want to do in life but i think that is where i am heading,identity crisis burnout as a data scientist,is data science worth it for me
685,the experiences i have seen have the following common themes managers know nothing about data and think that machine learning and statistics is going to end world hunger an exaggeration but given how outsiders sell their expertise it does not seem farfetched they hire an analyst to help with the process in some way when something goes extremely wrong the contractors blame it on something like noise in the data i am not in this situation anymore but this seems to be a side of the field that is rarely mentioned online what does one do in this situation i have found that trying to point out flaws in plain english and warning team members about flawed methodology to be fruitless,when you are not a manager what do you do about external contractors who are using poor methodology,how do you deal with bosses that do not understand data science
686,hi ampxb long story short i am an inprogress data scientist getting my phd in biostatistics and epidemiology looking to swiftly exit the academic field i have received many personal recommendations with both my skill sets and interests in becoming a data engineer once i graduate i would like to use my phd offtime summers and dissertation to upskill towards this end as much as possible i also had a close family friend and career advisor suggest i obtain a cloud data engineering cert for several reasons ampxb it would allow me to train field specific skills in a shorter amount of time it would give me a credential to start working on projects with local businesses etc to boost my portfolio ampxb tldr considering a cloud data engineering certificate should i do it which one what is the best way to prepare ideally given a whole lot of free time this summer ampxb thanks,cloud data engineer certification recommendations,data scientist to data engineer
687,im currently a sophomore in college and ive been applying for data science intern positions at various companies i had my first hirevue interview today with a finance related company and i was doing well at first but there were two questions which i struggled with and i think my answers may have cost me the internship these questions were briefly list some python packages or libraries you have used and why each was needed to obtain your objectives when would you use a linear regression how would you go about building one and what would you look for to decide whether it fits the data i dont know why but these questions had me stumped i know theyre not that complicated but the topics are just difficult for me to explain for some reason i was just wondering how you guys would answer questions like these as i dont want to make similar mistakes on future interviews,how would you answer these interview questions,data science internship interview questions
688,hey guys happy friday i wanted to share a link because i have got a lot of folks on reddit and fb asking me why the accuracy of their neural network is either low or its really high but not giving them the results they are looking for in their modelling i have made a short vid on building a deep learning model from scratch but also demonstrate why looking at only accuracy could be dangerous also learn how to fine tune some hyper parameters to improve accuracy and test results btw i am not monetizing this video nor looking to do so simply adding it for people to learn hope it helps here it is for those interested,deep learning model higher accuracy is not always better,i built a neural network from scratch with fb ads and facebook ads
689,hi all ampxb about years ago i took a career sidestep from an oilgas science role to data science with a data analyst stepping stone in the middle i am now a senior data scientist with a midsized medical technology company in their rampd division ampxb however there are five slightly concerning issues with my current rolesituation i am the only formally titled wouldata scientist in the company there are other is who easily have the knowledge and experience to be one but are put under the istats umbrella the company is ds capabilities are very much in their infancy but one of their key focuses is to change that it is the kind of company that does not seem to know what a data scientist does although thankfully they have given me a huge amount of flexibility and autonomy to get things done the term isenior in this company appears to be scaled differently to other companies i have been in i think everyone who has come in so far has at least a isenior role i never had any formal data science learningtraining and most of what i have learned has been on the job or what i am picking up from esl and prml i come from a mathsnatural sciences background so i like to think i have the mind to pick dsml concepts up quickly ampxb so far my role has been more of a data engineering one and i have spent the past year consolidating the company is data getting teams to move away from storing data in spreadsheets and coordinating with the it department to set up a data warehouse which has so far been very successful i am now in a position to start analysing data and building models to help the business although i am a little concerned about my lack in breath of knowledge of dsml ampxb i am really enjoying the job and i have no plans to leave but i always like to have an escape route and i worry that i have managed to oversell myself into a senior ds role i feel like i am underqualified to transition into another senior ds role should anything happen to my role or the company and that my current de work has taken time away from my development ampxb so what is expected of a senior data scientist and what should i be focusing my development on for now should i be expanding my knowledgebase of modelling techniques or managerial skills or something else ampxb thanks,expectations of a senior data scientist,data science in the public interest
690,so i am currently learning r i have been interested in data science thus far inspired by a masters in econ however i have been offered it training assistance and am being asked to choose java c cobol casl ii or spreadsheets it looks like the next best thing for me to learn would be java in regards to it being easy to learn and overall useage leading to a good range of options whether it be it or data science not entirely sure if the two are mutually exclusive any strong opinions i have posted some of my reference links for how i arrived at java before the others java ranked at least on a spot for language to learn good read for different languages,being asked to choose which of these languages if any are good for data science,is it better to learn java or c for data science
691,i am not an analytics expert i leave that up to my clients to manage themselves but i just had a client message me with something weird they have two websites and site aaacom has a tracking id of ua for example verified in source on pages and it is under it is own analytics account site yyycom has a different analytics account and a different tracking id ua for example when viewing the analytics for site y of the results pages are correct and from that site but there are random scattered pages in the report from site a mixed in clicking in analytics to open the link takes me to the page on site a the page on site y does not exist how is this possible i am stumped here and not sure how it is happening or how to fix it i have verified all pages on both sites are using their correct tracking id is no redirects or anything weird like that are set either thoughts,pages from another website with different tracking id showing up in my reports,how do i track my yolo traffic
692,hi there i am interviewing for data analyst positions with a few companies i am a student who is not majoring in a traditional field like stats or math but i have taken comp sci classes amp courses involving coding i got an exercise to complete before my next interview and i am unsure of how to approach it it reads you are an analyst at company x compx is considering opening a new amusement park in the santa fe area which will be constructed in a phased method rather than paying an engineer to design a new roller coaster they have opted to replicate two of their existing roller coasters to populate the first phase of constructionyour task is to use data pertaining to roller coasters at compx is other amusement parks to determine the two roller coasters that will be replicated in the santa fe amusement park your manager would like a summary of no more than pages containing your recommendation and supporting logic in addition to the written recommendation your manager has requested that you send any code files or datasets that were leveraged to arrive at your conclusion i was also given a spreadsheet with fields including the speed breakdown rate etc of each roller coaster can anyone tell me what equations i could look into compare the different roller coaster models i just want to know where to start any ideas or suggestions would help,got an exercise for my interview and i do not know where to start,data analyst interview questions
693,in this post you will learn about convolutional neural networks and how to use them for classification problem the article is broken into parts present the dataset and the usecase and explain the complexity of the image classification task go over the details about convolutional neural nets by going through their inner meachanisms and the reason why they are more suitable to image classification than ordinary neural netwoks set up a deep learning dedicated environment on a powerful gpubased ec instance from amazon web services aws train two deep learning models one from scratch in an endtoend pipeline using keras and tensorflow and another one by using a pretrained network on a large dataset happy learning post convolutional neural network,understanding deep convolutional neural networks with a practical usecase in tensorflow and keras,how to train a deep neural network on a single image
694,when i am on the google analytics dashboard looking at the audience it shows the data of me on my clients site it shows the active user me on the browser desktop and on a mobile device however why does it not save the data for the audience reports once i am out of the amor webpage do i need to give it over hours for it to save all the data and then display the reports to me tomorrow i had difficulties from the start of this after getting my beginners google analytics certificate i have been trying to learn more indepth by myself to get the gist of it for example amor had a different tracking code so i updated all the php files with the tracking code i was given in my admin tracking info i had a problem with tag manager but that was solved by blocking adblocks on the site tag manager shows no more errors but two results of tag analysis global site tag and google analytics any idea what i have to do to i want to carry on my learning in google analytics before the next test advanced google analytics i want to learn more about the tracks and measures the success of any campaign analysis traffic visitors bounce rates conversions channels user behaviour etc all these factors help to improve the business,managed to get the google analytics tracking code working it shows data but,how do i track users who have visited multiple pages on google analytics
695,trying to attain a strong grasp of statistics i have less than a year left before i am forced to make a career switch so trying to stick to my regimen i started in udacity to learn the basics like standard deviation z score etc i studied engineering in uni but i honestly have not touched a math text book in over years i was pretty much done with calc in high school and i never took statistics frankly i am thinking of just doing a few more khan academy courses and udacity courses for basic statisticslinear algebra before jumping into other topics like machine learningdata science w python courses does this seem like a good idea i appreciate any advice,how much statistics for data science,is it possible to get into this field without a degree
696,hello i am an undergraduate student taking my first course in machine learning but i absolutely love it and i have been voraciously consuming as many articles and materials that i can find suitable for my level my class has gone over mlps so i wanted to try to implement one from scratch the resources i used included my class is lecture notes andrew ng is coursera exercise the mit deep learning lecture available on youtube and many miscellaneous articles concerning activation functions and cost functions in the end i came up with this github link it works sort of okay but i find that it does not perform as well as i would have expected it does not seem to be able to draw a nonlinear decision boundary and furthermore the scipy minimize function frequently does not converge even when the training data is completely linearly separable included though commented out is a different implementation of the backpropagation algorithm and training which does not rely on the scipy minimize function but rather directly updates the node weights i could not get this algorithm to converge within a reasonable number of epochs i would be extremely grateful for any help that anyone could give regarding this program in addition to being new to machine learning i am also relatively new to python so please forgive any style issues thank you very much edit several of the hyperparamters and class attributes pertain only to the commentedout backpropagation and training algorithms sorry for being unclear,beginner why does my neural network perform poorly,question about backpropagation
697,hello i getting graduated from university next week in bachelor is and now due to lockdown i dont think it will be a good idea to pursue masters for job i am currently trying to become a business analyst i did some small internships before i also had a thought of studying abroad but i dont think without much job experience it will be a good idea however if i take the internship which will later be converted into into job i have to agree to their year employment bond and the work consist of learning jira and agile pay is obviously not good however the work experience can be very helpful moreever the office is merely mins awat if anyone can give me insights what to do it would be helpful,should i opt for masters or work experience,advice for a soon to be graduate
698,tldr where can i learn the fundamentals of ds without having to learn the technical skills im not a ds or someone who knows coding languages i do know that just grabbing data pulls and handing them off to people to create descriptive analytics is not using data to its full potential i want to drive change in my organization i want us to adopt real data science with industry standards and reap the rewards of the opportunities it can discover we have a lot of the data architecture getting in place but we need a cohesive strategy to guide us the next years are there any courses cheap online access youtube channels that i could take to help me understand the data science jargon understand the standard tools and practices the fundamentals outlined so i can talk with experts and guide business leaders i also would love to see semidetailed examples of successful ds models and the thought process and tools used to build it is there a reliable online resource community for external data or methods thanks,learning path for layperson to someone who can intelligently converse about data science,what are some of your favorite data science tools
699,hi everyone i am a practicing attorney considering making the leap to data science my ultimate goal would be to work in financial servicesfinancial industrylegal analytics as that is where my experience is and i feel very comfortable in the corporatebankingfinancial world i have a few questions i was hoping some of you may be able to help me with has anyone else made the leap to data science from a nontechnical career if so how was the experience and are you glad you did it i would be especially interested in hearing experiences from former lawyers or current lawyers who have folded data science into their work what math would you recommend that i learn to prepare for a masters in data science my last math class was over years ago and i think it is fair to say that i am probably at the calc i level on a good day someone recommended that i learn python does anyone have any good recommendations books online class etc for selfteaching specific recommendations would be highly appreciated what are the job prospects for an older studententrylevel job seeker assume earlymid s when finishing the degree i am not worried about the school side so much since i have always been a good student passed two bar exams etc but am concerned that employers may view me as damaged goods because of a previous career thank you so much for your time,career change to data science,is it worth getting a masters in data science if i already have a job as a lawyer
700,our predictive models use nonrandom samples of larger nonrandom samples to generate high and low probability areas no definition is given for what high or low probability mean these models determine where millions of person hours get spent each year and are a nonnegligible part of the cost of roads power lines pipelines military installations cell towers etc i have a cheap solution but need advice on how to explain to archaeology regulators exactly how garbage our current models are which in most states is just within meters of water i think most have a vague idea our predictive models are not good but dont understand that we could literally be doing worse than randomly digging to locate sites anyone have some good parables or concise easy analogies for me to open a conversation with,archaeology how to explain to regulators that our models are garbage,how do you find the best data set for your problem
701,hi guys coming from r i have previously used this book before i found the book is very comprehensive for learning data science in r and makes thing much easier as the author of the book actually creates the framework for the whole data science process from a to z data cleaning transforming plotting amp modelling however right now im trying to familiar myself with python as a lot of dl framework actually uses python more than r which would make it easier for me in the future to learn dl after learning ml for the basic of python syntax i have been using this site right now i want to jump straight to using the necessary framework for ds numpy pandas sklearn matplotlib amp seaborn but im not sure which path would be more beneficial and would give me better understanding whether to read the docs for each framework or read specific ds books that contain the az steps of ds using those frameworks any help and guidance is greatly appreciated thanks guys,learning ds and ml framework py documentation or books,what is the best free or very cheap way to learn python for data science
702,hello all ampxb i am not sure which community this fits into as it could fall into a number of them please direct me better if you think that there is a community which would rather chew on this problem ampxb i have received database enrichment data its rows and about columns i need to find matches between this data and existing data we have in the database i was able to match a bunch with vlookup is but because of simple formatting issues i know that there are more similarities i was able to match about rows with a macro i wrote that compares each cell in the enrichment data against all possible matching data in the database there was cells of data rows and columns to match i know that this method is very innefficient but it is the lowest level of effort right now ampxb thoughts,complex matching exercise,how do i match rows in a database
703,somy background worked as a digital marketing guy for web development agencies right out of college bs in business management in those agencies i touched on everything from social marketing seo some design email marketing consulting strategy and of course analytics i got a job working in a big ad agency focusing on social listening back in the summer i have always had a keen interest in analytics working with data that sort of thingbut my bachelor is never really even touched on it at all i mainly work in excel and that is hardcore for the social media department i would like to eventually bridge a gap between the digital and social department with my role and i feel like business analytics might eventually be the master is i should get that being saidi have no idea if i am even qualified or even considering the right degree program the big title sounds great and allbusiness analyticsbut i have a hard time concluding if it is the right degree i should go for maybe i should be looking at something safe like an mbaconsidering my current bs i am just wondering whether my informal experience is enough or even the right path for that type of degree sorry for being long winded tldr i have a bs in business management i have tons of informal experience that lead me toward business analytics but i am not sure if that is the right or isafest path also it is tough to find any online degrees since i do not see myself quitting anytime soon,career question trying to decide whether to get a ms in business analytics not sure if the right path background in comments,is a data analytics masters worth it if i already have a job
704,i am graduating in may with a masters in computer science and i have a strong interest in data science here is some information about my experience ampxb i took a data science programming course last semester and am currently taking a database systems course and an ai course unfortunately i never took a statistics course ampxb i am great in python not an expert but i know enough to get by i also know a small amount of sql php and how to create html forms i am decent in java need to brush up a bit on it and c i also have a good amount of matlab experience ampxb i have a small amount of excelgoogle sheets experience barely used it as well as some tableau and watershed experience from past internships ampxb i wonder what i should go after with my skills i also have the book cracking the coding interview which i know will be useful i am also willing to use datacamp in case the skills i have are not enough so far i am just looking for something entry level,what should i go for based on my experience,i am a year old and i have just finished my first data science interview what should i expect
705,i m living in europe graduated a couple of years ago with a ms in cs from an elite university and found a very high paying job working in analytics at an incredible employer in finance lately i have found myself increasingly dissatisfied as the work content is not stimulating some of my current points of dissatisfaction a lot of work involves simply reporting data which does not excite me as i was hired to be a data scientist i do not feel i am developing any sophisticated skills as i am having less time to do real science involving modelling and experimentation i feel that if i leave eventually i will not have done any really noteworthy ds projects that will earn me a similar pay check as my work is now trending more towards that of a databi analyst i basically miss feeling challenged the way i did during my ms with the fancy math statistics and novel methods we would be exposed to and i feel rusty there management has no clear vision for the team i am working in and i also have a very unclear idea about my future i have raised this yet the answer is very vague as my actual manager has very questionable qualifications to be in his role i work in a silo and do not have much opportunity to bounce my ideas off of others and learn through collaboration some points of satisfaction employer offers great perks and benefits compensation is fantastic i am earning way above average for my experience level and jobs i have interviewed so far offer around less which would be a tough pay cut to swallow very nice and respectful company culture i am in a position where i can have impact on the business as my voice is heard at the top management level i have learned a lot on the softskill side my current dilemma is should i move on from this company and sacrifice the nice pay check today in order to hopefully gain more useful handson technical experience and have better prospects later in my career or am i being too picky with what i want and should i try to make the most of my current work i realise that i am very lucky to be at an employer that offers great benefits and working conditions but i at the moment feel like i am sitting in an uncomfortable comfort zone i have very little working experience outside this company so i would highly appreciate your opinions tldr i am in a boring high paying job should i accept a pay cut now with the hope of finding something more fun and possibly better for my longterm future,my job is boring but lucrative should i accept a pay cut and find something more exciting,data science in the us vs europe
706,assume a binary classification task with a highly unbalanced dataset outcomes and is the minority class is the majority class i want to train a classification model to be very good at capturing class can i do this while training the model mentioned above one solution is to change the weights to of the minority class to say in xgboost scale_pos_weight i would like to know what are the methods to tell the model while training for example conducting kfold and gridsearch at the same time to find the best hypterparameters to focus on parameters that increases the models ability to detect class minority class the way to assess the model at the very end is to use a confusion matrix classification report to see how did the trained model predict on a test data set in predicting capturing the minority class some methods are upsampling down sampling etc using decision trees that are less sensitive to class imbalance and adjusting class_weights i am trying to understand how to do this,imbalanced data sets,how to deal with imbalanced data
707,hey all i was wondering if there is a specific subredditdiscord channel or something where i can go to get feedback on my data analysis work i have chosen to do some work on the new york crime data basically predicting the type of crime the link to my notebooks is exploration notebook and prediction notebook i do have some selfcriticisms but i am not sure how to address them so i am hoping the collective wisdom here can help explore map data i have plotted it but so what i do not know how to draw any conclusions from it anyone have any resources i have dropped some variables for example datetime ddmmyy and kept day month year since i reason that the model should be able to reconstruct the datetime if all of it turns out to be important i am not sure if this is a valid assumption or if what i am doing is wise predict i am defining correct if the class is the same but i feel like my error function is wrong i feel like i should be using cross entropy during the training process but i have no idea how to do that i feel like using real numbers to represent my classes is wrong and that i should be using onehot vectors since there is no real distance between a class and a class i am not sure if this opinion of mine is correct also i figure i should probably share the dataset i am not sure what the common method is so if people could suggest that it would be much appreciated xpost,criticisms on my data analysis workxpost mlquestions,looking for advice on how to approach a problem
708,hello everyone the title frames the question as simply as i can imagine if i read introduction to statistical learning pattern recognition and machine learning by bishop elements of statistical learning can i get a job as a data scientist i am graduating in a year with a bs in applied math minor in economics and have been a hobbyist coder strong in python have knowledge of sqlnosql and lots of irrelevant coding projects from an early age i am currently reading the bishop book and isl so i am just wondering where i stand and how far i need to go if your answer is no then can you suggest what else i would need to read the purpose of this question is to set some concrete goals for myself any input is appreciated,if i read x books can i be hired as a data scientist,what is the best way to get into data science without a degree
709,i am having issues with keras and tensorflow basically it gives me the following error segmentation fault core dumped anytime i try to fit a model with a convd layer my code works on the cpu it also works without any convd layers even though it is ineffective for my use case i have got cuda cudnn and tensorflow installed i have tried reinstalling keras and tensorflow i have tried reinstalling the graphics drivers cuda and all the other packages i am on ubuntu mint v external usb ssd drive with cuda v and i simply followed the instructions on tensorflow under gpu support for and under to install cuda tensorflow version is a theory i have is that cudnn is somehow broken and needs to be reinstalled even though i have reinstalled it multiple times so ampxb code sample import numpy as np import keras model kerasmodelssequential sequential model type modeladdkeraslayersconvdfilters kernel_size strides activationsigmoid convolutional layer modeladdkeraslayersflatten flatten layer modeladdkeraslayersdense dense layer of units modelcompileloss amean_squared_error optimizeradam compile model y nprandomrand random expected output x nprandomrand random input modelfitx y and fit error occurs here ampxb error using tensorflow backend epoch i tensorflowcoreplatformcpu_feature_guardcc your cpu supports instructions that this tensorflow binary was not compiled to use avx fma i tensorflowstream_executorcudacuda_gpu_executorcc successful numa node read from sysfs had negative value but there must be at least one numa node so returning numa node zero i tensorflowcorecommon_runtimegpugpu_devicecc found device with properties name geforce rtx major minor memoryclockrateghz pcibusid totalmemory gib freememory gib i tensorflowcorecommon_runtimegpugpu_devicecc adding visible gpu devices i tensorflowcorecommon_runtimegpugpu_devicecc device interconnect streamexecutor with strength edge matrix i tensorflowcorecommon_runtimegpugpu_devicecc i tensorflowcorecommon_runtimegpugpu_devicecc n i tensorflowcorecommon_runtimegpugpu_devicecc created tensorflow device joblocalhostreplicataskdevicegpu with mb memory gt physical gpu device name geforce rtx pci bus id compute capability segmentation fault core dumped ampxb,issue with keras and cudnn,cannot get my tensorflow model to work
710,we have a special landing page set up on our site that we used during a short lived campaign to draw in new users i want to go into google analytics and see how many people have been visiting our site since that campaign who have viewed that landing page once before i tried setting up a segment but i think i essentially told analytics to show me information about sessions that contained pageviews to that landing page i am trying to see instead is information about the users who viewed that landing page at one point but have returned to our site at a later time any help is greatly appreciated i am definitely not a ga guru,need help identifying number of new users who visited a specific page in the past,how do i track users who have visited a certain section of our site
711,i would like to request a datasite that ranks the best films of all time using the average of the films performances with academy awards box office and critic amp audience rating flickmetrixcom has a similar system but it only ranks the data using aggregate critic and audience scores thats why i believe adding in the other data will give us a more accurate idea of what the best movies are in the method im suggesting i was able to figure out gone with the wind is likely the best movie of all time its in weighted box office sales won oscars including of the main categories and has an on flickmatrix which has already compiled the other scores for me im just unable to create a system or dataset like flickmatrix that uses my system and i had to manually figure out the data for box office and academy awards and add it to flickmatrix data,dataset request ranking best films of all time,how do i find the best rated movies based on ratings
712,has anyone found sample data science interview prep skills tests and questions that were actually useful i have been googling my heart out but i have been getting a wide range of results and so far all are from the type of data science websites that are dedicated to getting those sweet sweet clicks over delivering decent information i am about to take my first hour skills test for a data science job and i am terrified i am not ready i am entrylevel and the company knows it so i do not think they are expecting me to be winning any kaggle competitions and frankly i do not have any kaggle experience i found a website that listed beginner intermediate and expertlevel questionsprojects but i foolishly did not bookmark it immediately the job description focuses on models experiments and statistics for what it is worth,sample projects and questions to prepare for a data science skills test,data science interview prep
713,i thought i would share a new open source project my team mate and i have been working on at our school is research division in short it is meant to allow website owners to place hooks on their html pages in the form of html attributes or javascript functions defined globally that allow data about how users use the web page to be logged examples are how far down they scroll what they click on what text they select and whether or not they share the page on social media then tools let you query the data to analyze it and an http api endpoint allows you to get recommendations for other web pages on your site they may be interested in calculated by examining the browsing behavior of all the site is visitors it is composed of opensource software koa mongodb and designed to run well in containers in fact the tutorial on the project is website includes scripts to pull from a github repo and deploy it as a set of containers on aws free tier we would love to hear if anyone finds this useful and get any feedback you have too main website link,rutilus new opensource customizable analytics software w recommender engine,how do you use google analytics to track and invest in data
714,i am a professional software developer with a web development background looking to do ml algotrading with someone as a hobby side hustle i am proficient in java python js angular react some db languages have taken andrew ng is course some college ai ml courses minor kaggle stuff added to an existing java ml project have implemented some automated historical current data downloaders code to save and load the trained model automatically execute the trades generated by the model on alpaca and run this all daily on an aws instance etc with an emphasis on keeping it all free i know there is somewhat of a stigma against both algotrading and trying to do this sort of thing on the cheap concerning timely data and execution time but still i am still mediocre at machine learning and finance in general but i learn best by doing and am quite selfmotivated thanks,looking for someone working on a ml python algotrading project to pair with,what is the best free or very cheap way to learn ml
715,i am following bluebrown is video series on neural networks and though most things are explained well one thing which he doesnt go into detail of is the cost function itself so we initially start off with a randomized set of values for all the weights and biases and calculate the error value by calculating error over all the training data next our job is to use gradient descent which essentially boils down to finding the minima of a function to get the optimal values of weights and biases which minimise the cost function and give us the best possible predictions but for doing all of this do not we need a function which is defined for all possible values of the weights and biases we start off with knowing the error value for just one particular set of values of the weights and biases and we never discuss how we found the error values for all the other possible values in other words how do we construct the actual cost function which we need to perform the gradient descent,how is the cost function for a neural network constructed,why do we get such a big error when training a neural network
716,i currently work in image processing using matlab i have worked with c and cnns in python briefly before from what i understand most dl jobs fall under the production or research side in the production roles c is more important whereas having a phd or publications and knowing pythontensorflowkeraspytorch are more important in the research roles since i do not have much work experience or publicationsphd i am getting it is easier to get hired in a production role i am guessing it is easier to get hired at large companies so to get a job at a large company should i focus on improving my c or use my time to work on projects that demonstrate mastery of dl concepts such as using variational autoencoders gans semantic segmentation reinforcement learning etc,how to get a deep learning job in production side,is it worth getting a phd in ds if i already have a job as a data scientist
717,hey folks dm me if this catches your eye for learning i currently have an active subscription of datacamp which gives access to all the courses and content available on the websitemostly related to data analytics and science now this membership is for an year starting with june till june there are still more than days for it to go i have been able to utilise most of the data camps content for my benefit and have had an humangous learning experience and i think its time for me to move onto other interests and vest time on those so if anyone here is interested in buying the subscription user profile can be changed accordingly on completion a certificate will be given by datacamp do message and we can work out the exchange,data science analytics online education datacamp,is datacamp worth paying for
718,hello all im a canadian with a business degree major in finance hoping to relocate to europe im looking to enter the field of data science and have been wondering if a msc in data analytics is equivalent to a msc in data science ive been looking for programs in the uk and not many data science programs list businessfinance degrees in their entry requirements the ones that do stirling lse city manchester liverpool sheffield are already on my list however im very interested in pursuing my masters in glasgow but both the university of glasgow and strathclyde offer a msc data analytics program that im eligible to apply both universities list data scientist as the career prospects of their programs but i cannot know if those applicants who landed a job as data scientists already had a programmingcomputing background id appreciate any inputadvice on schools and programs,msc data science with a business background,masters in business analytics or data science
719,i just graduated from my masters where i was also an ra and i have been interviewing for jobs but they have all gone horribly and i am left feeling so discouraged about my future in this field afterwards granted my undergrad was in biomed every company is asking me to know a different software and we did not focus on any specific one in school so i know the basics of all of them but not an expert in any jobs labelled entrylevel are asking for qualifications that i do not have and i do not know how to progress from here i am taking some online courses now to try and get to their level but i am worried if i take too long to learn it they will be asking about my postgrad gaps my family cannot relate because they do not understand how after finishing years of schooling i am not an expert and i feel like not many fields are like this did anyone else experience this,did an undergrad and a masters and i still feel like i do not know anything,how do i know if i am ready for data science
720,hello i was wondering if can get some help upon career goals and master is program in the field of data science i have graduated from college in the us years ago and worked in a consulting company for about three years back in my home country due to my interest towards data science data analytics i am in hopes of pursuing a master is degree in the us especially would prefer an online master is degree since data science online programs are new and not a lot of information is founded upon sharing their experiences on acceptance and workload would anyone be happy to share some insights i figured uiuc admissions require more in depth computer science skills that i do not have i was thinking towards uc berkeley and georgia tech there seems to be a lot of doubts since it is hard to figure out if both programs could be completed within a year fulltime and what approximately the acceptance rate be,online masters program,data science masters programs
721,hello i graduate college this spring and am in the process of applying for jobs i applied for an entry level research programming position and they are requesting i submit a code sample all of the information and examples i have found online regarding code samples are for software engineers i am not sure what exactly a code sample entails for a data analysisscience position i have used stata and r in my studies and am familiar with both i guess the main questions i have are is it just a collection of the codes i have used to analyze the data and do i include comments on what i am doingwhy i am using these codes thank you in advance,code sample for research programmer position,how do i prepare for a data science interview
722,hi all new data engineer supporting a new data science team my team is about to launch a group of binary classification data science models and i was looking at a side project to monitor these models and the underlying datasets after researching this subreddit and reading a plethora of articles online i really have not found a solution for it i am looking to be notified of any shifts in the dataset be notified of any significant decreases in model performance and if there is a decrease in performance identify what underlying shifts in the data have caused this has anyone found a good solution for this otherwise i am going to build a bespoke application for this i will be happy to post a python package and docker container barring any issues from my company publishing it if you do not have a good solution what else would you like to see in this application thanks all,monitoring of multiple data science models,what is your data science solution
723,hi after a couple of years of i guess hard work i was able to get my first offer as an ml engineer i am happy and hopeful and at the same time a bit scared i have a background in engineering and though i have been learning data science in the past couple of years i know the it job culture would be different for me i worked either in academia or in consulting firms both of which were super boring monotonous but with lots of additional time i never worked more than hours ampxb now i am moving to the tech industry with all the hype and buzz around it and for someone with not similar past it is a bit challenging for me ampxb i am asking from people who are actually inside the field for a few years what shall i prepare for what surprises might i be facing just any word of advice for a newcomer not to do crazy mistakes ampxb any constructive word of advice is highly appreciated nonconstructive is also find,experienced data scientist ml engineers what should i expect in the first few months,data science or data engineering
724,im on the interview team and just had my mind blown yesterday by a personal project that involved plotly a lot of really well done end to end data cleaning project sounds dumb but the field he applied it to was really novel cant say more without risking a coworker reading this this made me wonder whats are some of the good personal projects you guys have seen over the years from entry levels i tend to like seeing dashboards and data cleaning really what the job will likely entail mid level ive seen a lot but this is where it gets fun for me ive never had my mind blown by an entry level but mid and senior tend to not just use the tech but master it and have a good application for it,what personal projects have you been most impressed with from applicants,is data science for me
725,background ms statistics from umich and have two offers right now call them x y so x is a top us insurance company in a major east coast city living expenditure high around for rent team is friendly diverse and vibrant probably because they layoff of their modeling department recently i was hired as an analyst doing insurance modeling premium pricing marketing data analysis i do have close friends at that city y is a top global oil company locating at a midwest city close to chicago min ride low living expenditure for rent team is white male predominantim a minority i have to stay at the position for at least two years to transfer to another division like ds or finance pay is k higher than x doing database management work maintaining data quality monitor data request from other teams optimizing data storage and processings not using my stats knowledge and that might become rusty in the future no friends in that city but umich has strong alumni network at chicago career goal want to be a data scientist which one would you choose why thank you so much,two jobs offer comparison,i have two job offers and i would like to hear your thoughts on them
726,note i am going to crosspost this rcscareerquestions as well my question revolves around how to enter the field of data science given a background in statistics and econometrics to provide context i took a few math courses up to the level of undergraduate real analysis so i am no stranger to proofs i took courses relating to mathematical probability as well as econometrics so i think i am wellequipped on the statistics side what i do not have is the actual programming knowhow or portfolio to put it all together i have done some research and i know there are several options in general for those without a strictly cs background namely moocs boot camps and higher education disregarding the higher education option for now the two options require a basic understanding of what data science is and the general tools of the trade i am working on this via caltech is cs lectures and subsequently andrew ng is cs with the ultimate goal of getting a job in the field what are some of your thoughts on moocs vs bootcamps given someone with a similar background,entering data science from a statistics background,is it worth getting a masters in data science if i already have a job as a data scientist
727,i had this up before but accidentally deleted it i am looking for a dataset on us weed prices on the municipal level anyone know of a dataset or place to scrape it i found this site but they only let me look at recent submissions so i cannot get all the municipallevel data these people were successfully able to scrape municipallevel data but i do not know how they have a github link bottom of the page of the article with their scraper but it does not seem like it would work what i think they did was scraped the pages in order gtpage gtpage gt page n but if you actually look at the submissions it is the same page despite what pg is set to did the site break or is there some compsci reason that i do not understand,request regional street marijuana prices for the us,request us traffic data for the past three months
728,hey rdatascience i am a nb here and i am looking for some suggestions i am building a new etl and starting to focus on the e step i have not been able to find an existing project which seems to cover my requirements so far i could build my own but i would love to not reinvent the wheel if i do not have to this service extracts data from several different apis for hundreds of different companies each each one of these api calls can then dynamically generate an arbitrary set of additional api calls in turn to be launched in parallel a hypothetical example i call an api to grab all x subreddits from reddit then for each of these x subreddits i then call the api again to grab all y posts then for each of these y posts i again call the api to grab all of the z comments given this hypothetical you can see that you end up with a tree of execution where each node in the tree can produce n number of additional child nodes to be processed in parallel what i am talking about here is some mix of a web crawler except more constrained to well understood but varying apis and a batch processor i need each of these nodes logically separated like this so that if one fails it only stops execution for the possible nodes that come after but not the nodes at it is same level i have looked into building this as a set of microservices using an event bus to schedule jobs for a pool of workers then i could record the state of each of these paths and track when something fails and be able to debug and retry i would love some suggestions for this or an idea of other projects that look very similar so that i might gain some inspiration from them thanks edit i have looking into airflow and luigi but they seem better as proper workflow orchestrators perhaps even as the rest of the etl once the data has already been aggregated from these various apis another was aws batch but it is not very mature and the ui stinks if you disagree with either of these interpretations by all means lemme hear why,suggestions for batch processing andor state machine packages,is there a name for this kind of project
729,what questions to ask hiring manager to secure job offer had a job interview yesterday for an entry level data reporting analyst i think i did okay and the hiring manager gave me her cell number at the end of it i texted her soon afterwards thanking her for the interview and asked if any other applications materials would be needed whenwhat should i text her next to secure a potential job offer one question i do have for real is if theres room for progression to a more senior business intelligence type role rather than just reporting but i dont want to make the question revolve around me im a soon to be college grad btw,what to ask hiring manager to help secure a job offer,senior business manager wants to interview me for a data analytics position what do i do
730,q row lstm gt is this correct sigmoidkssh_i kisxi or you meant to say sigmoidwh kssh_i wx ksix_i b_x b_h ___ if authors meant then how do they explain the hidden units in layers for input size if the authors meant and are increasing hidden units what is the kernel size for the next layer also is row lstm described in the paper is same as convlstm q triangular context in row lstm if padding is used during convolution and k the output feature size is same as input then how context is lost is training possible on single gpu or it requires multi gpu environment i would be more than grateful to receive any advice on this,pixel rnn row lstm explanation in simplest manner possible,question about hidden layer size
731,hello i am a high school science teacher who is just picking up programming in texas we have released exams of the annual very wordy biology state test called staar and statewide the massive annual challenge is teaching the subject to english language learners while coaching them on also gaining a mastery of the english language in order to interpret and pass the test in teaching we classify vocabulary words into three tiers tier i simple words in everyday conversation like there here place dog tier ii intermediateadvanced words like predict depletion tier iii subjectspecific words like meiosis photosynthesis chromosome while our ells pick up tier i words throughout the conversation and other subjects and master tier iii words because we explicitly teach the vocabulary the gap is in picking up the tier ii words that are frequently used on these standardized assessments for you experienced folks in just a broad big picture sketch how would i go about creating a tool that would be able to create a list of highfrequency words from the released exams which are in pdf format released exams for biology are here scroll down,how could a beginner go about obtaining word frequency from pdfs,i am a data scientist and i do not know if i should quit or not
732,hi i am sure this is a situation many of you have come across before and i was wondering what your thoughts were many times when i am tuning my hyperparameters i will find that the model with the best cv error is actually very overfit when comparing the infold vs outoffold training error for example i just ran an xgboost model and the parameters with the best cv error resulted in a outoffold logloss of and an infold logloss of that infold logloss is lower than the out of fold which seems excessive if i created a model with these parameters i would expect it to be overfit however i would also expect it to generalize well based on logloss criteria so what are the general thoughts on how wouldifferent infold vs outoffold errors should be i know there is not a formula or any hard set rules i was just wondering how people handled situations like this i personally up the regularization parameters somewhat before creating my final model,balancing variance vs raw cv performance,how do you handle overfitting
733,correct my understanding if i have misinterpreted this but how does deep sort work when new people enter the frame of the image my understanding is that you train it by annotating each object in the frames bounding box so that when that object moves it uses both kalman predictions and attempting to classify the objects to deal objects being blocked at certain points but say youve done all this training and it was looking at a camera or a basketball game how would it handle someone it hasnt seen before coming into frame it doesnt have a classification for them is this valid or when i do my classifications should i make my classifications more broad like person or home team away team if the latter is the case then how does it use classification to differentiate between people at all,question regarding deep sort,question about object classification
734,hello internets i am cross posting this from cscareer since i was hoping for more advice than just amake flappy birds and since i am really interested in data analysis i hope i do not bother you guys too much i would really like to try and get well on my way to a job in about months i know the timeline is tight but to be frank my full time job is already starting layoffs if i could at least start to monetize at that point it would be awesome i have been messing around programming for quite some time mostly python and a smidgen of r and i would describe myself as low intermediate perhaps i work full time so the projects tend to come in spurts on the weekends now that i am seriously looking at making a go of this i am rather lost i know i need to tart up my github and i have a domain that i can make into a portfolio should i aim at increasing my project count what is the easiest way to begin to monetize i know that most freelancer sites are extremely hard to make decent money so far i have completed a variety of courses on udemy edx and coursera i mostly enjoy data wrangling so i have done things like kaggle is titanic project rosalind and other small bits and bobs fizzbuzz and i was involved with a project that extracted data fromone database applied tool and analysis and then added it to another really i have just been messing around thanks for reading tldr i am losing my job and am not sure how to actually go from messing around to making money,i am losing my job how do i go from messing around to making money,how much do i need to know for data science
735,okay i am currently in the middle of two pursuits i want to start learn mix martial arts and see if i have what it takes to be a professional fighter and i want to learn about data science subsequently the reason i decided to do both at once is because money is not an issue at the moment i am and i want to start enjoying my life in the near future i know that data science is a mesh of many different fields i also know its up to me to convince employers that my skills are necessary my goal is to use data science in conjunction with video games although i am not sure if there is a foundation for this pursuit i would be happy doing data science for any company since i have always admired the laws of mathematics and enjoy finding patterns in the behaviors of peoplefrom a physiological stand point some of the important fields for a data scientist to know are programming statistics business and machine learning i do not have a clear understanding of what machine learning is but i think it is the process of the computer combing the data for patterns if someone can elaborate more on what it is i would truly appreciate it i have learned programming in the past and was familiar with c and python although i have forgotten most of it due to not using the languages in over a year i can probably relearn the syntax in a week and i understand python is a popular language for data science i am interested in learning what experiences you the data scientists of reddit have that you are willing to share i am curious about your discoveries and how you discovered what you have learned the reason i would like to know this is so that i can begin imagining how to apply data science techniques to video games i would also like some guidance on what books to begin reading and what interesting newsletters might exist i do not want to begin with programming because i have learned so many times and its a dull place for me to begin i am also majoring in statistics and find it very interesting the reason i do not have a degree at is due to me taking a year and half off due to personal issues and a change in major from programming to math the fields i feel i should start in are either machine learning even though it may require a strong understanding of programming i feel i have an intuitive understanding of programming the other field i should study is the decision process in business so i can know how to best assist them so if you know any interesting or informative books about machine learning or business acumen then please let me know i am currently planning to begin my studies with the book how to lie with statistics thanks for all who reply,please advise on how to learn data science,is it worth spending a semester learning data science if i already have a job
736,i hope im in the right subreddit to ask this question i have a data set of lets lets say rows by columns the matrix represents the water level of each county over than span of years each row is an array that contains the county name and its water level for years so each row is a size array anyways when i graph this matrix in parallel coordinates using a javascript library called djs this graph is normalized by the high and low values by the way in the graph is the normalized high and is the low this is good so far but my main objective is to go through this mess and find counties that share a similar trend line i came up of three ways of doing this but they are not working as well here is my three methods methods i used to find patterns finding patterns by manually going through county trend lines from the graph above you can easily identify several similar patterns im trying to find as many similar patterns as possible i first did it by eye and grouped similar patterns the results turned out ok but im sure i missed a few counties obviously this is not a good way to go about this here is the three ways i did it using my algorithm to find patterns i made a simple algorithm that goes down the rows goes through each data point of a county and makes a string for that county that represent the behavior of that county for example if a county is line goes up down up it will have a string of udu im going to call this the behavioral string from now on once i have the behavioral string of all counties i then looped through the rowscounties once again and looked for any other county that has the least common substring ofsay there are years so the maximum length of the behavioral string is since the initial year is used to measure the first updown means that at least one year does not match i then put all of this into a dictionary where the key is the county name and the value is an array that contains the names of all counties that are similar to this county i though this was a pretty ok algorithm but the results showed a few patterns being there when they should not be there it was also leaving out many other patterns i have made a much smaller example that will use this algorithm and the covariance matrix which i will explain below using covariance matrix i was told by a redditor to do this but im still dont understand what this does in my case small x example using my algorithm and covariance matrix so here i made a x matrix example to test these out the picture has patterns abcde on the top right is a matrix of the graph is data the middle matrix is me just rotating the matrix to do calculations for the covariance matrix the rd and bottom matrix is the resulting covariance matrix i used a online covariance matrix calculator this is the results for that x test since there are years the maximum length of the on the behavior string can be i made it so it will output only of similar patterns on top is me using my algorithm and outputting a matrix where the row arrays only have patterns that has or more lest common substring below that is the result of the corariance matrix,how can i finding similar patterns in rows of a matrix,how do i go about building a data set with multiple seasonal patterns
737,data science has a large scope but for those wanting to learn about intriguing findingsconclusions as well as the new methodologyalgorithms to obtain those findingsconclusions what are the top ones to listen to i prefer cutting edge and explanation but balanced podcasts so it is not too drowned in the details and rather gives you keywordslinks to explore further i plan to drive to this so i need to be awake stats machine learning languages i found some but i was wondering if anyone knew more updated cumulative list full list of data science podcasts from adversarial learning gt becoming a data scientist gt data crunch gt data skeptic gt data stories gt freakonomics gt ibm big data gt learning machines gt linear digressions gt more or less behind the stats gt not so standard deviations gt o areilly data show gt partially derivative gt super data science gt talking machines gt what is the point gt,what are some really good data science podcasts,what are some of your favorite data science podcasts
738,hi all are you guys aware of any credible data science or analytics research on covid real time data that came out recently we have been into pandemic for more than a year now and i am sure must have good amount of data on covid but most discussions and research i have seen on covid were purely medical as it should be however since the pandemic has generated large amounts of data data scientists could have also looked at different aspects of pandemic such as biological spread patterns of virus wrt geography seasons business cycles health care metrics socio political metrics etc could be large number of other variables i just made those up govt responses and their effectiveness who succeeded and why who failed and why how to predict peaks or falls in covid cycles are their specific markers that could help some metric that stands out please share any research info if you have ongoing or concluded good ameteur work too counts random projects on github or do you think what i am asking is unrealistic,data science research on covid,data science and covid
739,i am trying to solve a time series classification and having trouble understanding what method would be appropriate based on what i have found this far i have two issues when using a hidden markov model it is going to estimate the states for classification however with my states being known i do not need that i have not seen anything thus far about using a regular markov chain but is that an option good python packages other types of models extract features from a time series and classify using other techniques it seems like to do that effectively you would need to define the length of your time series i have already been able to do this and now need a way to identify when a time series is in a certain state without defining a time window are there ways around those issues or am i possibly misunderstanding also are there any techniques here i am missing,time series classification with known states,time series classification
740,i have currently been working in my first help desk for months but it is hard to get raises or promotions even though i have comptia trifecta and microsoft certs i originally was set on system admin but after working in help desk i am worried system admin will be help desk i learned sql and some excel and i am really interested in business analytics however the job requirements for business analytics and especially data analytics are ridiculous and ofter require to years experience in anything from vendor orders purchasing agreements requirements sql sdlc contracts regression analysis qa project management payroll finance sales invoicing i was focusing on sql and excel which seem to be the main focus but even if you have those pinned doing the job is so industry focused it can vary widely and i do not know if i would be wasting time applying for these jobs based on my experience or if i should give it a shot my other option is to apply for more it support or system admin jobs maybe it is just my support job that is bad is system admin really help desk would i be better applying to it support or business analytics jobs based off my current experience i am just worried about getting stuck in help desk and not sure where to go,business analytics vs system administration,is it worth getting a masters in data analytics if i already have a job as a business analyst
741,hi all hopefully this is the right place to ask about this if not please let me know and i will remove this post i am working on a tool to make it easy to download twitter data in csv amp json format without fiddling around with api keys etc i would like to know from people who actually do this as part of their job what kinds of data should i make sure i support so far i have implemented search which lets you download the results of a twitter search as a dataset i was also going to implement user timeline download thread download likes by user retweets by user people search followerfollowing data and listmember data is there anything i have missed that you have needed in the past are any of these particularly higher priority than other data sets thank you so much for reading and have a nice day,have you analyzed twitter data in your work,need help with a project
742,years old berkeley grad well into a career that is not data science but i use python regularly and have been coding for some time in vba and python i am more of a business and financial analyst who ended up moving more toward a data role and just learned programming on my own by giving myself projects over the years i want to expand both my own knowledge and career prospects in other data roles and maybe even get a data science role in the future i have experience creating web scrapers plotting running linear and exponential regressions various data cleaning and manipulation sql etc i lack the math skills the last math class i took was in college so over years ago and the farthest i ever went is multivariable calculus i forgot pretty much all of this and maybe some people out there would be able to attest to the ease or difficulty in picking up the basics again if they have been in a similar situation i did pass levels of cfa which is a difficult finance exam and that contained bachelorlevel statistics i did that in i think so years ago i see that the mitx micromasters has a prerequisite requirement of multivariable calculus how difficult would this be for someone in my shoes i do not want to take the class for free i would want the cert and be able to at least put it on a resume in the other section i would have my company pay for the whole thing so the cost does not really factor in i genuinely like programming creating interesting visualizations that summarize and explain data patterns in a digestible way for other business users and am interested in learning the other things i do not know neural networks deep learning machine learning etc what drew me to this particular program is the fact that you can put mit on your resume and yes i know that any data scientist would not really care about mitx but it is better than nothing it seems pretty robust from both a math and machine learning perspective and i would be keeping my skills a bit more uptodate and fresh i do not see automation and data roles losing popularity anytime soon and want to be best prepared for my own future career prospects if i ever got laid off i want to be able to get another six figure job with all my skills and this program seems to at least legitimize some skills on a resume also since i work in a dataheavy role i could actually apply what i learn to my actual job giving me more credibility within my own company thanks for reading this through and i look forward to any feedback people may have thanks,is mitx good for my siutation,is it worth getting a masters in data science if i already have a job as a data scientist
743,hi for anyone here that plays league of legends frequently or even occasionally you all know how inters trolls and griefers ruin the game i recently watched a video from a league of legends pro about how the lack of punishment for these players ruin the game that got me thinking a selfmade riot ai reporting system using data from the riot api on matches player kdas in the match gold in the match etc i think making such a system would be possible with the amount of data that is available in league for those who are not players of league of legends what i am proposing is something that is similar to a spam checker to determine if a player trolled in a game or not any thoughts on the idea or suggestions btw i am in no way at an intermediate level in machine learning or data science i have recently began learning it so i was thinking on a project that can keep me occupied,thoughts on riot machine learning project,is there a way to track when players are betting on fantasy sports
744,say youre working on a computer vision problem based on video data eg driving how do you incorporate information from past inputs into your prediction for the current input at test time i am aware of d convolutions that incorporate the temporal dimension but even if you d conv over the past minutes worth of frames for each prediction which seems expensive youre still throwing out info from more than minutes ago what are some modern approaches to retaining past information at test time is incorporating an lstm the state of the art approach can we do better id be really interested to hear about different approaches to short term memory youve come across,short term memory solutions for video tasks,how do you deal with overfitting in ds
745,i am building a data warehouse for my company as part of this we are querying the google analytics api and feeding the results into the data warehouse so we can integrate it with other data sources however the data is never matching what we see on the web frontend granted we have a fairly popular site but i am seeing for example k sessions in a day vs k in the api query result what gives how do i get it to near the same in order to compare the aggregate results i have used the custom report and removing dimensions in the ga query explorer the report we are using has dimensions and metrics the number of rows per day is not that much so it should not be sampling in fact the resultset never says that the data was sampled which is why this is such a headscratcher we do not have premium fyi any help would be appreciated,ga is driving me up the wall with sampling and data not matching,how do i query a query in google analytics
746,hi rdatascience few months ago i have started my learning path to become a data scientist i had no prior knowledge of programing or data science so i turned to my friends at reddit for help after making posts like this this and this i have dedicated myself for months and learned what you suggested ampnbsp right now i am at the final phase interviewingand since i am not being successful as other people here seemed to be i turn to you guys again first of all let me give you some starting info i am a brazilian yr mechanical engineer living in london and fully dedicated to becoming a data scientist i have done the data science specialisation on coursera this is a very long course that covers from r programming to statistical inference practical machine learning and regression models i have done sqlzoo and codeacademy tutorials on sql i have developed a portfolio on github it has project atm nlp class rf reg rf and simple one of data importing and structuring right now i am doing the stanford machine learning course by andrew ng ampnbsp this is the study path that i have followed so far since january i have been actively looking for juniorgraduate data scientistanalyst roles in reed linkedin and it recruitment agencies the problem is that i feel like the response have not exactly been overwhelming i have done some phone screenings but only got interview with a manager and it was by the phone and they ended up choosing someone else with more experience ampnbsp i usually do good in interviews it has never been a problem for me in the past and i do not feel its a problem now have not done any technical interviews yet what am i missing here is it my experience i starting to think it might be my portfolio or my past experience which you can check here keep in mind that i am going for juniorgraduate roles i am legitimately trying to find ways to improve myselfmy cvmy portfolio i have done so much already any help welcome,the path to landing a data science job the final phase,how do i prepare for my first data scientist interview
747,matt tran the owner of engineered truth on youtube nowadays is working with a congo dude to promote data science courses he had multiple videos saying that even a bachelor is degree is not required to get a job as a data scientist since you can self learn online he even went as far as saying that cs and math degrees are worthless and you should just go to a data science bootcamp to get a job as a data scientist and now he is promoting his courses btw this is the guy who threatened and blackmailed a college kid for criticizing him so you know what kind of person he is his videos seem to target audiences who are living in rd world countries his courses cost dollars and claiming that this is better than the mit professor is course i did more research and it turns out there are actually a lot of people who are scamming people from rd world countries with their lowquality data science courses claiming that they can become a data scientist with an aboveaverage salary in just months they are basically preying on desperate people where regulations are almost nonexistent unlike the us or canada i know this may sound harsh but do you personally think people who purchased these types of products are responsible for buying shitty courses also has the number of online courses scam gone up in the past few years with the rise of popularity in data science,are there a lot of online course scams in the data science industry especially in rd world countries,is data science a scam
748,task i have to write a regression model the inputs to the model are element vectors that are themselves derived from different sized cohorts the cohorts generally have individual users problem i do not have enough data i have maybe of these cohorts potential solution once the cohorts come into our pipeline the individuals data are available including what cohort they came from each cohort is defined by parameters eg country age range gender income range so my idea is to take my entire data set of individual users slice the data along each of those parameter sets and then repeatedly sample that subset to generate my own synthetic cohorts potential problems i see repeated sampling leads to overlapping cohorts which is not how the original data is i have crunched the numbers on this hypergeometric expected values and determined that i can control the expected overlap i have arbitrarily chosen overlap to be acceptable the synthetic cohorts values might not accurately represent real cohorts for any number of unknown unknowns this could give my model high accuracy on the synthetic cohorts but poor results on future real cohorts due to the paucity of real data i am not entirely sure how to counteract this concern balancing the data set some cohorts are much bigger so those parameter restrictions can be sampled more leading to overrepresentation in the synthetic cohorts this is tedious but not impossible to overcome with computations what other pitfalls might i run into here i am sure there will be questions or clarifications needed and i am happy to address those for anyone who wants to think about this,what are some things potential mistakespitfalls for this synthetic data idea,how to deal with overlapping datasets
749,i just graduated in may with a bs in psychology but now i am looking to get a ms in data science in order to get better job i took an introductory statistics course in college but i never took a calculus class or any other math or tech classes my gpa was good though is there anything i should do to prepare before trying to apply to a ms program in data science perhaps in terms of prerequisite courses that i would need in order to qualify for such a program also i found this link in a thread about studying data science should i do a few of those before trying to apply,i want to apply for an ms in data science but my bs is in psychology,is it worth getting a ms in data science if i already have a job as a data scientist
750,i have been researching this for awhile it has been tough going because of most the research in this field has to do with web data or direct mail marketing goal i want to find what current customers in our current database are most likely to buy other products from us this is bb sales ideas recommender systems using item based and user base collaborative filtering ii could possibly turn the similarity scores into a list of top opportunities of customers that arent buying products with similarity scores association rules it is easy to get association rules but turning them into actionable data is a bit harder i have seen some research building association rules into regressions or bayes networks to segment or score customers seems really yinteresting but limited research for me to go off logistic regression i have products set up unique regression models with their own feature selection to calculate how likely a customer is to buy a product what is the best approach here any brain storming ideas are really welcome im just reading tons and tons right now to learn,turning reccomender systems or association rules into actionable data,how do you go about building a recommender system
751,i lack experience regarding time and memory complexity in general so i would appreciate any input on the following thoughts that i had when studying mlps multilayer perceptron if i have an mlp with two hidden layers of size k first layer and k second layer and i want to propagate forward one single data point with dimensionality d then as i understand it regarding the time complexity i would have to do d multiplications for each of the neurons of the first hidden layer ie k and then k multiplications for each of the neurons of the second hidden layer ie k which leads to a total time complexity of odk kk and then regarding the memory required for that mlp would it again be dk to save the weight matrix of the first hidden layers plus kk to save the weight matrix of the second hidden layer ie again odk kk are those results correct or am i missing something apart from the biases which i purposefully neglected,mlps timememory complexity,question about the second layer of a neural network
752,let is try and look at this with an example before i get into my questions let is say you are trying to predict the number of oscars a movie will win with qualitative data we can clean and plug in a bunch of data eg box office opening rotten tomato score days released before oscars etc throw that in an algorithm eg scikit learn is linear regression etc and start making predictions yes i know ml is more complicated than that but i am trying to keep this simple now let is say you have a data set of qualitative data all numerical that is to say for each movie we have the reviews on each movie from a number of judges each judge rated the movie on a score from to in different categories we know which judge rated which movie what score to make things more interesting judges can also review a movie more than once we do have dates of the reviews so we know the order they came in what are approaches to use this qualitative data for predicting still wanting to predict number of oscars a movie will win things i have thought of are averaging the score in each category by all judges reviews for each movie using a timeweighted average so the newest reviews are worth more are there other or better approaches i am not thinking of what if we know some judges are better worse at reviewing movies but we do not know who how can we account for this dropping highest and lowest reviews is there a way to weight the individual reviewers looking for ideas and approaches i can learn more about,regression prediction using qualitative numerical data,how do you handle outliers in your data
753,hello here has been a great development in recent years regarding transfer learning in nlp i would like to take advantage of the techniques mentioned in the title but i cannot figure out the proper way to do it coding and training it from scratch is either extremely hard or impossible pytorch itself does not provide something native in order to use those pretrained models ulmfit appears in fastai elmo in allen nlp and bert in the github repository of hugginface i will do my bsc thesis in deep learning amp sentiment analysis and i cannot find good resources in order to learn how to use them for instance the example in the github repository of hugginface regarding text classification with bert is lines of code which is kinda discouraging has anyone worked with them in pytorch could someone guide me on how to approach this thank you very much,how to use elmo bert ulmfit etc with pytorch,how do i use a pretrained sentiment analysis model in pytorch
754,im doing a little pet project where im analyzing paintings and so far for the algorithm development i just downloaded a bunch of images by hand off of google and manually entered the relevant metadata now that the algorithm is done im hoping to get a better assortment of images but would really love to not have to do the tedious process of manually gathering them i dont need much in the way of data just the title and artist is enough although extras like the year they were painted etc are always welcome does anyone know of either an already assembled source of images i can download all at once in large batches or perhaps a python script or similar that would scrub them off a site like google arts and culture or the metmoma websites these website are where i got my test images but as far as i can tell there isnt a way to download all at once from any of these sites only one at a time thanks in advance for any help you can give,anyone know a way to get a lot of images of paintings with metadata,how do i use google analytics to store a bunch of images for future reference
755,there seems to be the consensus that traditional companies are too slow to act that the management does not understand ai or the implementations are poor do you in general find this to be true i was having a conversation with a friend about lmnd which claims to have advantage by using ai in claim and underwriting process i had worked for multiple insurance companies of them pampc and all of them had turned into aiassisted claimuw operation or in the process of developing it let is not pick on lmnd of the fortune is i worked for all of them invested heavily in cloud solution datalake or data science in general since this is the case what gives startup any advantage just by using ai as their main business model or am i simply in a bubble where while there is action the startups are magnitudes ahead of traditional in terms of ai development it just seems i live in a parallel world where ds is doing terribly outside of tech sector when it is just not my personal experience at all,is traditional company really too slow to change,what is your experience with ai or cloud
756,hi today marks the th application i applied for during a span of months all applications were ones that closely matched my current skills ie entry level mysql tableau excel data cleaning with sql analysis etc i have zero working experience in analytics and have a github portfolio showcasing my analytical skills technical skills at the very least i have not gotten a single interview is the job market for data analyst right now in ny not worth getting into i know its been only applications but not a single interview on mostly entry level jobs maybe i am just not competent enough either i am honestly just looking for a long term position career because i have been unemployed for years and need something i am just feeling alittle emotional because i have studied and worked hard relatively for myself for months on everything that i have learnt so far currently working on python as well with no job let alone a single interview tldr applications no interview unemployed years sad about it lol,applications no interview,i have a job interview tomorrow and i do not know what to do
757,hello all after having published roughly free blogposts we decided to collect and organize most of our resources to make a selfcomplete guide for beginners in deep learning the course that we created is interactive and textbased our aim is to learn the principles behind deep learning architectures explore the theory and intuition behind the algorithms and build your models with pytorch ampxb lessons coding challenges pytorch playgrounds quizzes deep learning illustrations ampxb who is this course for software engineers that looking to learn more on deep learning data scientists that are interested in deep architectures aspiring ml engineers and college grads with basic programming and math background ampxb ampxb what you will learn the intuition and math behind neural networks training neural networks convolutional neural networks recurrent neural networks autoencoders generative adversarial networks attention and transformers graph neural networks ampxb it focuses on handson experience and interactivity you can code and train your models with pytorch directly in your browser you can also run jupyter notebooks inside the platform ampxb we believe in textbased course because text is faster than videos you can learn at your own pace you can keep notes without pausing the video you can run your code straight in the browser,d introduction to deep learning amp neural networks,deep learning with pytorch
758,hi guys i am slowly trying to build skills to break into the data science world and i recently completed a six month certificate course from university of texas i know these certificate courses are not enough to get me a job but it was a good introduction to python and using it for data analysis i am following this up with an additional certificate in artificial intelligence and machine learning also through ut the company has offered me two complimentary courses selected from these four sql seems straightforward just using sql big data analytics hadoop spark yarn map reduce hive apache kafka and a few others are skills they list as something i would gain artificial intelligence on the cloud aws sagemaker deploying models on the cloud amazon lex and amazon rekognition are the skills they list building ai first product probabilistic systems ai designing principles supervised algorithms reinforcement learning algorithms data collection and analysis are the skills for this one my question is which of these two would you select i recognize sql is a major necessity but i am also taking a coursera course on it already my ultimate goal is to apply for a master is degree because well yeah i have seen how these certificate courses are talked about which of these would make me look the most appealing to a graduate program and also allow me to hit the ground running,tips for a newbie course selection thoughts,is it worth spending a semester learning r or python if i want to become a data scientist
759,so i have been looking into shorthand writing systems which are what reporters and stenographers use to transcribe conversations it is basically creating a reduced writing system and including use of symbols to write faster and it will generally require some expertise to decode experts in shorthand can apparently write over words per minute naturally from here i started thinking about what the digital equivalent to shorthand would be and i have thought of some random ideas that may have a place in a similar system text expansion if you went crazy with this then there would likely be a huge learning curve using a typed shorthand system like keyscript then decode it with some ml system although i would imagine that this would have a lot of challenges predictive text,discussion nlp what programmatic ways are there to increase typing speed,is there a name for this type of machine learning
760,im at a late stage startup and were beginning to build our ml production framework i recently read about ubers michelangelo ml platform and theres a section about managing data where they discuss feature stores so ive started to do a little digging it seems like its a fairly new concept not many articles about them and only a few platforms that seem to directly support them the main one ive come across is hopsworks by logical clocks regardless my question to the community here is has anybody used or built a feature store what was your experience with it ie difficulty to build or ease of use did it make your job easier and was it easy to incorporate into your workflow lastly what tools did you use to build it,feature stores,how do you build your own ml platform
761,i am still learning this field but i had in the past taken my dataset of genomic variants filter it down by variance run a pca plot to see if there were obvious clusters if i saw two clusters i would run kmeans with k on the dataset not the pca components and check the pca again to see if kmeans labeled the same points today i did this with a new dataset and it showed very obvious clusters but when i ran kmeans with k it did not identify the clusters i was trying to use kmeans as a quick way to label the groups and verify the clustering so i could look at their associated traits etc i understand one is a dimensionality reduction tool and the other is an unsupervised learning algorithm but past that maybe i actually do not know what i am doing,should kmeans and pca provide the same clustersd,how do i know if two features are the same
762,hello everyone was hoping for some help on this i have cross domain tracking setup for when my users go to a offsite shopping cartcheckout process and i have referral exclusions set up on that domain however the cart provider only has ga code on a couple of their checkout process pages so my flow looks like my site with ga code gt their checkout page with ga code gt their checkout page with no ga code gt their thank you page with ga code which is my destination conversion so this is totally screwing with my conversion tracking right i am getting a huge number of conversion traffic sources as directnone my guess is that when the user hits the page in the checkout process without the ga code it breaks the chain of ga so it cannot follow someone from for example facebook all the way to my site to their site to conversion am i correct if so has anyone else dealt with this or have any ideas thanks,weirdo ga implementation need help figuring out,google analytics cross domain tracking
763,hi a newbie here i am new to the world of data science and wanted to know if there are certain skills that would help me on my journey i do not much knowledge on the topic so here i am asking a question lmao so in anutshell what i want to know is are there anything that would help meand i mean truly help me some of the things i have been told it would help me some programming experiencenot master it but you know the basics preferable python or r learn how to use sql some math isi have not got a brief answer so it would help me if you clarify what kind of math and pretty much that is all i know i have also listed some of the things i already know pythoni will say i am a intermediate programmer calculus iif that is even needed lmao and in the process of learning sqlif you have any suggestions for that do let me know sooooo waiting for your response thanks y will,is there a prereq for data science,i am a new data scientist and i have a question
764,since i am self taught i have spent a lot of time digging through apis and medium articles but i would love to hear some personal experiences and tips it can be hard to even know what to google or how to ask questions i am writing some python to process several large csv files gb from an agentbased model for most of the programming i have done in my degree performance was largely irrelevant however i need to process anywhere from of these files for a single plot so the programming choices i make actually matter now which is intimidating but exciting these data i am working with usually have inconsistencies in formatting normally there are attributes but occasionally i get rows with attributes and i need to ignore these entirely there is no consistency on where these additional lines appear what is the best way to get rid of them is it worth the processing time to scan the db and drop these rows it seems awfully expensive to check all million lines on the topic of dropping these files also contain a couple attributes i do not want as well as many duplicate entries that i do not need since i will need to do several splitapplycombines on each of these csv files is it recommended to clean up the data first and if so what is the convention on doing so i was thinking about a script to read in clean up then write out the data this seems like a lot of readwrites to endure but i do have to scp the files onto a server to run the plotting code so maybe i should any heads up on operations to avoid or performance optimization tips would really help me out unfortunately i am on my own with this project so i do not have anyone to ask except internet strangers help me internet strangers you are my only hope,looking for personal suggestionsexperiences on handling large csv files in pandas,how do you store your data for future reference
765,does anyone on this subreddit know if there is a way to gather business names and addresses for free from the government either state or fed ideally fed i do not need all of the information hoovers or infousa have i just need the business name and having any sort of address would be great too but really would not be essential also as a disclaimer i am building a program that will help consumers figure out what credit unions they can join we launched a successful kickstarter to do it but in building the tool we have discovered that having a database of business names and ideally addresses would make the program work much better basically if you work for certain companies you can join certain credit unions we are writing a program that reads the credit union is bylaws and ideally it should identify the right company long story short we are not going to use this for marketing purposes,request where can i find a list of all businesses in the us,anyone know of a good free database for storing address data
766,i know autoencoders are useful for creating lowdimension embeddings of higher dimensional input vectors as a general rule are these compressed embeddings better for classification andor regression or does anything special have to be done in the compression phase to ensure that relevant features are properly captured consider a binary classification scenario with data of input dim situation build and train a network which goes from input v to output classify situation train an autoencoder to sufficient fitness which takes input v to v x compression build and train a binary classifier with the v input vector data set i know this stacking strategy is used a lot especially when it comes to pretraining convolutional filters but is it wrong to expect the v embedding to be more separable in terms of higher accuracy and given model complexity automatically by virtue of being a compressed embedding,are autoencoders useful for improving separation in classifiers,how to deal with overfitting in deep learning
767,hey im a college rising senior studying mathecon in the us with interest in ds i didnt reap any success with any of the recruiting efforts for this summer so im currently spending my junior summer with no internships i do have a couple of research positions that do a lot of data work for the summer but i am really disheartened that i couldnt land a tickettoafulltimejob by getting an internship this summer this is also having a great toll on my mental health and i spend mostly all just with planning anxiety and i am unable to execute any of my plans be it studying doing projects or even socializing my family also doesnt have enough money to support me for a graduate school after my undergrad so i really need to look for a full time job post graduation i did interview well this year but unfortunately was unable to land anything i need some advice as to what i can really do through this summer that can help me recruit for full time opps through senior year im also open to exploring other career paths like swe but i dont think im even passionate about those roles any suggestions about helping me getting started would be greatly appreciated,undergraduate student looking for summer advice,i have a summer internship interview for a data science position and i am really hoping for some advice
768,i decided to learn data science from scratch started with python courses got some more courses on numpy pandas matplotlib and scipy i had some projects in mind but then i stopped i want to get back to it but i keep coming up with excuses i will learn data science one way or another it will take time for sure and i want to get rid of those idle time i thought a study partner would be one of the solutions to the problem i am having is there anyone else in similar situation and wants to create a study group we can share our experience and maybe have some daily and weekly deadlines on mutual projects thanks in advance,study partners to learn data science together,how to learn data science from scratch
769,i am trying to view the google organic search terms that are scoring the most conversions for my site i have linked analytics to my webmaster tools account but i am not sure what is the best way to do this in analytics if i go gt conversions gt attribution gt model comparison tool i can see the number of conversions attributed to organic searches but i cannot view the search queries that resulted in these visitors if i go acquisition gt search console gt queries i can see search queries but i cannot work out how to display conversions as a field in this report moreover s of the search terms are classified as other and i cannot seem to drill down through this classification to view these search terms do i need to create a custom report to achieve this if so how would i go about doing that,google analytics tracking conversions from organic search terms,how can i track organic search queries in google analytics
770,hello i am recently involved in a project where we would like to use machine learning approach to guide the design of new materialsdevices my background phd in ee researcher in the interdisiplinary field of electronics materials and chemistry intermediate level of programming skills a lot of experience in c and embedded c good experience of matlab basic experience of python java basic knowledge of statistics that allow me to pass the undergrad and graudate level statistics courses but that was about years go new to machine learning description of my problem consider an array of design parameters x where the array size n at the moment but would like to extend to gt eventually and an array of devicematerial performance where the array size n these two deivce performance will then be combined with a known formula to generate an ultimate index for the performance z goal is give an index device z derived from device performance obtain the array of design parameters the ultimate goal is to design a software that will instantly give the user the set of design parameters based on their expectation of device performance datasets at the moment i have about datasets but i could get more if needed these datasets could be obtained using empirical fomulaes or finite element simulations question i was initially thinking about using regression to solve my problem it does not seem to be a difficult problem if my task is to build the relationship from the design parameters x to device performance y and ultimately index z and predict the the device performance with a new set of design parameters on the contrary obtaining the reverse regression from the index z back to device performance y and ultimately back to design parameters x seems quite difficult i have tried to google inverse or reverse regression but i did not have luck finding practical examples perhaps instead of solving this problem using linearpolynomial regression i should use a different approach do you have some suggestions my goal is to implement this application preferrably by following some similar problems and their solutions instead of digging into the underlying theory and mathematics i need to mention that we have some additional information that might be useful when buidling the ml algorithms for each design parameters or device performance there is usually a range that have physical meanings we might be able to embed that into the algorithm to simplify the problem thank you very much for reading through this and appreciate that,algorithms and methods for predictive device design,is there a good way to deal with a very unbalanced data set
771,hello everybody i apologize if this post is inappropriate but i am hoping it is within sub rules we are starting a tech company in the northern california region and are searching for a possible ctocofounder what we are trying to do is to bring a smart management system for retail businesses our system will replace or augment ownersmanagers by creating smart and dynamic task lists for employees the task lists are generated using ml vision processing algorithm ie that detects there is a spill or a misplaced item and iot sensors that are linked up to provide data such as when an item goes out of stock when retail businesses are run efficiently and effectively by ownersmanagers through clear and concse direction for hourly front end employees on what to do on an ongoing basis the businesses are much more profitable and we are simply trying to duplicate this increase to their bottom line using our software if what i wrote above sounds intimidating then do not be alarmed what we are trying to do does not require that deep of a dlml knowledge in fact someone who has done the coursera ml class from stanford and who can code very likely is qualified enough if you have some decent knowledge of dlml can code and is interested in becoming a founding partner of a tech company in the heart of the tech industry near silicon valley then please send me a pm and let is chat further,seeking cofounder,how do i go about creating a database for my company
772,i like to be on the lookout for data analysts for both networking and recruiting purposes but i am finding that searching the title data analyst returns a flood of generic analysts who really do not have an interest in data scienceadvanced analytics among those who call themselves data analysts you have those on the more preds track what this sub often means when referring to a da ie ppl who have done more rigorous statistical work built dashboards and maybe some modeling and then you have a huge pool of generic runofthemill analysts whose analytical competencies pretty much end at excel pivot tables and building a powerpoint presentation and would not be able to tell you the difference between a pvalue and a pancake this is partially why i personally am not a fan of the distinction we make between da and ds if we think data scientist is an amorphous nebulous term data analyst is times worse so for those who are officially titled as das wondering how you stand out from the rest of the crowd,data analysts how the hell do you stand out from other data analysts,data analyst vs data scientist
773,hi everyone i am currently working as a software engineer at a large company i got this job after undergrad and most of my skills are selftaught and learned on the job since my undergrad degree was in biomedical engineering i have been working for around years now and have gotten to a place where i would like to get a graduate degree in the field i am working in just to have some formal education behind my experience my bachelor is has helped in my job a bit but i mostly write code and analyze data i had planned on going into a master is program but dropped it when i got this job and now want to learn more about data science and get that master is degree i am looking at the uc berkeley data science master is online and the ucsd part time data science master is program would you recommend these anyone done them that can share their experience i think the courses and programs look interesting and i want to learn and get a higher education degree i have found that coursera etc does not work well for me because it is not application based and i cannot keep myself accountable thanks in advance for your help,software engineer considering a master is in data science please help,is a data science masters worth it if i already have a job as a software engineer
774,wanted to get this community is thoughts around this latest news article also included a response ampxb quote from the article please read the full article as it is short gtoften these studies are not found out to be inaccurate until there is another real big dataset that someone applies these techniques to and says oh my goodness the results of these two studies do not overlap she said gt gtthere is general recognition of a reproducibility crisis in science right now i would venture to argue that a huge part of that does come from the use of machine learning techniques in science ampxb i also found this respectful response from favio vasquez,discussion machine learning causing science crisis,is there any merit in using data science to improve the lives of customers
775,hi my team just received an excel file with data from glassdoor reviews for our company for the last years the data contains job title quite a few blank fields review city and state names quite a few blank fields current job yn rating from if blank to highest rating for overall satisfaction career opportunities comp and benefits senior leadership worklife balance culture and values business outlook getting worse staying the same or getting better recommend to friend yes or no ceo approval approve no opinion no rating or do not approve pros and cons as free text fields i have been playing around with the data i was wondering if any of you had suggestions on interesting ways to look at this data to get insights thank you,ideas on how to analyze glassdoor data,is it worth taking a job offer with no compsci background
776,hi ampxb i have a dataset of very highquality images my goal is to detect the sponsor logos that are present in the game when it comes to the logos the model does a great job ampxb every single logo in the game is detected well however i also get these false detections in the pregame section of the event ampxb of the dataset is a distractor set to help the model generalize better and not overfit however the results are the opposite of what i hoped this model trained for a fullday on colab pro and like i said it reached a best map of ampxb why would this happen how can i improve my model,false detection when running a test on yolov weights that have map,detecting false positives in google colab
777,hi recently i get accepted on a university and i listed ds as my major i have no idea what it is what does it do what i need on my college and i have no programming backgrounds do not worry i am still on my way learning python i did my best to know what ds is from asking my friends that workinternship on computer science google etccan someone explain it to me what is ds what makes it differents from any data job in example data analyst data engineer etc laptoppc specs do i really need high end gpus from what i understand i only need cpus with high cores and mediumish gpus like gtx super,what is data science,what does a data scientist need
778,say for example i have a dataset containing transcripts of a dungeon master interacting with his players i will have a sentence like gt you examine the obsidian stone and feel an unusual coolness underneath your fingers it glows with a magical aura what i would like to achieve is a model that can spit out something like stone as a probable material object with obsidian as a modifier and tell me that one of its properties is unusual coolness or coolness that is modified by unusual etc i am basically describing a tree diagram for sentences with tokenization of information such that it can be manipulated by programming logic what sort of machine learning concepts could i learn that would apply to this situation i am familiar with the basics of neural networks and their structure but most of my knowledge is practicallike taking an existing model for tensorflow and finetuningrunning it with offtheshelf libraries i have only coded a cnn for image recognitiona simple written letter classification program,i need some help learning what it is i need to learn so i can accomplish this machine learning goal basically extracting tokens and context from natural language paragraphs,what is the best way to train a deep neural network on a single set of data
779,so who are we and what do we do founded as adp dealer services in cdk global is the largest global provider of integrated information technology and digital marketing solutions to automotive dealerships and manufacturers in more than countries worldwide for the worlds biggest car brands although we operate on a global scale we are small by comparison and that is a good thing it means that we are still a business where every person matters and where anyone can make an impact on our growth and successwe have opportunities in a wide range of business areas so wherever in the world you join us you will get the support training and tools you need to make significant steps forward in your career purpose of role provision of an excellent support service is critical to the achievement of cdk globals strategic plans for growth and profitability the support analyst will have expertise relating to a specified cdk product module and will serve as a point of escalation within a customer support team assisting colleagues in addressing customer enquiries and achieving successful call closure working as part of an assigned team providing support you will assist colleagues in dealing with technical enquires and may deputise for the team leader in their absence this role requires someone who is a specialist in bespoke software support you have a background working in a technical problem solving customer service environment and have experience of investigating and identifying solutions to a range of situations you have outstanding verbal and written communication skills are resourceful and well organised and are prepared to take responsibility for successful issue resolution you have a passion and commitment to providing service excellence key duties amp responsibilities providing support to support analysts to ensure calls are accurately investigated and ensuring the cause and the symptom of problems are identified and resolved analysing and resolving complex product issues using analytical technical or programming skills responding with empathy to customers dealing with their needs and acknowledging their operational pressures and deadlines guiding advising and coaching both colleagues and customers on issue and problem resolution documenting solutions and producing written guidance on resolution steps and procedures proactively acquiring knowledge of the cdk global autoline product suite and associated toolset and working closely with management to increase the technical level of skills and competence of colleagues reporting issues and recommending process improvements to other teams to minimise queries and problems arising and to increase customer satisfaction levels deputising in the absence of the team leader liaising with other cdk global teams or departments to develop and to maintain high levels of customer service and effective resolution of customer enquiries key results indicators amp measures of success service responsiveness productivity and time to resolution to agreed standards resolution of calls problems within defined deadlines positive engagement and customer satisfaction demonstrated by customer feedback from csi survey achievement of departmental objectives demonstrable contribution to continual improvement of support processes and practices evidence of ability to provide effective coaching to support analysts who do we look for we look for people with the right cultural fit that means being passionate and enthusiastic and having what it takes to drive our business forward we also look for people who are keen to develop new knowledge and skills because our growth is ultimately dependent on yours skills knowledge amp experience high level investigation analytical problem solving and trouble shooting skills ability to efficiently plan and prioritise workload to meet deadlines superior communication skills including telephone virtual methods written and verbal skills in local language and english knowledge of customer expectations experience of working with customers demonstrable ability to influence and overcome objections ability to work as part of a high performing and cohesive team ability to interact with all levels of cdk global customers and associates coaching and mentoring skills desirable bachelors degree or equivalent experience essential specialist technical professional qualifications or working knowledge in one or more of the following areas as determined by the role assignment erp application support module specialisation years of supporting customers to a satisfactory level of performance productivity and customer satisfaction recognised technical coaching ability what can we offer you to help us attract and retain the best we pay people according to performance not tenure excel in your role here and the rewards will be excellent too we will also help you to grow your career not only through focused investment in learning and development but also by enabling you to explore the opportunities our global market has to offer apply here,cdk global is looking for a support analyst in hungerford uk,how to find a mentor
780,hi everyone recently i started studying a graduate diploma in data science online but i am really struggling at the moment we do not have any labs just diy exercises weekly lectures are hours each with mostly the lecturer reading slides and consultation times are mins each student per week i have no one to discuss my learnings and concepts with and i have no source to hear other peoples thoughts do you have any recommendations on where i can participate in these types of discussions for example right now i am studying big data processing parallel sort parallel join etc but i cannot even find anything online about these practices that are newbiefriendly any help would be greatly appreciated and i would love to connect with people in the field i am feeling very disconnected from everything right now and only have my lecturer is weekly mins to reinforce my understanding,struggling with lack of discussion,how do i learn about data science from scratch
781,fellow redditors currently a master is candidate working on thesis please excuse me if i sound whiny not my intention i just hope to seek guidance especially from those of you in the industry on whether data science is even right for me as i started to work on realworld big data for my thesishave not been having fun as much as i did when i was learning theories in lecture halls as a matter of fact i am downright miserable as i google for hours to debug my code or wait hours after hours to tune hyperparameters with gridsearch and i cannot imagine the extent of preprocessing coding building scalable infrastructures and selling your work to laymen getting any better in industry so a few questions am i just not fit to be a data scientist if i dislike coding and do not have much talent for it or does it get better that is either would i get used to it or would enormous coding projects become more manageable in teams for example i am actually not too used to tensorflow which i have to use and the learning curve is pretty damn steep for me what was your expectation going into industry what caught you off guard if anything really sucked in industry did it get better if so how despite the no two days are the same nature of ds does it ever feel mindnumbingly repetitive what does the career progression feel like since ds is a relatively new designation at most companies i would imagine there usually are not clearcut progression tracks does this bother you at all have you seen any data scientists that move up the ladder in creative ways do you happen to know anyone who was at a similar crossroad and decided to move away from ds what was their thought process do they regret not going the ds route thank you in advance for your thoughts,is data science even right for me,is ds the right career for me
782,hi i am currently a junior in college and i am trying to decide between two internship offers for summer i have an offer from amazon for a software development engineer internship and an offer from jp morgan for a data scienceai internship i ultimately want to become a data scientist so i am leaning towards jp morgan but i have some concerns and i would appreciate some advice i already accepted amazon is offer back in september i applied to both amazon and jp morgan in august did not hear back from jp morgan so i accepted amazon then i got an interview with jp morgan in october and i got the offer in december so if i take jp morgan i would have to renege on amazon amazon has a better location and higher salary those are not a huge concern for the internship but the location would be a plus if i get a full time offer there however i have heard bad things about amazon is culture so i think it would be better to work at jp morgan full time for jp morgan i can choose between two teams hr data and analytics solutions for amazon i do not know anything about my specific team yet but i know that the office i got assigned to has teams that work with devices and ground stations both of these sound more interesting to me than the jp morgan teams but i would be doing software engineering work instead of data science so there is a tradeoff i am also worried that a software engineering internship would make it harder to get a full time job as a data scientist overall i am just confused about which would be the better option and it would be super helpful to get any advice from people in the industry thank you,amazon sde intern vs jp morgan data science ai intern,jpmorgan or amazon for data science internship
783,i am a recent maths graduate applying for data science jobs by far my strongest language is python and i have some experience with r and sql in many job posts unsurprisingly i see that they ask for proficiency in at least one of pythonr among other things one thing i have noticed more and more is a demand for expertiseexperience with javascala usually at least one of the two it would be great to get some insight from practising data scientists into why this is the case perhaps some examples of where one of those two are better to use over python and whether ianyone looking to break into data science should dedicate some time towards learning them thanks in advance,javascala in data science,how much python knowledge do data scientists really need
784,hi i am new to the field of bi and i have two pending offers one from an established multibillion dollar organization and a fancy title with lead in it and another offer from a growing midsize org with a basic title both are bi roles doing similar things except at the smaller company i would be communicating with senior leadership more big corp wants contracthire with a pretty high conversion rate the difference in pay is about k usd big company pays more the big company is also pretty notorious for it being difficult to move up as many big companies are my goal is to get a pay bump in years from k to kk from more experienced people in the fieldwhich is the better option for longterm progression,career question big org w fancy title red tape or midsize w more freedom,is it worth taking a pay bump to lead a team
785,hi folks i am a dev advocate on the emr team at aws and i recently did some analysis for a new feature we launched that i thought others might find useful fire season is quickly approaching already here out on the west coast last year i was glued to various air quality sites but i wanted to dive into the data and make my own map in case those sites get overloaded again i used bokeh for the data visualization openaq for the air quality monitor data censusgov boundary files for county and state geo data and geopandas for reading in those shapefiles and reprojecting to a conic us map then i put all this together on top of emr on eks spark on kubernetes that now allows you to build your own custom container images i wrote up a stepbystep guide to doing this here as an example here is an image i generated back on june th,build your own air quality map with openaq and emr on eks,looking for a data scientist to partner with us on a project
786,i am modeling a noisy dataset of id is and have been tasked with creating a model to predict whether an id exists at some arbitrary point in time this is necessary because an id may not be observed at any particular time step let is say week the idea is that if an id does not show up for that week it may or may not have ceased to exist you can imagine if the id has not been seen for more and more consecutive weeks the likelihood it has ceased to exist goes up are there any preestablished approaches to handling this sort of persistence problem i have already built a basic supervised learning model for the problem using exogenous and endogenous variables that works fairly well but wanted to see if there is any work that is been done on this sort of problem before i do have ground truth labels that are more accurate for the case when an id reappears hence taking the supervised learning approach,modeling approach for id persistence,is there an accepted stateoftheart for when training a model on a set of variables
787,i made a germanenglish model using the code given in this repo i can evaluate the loss of the model etc but i do not know how to write a method that would take in a german sentence and output the english translation however i want to calculate the efficiency using bleu scores but as far as i know i will have to use the model to translate a german sentence and then compare the english translation with a reference sentence but i do not know how to use this model to actually perform the translation any help would be greatly appreciated tldr need help writing a function that uses the model in the link to translate given sentences from source lang to target lang,need help calculating bleu scores for this model,how to calculate the loss function of a model
788,my partner is a data scientist and is incredibly typea he enjoys building things lego puzzles watching the stock market and is always learning more about his jobfield of work i am quite the opposite and i am having a hard time with part of his gift i do design work industrial floriculture so i would love to be able to design it or get inspiration from something i know a lot of people may say galton board but im not sure if he would actually enjoy that or not he is super minimalist and doesnt buy things just to have them it has to be something he really wants anyway if you have made it this far thank you so much and i would love to hear any ideas not for christmas just planning for his birthday in the coming months happy holidays,help selecting a gift,i would love some advice on what to buy for my data scientist partner
789,i have just started studying neural networks and i managed to figure out how to derive the equations necessary for back propagation i have spent nearly days asking all of my professors and googling everything i can find my math skills are admittedly poor but i really want to understand how this particular formula mathematically makes sense the formula is used to update the weight after the gradient has already been found w w l dcdw where w new weight w old weight l learning rate dcdw the partial derivative of error function and a member of the gradient vector of the cost function what i know so far the gradient is a vector of it is partial derivatives and the maximum rate of increase is given by the gradient itself each partial derivative gives the maximum rate of change in the direction that the derivative is taken with respect to dcdw is one of these partial derivatives dcdw evaluates to a rate of change it is sign can tell us the direction of change the value itself is the proportion between change in cost and change in weight at a particular weight somehow multiplying dcdw by the learning rate is only taking a small portion of this rate as the change in weight what i cannot reconcile the learning rate is just a scalar without units how is it possible to just multiply a scalar by a rate and end up with a measurable change in weight what am i failing to understand here i would love answers clues resources or any kind of help as soon as possible thank you guys so much,what is the mathematical intuition behind gradients in a neural network,how do we calculate the derivative weight of a neural network
790,i am using a wordpress plugin called easy azon to add amazon links for different amazon affiliates programs to my blog it allows you to cloak your links to a subdirectory of your website like this goproductidusamazonid i do not have access to those subdirectories to add ga code to them is there a way i can track these links in google analytics i would like to be able to see which traffic sources and pages on my site are driving the most clicks to amazon i am familiar with ga on a fairly basic level but most of the tutorials i have found online for accomplishing this require you to add code to the subdirectories which i cannot any advice would be really appreciated,tracking cloaked affiliate links in google analytics any advice,can i track clicks on amazon links with google analytics
791,hey guys i am a data science student and i am required to make a sentiment analysis project using python and twitter data i should use python numpy pandas matplotlib scipy scikitlearn seaborn beautifulsoup scrapy tweepy igraph twitterapi nlp to do the following tasks load data from twitter data analysis transform of raw data into graphs analysis of the impact of results on a financial market i have already learnt how to get the data i might need using tweepy but i am really struggling to find a good idea for the project as i do not use twitter and do not know what information can be interesting for a sentiment analysis which can have an impact on the financial market for example i would be really grateful if anyone could help me to start by suggesting a certain objective or idea or showing me something that is already been done in this context and giving me some hints on how i should proceed thank you,i need suggestions for a sentiment analysis project,twitter sentiment analysis
792,i am managing my first data science project at work and my boss keeps asking me how much data i think i need i really have no idea what to say if i had a lot of previous experience i might at least be able to say something like well i had suchandsuch amount of data on this other project and we achieved thisorthat success rate on it but i do not i try to tell him that i do not really have any way of answering that before doing any training but i think he has it in his mind that i should be able to give him a number and the data we need is hard to get so i know that comfortably large data sets are pretty much out of the question have any of you ever gotten that question and if so how do you answer it,what do you say when they ask how much data you need,how much data do i need to know for a project
793,i am well aware that this question is as broad as the pacific is deep but i am interested in hearing some general discussion about the topic obviously one of the first steps in a ds workflow before getting to the fun parts is to do the exploratory data analysis usually this has a number of goals usually but not limited to outlier identification identifying necessary data modificationwrangling multicollinearity assumptions distribution linear relationships transformation high level variable selection other for the most part i and i assume many others just do the basics boxplots scatter plots examining the data structure in a dataframe or similar run some basic statistics etcobviously it will be data and case specific each time but for those who have had more exprience what is the workflow that you generally follow for the eda which visuals do you usually output which ones do you focus on the most any cool packages that you have found that help you along or that really streamline specific parts thanks in advance,whats your exploratory data analysis eda sop methods tips and tricks,how do you handle outliers in your ds workflow
794,hi reddit happened upon a facebook ad for the northwestern data science bootcamp and i am trying to decide if this is worth my time and money i am working on some personal projects on my own and have some prior experience in coding but i feel like this covers so many subjects that i would not know where to begin with on my own others have recommended online courses and i have had some luck with those in the past but have found that my motivationtime to dedicate to these ebbs and flows based on other things that are happening in my life a little about me yo employed fulltime with a techdata company i get to use basic sql and a little bit of plsql in my daytoday so i am fairly proficient at that but i know i could get better my company is also pushing ai very heavily recently so any experience even basic i can get with that will be beneficial i believe i have some prior coding experience as i mentioned earlier i took several cs classes as an undergrad and am moderately proficient in c and python however i was not a cs major nor did i finish the minor so i am just a guy with a passion for coding my employer will likely reimburse the cost of this course up to so after a bit of googling it appears i will only pay around halfprice is this worth it,is a bootcamp worth it,is it worth getting a masters in data science if i already have a job as a data scientist
795,hey guys i came across a case study for an interview the dataset contains number of app downloads over a period days labelled as follows first days are normal days next days the company ran an ad campaign on tv and the last days are post campaign days the question is to check if the ad campaign has any effect when plotted this data is found to be cyclical my approach was to use the first days to build a time series model based on first days and use it to predict the downloads for the next daysie simulate how the downloads would be had there been no ad campaign and compare these values with actual available data with a ttest is this approach correct would appreciate any suggestions,what is the right approach to this problem,how to measure the effect of ad placement on app store data
796,i work at a state park and the park manager has me and a coworker at the main entrances of two parks under his jurisdiction asking each car that enters what zipcode they are coming from i dont know the exact reason for this but i would assume it is covid related to send the data off to the state government all he wanted me to do was to record the zipcodes on a piece of paper for him to send in at a later time but i figured that using excel to record them would be a much easier way to read the data in the end if they want to get nit picky so i fired it up and ive never really used it before so i had to figure out some of the different simple functions to make it so i didnt have to do a bunch of stuff in my head or calculate it then i tried to make it easy on myself and learn how to use the geography data type feature that is built in but couldnt figure out how so i had to look up the towns associated with the zip codes one by one is there a more simple way for me to just have excel fill in the towns for me also i would like to make a heat map or something of the sorts showing the most popular zip codes coming to the parks but i think my college has blocked me adding the bing maps addin to excel is there any other feature that is free which i could use to create a heat map of the zip codes thank you and sorry if this isnt the proper sub for this question tldr looking for a way to heatmap zip code data without excel for free and also find towns associated with zip codes on excel as well,analyzing zip code data for work,how do i find the best free or very cheap data to analyze
797,hey we are collecting data for research and we need your help we collect images of different document types that are typically filled out using handwritten not printed text these documents need to cover several types including applications invoices tables medical prescriptions contracts bills blackboard bank checks handwritten notes travel entry forms etc the reward is dollar per images there are data requirements handwritten text should be more than of the page the resolution of the image should be at least w format type for the upload should be in the jpegs format only the photo taken for this project photo taken recently will be accepted the text lines in the photos should be easily recognizable for human transcription the native speakers should write in natural style while taking a picture the horizontal direction of the image should be in parallel with the content reading direction the image contains no more than one pages no mixed languages avoid too many mathematical or chemical formulas on the page no personally identifiable information includes personal full name mailing address email address phone numbers social media handles ssn numbers tax ids passport numbers driver license numbers and license plates credit card numbers bank account numbers and bank routing numbers should be present in the images using the pen or correction tape to erase the text area is acceptable data will be uploaded through our app pictures without camera information will be rejected the maximum of each category on the same patternformat images the maximum of handwritten notes on the same patternformat images the maximum of each category from one person images the horizontal direction of the image should be in parallel with the content reading direction try to type more text that are hard to recognize when uploading avoid taking a lot of photos with the same background if you are interested please contact me here are some examples imgoxppeid imgpjponqid imghnfrxuid imgrhunid imgcuksid imgobjkpxqid imgqtphbpid imgmanwiid,collecting images of handwritten text with reward,i am trying to build a dataset for a school project and i have a few questions
798,hi i am trying the course on deep learning by udacity on the fifth assignment you have to train a wordvec skipgram model against a dataset called text the course assignments are inside ipython jupyter notebooks ampnbsp everything is working fine when the model is trained the embeddings work as expected for example using the cosine distance the words near king are the expected ones like prince or istate etc a tsne generated graph also shows that related words are near each other ampnbsp the problem i am having is i cannot get any meaningful example of embedding arithmetic to work in the internet there are many examples of operations like king aman woman queen that are helpful to gain intuition about the meaning of the embeddings ampnbsp what i am doing is just taking the embeddings for those words and adding and subtracting them then searching the nearest embeddings to the one i get by using cosine distance after normalizing like nearest_words_tonormalizeembeddingking embeddingman embeddingwoman instead of queen the nearest words i get are king and woman which i do not know how to interpret ampnbsp get the embeddings of the words involved in the arithmetic test_relations_words king aman woman queen tf_test_relations_words tfconstantdictionarygetkey for key in test_relations_words dtypetfint test_relation_embeddings tfnnembedding_lookupembeddings tf_test_relations_words king test_relation_embeddings man test_relation_embeddings woman test_relation_embeddings queen test_relation_embeddings make the operation expected_queen kingmanwoman normalize the vector norm_expected_queen tfsqrttfreduce_sumtfsquareexpected_queen normalized_expected_queen expected_queen norm_expected_queen evaluate cosine distances to the rest of the normalized embeddings tf_distances tfmatmultfreshapenormalized_expected_queen tftransposenormalized_embeddings near_queen tf_distanceseval indices near_queen argsort for i in indices print the word is at distance from expected_queenformatreverse_dictionaryi near_queeni ampnbsp the word king is at distance from expected_queen the word woman is at distance from expected_queen the word son is at distance from expected_queen the word audrey is at distance from expected_queen the word emperor is at distance from expected_queen the word queen is at distance from expected_queen the word reign is at distance from expected_queen the word prince is at distance from expected_queen the word shimazu is at distance from expected_queen ampnbsp i do not know how to interpret this also i do not understand why tsne does not show clusters of words as it is supposed to do even in the original graph from the tutorial there are not any of them ampnbsp thanks,cannot find meaningful word arithmetic examples with wordvec model,question about word embedding
799,also posted to rmachinelearning for opinions i did some searching on different threads for situations similar to mine but would also like some specific opinions background i graduated from a decently prestigious university for undergrad with a dual degree in psychology and applied mathematics i then got an entry level data analyst job for the experience but would like to graduate to data scientistfurther in the future currently i am also teaching myself python through dataquest and the likes also potentially builds up portfolio i am learning a ton of sql and other visual programs such as vs in my first year at work dilemma now that i have gotten used to the work environment and not to mention my company is willing to pay for some tuition i feel like i have a great opportunity to pursue a masters as well this would have to be online as i have no plans to stop working fulltime and my local colleges do not offer programs to suit my question and interests narrowed down is cs or applied statistics my ultimate career goal is to do something with machine learning i understand ideally you need both subjects but i am ganna have to pick oneself learn the other as much as i can it looks like for cs i have narrowed my option to georgia tech is omscs program which i had to double take at the k price tag what a great price for to the best of my knowledge a great program that even lets you specialize in machine learning for applied stats i have also narrowed down the online options to penn state is program there are other schools but they are either more expensive psu is k for the degree or their course offerings do not seem as greatinteresting to me or both i feel like i would like every one of the courses that psu offers i am not interested in a pure ms in statistics because i just do not love the theoretical aspects of it especially indepth and i would rather do one of the others that i am more interested in my thoughts with this not being the first time cs vs stats is mentioned there is obviously no objective winner i feel like in this case with my current state and picks i would be better off choosing cs gt is program has a specialization in ml which is my end goal anyway plus if all else was equal k vs k is a no brainer however i have also heard that stats is harder to selfteach and a strong foundation is required would the statistics courses in a ml oriented cs program be enough convince me whichever way thank you,masters cs or applied statistics,is a masters in data science worth it if i already have a job as a data scientist
800,i am pretty new to the world of data science and am wondering which direction i should go next from what i have gathered these are the areas an aspiring data scientist should work on r or python programming statistical knowledge data visualization sql machine learning i am a phd student in the social sciences with a quant minor so my stats knowledge is solid and i have implemented various models in my own research or in class ols logistic regression multilevel models structural equation modeling etc all models implemented and visualized using r and ggplot right now i am working through dataquest which i have found great for learning python and i am almost to the sql courses so that leaves me to choose between focusing on machine learning or data structures amp algorithms which is more important or which is the next logical step in my learning experience thank you for your time,what to study next machine learning or data structures amp algorithms,what are the best resources for learning about data science from scratch
801,hi all i have two questions where does ip tracking stand in relation to ga is tos i read the terms here but there is no explicit mention of ip addresses from my understanding ip addresses do not quite constitute pii but it is a bit of a gray area our legal team told us in writing that it is okay to track ip addresses on our website but i wanted to check with you guys to make sure we will not be violating ga is tosbest practices if it is not a violation to do track ip i am wondering if anyone has had any luck implementing it as a custom variabledimension that can be used with the rest of the ga data for example would something seen in this blog work thanks,ip tracking implementation and tos questions,legal issues with tracking in google analytics
802,hi i am currently a research assistant in a longitudinal study currently the project is still in its initial stages this study would be an online survey i am tasked to handle all the data related tasks data management data analysis as i have just graduated psychology not long ago i have basic knowledge when it comes to stats and have not how to properly handleanalyse a longitudinal study to those who have experience with conducting a longitudinal study there are a few questions that i hope to clarify what did you used to programs to handle your data or is there any packages found in pythonr based on my research i only found redcap is there anything else how to analyse longitudinal data and deal with missing data based on what i have gathered multi anova repeated measure anova is unable to handle missing data is there any useful books that i can read to better equip me for the data analysis that i will be doing in the near future if there anything important or issues you previously encountered in your studies that i have to take note of please also let me know thanks in advance,need help with longitudinal study unsure of what programs to use and how to analyse data,how do you deal with missing data
803,specifically my problem is to analyze missions profiles eg think airplane flight profilemission for a close example and compare one mission to many others in the course of doing so pros and cons for the other missions should be taken into account and a suggestion should be made if a more optimal mission is noticed that is similar to the one i am analyzing i thought about running through some classification algorithms the basics of which i have been covering but not much beyond that but am hesitant because no two missions will be equivalent so realistically i am just looking for broad similarities and differences this is my first big jump into ml so any help or pointers in the right direction is fine i do not expect anyone to solve the problem just looking for a push in the right direction for research thanks,suggestions of where to start for similarity analysis using ml,looking for similar airbnb datasets
804,i am a data scientist with years of experience working as a team of one within an analytical unit of at a midsize company in a nice east coast city that is not nyc i have been offered a job at a fortune company with a team of embedded in a group of data scientists the new job would come with a higher total comp vs but longer commute in the short term i would move closer when my lease expired so that would end up disappearing although rent would be higher i want to become the best data scientist i can be and i am wondering if i need to make the switch to get the mentorship to develop those skills i read a lot on my own but have not gone to meetups before i would be very interested in going though i really like my current job and would not switch for the increase in pay alone the potential deciding factor would be based on increasing my skills and future career growth potential i would truly appreciate any thoughts or advice from all of you,individual data science vs part of a team,data science in the west coast vs nyc
805,hello everyone i am a junior data analyst for the sales team at my company this is my first real data analytics job so excuse my simple question my team has been given the option to choose either tableau or power bi to present our data right now we have all our data and presentationsdashboards in excel i am just now looking into the merits or down falls of both i was wondering if the wonderful people on this sub can share their experience with both tools some key points i am the only one on my team who is familiar with any coding languagepython vba sql so if the tool has a scripting language the closer to any of those the better as it will help me get up to speed faster i am learning power query and m language in excel right now but i am kinda hating it as it is very finicky with our ugly data a lot of our data is manual reporting which tool can handle dirty data better ampxb i mainly report my data to people but often send out to dozens of people is one tool better than the other at presenting to someone who might not have a paid user of that tool which tool is more sought after in the industry i do not plan to leave this job any time soon but learning the more popular tool is of higher importance to me,would you recommend tableau or power bi,i am a new data analyst and i do not know what to do
806,this is a big decision for me to make and i feel that there is no better place for me to look for for some support than this community so im hoping youll bear with the length of this post and provide some solid feedback i have reviewed other similar posts re going back to school to pursue a phd but did not find any with a similar context which is why i chose to write this post at length there are several questions at the end of this post that im looking for concrete answers to the context i started a specialized diploma in applied computer science in got super interested in data science and dropped out to pursue a selfstudy path through coursera just before moocs were mainstream i have been working in the software industry for seven years years as a software engineer and years as a data scientist unfortunately ive been the only data scientist in the three different organizations ive been employed at and havent had the opportunity to grow as a professional data scientist which isnt to say i have grown as a data scientist or professionally within a professional context i have learned a lot about business business and data strategy scoping data problems and software development and have had the opportunity to work on a lot of endtoend data problems none of which made it to production ultimately i dont feel like ive delivered much tangible value to the organizations ive worked at while in a data scientist role my work has mainly positioned them well with pocs and educated them on internal and customerfacing use cases ive also never had anyone validate my approaches or results the closest i get are responses from the online community to questions i post when im really stuck over the past few years my understanding of applied predictive analytics ml in the context of real world problems and inferential statistics has improved mostly from countless hours of learning concepts and speaking with business stakeholders it pains me to say ive completed a total of three portofolioworthy projects which are mediocre at best eg achieving an fscore of on a realworld multiclass classification task i completed for work and have only participated in two kaggle competitions ranking low on the leaderboards im totally aware that more of my time should have been spent completing projects and building my portfolio rather than learning reflecting on my interest in learning over implementing has hinted toward the fact that i will probably enjoy a career in research so all of this coupled with a strong interest in ai more agentbased models rather than dnns like the content in aima by norvig and russel statistics biology math and solving hard problems has me seriously considering going back to school to complete an undergrad then postgrad programs im sure being jaded has something to do with it but ive become quite depressed at thought of the path im on being stuck in this data scienceteamofonewithnoproductionprojects role even if i get to do real data science i dont like the thought of working directly on impacting the bottomline i want to do science work on the cutting edge and have a larger impact with my work im fine if my work indirectly impacts the bottom line the plan completing my diploma in q with a comprehensive project to demonstrate my industry experience going back to school in q to complete my cs bsc within years years thanks to a local college university partnership that i qualify for after completing enrolling in a msc program in hopefully fasttracking to a phd program by getting an ideally highpaying research position as a scientist doing work that im passionate about by i would love to work for a big tech firm like microsoft deepmind netflix or a company doing precision medicine like i want to clarify that my motivation for doing a phd is not moneydriven but it would be nice if my hiatus from fulltime employment for years pays off from a financial perspective to be clear im interested in a phd because i want to be immersed in a field of study that im passionate about become an expert in it and do proper science to advance that field i feel going back to school will also help develop my critical thinking skills which i feel need work here is where it gets tricky ill need to work parttime throughout this whole endeavour thinking hours week this might be possible at my current employer definitely doable at a previous employer my strategy is to negotiate a higher salary to offset reduced work hours i want to get married and start a family within the next years my girlfriend and soontobe fianc she doesnt know it yet is ultrasupportive of this move i still want to make gt k annually after completing my phd to support the lifestyle i want for me and my future family the computer science department at the nearest university western university formerly uwo doesnt appear to have strong ai research areas see my questions for you career does this sound like a reasonable path to take given my career trajectory to date and passion for research am i sabotaging my career to provide some more context data scientists are in low demand in the area lots of tech companies but most are late majority laggards when it comes to creating a ds capability and are paid less than software engineers are there still going to be lucrative career opportunities in ai in the next five to ten years for a year old doing ultraspecialized work in eg computational genomics if i complete a phd in a focussed area like computational genomics as opposed to machine learning deep neural nets will the big tech companies still consider me for research positions one of my biggest fears is that by the time im done my phd technology will have advanced so much that either my expertise will become outdated or the problems will have already been solved is this a rational fear academic am i able to find a research topic that really interests me or does the university faculty need to have expertise in the specific topic that im interested in eg if i wanted to do research in largescale casual inference in genomics does a faculty member need to already be doing research in this area is there such a thing as leveraging expertise from two different faculties doing a phd that spans multiple disciplines eg statistics and computer science what are some open research areas in ai that excite you and that will still be relevant in the next ten years i want to futureproof my move in the best way that i can math is a weak point for me ill be taking some math courses in the cs bsc program but not sure if it will be enough for a grad program should i look at doing a minor in math instead of statistics or specialization in bioinformatics what are some interesting research areas in agentbased modelling a sincere thank you if you read this far,should i quit my data science job in industry and go back to school at to complete an undergrad degree and a phd in ai,is it worth getting a masters in data science if i already have a job as a data scientist
807,hi everyone my name is pani i am currently enrolled in a business administration diploma with a finance specialization but lately i have been more interested in the data analystscientistengineer type jobs i am curious if it is possible getting into these roles without having a degree in computer science or statistics for example has anyone tried also i would like to move more into a data science job combined with my finance background here is an example of the job description for a data analyst job at a bank participate in all aspects of a systems development life cycle within the development team facilitate discussions with business clients document business requirements and service level agreements turn business requirements into data model and generate source to target mapping and other technical documentation data transformations design and operational support documentation analyze data in hadoop big data environments and structuredsemistructured unstructured data from various sources ensure compliance with all applicable data regulations and policies apply a variety of analysis tools to interpret data and identify patterns works with key stakeholders within all business functions to align technology solutions with business strategies gathers requirements from business units and translates those to programmers and developers demonstrates an informed knowledge of business functions to resolve problems and capitalize on improvement opportunities works on multiple projects as a project team member serves as a liaison between the business community and the it organization in order to provide technical solutions to meet user needs bachelor is degree in a technical field such as computer science computer engineering or related field required years of experience as a data analyst information analyst business systems analyst required must have extensive knowledge and experience with sql talend datastage nice to have python sas experience with big datahadoop technologies right now i am enrolled in a few online data analyst courses on udemy and coursera would there be anything better to start learning or possibly a better road map for selflearners with so many skills needed it becomes quite confusing from what i have read the path goes data analyst data scientist and then data engineer,data analyst route,data scientist to data engineer
808,hey im currently a junior mathematics major and i just found an internship opportunity with a professional sports team i need advice as to how to increase my chances of getting an internship with them if this is not the right subreddit for this kind of question please point me in the right direction but if i can ask it here what are the best ways of increasing my chances of at least getting a call back the internship does not call for any programming skills but its still a great opportunity to get my foot in the door in the industry im very interested in thanks and hope to hear from yall soon,help with internship possibilities,data science internship
809,network data can be conveniently modeled as a graph signal where data values are assigned to nodes of a graph that describes the underlying network topology successful learning from network data is built upon methods that effectively exploit this graph structure in this work we overview graph convolutional filters which are linear local and distributed operations that ade quately leverage the graph structure we then discuss graph neural networks gnns built upon graph convolutional filters that have been shown to be powerful nonlinear learning architectures we show that gnns are permutation equivariant and stable to changes in the underlying graph topology allowing them to scale and transfer we also introduce gnn extensions using edge varying and autoregressive moving average graph filters and discuss their properties finally we study the use of gnns in learning decentralized controllers for robot swarm and in addressing the recommender system problem link,research paper graphs convolutions and neural networks,research graph neural networks for distributed data
810,hi i am currently a graduate student who is graduating in august and is entering the workforce i am completely stumped on how to prepare for the job market and i am looking for guidance on where to begin a little backstory on myself i have been living in the united states for the past years and have received a bs in computer science in during this time i was an extremely troubledunfocused student who was fighting severe depression and did not perform very well this led me to be on academic probation two times but i managed to get myself reinstated right away another consequence of my choices meant that i was not able to get even a single internship throughout my whole undergraduate career to add to the stress i was an f student due to my parents receiving their green card after i turned with the opt optional practical training around the horizon i got scared and decided to enter into a master is program in data science this bought me an extra years i managed to turn my life around at this point and with the fresh start and a tremendously patient advisor i managed to achieve a and will be graduating with a in august i know gpa might not mean too much during someones graduate career but to me it is a good sign of my personal progress with my advisor is help i was able to join get a gra position doing research in instance segmentation using mask rcnn and timeseries wind power forecasting using arima and lstm with economic dispatching the instance segmentation project got acceptedpublished at the bigdata conference for a poster presentation and i was able to get a trip funded by my school which was truly a great taste at success i have one more paper already accepted and waiting to be published in the journal of building engineering along with one more paper on the same subject being prepared for an ieee submission i already have work on the forecasting paper and once all the results are in we will be looking to publish that one as well i am a coauthor on all of these papers i am not back in the same situation i was in a year and a half ago i am graduating and this time my opt application has already been submitted and the start date is in september this leaves me days to find a job before i face deportation i am trying to prepare for interviewsjobs and am struggling to find a starting point i have taken several statistic classes in the past but unfortunately the suit of tests i used during my graduate career was not all allencompassing to add to this the data science program at my school is extremly new and i will be the first graduate from the program so i am not able to find much success talking to my peers one flaw i noticed in myself is that my statistical background is not as strong as i would like after doing some research i have found two books i am currently reading through to refamiliarize myself with the basics of statistics these books are think stats and think bayes i would love your suggestionsopinions on these books or any others that would be a good fit for me to add to this i have also registered in some edx courses on statistics and i am working through them in conjunction i am trying to find positions where i am using machine learning and doing analytics apart from just reviewing the basic statistics i mentioned above what else should i be focusing on to better prepare myself the skillset i am trying to sell myself on is that i am proficient in python java the concepts of oop and software development i have experience creatingvalidating ml models using tensorflow and r i have extensively used relational db mysql and some experience in object relational db oracle i have extensive knowledge on the unix system but can work just as easily on all os is lastly i am versed in readingwriting documentation with this in mind where should i start what resources should i be using as i mentioned i have just a little over days to find a position and the stress of that is fogging my head what should i be focusing on,masters in data science need guidance,i am a year old and i feel completely lost in my career
811,ampxb would it be hard for me to find my first job at the age of given that i have a phd on machine learning i might be able to do some interns during undergrad and phd but not a full time job i have been coding for hobbies and got interested in machine learning stuffs i am considering to enroll in computer science undergraduate program and go for phd in machine learing i am afraid my age would be a serious problem in my career also what i have been doing till nowi am years old is completely irrelevant to tech would i be able to find a job at the age of after i am done with phd also should i expect to be laid off at s i have seen a lot of post about ageism in tech and its extremeley depressing btw tution and other stuffs will not be of a problem since my parents have pledged to support me until i finish my phd,is ageism prevalent in silicon valley would i have a hard time finding a job with a phd on machine learning at the age of,is it worth getting a phd for data science
812,hello dear machine learning community i am a newbie in this field and i have a few questions first question i have features to predict one number lt number lt with polynomial regression what would be considered as a plausible sample size to reach an accuracy of roughly second question how can i improve my polynomial regression model the following is my regression splitting and training written in python using scikitlearn library what can i do in order to further improve the accuracy split the dataset into training set and test set from sklearnmodel_selection import train_test_split xtrain xtest ytrain ytest train_test_splitx y test_size training polynomial regression model from sklearnpreprocessing import polynomialfeatures standardscaler from sklearnlinear_model import linearregression poly_reg polynomialfeaturesdegree x_poly poly_regfit_transformxtrain poly_regfitx_poly ytrain lin_reg linearregression lin_regfitx_poly ytrain thank you very much for your input,help general questions and scikitlearn polynomial regression model improvement,how to train a regression model with multiple features
813,i am working to become a data analyst in the environmental field i got my ba in environmental studies and will be starting a certificate program in data science this coming fall i have already learned python and the apps arcgisqgis fairly well and am taking a couple stats classes this summer i know i will need a master is though and am considering environmental informatics environmental science gis or a similar field as a possible option with the potential to obtain a dual degree i think any of these would be adequate approach if i had taken more stem classes during my undergrad perhaps i would be better equipped to go into a more specific field hindsight is though so i am trying to make due with my life decisions however i would not mind finding out how others have faired if you work as a data analyst in the environmental field how did you get to where you are now any advice,looking to find out more on the intersection between environment and data science,environmental analyst to data scientist
814,i am currently working as a data scientist for a logistics partner for a tier tech company i am expecting job offer from a tier financial services company for the position of business intelligence would choosing business intelligence be a good idea or a bad idea how is the future path looking for me if i accept this offer i understand that business intelligence is descriptive analytics while the data science role is predictive i enjoy both but what would pay me more in future and what positions can i transition to from the new role any guidance is appreciated thanks a little background on me im a recent graduate with masters in computer science years of data science experience led teams in all positionsinternships college research positionspart timeetc publications focused towards financial sector other towards statistical analysis in geology,data science or business intelligence,data science vs business intelligence
815,i am a beginner in deep learning and doing lip reading as my project my dataset is gridcorpus i split and segregated the video frames according to the words spoken that is for the word four there will be the video namebbafa and inside that series of frame that represent the word now my problem is the word spoken by one speaker takes framesspeaks fast and for another speaker it takes framesspeaks slow i have an idea of sampling the frames to maintain a definite size ie every video should contain only key frames is that correct what should i do how can i proceed with this in feeding the nn thanks in advance,dealing with video sequences of variable lengthshort and long,how do i train a lip sync model
816,post copied from rlearnpython which is why i stress python throughout fyi hi all i have used python occasionally in the past at my current job which is sort of research focused so i work with datasets data cleaning merging etc looking to transition more into a data scienceesque job which seems to be basically what i currently do now except more advanced at a bigger company only like years of work experience did not major in cs but did do social science and stem bachelor dual majors at a very good us university for background a few quick questions mostly related to imposter syndrome perhaps not i feel like i write very straightforward code in the sense that if i am tasked with a dataset and need to clean and reorganize it i will do the straightforward thing to get from point a to point b once i check out a dataset and know the typically notthatcomplicated instruction on what i need to get i will instinctively have some ideas on what to do obviously while implementing i will run into some issues dataset not cooperating with parts of my code etc but i can usually figure out a workaround however the code is not sexy so to speak at least in my view but i do document my code or write a quick comment here or there use understandable and intuitive variable names and all the good coding habits mostly there are times i go back afterwards and look at my code and think yeah i could have maybe turned this section into a function since i reused it a couple of times and just copypasted each time and similar stuff but the code works fine and people should be able to follow it since it feels braindead straightforward from how i approached and programmed it i feel slightly weird about this because it feels like all the stuff i do is super basic that anyone can do is this just a case of imposter syndrome with coding or am i possibly underselling myself mentally programming by googling i must say i retain very little syntax since i swap between a couple of coding languages eg r matlab and honestly i could not care to remember all the details if i type something wrong and my program does not run i will just fix the error that pops up when my syntax is off but more specifically let is say i need to use pandasnumpy to reorganize datasets i do not have basic pandasnumpy memorizedeach time i will have to go look up a quick tutorial on some common functions but once i remember the syntax everything is easy since i know pseudocodewise in my head what i want to do to get from a to b for instance in my head i will be like oh okay i need to delete these columns since we do not need them then join a to b sanitize by removing nulls in this column etc each of those steps i might forget how to do so i will just look up how to delete a column pandas how to join tables pandas how to find nulls pandas grab the line of code then throw it into my program seconds later my code runs and gets me a nice dataset for the next step and i forgot not really how to do the previous stuff already again i feel slightly guilty about this since i do not really have things committed to memory but part of that might be i do not use python a ton but is that going to hurt me or is the fact that i know what i want to do and can quickly google the syntax line more important in the longrunrecruiting stage how much python do i actually need to know for a somewhat entry to midlevel data science job i look at a lot of crash course in python for data science stuff that people praise online and i look at the syllabus and they cover for loops importingexporting data creating plots etc i do all that sort of stuff in my current work albeit not necessarily in python and i have been told and i know that i am a quick learner with good communication skills so i know that if my tasks are here is a dataset clean it export it create some plots to visualize the data in python i can reason out what i need to do after confirming exactly what needs to be done and then go googlesearch up the appropriate code to put the pieces together see question so in effect i already know the material in the course the fundamentals behind loops dictionaries etc and i can work out the syntax easily with resources but that seems super basic no which is why i am sort of unconvinced that my current skillset is enough for an entrymid level data scienceesque job again maybe imposter syndrome i have been coding occasionally since high school currently mids so i definitely have a decent mindset on knowing how code works and it feels like second nature to implement all the basic stuff which is why i say i write straightforward code but it all feels too simpleam i correct in that i should be looking for more specific advanced stuff which is tacitly required for a strong entrymidlevel data science position or is it really just that is truly what you need to get your foot in the door and you will pick up skills as needed by tasks assigned to you for instance i know that projects are good to have to show what you have done is there a list of solid projects for strong midlevel data science positions so i can gauge how complex they are for example i like sports i have not done any python web scraping but i am sure i could find a website to scrape basketball statistics from learn how to implement that real quick and then write code which visualizes scoring streaks or investigates some sort of basketballrelated numbers question eg how does team a is turnover difference compare to team b is turnover difference or what is the correlation between average points scored per game by a team versus win easier said than done of course but i am confident i could do that within a couple of days if i really tried to is that enoughtypical work for socalled data science positions sorry for a longish post but thanks to all who have comments and replies,learning more python for data science jobs but feeling underpreparedimposter syndrome,how do i know if i am ready for data science
817,hi everyone so i have been running and testing an optimization problem on my computer for weeks now and i am getting tired of it taking so long i was wondering if any of ya will had any success with using cloud computing to speed up the computational process i am currently using an amd threadripper at full utilization i know nothing of cloud computing or anything what i am hoping for is to add a few lines of code to my project or to upload my code to somewhere online and then i will be able to use cloud computer or ibm is mega super computers or whatever to run my code incredibly quickly and get the results tbh i am still pretty new to some stuff and entirely self trained so while my code is good the only way i know how to utilize the outputs from it is by using print statements or printing to a csv or text file i have no clue how to run it from a command prompt or terminal or anything i am using pycharm and i click the big run button to run it sorry my introduction to coding was java on eclipse and that is all i have learned so that is what i am using i do not even know how to step through my function in pycharm like you can in vba lololol background about the problem i am using a genetic algorithm to optimize a good number of variables within a really large dataset and an incredibly lengthy computational process i have tried k iterations of the genetic algo and it still will not converge and that takes hours to run my code is already optimized as much as possible i have vectorized where i could cut all redundant processes and calculations reduced the number of data to only what is necessary etc in terms of the code it is very well designed not because i want to brag i had incredible amounts of help from insanely talented people but because i want to assure you that optimizing my code any further is not a feasible solution,optimization for model is taking forever code already optimized want to consider cloud computing any advice,how do i speed up my genetic algorithm
818,let is say i have a pretty simple problem i have some input data for instance abcd possible answers to a question test i have some labels for instance if someone has passed the test or not provided that i do not know anything else about the problem i do not know how much each question is worth so i do not know the exact criteria to know if someone will pass the test how would you try to predict the outcome of the test given a set of answers the first thing that comes to mind is do a classifier but the questions arise how do i know which of them to choose how would i know which of them would perform better how would i find out which of the questions is more important to determine the outcome of the test i have some experience with data science but always find it hard to narrow the possibilities to try the solve the problem,how do you choose the correct approach for a problem,how do i go about finding the right test for my problem
819,hello i am currently exploring the wonders of python and c programming but i am still very inexperienced though i am quite eager to learn for practice i have been examining and attempting to modify other people is code that they have put on github currently i have been trying to mess with omegle chat retriever created by indrajeetb the way the code is written the tool only retrieves random chats what i want to do is be able to retrieve my chats which i believe to be possible if i can modify the code to retrieve chats based on my ip date and time my questions are can i modify the omegle scraper indrajeetb created to retrieve specific chats from a specific timeframe based on my ip address and the datetimeframe are provided as values if so how could i modify the scraper to do this link to scraper,modifying scraper,how do i retrieve data from a chat bot
820,without any background in coding i spent playing around with python after work and decided to focus more on data science as this is what fascinates me most isince november i have been taking datacamp courses on python the initial courses in datacamp were great very smooth learning curve with the introduction of some ds concepts from the early on but the more i am moving into the ds track the more i realize that datacamp only has introductory courses on a vast number of technologies i even found their public roadmap on trello where i saw more intro courses on various technologies instead of deep dives or practical projects for their courses am i doing something wrong here does anybody have any experience with datacamp and has such a topical learning approach been beneficial for you going to kaggle and playing with titanic is an option but i am simply curious if i might be using datacamp in a worng way any tips and ideas would be highly appreciated ps sorry for any mistakes english is not my native language,am i doing something wrong at datacamp,what are the best resources for learning data science from scratch
821,hi i am about to graduate school in may i was never able to get an internship because of covid the one i had fell out i have been applying to jobs routinely at least applications although i havent fully set up a linkedin yet i have been applying on other websites such as indeed and ziprecruiter i havent heard back from a single fulltime employer i graduated with a major in statistics and have a minor in business analytics im proficient in python sql r sas and tableau however my biggest concern is going to be my gpa it is going to be when i graduate and i know this is really low i took it off my resume a while ago does anyone have any tips on why i cant hear back,tips on getting a job or even interviews i cant get anything,how much do i need to know for data science
822,we are communicators of uncovered knowledge derived from data and the only way we succeed in our job is when we communicate well if your goal is to research and develop ai and machine learning models then go get a phd in math or compsci i cant really think of any other way to do it but if your goal is to research and develop solutions to problems that we all face every day then you will have a better chance of landing a job in practically any industry around the world im not saying that this is easy but we as data scientists should think in terms of how well can we use our skills in math stats and codingsoftware to help people and businesses once i figured this out it helped me get over my imposter syndrome and actually feel confident in my ability to work as a data scientist,we dont construct black boxes,how do i know if i am ready for data science
823,this was probably my worst interview experience by far i have been working on transitioning into a ds role for almost a year now the first stage was a take home assessment which i know do most professionals it is not worth their time but since i normally get rejected after hr asks a few stupid questions and then pass on my cv to the experts i thought this was my time to shine so i busted my ass and did the take home case study and put together the presentation in one week i presented it to a senior ds and the team lead and they were actually blown away at my analysis insight and how i clearly i presented it the way i manipulated the data and compared it to an ml model no one else did it like i did according to them i also studied the industry so we were speaking the same language i was selected to move on to stage within days of the interview stage comes along the interviewers are c level guys apparently nothing at stage one mattered because i had to reintroduce myself from scratch they did not even read my cv and asked if i got another case study which no one sent so they ended up asking me about the case study on the fly it was obvious that it could be solved with time series prediction and i named arima as a possible candidate but i was not very familiar with its pros and cons something i would google on the job to understand never mind i described what data i would collect and how i would collect it analyse it and compare it to what was currently there in order to improve the situation nevertheless rejection a week later i do not understand why they do these things i busted my ass and absolutely killed the case study presentation and even industry knowledge but at stage that was all forgotten and i got docked on not knowing the pros and cons of one ml algo anyone could google despite describing the whole data science process ugh sorry for the wall of text i just needed to get it out there,i had the most ridiculous set of interviews at the same company,did i screw up my first data science interview
824,im currently working on my own cnn implementation just for learning purposes nvidia uses what they call an imcol gemm fused kernel to profit from the advantages gemm offers while using significantly less memory than a seperate imcol layer would need nvidia is implementation is closed source afaik using cuda i already created a working imcol gemm fused kernel that i use for both forward and backward propagation it is already a lot faster than computing things on the cpu but my index computation for copying values from global memory to shared memory and storing them in the correct order for gemm basically the imcol operation is rather very inefficient as it uses x x x x x per element copied and for filters of size xx each thread has to copy elements i would like to have a look at some professional implementations of imcol gemm fused kernels but i could not find any could anyone provide some links thanks in advance,imcol gemm fused kernel example implementations,xcolm and udacity
825,it is fairly intuitive talking about distribution of samples where samples are scalar values we say that people weight follows a normal distribution weight is a single scalar value i do not get the intuition behind distributions when people talk about high dimensional data for example when someone says distribution of images in test data is different than train data i know it means the images are different eg lower quality blurry different lighting conditions but is this all of it or there is concrete mathematical approach for quantifying these distributions another example that comes to my mind is algorithms like tsne they work by approximating distribution of the original data with distribution of a lower dimensional representation by minimizing kullbackleibler divergence,the intuition behind high dimensional data,how do you deal with outliers
826,i graduated with a bachelor in mechanical engineering and i had a job in the hvac field and another one in the electric distribution field in the second one i worked with data and learned python sql and tableau but this was a very small part of my job the pandemic started and i decided to go back to school because of the small tasks i did on my last job i decided to go into data and the degree i am getting is masters in big data and business analytics in the masters i strengthened my foundation in data wrangling and i learned also about machine learning some programs i learned to use are r keras tensorflow hadoop carto mongo gephi i will graduate soon and i was wondering about what positions i should be applying to i know that data scientists have a good salary but also demand more experience i have no actual experience in data the only personal projects i have are tableau dashboards should i start as a businessdata analyst and work my way up to data scientist or apply to data scientist since the beginning is there a set career path,what should be my first data job,i am a new grad and i have a few questions
827,hello all i have a model with several different hyper parameters and i would like to tune them i have a script that generates all possible combinations of the hyperparameters and trains the network with each of them my question is regarding how to decide with model to choose do i choose the model which gives highest performance on dev set or the model which gives highest performance on test set when i read research papers and they give the best scores they got how do they choose which model is results to give do they get the model which gets best performance on dev set and run it on test set and give those results tia,question about hyper parameter tuning,how do i choose the best test set for my model
828,i have a background in psychology and after graduation i worked with stroke rehabilitation after doing this for nearly three years i decided to take a huge leap of faith and began a masters in data science i have no idea how i was accepted my experience in the field was literally nill i am really enjoying my masters but obviously progress is very slow since i am learning everything from scratch i decided to quit my job and do my masters part time so that i could dedicate my time fully to it and take it at a slow enough pace to learn everything properly i have recently realised that i will graduate at and will be competing for very very junior level roles with new graduates my background is also allot weaker since i will only have years experience as a student will this put me at a disadvantage i do not know if i have left it too late,data science career change advice,how much do i need to grind data science
829,hi everyone although a developer i am new to machine learning and am currently programming a chatbot using tensorflows sequence to sequence seqseq model i am referring to google is nmt tutorial here im under somewhat of a tight timeframe and havent been able to pour hours over books as i usually do essentially im using a neural machine translation system going from english ltgt english to effectuate the bot is responses interestingly i am using reddit comments as its training data if my understanding is correct the nmt system essentially consists of an encoder to build a thought vector which is a sequence of numbers representing the source sentence and a component called a decoder which processes the numbers in order to return a corresponding number sequence this is then converted back to words representing hopefully an appropriate response this approach is particularly suited to capturing longrange dependencies in language as it treats text as a whole not translating it in chunks as in older systems nmt typically leverages recurrent neural network rnns which is the natural choice for seqseq and is used during encoding and decoding however rnns suffer from the vanishing gradient problem which is caused by the repeated use of a recurrent weight matrix in rnn models this is where the gradient eventually becomes negligible and subtracting it from the original matrix doesnt makes any sense and hence the model stops learning im quite unsure on whether i have explained the vanishing gradient problem correctly and sufficiently in the context of nmt and rnn furthermore i have read previously that using a lstm recurrent unit in a deeplayer rnn can overcome these effects is that correctly and what exactly is meant by a lstm in this context i highly appreciate your help getting my head around this,vanishing gradient problems in seqseq models,how to deal with missing values in a recurrent neural network
830,hi i have just joined a company and am looking at some tracking questionsissues with their google analytics account the biggest current issue is that in the ishopping behaviour analysis there are a slightly higher number of isessions with checkout than isessions with add to cart this anomaly only affects returning visitors and within that segment seems consistent across countries devices channels etc i suspect that these are visitors who choose to use an offdomain payment method such as paypal where the visitor is passed over to another domain not under our portfolio and then returned back to us the session timeout is hours far higher than the average session duration even for those who check out i know that if all domains were under my control i could use crossdomain tagging to maintain the session assuming this is the likely culprit what is the best approach for mitigating the issue thanks,maintaining a session during an offdomain checkout stage,crossdomain tracking
831,as the title states i am the sr data scientist at disney who has been hosting a bunch of free qampa sessions for you all they have been an absolute blast and have led some great discussions ps i will be hosting another in a few weeks i started taking a look at all of the questions that were asked and began putting together youtube videos where a started creating youtube videos that you guys will find helpful there is anything from project tutorials to interview prep here are some videos that i have put together recently full qampa recording with fellow disney ds spotify recommendation engine tutorial ds resume critique top coursera certificates for aspiring data scientists using gpt to generate new netflix content this is all fairly new so i would love to get your feedback verification my photo my linkedin feel free to connect,i took all of the unused questions from our data science qampa is and started to put together other educational content for you all i would love to get your feedback,i am hosting another data science qampa session at pm pst i will be joined by a guest presenter
832,the description states a place for data science practitioners and professionals to discuss and debate data science career questions while rule number one reads stay on topic a place for ds practitioners amateur and professional to discuss and debate topics relating to data science so which is it a place to discuss data science career questions or a place to discuss topics relating to data science additionally on the a meta post from six months ago the moderators write we are not trying to be a place for academictechnical discussions since subreddits like rmachinelearning raskstatistics and rpython already cover those areas more specifically and we are not trying to be a place for learning about transitioning into or getting a job in data science since there are countless other blogs and websites discussing how to do that so we can write about data science topics as long as the topic is not technical and we can write about career questions as long as the question is not about getting a job i understand this is your page and you have every right to decide what kind of content you want on it but it is frustrating to spend a long time writing a post or a comment only to have it be deleted would it be possible to clarify the rules by adding examples of the type of content you would like to see in addition to what you do not want to see,meta what exactly is this subreddit supposed to be for,what are the best resources for learning data science
833,so i am in a unique situation i am making my own website where people can post questions and others can subscribe to that question each question has a set of tags ampxb to be honest i have not given this recommender system much thought but thing about this algorithm ampxb create a binary matrix of each user is subscribed questions like this qustion question question question questio n tag tag tag tag n and so on and so forth then we calculate the determinant of this matrix using mathjs i am using javascript because the site is written in js otherwise i would use python and numpy but man django sucks ampxb then we calculate the euclidean distance of the determinant from each question is tag and if the score serves right we show the question in the recommendation page ampxb but ampxb how to serve the score what should the score be what should be our standards for the score ampxb thanks for your response,what do you think of my recommender system,how do i calculate the number of users that have visited a certain section of our site over a given period of time
834,hello i hope everyones day is going well i am currently a data science student pursuing a bachelors of science and concentrating in computer science i worry a lot about my success in this field for some background i was never quite good at mathematics and i never even knew what coding was until i took a class at my university and thought it was super cool and interesting i am also a girl in a male dominated major and everyone just seems so impeccably smart i sometimes feel like im not smart enough even though ive held a gpa i try really hard and try to study a lot but sometimes i worry that i wont be smart enough to be successful on this path im really interested and wanting to continue with data science but i constantly feel like i am always worried about not knowing enough i worry that i dont know enough programming languages or that my statistic background isnt as strong as companies it should be and the list goes on and on im also really intrigued by data architecture and engineering especially building data pipelines etc i know that i have a lot to learn and i have to be okay with constantly learning for the rest of my life however i feel like my fear of not knowing enough or being prepared is almost hurting me and driving me crazy i cant stop thinking about it if you have any tips on what helped you as a student and what helps you know id appreciate it also if you have tips on some books that are related to data science informational then also please feel free to recommend them thanks,currently a data science student but need advice,data science career advice
835,hello reddit community i am new in ml and tensorflow so to improve my skills i have tried to implement network achitecture proposed by research team of iiitdelhi i think that i have done many mistakes in my implementation there is one bug and i do not really know how to fix it i have asked a question on stackoverflow you can find buggy code and full error stacktrace there also i would be very gratefull if you could help me to improve documentation written in the readme file what should i removeadd there ampxb could you take a look on my code and help me to improve my work original paper github question on stackoverflow,usegnet implementation while learning tf,how do i know if my model is ready for production
836,hi i am aware in the basic set up of a hmm you can calculate the log likelihood by summing the final recursions of the forward algorithm over all the hidden states does anyone have any idea if this result stays the same when you introduce a new set of latent variables that allow you to model the emission distribution as a mixture in the graphical model the mixture components have arrows coming from the hidden state and going to x the model i am thinking of can be found in this paper figure i feel like these new latent variables do not affect the forward amp backward computations of alpha and beta at all and in this case i think the log likelihood can be calculated in the same way as without the mixture components is this correct thanks,calculating the log likelihood in a hidden markov model,question about latent variables in keras
837,at my old job it seemed like i would have a new project with a new dataset every few weeks the hardest part of my job was understanding the data not completing the project last year i built a data catalog using the nocode platform bubble and shared it here we ended up with quite a few people testing it out and using it on personal projects in the last months i took the original platform i built and leveraged some opensource platforms like amundsen to rebuild a modern data catalog focused on making data documentation transparent collaborative and straightforward for anyone or company we have a sandbox environment with dummy data that we are looking for user feedback on if anyone is interested in giving it a spin please let me know we are planning to release a public version for anyone to use early next year happy new year and i appreciate anyone willing to give it a try,i made a modern data catalog tool for anyone using a word document or excel sheet as a data catalog im curious if anyone would like to try it out,looking for feedback on a new data platform
838,so i want to move to europe but the pay in the industry i work in isnt very favorable i would ideally like to study in a field that i could work remotely so that i could live where i want but ultimately make a united states level salary so data science seems to be something that would be ideal at least in theory now ive been googling a lot of stuff so naturally get targeted ads one that seems intriguing is coding with max which has a week program that claims to get you set up for an entry level position in data science i assume while starting i will take a pay cut as is the case with most changes in careers but data science definitely has a higher ceiling than my current role so the questions i have are is data science actually a field where i could work remotely is a week crash course actually enough to land a job and how does everyone like their careers in data science thank you for any insight that you can share,interested in learning to work in data science,data science in the us vs europe
839,i am looking for a dataset of the frequency of first names by ethnicity in the united states from census data i can get that kind of data for last names as well as overall first name frequency not by ethnicity but they do not have the first name by ethnicity data available for privacy reasons from what i can tell i do not need it to be census data either just something with a large enough pool that it is fairly representative of the us so it could just be raw data from a sufficiently large survey of something where name and ethnicity were asked enrollment data or something data from sports etc i just want it to be big hopefully at least unique male names thanks in advance edit i should add that i know about the new york city data but ideally i am looking for something with more unique names,request first name frequency by ethnicity,request us raceethnicity data
840,i have been accepted into an msds program i am extremely grateful for this opportunity yet i still have some selfdoubts i am wondering if mscs would have been the better option i did not apply anywhere for mscs because i did not do cs for my undergrad i am in the final year of chemical engineering considering how competitive cs is i did not bother applying since i thought i would have no chance now i feel bad that i did not do cs to begin with is doing msds a good option for transitioning to ds the roles i would like to work in are big data engineer and ml engineer will this be possible with msds,mscs vs msds,is a ms in ds worth it if i already have a job as a data scientist
841,so i am very new to google analytics and i will not lie that some of it is still gibberish to me however as i have been watching my stats i am starting to see the various affects of ads and seo the two items that make the most sense to me is the bounce rate and pages viewed per session right now my bounce rate overall is at but within my paid search and organic search it is down to amp respectively and my pages per session is overall but and for paid and organic searches as above i think that means the content is good once people are at my website but i do not have any conversions to go with them i am sure this is an age old problem that is asked often however i would like to know if i am tracking the right stats should i be watching something else what tweaking should i be performing to start to see better performance and finally what can i do get more conversions i assume that posting the website is ok if not please accept my sincerest apologies just because xoxo,bounce rate down pages per session up but still no conversions,how do i track how many people visited my website through a certain period of time
842,i graduated in december ms in computer science i have a bachelors degree in math i started looking for data scientistanalyst jobs and some ml engineer jobs once i graduated i did not think i would be able to handle schoolwork and interviews especially considering takehomes at the same timeand i believe this was the correct decision i had a weeklong takehome that i foolishly ended up dropping hours into i have probably put out or applications in the past months it does not seem like i have a huge problem landing interviews i actually get a response rate of and i have made it to the final stage at companies all to end up with rejections most recently i was even at the stage of discussing compensation for an ml engineer position at a startup and they asked me what my expectations were i said roughly in total compensation and i guess that was too high i sent in a takehome around a week and a half ago got progressed onto the next stage with the department head and thought i really clicked with him today i got a rejection because there was an issue with my test the thing is during the interview i was literally told that i passed at this point i am tired frustrated and i do not know what i am doing wrong i am starting to wonder if they just do not like my personality i feel like a complete fool because i have valuable degrees and a biology bachelors but that is probably not going to help me much and cannot seem to find anything i am concerned that the longer i go without a job the more of a red flag it raises to employers i do not know how long i can keep saying i am a recent graduate from ___ is this experience normal,months after graduating with a masters can land interviews but cannot land job,i feel completely unqualified for data scientist roles
843,let is say in individual is curious about the level of detail and extent to which companies like google aggregate and sell your data what would be the most efficient way to run a test like this i am assuming i would have to setup a llc and approach google as a marketing company etc i am curious if anyone here has experience with how data is aggregated and sold between companies the level of privacy restrictions if any limitations of who they will sell to what an individual wants to do with the data if they care and general cost ranges for example location pings for cellphones of every single person in new york city for the past year,buying data for research and experimentation,how would you set up a google analytics data experiment
844,hey all i am an academic scientist with a background in data science ecological models for invasive species i am working with a nonprofit conservation group interest in hosting educational workshops in the new york city metro area we have talked about organizing a workshop for career data scientists interested in finding paid or volunteer work in environmental science and conservation biology we are talking about day course with speakers from government and nonprofit environmental groups plus some skills lessons on how we extract environmental data from government or private databases the goal would be to provide data scientists without a biology background some domainspecific knowledge to break into this field there is not much money but it is exciting and rewarding to be a part of environmental advocacy and protection hypothetically speaking if this was near your city would you want to drop by or even be willing to pay to attend we are not looking to make a profit on these workshops just cover the costs for speakers lodging etc,floating an idea workshops for data scientists interested in contributing to conservation and the environment,looking for data scientists to partner with environmental groups
845,hey i am new to data science i am a data engineer my team wants to build a proof of concept to showcase what data can be used for at our company we have data for training courses our customers took for our products our goal is to try and build something that can recommend training courses to a user in a marketing email based upon what they have already taken immediately i thought of a recommendation system though we do not have ratings on the courses from the users or a lot of demographic data i also then thought about doing a market basket analysis to recommend courses based on what courses people commonly took together what would you recommend starting out with thank you,market basket analysis vs recommendation system,how do you go about building a recommender system
846,hi i have used nn before but never in the way i am trying now normally i have a bunch of data which leads to either one outputsay sigmoid or regression or a classification probability chance of it being a shoe skirt etc in a cnn example of what i am trying ampxb bob sandy tom go to the store depending on who goes different amounts of money gets spent by each so ampxb input bobsandytom gone shopping or not gt gt gt gt gt gt gt gt ampxb to make it a bit more complicated they each have twins who can go in their place who will change the result but at most can go so say jeff hannah joe are their twins it could be bob sandy joe instead of bob sandy tom and instead of it would be for example i was thinking a neural net which takes as input a one hot encoded placement which takes their attendance bobjefft sandy hannah joey tom and then outputs an estimated cost for each given historic data in this case they will always spend the same amount when the same combination of people are together i could not really figure out how to do the inputoutput of it to a neural net using say keras or what loss function i would want to use here ampxb any thoughts or links to examples are appreciated ampxb thanks,how to do multi input and multi output nn,is there a name for this type of neural network
847,i am not sure if this is the right place to post this but i need helpadvicea listening ear i recently graduated college with a bachelor is in math and was hired months ago as a data analyst myself and two other people on my team have been assigned to this project developing a knowledge representation and reasoning system i think my boss thinks that because i have a math background i am some genius or something i honestly struggled through my degree and got okay grades major gpa was a if rounded up he is put the other two on knowledge representation and myself and myself alone on reasoning which he admits is the harder part i just do not understand if he wants my reasoning system to cohere with their knowledge representation then it seems like the knowledge representation part of it should have to be completed first we have been at this project since late august and i still feel like i have got nothing whereas the other two have code almost in production i have contributed modestly to the knowledge representation part of things but i am always a bit behind the curve i feel like i am going to get fired for underperforming i literally do not know how i am going to see this thing through it is stressing me out so much i have been getting really dark thoughts that i will not talk about explicitly but i think you can imagine what i mean,i was hired as a data analyst months ago by an ai company and my boss is expecting me to create a reasoning system as part of our attempt at krr i feel extremely overwhelmed and am convinced i will be fired for underperforming,i feel completely unqualified for a data analyst role
848,this community should make a pathtrack to answer the question using completely open source courses booksto learn and challengesto practice organized in the required order so that we anybody can directly jump to that we can further add it to the sidebar for everybody is benefit the idea is to start with parts coding pythonr theory and practice give suggestions statistics theory give suggestions basics of data analysis give suggestions after this implementation of stats theory in challenges and datasets would be the main focus in the language of your choice the second part of the learning curve is diving into the ml theory and implementing it via kaggleopen source challenges andrew ng course titanic kaggle challenge give suggestions the third part would be the transition to deep learning give suggestions the idea is to create a balance of theory and practice which makes the entire process much more enjoyable the track could span over a year if required edit made some major edits,to go from complete zero to deep learning contributions required,looking for a mentor for deep learning project
849,i recently landed a role as a data analyst and i have been given a pile of giant excel spreadsheets full of data and asked to cleansevalidate it during grad school i worked a lot with r and sas and had some minor interactions with sql python spss etc but i am willing to learn pretty much any software i can get my hands on i have asked if i can get access to any of this software and the answer was a hard nothey want me to do everything in excel only i know i have seen other people at the company using sql but for whatever reason they have not given me one they do not want me using anything but excel i have tried to explain that something like r would be totally free and they do not careit has to be done entirely in excel is this something people actually do or should i see this as a red flag and go running in the other direction are there any tutorials or anything that might be useful i have done some basic stuff like pivot tables and vlookups before but usually excel is just the first step before switching to something more powerful for the actual analysis am i being elitist by thinking the idea of using nothing but excel is laughable it just seems so much more tedious thanks in advance for any advice you may have,data analyst limited to only excel,i have been asked to do a data analysis for a company and i do not know how to proceed
850,been seeing a lot of posts recently of people being hired to do data science and ending up in from a data point of view suboptimal work places in my opinion many of these places had red flags from to get go based on the description of the company they gave my main advice is to be as critical to the company as they are to you screen their job posting with as much rigour as they screen your cv trying to get a sense of what you will really be doing irrespective of your wouldata scientist job title typical red flags for me would be not exhaustive no mention of cloud related tooling sql and data warehousing featuring more promintently than anything else reason being that if i wanted to do a da job which i really enjoyed from past experiences i would just apply for that no mention of any kind of version control use whatever tools and languages you want on the job this one is very particular but to me that would indicate no standardisation probably a lot of csv files excel users adhoc analysis on notebooks and very little being put into production automated this might be a pet peeve but i believe in many cases long term value from data cannot just be done through adhoc analyses and of companies are not mature enough to let everyone use their own tools without it becoming an unmaintanable mess no mention of anything casual this one is personal colleagues are colleagues and not necessarily friends but a workplace with a few social amenities would make being hours in the office more bearable not all of the information you value can be gotten from the job posting so the next step would be to think about what you value ahead of the interview and ask them in a polite manner job interviews should be as much of you deciding if they are a fit for you as vice versa this may help you to uncover small details that can help you decide picking one offer over the other even if you only have offer knowing what you are getting into in advance can help you make peace with prepare for it,advice to all job seekers be as critical to the company as they are to you,data scientist is the worst title to ever land a job
851,to begin my question i would like to quote a paper by ishawaran et al on random forests for survival analysis data in which the authors very concisely outline the difficulties of feature selection ie which variables to include in a statistical model in classical regression models and how this problem is somewhat alleviated with more advanced models further because these methods ie classical regression models eg cox ph regression even though it is semiparametric are often parametric nonlinear effects of variables must be modeled by transformations or expanding the design matrix to include specialized basis functions often ad hoc approaches such as stepwise regression are used to determine if nonlinear effects exist identifying interactions especially those involving multiple variables is also problematic this must be done by brute force examining all twoway and threeway interactions eg or must rely on subjective knowledge to narrow the search in contrast these difficulties are handled automatically using forests we illustrate the ease with which rsf can uncover complex data structures through an indepth case study of the prognostic implications of being underweight overweight or obese and having severe but stable coronary artery disease investigators have noted complex patterns surrounding possible reverse causation in underweight individuals interactions with smoking and an unclear inflection point at which point increasing body mass confers increased risk some have identified a possible obesity paradox among patients with established heart disease in which increased body mass predicts better survival to clarify these issues we analyzed a large cohort of patients with coronary artery disease undergoing isolated coronary artery bypass surgery using rsf random survival forest we identified a complex relationship between longterm survival body mass renal kidney function smoking and number of internal coronary artery bypass grafts we believe our novel findings help explain some of the apparent contradictions previously reported source essentially the authors claim that traditional regression models struggle with feature selection and the newer models eg bagging random forest are able to better deal with feature selection i do remember from an intro stats class the somewhat tedious process of determining which variables to include in a multiple linear regression model as the authors described i remember there was something called cp mallow is criteria in which potential variables were repeatedly included and excluded in the regression model and the value of cp mallow is criteria was monitored a final selection of variables for the model was decided on the basis of this criteria however this selection process becomes inefficient for large datasets if i understand correctly this means you would have to refit the model for many different combinations of variables resulting in a combinatorics explosion for a large number of variables like the authors mention you can also manually hard code interaction terms in the model eg logvar varvar varvarvar varvarvar etc and there an infinite such number of potential interactions improper feature selection can also result in unwanted effects such as multicollinearity the last point i would like to bring up although my knowledge of mathematics is not strong enough to fully substantiate it is that classical regression models are said to have a tendency to overfit i do not know why i have seen visual demonstrations of this but i do not know if there is a mathematical explanation behind this or if it is just an empirical observation and poorly generalize to new data again i do not know why and that classical regression models are only able to recognize linearly separable patterns in the data intuitively i can understand this eg draw a circle of red points and a smaller circle of blue points that fits in the red circle a single line can not separate the two colors but i do not know if there is a mathematical explanation behind this this brings me to my question about feature selection for large datasets with the advent of technology data is becoming bigger and bigger everyday convolution neural networks are the go to method for analyzing pictures a standard black and white picture is said to have variables whereas dna is said to have even more in such instances it surely must be impossible to address feature selection as done in conventional statistical modelling please excuse my poor understanding of math but my understanding is that newer statistical models have built in methods of handling the feature selection problem for instance random forest randomly chooses different combinations of variables and sees which combinations result in better model performance the exact randomizing mechanism uncorrelated trees is said to also prevent against multicollinearity i ahve heard that the creator of the random forest algorithm leo breiman claims through theoretical statistics that random forest by definition can not over fit and has some desirable error bounds and convergence properties is this true meanwhile i have read on data science blogs i am not going to lie that deep neural networks are able to automatically learn and consider useful combinations of features for approximating the target function am i correct all in all what i want to ask here for large datasets where sometimes the features do not have any immediate meanings eg a patient is blood pressure vs the information contained in the st pixel of a photograph is there any real way to handle feature selection or is this usually taken care of by the statistical model itself eg random forest and neural networks i have seen examples online where people attempted to write a massive for loop in which they train the same model with thousands of variable combinations but i am not sure how feasible this is can someone please provide a comment on this thanks,feature selection for large datasets,is there an accepted stateoftheart algorithm for determining optimal survival rates
852,i am trying to push for my org to hire me as a ds currently da also we do not have a ds at the moment i want to put together a little presentation that explains in business logic why they would want to do it and what exactly i would be doing i have a plan of what i would want to do but i want to be able to draw some more concrete lines in the sand as my current role is pretty random i am of da is where the other da is mostly a bi analyst building dashboards and reports i take care of marketing needs and do a lot of adhoc and random stuff what kinds of projects do you work on do you have responsibilities that would not necessarily be considered ds do you have other teammates to collaborate with or do you primarily support yourself ie acquiring datasets building analytical tools etc,do you work alone or on a very small team if so what are your responsibilities,what would you do if you were hiring me as a data scientist
853,hi i am studying python and data science to become a data journalist i am now building my portfolio and using my new knowledge to analyze data and create video stories i am googling through my tasks and usually i can reach the needed goal but from time to time i am stuck and i do not know what to ask i think i am still in a stage where i do not know what i do not know i hope to find a community where i can tell what goal i need to reach and people tell me where to look for answers according to subrules rdatascience is not stack overflow and rule rdatascience is not a homework helper i will not post my basic questions here thank you for your time,is there a community for beginners to ask basic questions about data analysis,where to start
854,hey there first thanks a lot for reading this we are a group of german students in the marketing field and we currently conduct a study on future trends and customer challenges with the crm system salesforce as part of our seminar work weve developed a brief survey for companies who use salesforce to go through however the response isnt quite as strong as of right now we need more of these surveys completed for our work and we have not much time left if youre still reading you can help us out with your knowledge if you know a thing or two about salesforce or maybe youre even a salesperson in your company and you use salesforce you would help us out a lot by filling out the survey it should take less than ten minutes and the data will be treated and stored anonymously we really appreciate your help and thank you for participating,we need your help as salesforce users,data science for salesforce
855,okay so i understand the basics and have intermediate programming knowledge i am currently doing a volunteer credit with a nonprofit and i am having a hard time seeing how i could apply anything i know like at all my professor is extremely hands off and mostly on vacation and my supervisor does not know much about data analysis and such like if somebody says we have x y and z problems i know there is probably a way this could be at least somewhat helped with data science but i do not know how to do that where can i learn i feel like everything i have learned so far is just good for the books or for running tests on academic research but i have no idea how to apply it in the real world i am sure examples would help are there like journals where people publish what they did with real life data or like trade magazines or something industry sharing i am kind of lost and frustrated thanks,how to solve realworld problems with data science,how do i know if i am ready for data science
856,we have a small business and use a third party who manage online services for us including some google analytics insights at this point all they do is send us a monthly report with some analysis around traffic to our website i thought i would set up an account so i could jump in and find out about how successful particular online promotions were so i found our tracking id in wordpress can i attach this tracking id to my google analytics account or is our rd party provider the only ones who can use this id meaning i need to set up a new one which would mean i cannot track anything prior to the time i set the new one up thanks,a very basic google analytics question,how do i track a specific user id on google analytics
857,hello everyone ampxb i need to build a realtime dashboard on the web from a database perhaps postgresql where it is possible to apply various filters to all the graphs in the dashboard such as date ranges minimum and maximum values names ampxb when clicking on certain graphs or values of these graphs there must still be the possibility to drill down thus displaying new graphs or values or even be able to apply a filter with this click ampxb the dashboard is for integrating a productplatform on the web it is part of a page it must have a beautiful and responsive interface and be as personalized as possible thus distinguishing its visual appearance from the others such as the kibana metabase tableau ampxb there is a very important criteria for the choices i only have or months to develop this in localhost and the choices to be adopted must have a light or medium learning curve ampxb i have already done my research to build the visual appearance of the charts that will compose the dashboard chart js seems to me to be the most suitable library it has beautiful charts is responsive and seems easy to use to develop the remaining frontend i thought about the react framework to make it in real time i saw that graphql is used a lot but i have no idea how to use it i will have to learn everything does it have to be done with something else like nodejs for backend for data filtering i have not found anything very useful to use with chart js will i have to do all the code from scratch to apply every filter i want ampxb ampxb thank you very much,real time dashboard help,best way to store a large amount of data in a database
858,hello everyone i am currently building a multiclass text classification linearsvc model i have some questions about improving the model is performance i am curious to know about anyone is approaches to this as well here are my questions when i test new data on my model i would like to flag lowconfidence predictions i have been looking into linearsvcdecision_function but this produces a d array of confidences for each label in my output i am not really sure if this is a useful metric for flagging poorly classified data outliers how should this be interpreted is the tfidf vectorization for feature extraction good enough to standardizenormalize the data finally i am hoping there are some approaches i can take to visualizing the features wrt my output labels to identify classes with common features that predict new data incorrectly as a result,question improving model reliability and interpreting confidence scores for new unseen data,question about outlier detection
859,hi folks longtime lurker first time poster here so please be gentle long post warning so here goes i majored in computer science in my undergrad got lost into the investment banking world for a bit then through a job in a data science consulting company turned back towards cs and data science was with the consulting company for years and in the past years i have been part of a gaming company leading their marketing analytics team i have always been handson and hence i am deeply familiar with machine learning models can describe and derive math for some of the models linear backprop and some generative models and write code to demonstrate the inner workings of linearensembleann models at work i am able to guide data scientists and analysts to build libraries models for clustering classification and regression we have built systems that do media buying or automate sales so far i have handson experience building timeseries models regression models for various purposes churn prediction models customer behavior clustering models i feel i can code and have been able to cover about questions on leetcode with about acceptance rate i am often intimidated by folks who studied machine learning in school feel like without a formal education i have been missing out on something i try to fill the gaps and try to take courses have been through stanford is cs and going through csn a bit challenging for me i feel like i am making a difference at work our models allows for plenty of experimentation and automation for media buying and feature experimentation product managers and marketing managers rely on our models to make decisions my questions are as follows would machine learning teams in faang consider my profile for recruitment if yes what is the typical level to target lead or individual contributor or manager im a little worried about my age and think that it might be work against me should i be worried do you advice i continue to pursue a management career although my bosses and reportees like me im not too fond of it should i consider going back to school and get deeper into machine learning i feel that the research is exploding and i cant keep up along with work,cs undergrad year data science experience move to ml,is it worth getting a phd in data science if i already have a job as a data scientist
860,our ability to tackle the pandemic as a united global family is primarily because for the first time in history we can keep everyone informed on its realtime global spread thanks to the johns hopkins university making their dataset of confirmed covid cases available to the public enthusiastic builders were able to build interactive realtime dashboards that are keeping the world informed on our progress in this fight the covid pandemic tracker built by a member of our early access program the covid pandemic tracker includes a zoomable heat map and sorting features like population density age group distribution and case fatality rate it also has the ability to compare the spread of the virus in different countries on both a linear and logarithmic scale click here to interact with the app and see it in its full glory how the covid pandemic tracker was built though the creator had no prior experience in coding he wanted interested in learning nocode development and wanted to create something useful for everyone his primary goal to build an interactive coronavirus tracker that is easy to navigate informationdense and visually pleasing kelpapp was the perfect fit read the full story and the specific steps here why kelp kelp is a nocode visual development platform where anyone can build beautiful data apps our goal is to enable individuals and teams to easily design and develop interactive experiences that will enable them to get the most out of their data boost productivity and to save a lot of time and effort in the process join our early acess program and build your own magnificent apps,new nocode data apps builder for realtime streaming data,looking for data on covid cases
861,this is now the third time ive had a ds bootcamp grad join my team not by choice and im having disastrous results do they not teach you how to operate computers or use the command line how to deploy to anything but oneclick paas with no iam why is the answer to every business question a cloned repo you found on tds that uses apis we cant license how can you not know sql or how to set up a local instance why is docker such a fucking mystery to all of you ever heard of venv yes i know it works on your personal machine because youre using a webbased ide our company blocks for a reason like i get it everyone else in the company is ready to fire the money cannon straight at your face every time you say neural network but ffs learn how to run something anything on an actual enterprise grade cloud provider az aws or gcp if you must learn to use git so i can actually work with your stupid ipynb notebooks and for the love of god do not keep asking me to call you a data scientist in meetings you were a barista weeks ago no matter what they told you at general assembly sorry for the rant im just boggled by what these programs are teaching people and telling them theyre qualified to do after theyve taken your money if youre not walking away from your program without knowing how to at least do a tiny bit of etl or understanding that not all the data in industry is going to be as clean as the yelptwitterkaggle data youve been using your little pip install imadatascientist toys on youre going to run into people like me who know enough to know youre a sham but who wont tell you so but instead rip you anonymously on reddit there now i feel better love to all the actual data scientists out there also i do of these things as well but im just a dumb product manager so im allowed to,ds bootcamp grads wtf is your deal,how do i know if my data science plan is realistic
862,so i have been working as a data scientist for years i have a ba from a top university but no other degrees did not take basically any comp sci in college i cannot pass tons of interviews and am kind of lost on how to get better at machine learning i take a lot of courses on coursera and learn every day and also did quite some leetcode in particular i think i am weak at practical implementation of models dataset cleaning etc error analysis and improving the model basically i am not good at ml despite doing it for years in industry my day job i basically only get to implement pretty simple models on a not very diverse set of problems i try to learn every day via courses but do not think this is really getting me very far other than knowing a lot of stuff i cannot pass interviews for senior data scientist positions despite trying pretty hard i think there is something wrong with how i am going about studying,how to actually get better at machine learning,how do i get better at machine learning
863,until the latest version of google analytics a friend of mine used to receive a report every month with a general overview of various metrics from his website the report looked very similar to this example i found via google the reports stopped coming after the newest version of analytics was launched i promised to help set up his account to do this again but quickly realized that apparently it was not going to be that easy i basically want analytics to email a standard report with metrics from the menus audience traffic sources etc nothing fancy or complicated pretty much a report like this one but i cannot seem to figure it out can someone please help me or point me in the right direction as to how to do this thank you,how do i create and send reportsin the new version of google analytics,how do i set up a google analytics report for my friend is site
864,i have an extremely noisy dataset and i try to minimize the mae apparently when my linear regression makes its prediction it has something like mae when compared to the mae of an allzero vector and as i divide the estimation of every observation by some factor it improves dramatically factor mae factor mae factor mae factor mae factor mae factor mae factor mae factor mae factor mae factor mae note the mae is sometime negative because it is compared to the mae of an allzero vector so means that the mae of an allzero vector is better than the algorithm is prediction by a why is it that my linear regression guesses numbers that are so big such that they harm the mae score so significantly is there any good method to deal with that,in very noisy data the mae of my estimation improves substantially when i divide it by,how to deal with a very unbalanced data set
865,object detection models like faster rcnn and mask rcnn generate thousands of region proposals where typically only a handful of objects might exist sometimes it is easier if you can help guide these models to the correct areas of interest in this tutorial we will show how you can do just that with full python code included directed mask rcnn allows you to specify regions where the model should look for objects reducing the number of region proposals that the model processes reduces the computational time of the model topics covered in this tutorial include overview of the rcnn model region proposals manipulating regions produced by the region proposal network rpn directed mask rcnn references tutorial link,tutorial how to implement directed mask rcnn with keras,tutorial how to implement region detection with mask rcnn
866,hi all i am not sure if this question belongs here and it is very open ended i would like to hear your opinions on this though i am a data science intern at a manufacturing company in the semi conductor space and i have access to the bookings backlogs and billing data of this company there are no other data scientists in this place so i guess they are trying to figure out if data science works for them through me i do not have a lot of business experience so i am not able to figure out a problem to apply machine learning and predictive analytics on this data or if it even makes sense to do that so i would like to know what other data scientists in similar manufacturing companies do and what kind of business problems do they solve thanks and sorry if this is in the wrong place i have researched a lot and tried to talk to people in the company but i could not find anything tangible off the top of my head i can only think demand forecasting but is that a good problem to pursue are there other problems thanks and sorry if this is in the wrong place,how to use data science to improve business in a manufacturing company in the semi conductor space,data science in manufacturing
867,hey guys i tried to solve the titanic problem with a decision tree link here after creation of decision tree i tested the tree for my trainingsdata accuracy that sounds possible compared with what i have seen in the net before now i evaluated the given test data compared with the solution and got an accuracy from around which should not be possible with a simple decision tree here is my code it would be awesome if someone can give me a hint why i get this score i cannot locate my fault edit sorry get my fault i used an incorrect file for validating my test data which only divide between male and female passengers female survived male does not,got about score with decision tree stupid mistake,can someone help me understand why my decision tree is not working
868,i think one of the main problems in analytics is the lack of people information it is controlled by superplatforms like google and facebook but as soon as you have transition from the channel to the website you lose the information as much as possible you should tackle this with url tagging include the targeting info into your landing url and you are able to do personalization like dynamic pricing or tailored content by retrieving the targeting information from the url and rendering the page accordingly a smart system would not only do this but record the interactions of different targeting groups eg men amp women and use this information to optimize for a goal eg determining optimal price point per user group i wrote more here,dynamic pricing and incomplete people information,how do i track a specific group of users in google analytics
869,to be specific can someone help me if i should major in math or computer science i have done more programming than math recently but i still plan to do more math in the future i will likely go to grad school my future research interest seems to that it is something that has to do with applied math algorithms data science also i do not want to ever ever teach in my life i hate teaching with passion here are some of my other interests logic philosophy skepticism epistemology personal development linguistics linux the lisp programming language i would like to add the fact that double majoring is a possibility and that my university is free so i am not going to lose money by doing that,best major go get into data science,i am a math teacher who wants to become a data scientist
870,not the best titlekeywords above time series just checking what methods i should be looking at have a set of numerical data after cleaning nulls and bad reads have cols x rows with a nominal setpoint column plant feed rate and other columns of varying relevance nb the setpoint should result in the plant feedrate subject to the plant response to other columns of input set point is input other columns are input some will be autoresponding to internal signals ie pump turns off when tank is empty or full plant feedrate is output looking at the charts it is reasonably obvious the actual feed rate lags the setpoint by some time period shortlisting the high correlation data points also indicates a time lag the time lag varies with some columns data is from an industrial process plant and time delays due to retention transport delays etc between instrumentation on pumps tanks conveyors etc is to be expected while i have some methods i have used to cater for this they are crude and custom rolled also tedious to implement i suspect the methods used in share price prediction will be similar likely other fields have developed similar methods,predictive analytics methods,time series optimization
871,i am not sure how i can solve the problem of matching let is say programmers and projects let is assume i have profiles of programmers languages interests prior projects etc and projects languages wanted area of expertise wanted etc and i now want to connect those two recommend programmers for projects and vice versa ampxb the conceptual problem i have is how to solve this with neural networks the number of classes is dynamic so to speak if i model a project as a class then i would have to retrain everything because i now have a higher number of classes and thus the model needs to start over this cannot be the solution ampxb my idea was to use the nn as embedding for programmers and projects alike and then cluster the programmers around the projects and compare the result with the labelled data let is say i have gotten feedback on how good the match was for example does that make sense is that a feasible approach or would i just design features by hand and use a istandard clustering algorithm how would i even train the model by using the cluster association as sort of cost function the next issue i see now is the same as with clustering only approaches now the hyperparameter is the number of clusters i want ampxb any ideas,how would i approach this problem,how do i deal with missing data
872,hello i want to create a classifier that takes an image of a pokemon and outputs its name i have a folder containing a picture of each pokmon the input images are not going to be very different from the data set and by that i mean all pokmons are going to be on a white background so it should not be too complicated to perform i had a few ideas for how to do it have a cnn with an output for each pokmon this seems too complicated for what i need and also i have only one instance for each pokmon color ratios see how much of each color is in the image and compare it to values in the data set shadow transform the input image into a bampw shadow who is that pokmon style and try to see which image of the data set fits the best by scaling moving and reflecting i am not sure exactly how to implement any of these methods or if they will even work so i would love to hear what you say about it what will be my best option,how can i create a pokemon classifier,how to train a neural network to recognize different lighting conditions
873,i heard that a data scientist job could vary a lot by company i would just like to confirm if what i heard is true and if anyone could provide further insights besides the roles which are essentially the same as data analysts or data engineers my friend who is a data scientist told me there are two types application data scientists and research data scientists he says the application type ds does modeling to solve a business need and only uses tools which are already developed there are not a whole lot of models he uses xgboost random forests neural nets glm etc to choose fromplay around with besides just tuning parameters he says it gets boring fast and already learned pretty much all he can within years he says the research ds are the ones who do the most interesting cuttingedge work eg nlp ai voice recognition selfdriving cars deep learning and creating new algorithms this is the interesting and high paying ds work that most people want he also claims the following increasing order of pay interesting work and difficulty application ds lt software engineer lt research ds my impression was that the application ds is what most data scientists are and it is interesting creative work the research ds job is mldlai research requires a phd and are more like researchers than actual data scientists could anyone verify how much of what he says is true does application ds really get boring after awhile is the pay comparison among the jobs correct on average is there really such a divide in ds and if so is it difficult to switch from applications to research wo phd after a few years of experience,types of data scientist jobs,is it worth getting a phd in ds if i already have a job as a data scientist
874,hi guys i need some advice as i want to report some insights on a number of twitter accounts desired flow twitter data collection storage and analysis by using google data studio i want to perform analysis on accounts grouping them by segments i came across of bunch of services such as supermetrics everythingdata powermyanalytics reportingninja due to the large costs involved i would like to develop the process myself by collecting data storing it and achieving the same data standard as these companies achieve i am sure someone has developed such a process and can advise me how i can start working on it and learning pr use prebuild script i would like to collect data that would allow me to answer the below questions tweets volume impressions retweets likes followers increase identify which tweet had the largest engagement followers engagement likes retweets profile clicks and any other available information for deep analysis i do understand what i need to get twitter developer account to get access to api firts but what is next can someone guide me to resources on how to retrieve data store it correctly and etc,twitter analytics and data storage via api some help needed,how to store twitter data for future use
875,im and currently live with my parents i graduated in business and ended up working in technical support wfh for a large commerce client through an outsourcing company i get to help troubleshoot issues related to apis and feeds but theres so many corporate redtape that im very often passing things on and not getting to learn much about them beyond surface level im also under nda from disclosing my client pay is slightly above minimum wage i despise the work and dont find myself learning anything useful im considering quittingmy parents despise me for not taking over the farm business and its lead to this stockholm syndrome relationship between us even though i tried farming for a few years fulltime and help them most days ive come to terms that the only option for me is to leave because of the huge strain its leaving on me and im considering moving country so that i can get a fresh start i find myself in a sort of depression theres times ill just blankly stare at my computer in work for minutes and cant do anything and then i feel worse afterwards my parents often rant and call me useless for being in a deadend job and i end up feeling x worse immediately after i then fall into worse habits until i pick myself back up again later i tried to get my shit together from about months ago and picked up learning python and sql i finished the analyze data with sql course through code academy recently learned tableau and done yt tutorials on python i enjoy the courses can learn pretty fast and actually feel motivated to do them however i still feel like ive a hundred more miles to go and im afraid this will turn out to be a fools errand ive saved enough money now that i could realistically live comfortably with no more income for about yearsim currently considering the following options try bullshit my way into an entrylevel da job and swim through the storm get an unpaid internship and swim through the storm except now theres no pay less expectations and i feel like less of a fraud take a year out to do an intense online year bsc degree in data analytics from a reputable it college my government offers these for the equivalent of to graduates of nonrelated disciplines quit my job and study fulltime for some proper certs like google data analytics professional certificate or da analyzing data with microsoft power bi allowing me more time to focus and not burnout tldr switching careers from tech support and dont know the best approach,should i quit my job to study data science full time,i feel like im drowning and im not making progress
876,hey everyone i was one of the authors of the original cips paper and i thought it would be fun to do a breakdown of this followup paper that takes cips into the d world if you have been following generative ml for a while you might have noticed more and more gan papers focusing on the underlying d representation of the generated images cipsd is a daware gan model proposed by peng zhou and the team at shanghai jiao tong university amp huawei that combines a lowres nerf surprise with a cips generator genuine surprise to achieve high quality x daware image synthesis as well as transfer learning and daware face stylization fresh out of the oven full summary processing video mzgwtfiv arxiv code subscribe to casual gan papers and follow me on twitter for weekly ai paper summaries,cips followup paper explained harnessing the conditioning sensorium for improved image translation minute summary by casual gan papers author of the og cips,d how do you generate your own neural network from scratch
877,hi all i am a new student of neural networks and am looking for some pointers in terms of learning resources and technical direction for a new project that i am starting i am looking to build a solution to optimize route planning i have a relational database of destinations each with an address based on these addresses or nodes the goal is to create a solution perhaps involving a neural network that is able to create optimized routes based on the number of available trucks and their capacity my background consists of years of software development experience save for reading about neural nets i have not yet built anything as this is my first foray into the field i am very excited to begin learning and building but i am have a lot of questions i have not yet found a community or forum where i can ask these questions so any pointers would be greatly appreciated thanks everyone,looking for direction for a new route automation project,looking for resources on building a neural network from scratch
878,hello everyone i am currently selflearning data analysis and data science from scratch and i am really enjoying the process i am still a begginer at the moment and still have a long way to go i have just familliarised myself with python and the numpy and pandas libraries just now diving deaper into data cleaning i was wondering if any freelancer out there would be willing to connect for the prospect of a future apprenticeassistant to help with freelance work i could help by handling simple parts of projects at the start and escalate to harder ones as i go along helping to speed up your work i am not looking for any salary just some mentorship and a reference in the future anyone interested feel free to dm me so i can adress any questions,any freelancer looking for an appreticeassistant,looking for a mentor
879,good evening everyone i hope you are doing well i will start by a little introduction about myself i am a computer science tunisian student north africa and i am currently studying a bachelor degree at a good private university here my studies are in french english is my third language and i really want to improve it more by studying abroad my grades are great my last semester i got a we do not have the same educational system as americans for example but trust me it is very great like a x gpa we have the french educational system so it is really hard and i have coursessemester unfortunately we do not have many opportunities like most of the big countries out there but i want to keep searching i want to enroll in a masters in data science or maybe ai or machine learning in an english speaking country us uk canada australia but i am really interested in canada or maybe scandinavian countries my main goal is to have a good education and to study in a city where i can have good job opportunities just after graduation my opinion is that my personal projects and motivation are the key and they are more important than the university or academic results so what i want mainly is working in a big country and start a career from there and my only choice is to start there after studying there unfortunately my country is not a good place at all to build a very great career especially in tech i want to find a scholarship in canada for example even in a medium level university where i can get closer to an advanced country the us is very very expensive and all the entire world is applying for american universities so i do not think i have a chance compared to other students coming from big countries do you guys have any idea of good medium level universities with a decently good masters programs in ai ml ds and can offer me a full funded scholarships that i can apply for in canada for example thank you for reading my post and i hope you guys can help me have a very good day,studying ms machine learning or data science abroad,data science in the uk
880,i am almost years old i have already have numerous gaps on my resume as i have traveled before have had numerous unemployment periods and spent a long time in grad school to just get a master is i am still struggling to get an entry level ds related job however i have gotten multiple phone screens per week and several onsite interviews per month so i do not think my resumebackground is awful i got my master is about a year ago i worked for a company for a few months and also worked as a freelancer for a few months since then my last freelancing gig ended a couple months ago i have spent the past month on vacation abroad i am considering taking more time off but i am unsure how harmful it will be to my job search for dsrelated jobs when i return home how harmful is it to go travel during time you are unemployed what excuse can you tell interviewers as to why you had that gap on your resume due to traveling abroad,how harmful is a few months vacation for job search for entry level ds jobs,i have a few questions for my resume
881,data and machinelearning analytics are becoming more widespread but they grow in complexity with larger datasets requiring much time for configuration researchers spend less time actually in data science than getting their systems up to date which can prove difficult at times ibm has opensourced codeflare a machine learning framework that will allow developers to train their models more efficiently onto the hybrid cloud this new framework is an exciting concept for those who are looking to simplify their workflow and shorten the time it takes the idea behind this design is that when users have work pipelines running they wait up to hours before receiving a result while using this new framework its implementation into these machines will require only minutes full story,ibm open sources cloudflare a machine learning framework that simplifies ai workflows onto the hybrid cloud,what is the future of data science
882,hey so i am about to start my last year at the uni i would like to learn data science do some kaggle build a portfolio and get a job after i graduate i would like to build a pc for this with a budget around i am planning on doing nlp stuff mostly i have read tim dettmers is blog but i really cannot decide my questions are should i go with a ryzen or a x and spend the difference on some other part since ml is not cpuheavy am i will i be in need of gb ram or am i fine with gb do i need a toptier ssd like the evo would sli give me a huge advantage in the future should i buy an slicompatible board now and get a nd gpu later on or spend that money on other parts which gpu of the above has the best value for me are the price differences between them even worth it based on the blog mentioned above tensor cores are not as important as memory bandwidth and bit compute capability which all of them have for rnns nlp uses rnns mostly if i am correct ampxb super super blowerstyle super vramgbgbgbgbgb bandwidthgbpsgbpsgbpsgbpsgbps tensor cores price local store some builds i was thinking about build ampxb typeitemprice cpu amd ryzen ghz core processor alternate motherboard asus prime xpro atx am motherboard arlt memory gskill ripjaws v series gb x gb ddr memory alternate storage adata xpg sx pro gb m solid state drive amazon deutschland video card gigabyte geforce rtx super gb aorus video card mindfactory case nzxt h atx mid tower case caseking power supply corsair rmx w gold certified fully modular atx power supply amazon deutschland prices include shipping taxes rebates and discounts total generated by pcpartpicker cest ampxb build ampxb typeitemprice cpu amd ryzen ghz core processor alternate motherboard asus prime xpro atx am motherboard arlt memory gskill ripjaws v series gb x gb ddr memory arlt storage adata xpg sx pro gb m solid state drive amazon deutschland video card msi geforce rtx gb aero video card case nzxt h atx mid tower case caseking power supply corsair rmx w gold certified fully modular atx power supply amazon deutschland prices include shipping taxes rebates and discounts total generated by pcpartpicker cest ampxb build ampxb typeitemprice cpu amd ryzen ghz core processor alternate motherboard gigabyte x aorus ultra gaming atx am motherboard amazon deutschland memory gskill ripjaws v series gb x gb ddr memory arlt storage adata xpg sx pro gb m solid state drive amazon deutschland video card gigabyte geforce rtx super gb gaming oc video card caseking case nzxt h atx mid tower case caseking power supply corsair rmx w gold certified fully modular atx power supply amazon deutschland prices include shipping taxes rebates and discounts total generated by pcpartpicker cest ampxb this is my first ever time building a pc therefore any advice is greatly appreciated thank you,need someone to tell me which pc build to go with for ml,am i wasting my time building a deep learning rig
883,hello i need a second opinion ampxb some backstory i have finished my electrical engineering masters degree with a focus on neural networks and data analysis i was jobhunting for about months before i got into a job as a data science consultant i let others look through my application and such and it seems alright anyway i think the problem i have is that i am lacking work experience as i have done only odd sidejobs during my undergrad but not really related to programming or data analysis itself the current position i have now for about months is more in the field of business intelligence and dashboarding and honestly i do not really like it but i also know this is part of the consulting job where it is really depending on the project itself i am contemplating of quitting my current job and searching for another one which is more aligned with the field of data science and programming the problem i see here is that i would be again in the position of not enoughreal work experience mostly getting rejections on job applications and not getting more work experience because i am getting mostly rejections the alternative is to stay for maybe years in the current company try to get into more technical projects doing some certificates are they worth anything and gain some more work experience before i go job hunting again for a data scienceprogramming heavy job a small side note for me data science is more in the field of analysing time series or other unstructured data using machine learningstatistics to get info out of data or find patterns and so on any advice or opinions,question regarding my first job in the ds field,is it worth getting a second masters degree
884,styleganv generate hd videos and edit them with clipodels pop up over the last year video generation still remains lackluster to say the least but does it have to be the authors of styleganv certainly dont think so by adapting the generator from stylegan to work with motion conditions developing a hypernetworkbased discriminator and designing a clever acyclic positional encoding ivan skorohodov and the team at kaust and snap inc deliver a model that generates videos of arbitrary length with arbitrary framerate is just more expensive to train than a vanilla stylegan and beats multiple baseline models on and resolution oh and it only needs to see about frames from a video during training to do so and if that wasnt impressive enough styleganv is clipcompatible for firstever textbased consistent video editing full summary blog post styleganv generate hd videos and edit them with clip arxiv code coming soon subscribe to casual gan papers and follow me on twitter for weekly ai paper summaries,edit videos with clip styleganv a continuous video generator with the price image quality and perks of stylegan explained in minutes by casual gan papers,research google ai and stylegan
885,hi im dealing with what seems to me as a simple problem but i guess i yet to find the right keywords for google to help me i have raw data comming in to a snowflake table in the form of user id session id event id and i want to get the results as follows user id session id did event did event did event the query is simple enough to produce and i created a scheduled task to run every day and to summerise the sessions from the past day into a new table this is ok but when i query the data i would like to get the already sessioned data from the session table and to compute the session from the raw table im not sure what are the best practices today and if what i did considered good any advice will be appricated,data pipelines designes and questions,how to query google analytics event data
886,apologies beforehand as this is going to be long before you instinctively say yes let me just quickly clarify that my phd in physics was entirely experimental and i did not do any kind of advanced numerical simulations that people kind of expect of us to do my only exposure to coding was literally just writing hacked up python scripts with zero thought given about oop documenting and unit testing now that ive got that out of the way heres the summary of what ive tried so far been applying for year applied to about places in total some of them were low effort i admit did a data science bootcamp months ago several recruiters started calling me on linkedin had about interview onsite interviews after the bootcamp managed to progress to the final stages for of them rejected from all of them recruiters have stopped approaching me for the past months in interviews i got asked about almost everything imaginable from machine learning algorithms to rest apis to hadoopspark and even ab testing i admit i was completely unprepared at first and had no idea just how much i had to prepare just to pass these interviews even though the job itself may be just bi reporting or excel stuff in disguise however i am wondering whether this realization has come too late now i mean as i said earlier recruiters have stopped approaching me on linkedin for the past months also i only just recently found a part time temp job and its only a few hours a week but i could get axed at any time just so i dont keep deluding myself reading my pile of books on machine learning spark flask etc i need to have a harsh reality check on what my chances are now in data science if there is any taking into account im not exactly a fresh phd grad anymore its been year now i dont have any relevant commercial experience unless you count the bootcamp the current immense competition for junior data scientists apologies for the wall of text and thank you for your time in reading this,i need a harsh reality check on whether i can still make it in data science i have a phd in physics,i feel completely unqualified for data scientist roles
887,so i am a person who is really obsessed with privacy i was wondering how a friend from a few years ago was doing so i searched their facebook page and then i clicked on the pictures and some posts i did not hit the like button the problem is me and this friend fell out years ago and i am the only person he knows from my country i know this for a fact so i have a couple of questions let is suppose i do not have my country and my city listed in my profile if this person were to go to page insights page views sort by country and city would my country or city show up i am trying to say even though my country or city do not exist in my profile would facebook show my country or city based on my ip address let is suppose i do have my country or city listed in my profile if i visit his page and page posts and i deactivate my profile immediately after will my country still show up in the page views do visits from deactivated profiles show up on statistics note i have never used my facebook account from my phone only mozilla on my laptop my anxiety is through the roof right now because i searched this randomly and i dont wanna look like a creep,facebook page insights page views question,how do i know if my city is really my home
888,hi all reaching out to this community for advice i have technical background and business acumen lately i have been investing nearly all of my time getting the basics of data science and ai i would like to get into consulting as my hypothesis is that i can be a good bridge between business and technical what are some ways to enter the data science commercial ecosystem as an entrepreneur should i start alone or work with experts right away if you are an expert data science practitioner do you see value in someone with less technical ability than you leading such a team in what way does such a profile provide real value so far i have been trying to nab up jobs on upwork and start building a track record would like to expand my horizons,how can an exphysicist with business experience hack their way into data science,data science consulting
889,hi guys this is my first time here and i have enjoyed the discussions so far even when my knowledge is far behind my interest in the subject i will contextualize my situation i am a year old marketing student from argentina we do not have a lot of courses down here about data science and machine learning so i wanted to start an edx micromaster teached by the mit called statistics and data science the thing is i am a lil bit worried about the prerequisites of the first module of the program probability the science of uncertainty and data collegelevel calculus singlevariable amp multivariable comfort with mathematical reasoning and familiarity with sequences limits infinite series the chain rule and ordinary or multiple integrals how hardcore do you think math is going to go i am comfortable with learning the basics of each point but having to go hardcore on every aspect of each topic is a different story do you think this is a viable way to start learning about data science would love to hear from you,newbie here need some advise,how do i know if i am ready for data science
890,hi i am a junior undergrad i got selected for a final round interview for a data analytics internship at a healthcare startup it is in days from now it will be with two vp is each a separate interview i have one previous internship as well as one project on my resume i would appreciate any tips at all i am not expecting to do that great because i am currently being ghosted by two other companies after final round this seems to be my only chance for an internship this summer so i really want to make sure it goes decent at least if i dont get this i probably will not get any other internship this summer any help or preparation tips or other relevant advice is greatly appreciated,tips for final round data analyst internship,data analytics internship interview tips
891,i work at a large company in the retail sector i was hired in july as a python developer my old boss presented me with a demand involving data facebook offline conversions api i used airflow to automate this task and drastically reduce process time people working in the data science sector knew about it and invited me to work there in early november i started working as a junior data engineer my current boss said he wanted someone to learn all the processes from teh scracth since the data science team only had seniors engineers the team also has mathematicians data scientists and data analysts about my first weeki am really enjoying what i am doing i have heard and read some people say it is a monotonous boring and difficult job but i do not think so i work a lot with sql and nosql i believe that of my working day is dedicated to this i often have to redo queries to input new data to analystsscientists or simply clean up the raw data my view on any job is as long as it challenges you it is worth it and it is not boring each day i try to set goals and reach them at the end of the day it helps a lot to dedicate yourself to what you are doing and i do not want to sound like a coach or anything like that but always trust the processjourney ampxb and what did you think in your first week of work as engineersscientistsdata analysts,my first week as a junior data engineer,is it worth spending time learning r or python
892,i opened this discussion for the second time since even though i get some upvotes i could not get any responses i hope this time i get some answers ampxb hello everyone i am research master of economics student in one of the leading universities in europe during my bachelor i took two courses about r and i have two short internship experienceeach of them was months and my responsibilities can be considered as wouldata analyst who uses r during the first year of the master i took three econometrics courses in which we focused on linear regression logistic regression time series and panel data hence i believe that my econometrics knowledge and background are good in the second year i will take two data science courses in which we go through elements of statistical learning and introduction to statistical learning books plus i will also take two microeconometrics courses one is theoretical and the other is applied so do you think that this background is enough for being data scientist i believe that i should experience more in the application aspect especially for coding what should i do more in order to survive in the industry do i need learn python my opinion is that improving my r skills will be more efficient than learning python from knowing nothing is this true your comments and suggestions are more than welcomed and very valuable for me thank you,as a research master of economics student what do i need in order to survive in the industry as a data scientist,is it worth spending time learning r or python for data science
893,im working on a toy problem where im trying to build a dl classifier to predict whether or not a user query is a product search or a general question i have a dataset with a bunch of example searches ie dog toys apple tv and i also have another source with a bunch of general questions how to hook up hdmi cord unfortunately i do not have an entity recognition system to tag products i built an lstm and got accuracy with a loss of on the validation but when i predict a couple examples it always is wrong the dataset is k searches and k questions i used weight priors in the keras model but it doesnt help any suggestions,sparse classification,question about model accuracy
894,scope i have a input of values which are generated at runtime no information about the features is known until runtime the number of categories per discrete feature might range from to the features will be used as input into multiple machine learning models such as neural network at first in order to investigate which algorithm works at best for them in terms of classification performance the final goal is to build a anomaly classification application the data has to be parsed to csv in the final step information at runtime foreach index these information are known value itself normalized between and if continuous vector position in terms of onehot encoding position for the if discrete vector size number of distinct categories if discrete if continuous discrete continuous bool question how do i build one universal usable feature vector for the majority of machine learning algorithms importance of the algorithms in this order neural network svm oneclass bayes regression principal component analysis could anyone provide some references for this i need more for my thesis my idea yet i thought about a nested model in which each of the inputs is connected to one input layer thus creating a single point of input this layer consists of a nested feature vector this is a onehot vector if the value is discrete otherwise if the value of continuous nature the input unit is solely the normalized value i hoped that training would then force from each nested layer of discrete values to get me one continuous value leading to having a input value of continuous values you might realize at this point from my working nature that my experience focuses on neural networks yet unfortunately i am running out of time with my thesis to try all variations and experimentations out by myself without addition creative input confusion could this approach of continuousing all values work how would i parse something like my system into a csv structure do other algorithms than neural network support such approach i thought perhaps about putting everything into a vector of size n of the largest feature vector filling all additional places here with zeroes also i thought about if it might be better to make the continuous values at first discrete too by placing them into the corresponding places with the n sized vector this would enable me to create one matrix where each row has equal column size while each row represents one feature however the matrix structure confuses me to for the neural network as i am not sure if i would then train the neural network with one input feature per row the approach already discussed or just use one input unit per place within the matrix like a image recognition neural network where each pixel is one input unit independently from its xy axis position,build a nested feature vector of both discrete and continuous features,question about continuous feature size
895,i am tracking prices for general bargains and specific items every day at the same time there are new x deals i get data like name price_old price_new discount based on this i calculate amount of discount to catch good deals i also check for quantity of items how many of them were bought and based on this i calculate amount of bought items this is columns do you have idea how can i optimize it do you have suggestions to optimize number of columns what would you do to merge number of bought products with amount of bought items my problem is that sometimes there just or items whole the deal is bad or there is products and the deal is great lastly how to save such data i want to track those deals every day to find some trends and in the future get good deals right away based on them,price tracking data storing,how do i track how many items are being bought at a specific time
896,in a new paper a trio of columbia university researchers propose a novel framework and hierarchical predictive model that learns to identify what is predictable from unlabelled video the paper learning the predictability of the future introduces a hierarchical predictive model for learning what is predictable from unlabelled video inspired by the observation that people often organize actions hierarchically the researchers designed the approach to jointly learn a hierarchy of actions from unlabelled video while also learning to anticipate them at the right level of abstraction the model thus will predict a future action at the concrete level of the hierarchy when it is confident and when it lacks confidence will select a higher level of abstraction to improve confidence here is a quick read columbia university model learns predictability from unlabelled video the paper learning the predictability of the future is on arxiv the code and model are available on the project github,r columbia university model learns predictability from unlabelled video,researchers at university of guelph propose a new hierarchical model for unsupervised learning
897,hi guys i am trying to break into the financial industry i am interested in learning logarithmic regression i have chosen logarithmic regression because in finance we always talk about strong growth periods followed by a levelling off this typically applies to economics as well since economics is the sum of all businesses it is just a much longer time frame i will be using this for company and economic analysis do you guys think logarithmic regression is the right type i am aware most people use linear regression are there any go to sources for someone who is cfa level level i do not necessarily want the bare basics i am looking to get a more intermediate source if possible any suggestions would be nice from tools within regression to any curriculums you suggest i go through books anything would be nice thanks guys,sources to learn logarithmic regression,looking for some economic regression books
898,i want to start with having a point xy travelling in a direction vxvy towards some other point and i am curious what the data should look like i would like to make a standard neural net that learns how to steer away from hitting an obstacle i am saying standard because that is what a guy at this course said i am just unclear at what the normalized inputs look like for simplicity lets say i have just one point and i start the netwrok by driving it towards the point i have my positon xy which can be normalized by width height i have my vector xy which is normal i just do not know how to normalize this point or danger level is it some normalized value between the driving thing and the wall distxywallxwally point_of_no_return or something then one final thing how do i tell my nn to take action ie steer left or right do i feed it data that is like input danger_o output,how do i normalize the inputs on collision detection for simple setup,how do i train a neural network to recognize different inputs
899,i have been looking into making some reinforcement learning agents for a continuous action space and keep getting search results for the actor critic method this method does seem to provide continuous value outputs for actions however from what i have seen most use these values as a probability matrix if output from the actor is and output is then action is taken then the results are measured and if the policy does well then it is reinforced becomes or something next time around what i am looking for though is a system that does all actions at once but only varies the degree at which each action is taken for example when driving you are never not steering and you are most likely controlling the gas pedal at the same time you are setting gas to amp of max amp or even amp if you are slowing downbrake set to gtamp likewise you are either steering straight left right or some inbetween value slow right hand turn all the time my question is how to update your action policy given that the better policy could be positive or negative for example say our steering action value is and we do better than our critic expected how do you reinforce that when adding to it could cause a crash and subtracting could also be less optimal am i thinking about this method wrong or is actorcritic meant to be a stochastic result used to select only one action and i should use a different algorithm,reinforcement learning in continuous action space with multiple actions at once,what is the proper way to evaluate a model is performance
900,hi everybody i am new to reddit so sorry if i do not know all the ins and outs of it yet i am currently following a mathematics and statistics bsc in the uk and i would like to follow a mooc on data science i really enjoy mathematics and have done many personal projects on python however i think a mooc on data science would help me to stand out in the massive amount of students sending their resume to companies furthermore i have got plenty of free time at the moment so i would like to make the most of it i have done some research and those three look interesting not knowing much about the topic i need your help to choose the right one i would like to know if one of them stands out if not do you have any suggestions on different courses available thanks in advance for your help and i am happy to answer any of your questions best regards,need help choosing the right mooc on edx,data science career advice
901,i am doing an internship for a government contractor i was given access to their data files and basically told to make a model with them the data is in my opinion poorly organized poorly structured unclear some important files from certain dates are just straight up missing and nobody seems to be able to tell me much about what it even means or represents i have a general idea of what it represents thats all thats everything i have to work with i am beyond stressed and frustrated is this the nature of a data science job i need structure and an idea of what to do maybe this is not the field for me,is it normal to have no guidance on what problem to predict solve,how do you organize your data
902,i applied for an internship position as a data scientist in a startup i had one technical interview of hour regular coding questions and ml questions then an open question feature prediction for which i had week to complete then two hour technical tests onsite on gnral coding skills and ml knowledge i have my final interview with the data science director tomorrow it is expected to last between min and hour the recruiter told me there might be a technical part what kind of questions do you think the data science director could ask i want to prepare it the best i can but i am not sure if i should focus on ml algorithms the theory behind them or maybe prepare present yourself and why join us questions i know no one can know but maybe some of you went through a lot of processes and have more experience with it thanks in advance i spent so much time on this application more than hr in total i really do not want to screw this also the company is very well reviewed on glassdoor and i had a great impression when i did my onsite tests,interview with the ds director,i have an hour interview tomorrow for a data scientist position and i do not know what to do
903,my validation dataset is an exact copy of my training data set however during training at the end of each epoch my training accuracy is or so average of all batchesand my validation is around if i change optimizer i notice that the gap can be even bigger my fulldata set is only images during training my batch size is and steps_per_epoch is so the model should be seeing around images why is there such a huge discrepancy between training and validation accuracy if they are the same dataset here is how i am fitting my model r_optimizer optimizersadagradlr epsilonnone decay r_batch_size r_epochs r_steps_per_epoch modeloptimizer r_optimizer modelcompileoptimizer r_optimizer losscategorical_crossentropy metrics accuracy history modelfit_generator train_gen steps_per_epoch r_steps_per_epoch epochs r_epochs validation_datavalid_gen validation_steps npceillenvalid_genfilenamesr_batch_size callbacks callbacks shuffle true verbose i am using xception via transfer learning and have added the following layers global_average_poolingd_ dense_ dropout_ dense_ dense_ dropout has been set to by copy the weights and creating a new model previously it was only if i change optimizers to optimizersadagradlr epsilonnone decay and compile again sometimes i see a difference in accuracy i dont understand why,discrepancy between training_acc and validation acc during training despite same dataset for both keras,why am i getting this error
904,does decision tree classifier works with numerical range in this example set of dataset i am planning to test the data regarding the age range of and above using the performance score of these employees can the decision tree be able to make the decision by using age ranges the objective of the program is to identity what affects this employees age ranges by using the numerical data under education and of years exp so the output would beusing gini index here age factor that affect based on age range education of years exp is it possible to train the algorithm by basing the age range and performance score i am still a beginner in data science i have not heard of using numerical ranges kuddos,working with numerical range in decision tree classification,question about the decision tree
905,website value prop build your resume using modern templates designed for the professional world pain point formatting resumes is a hella painful processif you have used word latex indesign anything else you would know that it is hard to get it to look exactly like you want it spending more time on the format than you are on the content is crazy so i created jumpr to help build resumes designed to be both elegant and effective ampxb i started building this site in my senior year of college and i finally got it to a point where i feel like i have made something valuable enough to share it is been a pretty tough journey balancing a side project on top of work and life it took me whole years to build this i think i have started over like times switched technologies halfway through angular to react and lacked motivation whenever i had the chance to work on it i am proud of what i am made and i am looking for some constructive feedback from you all,finally finished my website after working on it for years looking for feedback to help data scientists find jobs,i have built my first data science resume
906,hi building a nn model includes finetuning many parameters including hyperparameters architecture vectorization and more in most cases it is very hard to know in advance what will work best and a very common answer to questions like what learning rate should i use is do cross validation and some kind of grid search and find the best value the problem is that training a network takes a lot of time hours or days what is the best strategy here should i try different things on small subset of the data and hope it will work the same way when ill train on the whole set also what is your general strategy when training a network do build a network that overfits the training set at first and then handle it using different techniques or do you try to build the best network from the start any general advice will help thank you,how do you run long experiments with neural networks,best practices when building a nn
907,aliasfree gan more commonly known as stylegan the successor to the legendary stylegan came out last year and well and nothing really despite the initial pique of interest and promising first results stylegan did not set the world on fire and the research community pretty quickly went back to the old but good stylegan for its well known latent space disentanglement and numerous other killer features leaving its successor mostly in the shrinkwrap up on the bookshelf as an interesting yet confusing toy now some months later the team at the telaviv university hebrew university of jerusalem and adobe research finally released a comprehensive study of stylegans applications in popular inversion and editing tasks its pitfalls and potential solutions as well as highlights of the power of the aliasfree generator in tasks where traditional image generators commonly underperform lets dive in and learn shall we full summary blog post stylegan video editing arxiv code subscribe to casual gan papers and follow me on twitter for weekly ai paper summaries,paper digest third time is the charm image and video editing with stylegan minute paper summary by casual gan papers,meta the future of stylegan
908,so let me give you a brief about my current situation i am holding a bs degree in mechanical engineering an mba in finance years ago when i started my mba i also found a job as an accountant in a retail company which i am currently working to be honest i was working really hard and was eager to grow in this company took some courses in accounting and tax laws to cover up the gaps i realized and i was quite good at what i did i heard many times that some of managers recognized me as the next senior accountant of the firm as the company grew but it was not like that the cfo and his surroundings did not accept a not accounting educated person as an option to rely on but i wanted to grow working in the industry i realized i was more passionate about the data than the process of creating the financial data that seems more challenging so i became more and more interested in the data science and hated more and more the accounting and their perspective now i am eager to make a shift in career i already have the mathematical and statistical background i kinda can say that i also have the business insights background or at least i can say that i can try to find the answers also i know some programming as much as its needed as a mechanical engineering student to solve the numerical problems and also i have created some html css websites as a side hustle some times ago but there is something that holds me back from leaving my comfort zone and pressing the apply for the data science community button and that is will the data science community accept me will i be faced with the phrase of not qualified because of a non computer science related field because i am just tired of trying to do my best to fight in a field in which i do not belong there and after passing some opponents just the moment that i am about to enter the interesting league to be slapped in the face,computer science academic major necessity in data science,is it worth getting a masters in data science if i already have a job as a data analyst
909,hello everyone ampxb i recently started the journey to learn ml and taking the practical route to avoid discouragement currently taking the fastai and amazon courses to learn some of the basics so i have seen the random forests and image classifiers and find them quite interesting and can apply it to some data sets but i have a data set that i want to start processing and i slowly progress in my journey but i would like to focus on those algorithms techniques before other ones the big issue is that i do not know the terms so i can read about them ampxb so this is the dataset i want to work on it is a x pixels spectral cube every pixel is a complete scan of infrared spectra and the same cube is taken n times every pixel is a spectra example of spectra taken n times ampxb the data consists of a set of cubes taken in n time intervals the face of the cube consists of x pixels in x y coordinates every pixel contains a spectra with axes x frequency y absorbance ampxb here are the different problems i want to solve and how i have been starting to identify how can find the solution ampxb identify concentrations of particles since the sample is a solution every pixel in theory should be the same i want to find when the solution actually concentrates in an area in this case it should be noted by an increased absorbance values in that particular area in this case if calculate the average of every frequency and then subtract that to all my points i should end up with just the points that have been increasing the concentration and i believe i can train an image classifier to identify this regions and that should at least tell me the issue is happening then looking at that values per n time measurement if the percentage increases past certain point i can identify at what point in time this concentration started and how fast is happening i dont know how to combine it with the previous step or even if i should combine them at all identify sample degradation the sample can be identify by a series of peaks in the spectra those can be modeled with gaussian curves as time increases the curves absorbance can increase and the width of the curve be smaller but the peak location should not change also if new peaks appear those are signs something is going bad so i can probably identify when regions of the sample start going bad because they will be trapped by the previous filter but how to differentiate it from the previous case to identify when the degradation happens i can process the spectra and just extract a set of the gaussian curves that fit the model and then track the change over time if one peak increases something else must decrease how can i keep track of this because i have to look at every point and every time measurement because the degradation happens over time i was thinking on simplifying this making avg of the whole image and comparing with each n measurement because it should keep the same pattern until degradation happens ampxb so i think i can solve some parts of it but how to i combine the parts together so that i can get the whold story if where i am stuck ampxb sorry for the insanely long post ampxb ampxb thanks dicesds,need some pointers on what to focus on,how to deal with overfitting
910,hi i currently have a single ti which i use for deep learning projects and kaggle competitions i intend to upgrade my rig but i am not sure if i should go for another ti or sell my ti and buy a ti the price for both is almost the same actually i need to buy another psu if i go with gpus so xti is more expensive xti pros can run experiments in parallel a bit faster and more memory cons more power consumption need to but another psu cannot upgrade further ti pros can train on fp roughly faster than a single ti and almost doubles the memory less power consumption easier to sell later imo can buy a second one later no need to buy a better psu right now cons less raw memory vs much lower performance than xti on fp need to sell my current ti different gpus would be bad i believe anyone went through a similar experience and can give some advices thanks,buy another ti or upgrade to single ti fp,x ti vs sx ti for deep learning
911,my current role is more heavily focused on data prepcleansingautomationreporting and project management i can develop and implement solutions but i am not as strong as i need to be when it comes to the more abstract thinking like deriving actionable insights from data drawing conclusions making recommendations etc my company is in professional services and they are very implementation focused so i can have ongoing projects where we deliver a solution and it is on to the next project while the end users auditorsaccountants are left to do most of the deeper analysis themselves this is also in a very niche industry auditaccounting and while i have picked up on some of the concepts specific to this field i do not have a deep accountingaudit background i also ran into this issue when i was going through the beginner courses on kaggle where a few questions were posed and we had to examine the data in the exercise and draw conclusions from it i was completely stumped as my brain is not used to this type of abstract critical thinking how can i further develop and improve in this area,how to be more analytical derive insights draw conclusions from data etc,how do i go about creating a dashboard for my clients
912,hello everyone i am taking a course on udacity about reinforcement learning in a video they say that since the following equation holds bk q_ bk q_ leq gammak q_q__infty it can be useful to run the value update more than once they apply k times the bellman operator to both qltsubgtltsubgt and qltsubgtltsubgt now i have a question do they mean that is useful to update multiple time the qvalue for each reward this kind of make sense to me because it could be that this makes something similar to what happens with a higher learning rate but being more stable i do not know whether it is true or not and i did not try to prove it is my reasoning correct,does updating value in qlearning more than once per step make sense,question about udacity and reinforcement learning
913,basically my second week at my employer corporate innovations in a big corporate firm and my employer says i am not really sure why i wanted a data scientist in my team it was more of a gut feeling we are sure we can find things to do for you i am pretty disapointed and clueless at this moment since i turned down a good offer from a startup for this so people what are my options and basically best course of action this is my first job as a data scientist recent grad couple of mediocre internships as a data scientistml engineer good dev exp how do i turn it into a good situation,on second week manager says he isnt sure why he hired a data scientist,data scientist to data engineer
914,i am currently working on a university project which requires collection of some historical timeseries data via a rest api i am then looking to correlate this data with the weather in that location my issue is that i am unable to find any sources which fit my criteria are free simple to use i initially looked at google trends flight data and twitter trends but none of them were free or easy i simply need an api which returns some data for a given region in a certain time window preferably hourly and cannot for the life of me find any sources can anyone point me to an api which may be helpful,request looking for any free api with historical timeseries data by location,looking for twitter api timeseries data
915,i want to determine predictor importance ideal is to retrain same model on same dataset missing each variable in turn this is too time consuming the recommendation i have seen everywhere is to remove the column by converting it into noise by replacing it with its permutation why is it not better to replace the variable with a constant thus muting the signal i ran an experiment on my own natural dataset with highly crosscorrelated variables removed variable importance was computed using the constants mean median and values common in variable i used all of caret is regression models loss function is pearson is correlation data with no error was removed all center constants produce less of a drop in correlation than permutation about of the time constants did not make same error therefore interaction and conditionality at least all decision trees would do this take all available values in a variable and use them as the muting constant weigh by constant is occurrence the mean of that is what permuting converges to as more iterations are run right i can not think of what to try next to understand this problem,why not use constant instead of permutation for variable predictor importance,is there a reason to remove outliers from a model
916,i have been browsing online other reddit sites and amazon looking for the best available book on statistics that covers the basics of statistics all the way to different methods of hypothesis testing sampling and experimental design there are times i need basic refreshers and reminders on limitations present in each statistical methods when it comes to sampling or multivariate testing and i would like to go over the concepts before i deep dive into developing experiments while i know i can do searches online my preference for books is that it gives me focus and the tone is consistent to allow me to understand the flow of concepts being described in the book would like your recommendation for a book that is not dense with text sometimes the authors just love to write so much for no reason uses examples to demonstrate concepts focuses on proof,best book on statistics for someone who needs a refresher on statistics,best book to read for data science
917,hi i was hoping you all could help me with some suggestions for a new title i am moving to a new position within the same organization and the current position title is research analyst i want to change this as part of negotiating the offer they are receptive to my suggestions so i think they will agree to whatever i ask within reason for some background the new position is a lot more statsheavy than my current one i will be doing logisticlinear regression anovas chisquares etc they istrongly preferred someone with a phd for the role which i have in the social sciences there will also be a lot of data wrangling and merginganalyzing datasets along with creating dashboards in tableau the general field is education research the position was advertised as research analyst but i do not want to keep that because it would look like a step down from my current position title senior research analyst also as far as salary grades at the company go it is a step up and fairly high here are my ideas for a title i am going to pitch so far senior research associate senior statistical analyst statistical analyst i know there are other titles out there that might be relevant but i cannot think of any any suggestions would be greatly appreciated,what would you call a position higher than data analyst lower than data scientist details in post,is it worth taking a paycut to become a data scientist
918,im looking for career advice as i feel that i dont have a clear direction of where i am going i am originally from west africa i have a bachelors and masters degree in business administration from a university in my home country but none of those hold any value here back home i was working in accounting after getting my green card i started working as a driver eventually my friend suggested going into data science i was accepted into an ms in data science program and i am currently in my first semester so far everything is going smoothly the only drawback is that because i am not a citizen yet i was given a limited amount of student loans the rest my wife and i had to use from our savings my wife is also new to this country and we are relying on my success in this program to become financially stable i graduate in august i want to ensure that i have good job prospects when i graduate my program is online and i dont interact with many people can someone advise me on things i should start doing now that would increase my chances of getting a job when i graduate i am particularly interested in business analytics or anything related to business and data science however im open,can someone offer me career advice,data science career advice
919,hi all my employer offers an educational budget which i can pretty much free to spend it is about euro is each year and money i do not spend transfers to the next year for up to three years do you have any good ideas on how to spend this i have finished a msc artificial intelligence years ago but have been working in the information security field i did however stay a bit up to date by following free online courses i have decided however to move back to ai and there is even a chance i can do that with my current employer both soft skills and technical skill suggestions are welcome on the soft skill side i recently followed a story telling training which was quite useful on the more technical side i am only aware of the courseraudacity etc and programming sites like data camp,what are good ways to spend educational budget,i have a job offer for a year but i do not know what to do
920,i am wondering what suggestions people have for keeping their skills sharp andor for picking up new ones as they search for work in this field especially since there is so much with new things to read about almost daily with perhaps a little more focus on the time between graduation and first job the obvious and general response here would be to search desired job listings and brushuplearn the skills required accordingly though this is not always so easy and the variance of skillsknowledge can be high excluding the very obvious ones there is also the issue of domain knowledge of which one may not have any at all let alone specific to the job applied to picking up on this can seem tough from the outside especially to be up to date on current practices perhaps someone can suggest some useful booksblogsetc which would help those of us coming from a purely statsanalysis type of background to get used to certain domain spaces and the techniques there industries like financeecon biomedical admarketing etc seem to use familiar methods but sometimes have rather unfamiliar nomenclature for them a bit about my background if anyone would have some direct suggestions for me i would be very appreciative masters in stats bachelors in math have had some basic analytics work using google analytics a short semester internship for a pharma company as a statistical consultant quite good with r intermediate with pythonsqlsas familiar with most modern learning techniques i have tried to keep sharp by reading statsml books learningrefreshing topics on youtube testing out some tools in kaggle comps despite this i am still quite nervous come every interview there have not been many sorry to be so long winded thanks in advance,keeping sharp while looking for work,what are some of the best resources for learning about data science from scratch
921,so i am allmost done with my marketing major and i did a minor in big data and enterprise resource planning but i was wondering what are some good skillsets to have to be able to communicate with data scientists or even understand the numbers or calculations that are being made we work alot in spss for data we collected in surveys etc but big data seems to be the most important data source the coming years o yeah what are some good coding languages that are used for big data if this is involved i know i might not even be in the right sub or that i am completely thinking about something else and yes i know i did not do calculus etc so i wont be able to do the calculations i just wanna know some good resources to have to be infront of the rest of the flock,marketing major looking for data science info,what are some good data science skills for someone who is completely new to the field
922,i recently finished my master is in data science from cuny and after some traveling to clear my head am applying to jobs i am wondering how i should be spending my time ie building a portfolio kaggle practicing python for job interviews buffing up on algorithms etc a little about myself i am mid is and worked on the data and messaging side of politics from state to national level campaigns but my work was mostly in sqlspss i am an intermediate in r and python and competent in the data management libraries like pandas and dplyr for now i am focusing on marketing data science jobs to get my foot in the door although i will likely expand those parameter soon,finished a data science master is suggest next steps,how much should i spend on personal projects
923,undergrad entering junior year here i am taking a class next semester on statistical computing aka r i want to put some stuff on my resume with r as well as genuinely get experience with the language on projects since i see myself using it in the foreseeable future my school luckily is a large research university research assistant positions are relatively easy to find but that does not mean that they will be meaningful positions i found a short list of teachers whose research looks very interesting in the cs amp biostats departments they all deal with data analysis amp decision making i am just curious if this is the best way to get experience working on r both professionally something on a resume and educationally actually knowing how to use the language i am hoping a professor would begin by giving me some data sets work on and clean all the while giving me exposure to the kind of work a data scientist would be involved in as i complete my course on r i hope heshe work into a more involved role the risks i see is just that i do not know any of the professors i am about to contact i found their names because a fellow intern did a summer program involving biostats research i was wondering if anyone here who has done research found it a useful experience for the industry also would a business school use r for any research is it a factor in technology amp operations marketing or finance the cs amp biostats departments have plenty of grad students doing research the business school has less grad students and much more so they might have more meaningful positions for projects with plenty of funding i may be able to find a stronger position there but am not sure if any of them leverage data science,is doing research at my university the wrong way to approach learning r,how much do i need to know to get a data scientist position
924,hey rlearnmachinelearning im a math student who got interested this field after watching grant sandersons bluebrown videos in machine learning i started trying to develop my own neural network and heres how its going my goal was to develop a neural network capable of recognizing handwritten characters i have a neuron input layer that runs through three neuron hidden layers and outputs into a neuron layer im working in matlab because its what im most familiar with i created four random sets of weights and biases and a training set of characters and the algorithm for the character recognition works well what im trying to figure out is how to backpropagate to fix the weights and biases to increase accuracy i know somewhat how to find the cost function with respect to the input neuron but i cant figure out how to use the cost to adjust my weights and biases thanks,backpropagation on a neural network,how do i deal with a neuron bias in r
925,im a phd student studying genetics my work is entirely computational between grad school and undergrad ive had coursework in python r c java javascript and have had some limited exposure to other frameworkslanguagestoolsets outside of geneticspecific software i have no intention of staying in academia and data science seems like something i would be interested in however most data science resources i look at seem machinelearning focused which is something i havent used at all i understand it at a general level and have done some tutorialsyou side projects to learn a bit more but its obviously not something i would have phdlevel knowledge about how important is it that i master machine learning topics are there data scienceadjacent job titles that would be a better fit for me,is machine learning a necessary part of any data science resume,is it worth getting a phd in data science if i already have a job as a data scientist
926,hello a beginner level ttest below would appreciate some help i am trying to analyze ab test results for user engagement total time spent on site for control and treatment samples the sample distributions are heavily right skewed as you would expect most people spend a few minutes on the site while some heavy users spend longer the treatment size is of the population with total sample size i am thinking i need a sample ttest unpaired since different users are assigned into control and treatment the first task is to identify the metric total time per user aggregated over days or total time per day aggregated over users do you guys have any tips on how to choose this also am i right in thinking i need to sample of the both variations so my samples are of equal size importantly my plots do not seem to be satisfying the assumptions for a ttest ie normal distribution and equal variance any tips thanks in advance,means ttest with skewed sample distributions,how to deal with overfitting
927,i am currently studying at university majoring in data science and artificial intelligence and i am halfway through my major i want to distinguish myself from my peers and give myself an edge when applying for jobs and i feel that certifications are the way to go so my question is which certifications should i take given that i have a very good grasp of python and pandas moderate expertise in scikitlearn and docker and very basic knowledge of tensorflow i am a very very fast learner and do not consider myself to be a beginner to the level of my peers albeit still a beginner i found a couple of certifications online but do not know which to choose i read reviews about the ibm data science professional certificate saying that it is targeted at absolute beginners is that true if so what do you suggest i take other than that preferably not targeted towards absolute beginners please suggest more than one certificate as i plan to take more than one at the moment i feel like lean more towards data engineering big data architecture and such more than modeling and such but i do not mind taking certifications in either of them as i am still early in my career thanks in advance,which certifications are best for someone who is not an absolute beginner,what are some of your preferred certifications for data science
928,as someone who is potentially looking to break into data science when i read up on it it seems the barrier to entry is astronomically high very proficient in coding also have to have great business skills you have to be very good at math not to mention being very proficient in sql this seems more as a mid career job then entry level i am getting a comp science degree from my understanding it should transfer into data science pretty well and i am learning python then sql my question is what is a job that may not be in data science however would be a good road map to data science i am thinking potentially something like a business analyst would that be a good route also what should i be focusing on to supplement my cs degree,what is the entry level job before the entry level job,what is the best way to get into data science
929,hi i am currently a student who is working on my final year project i would like to ask for some guidance please so currently i will be developing two websites with html css and some php one of the websites will be on a cms i would like to create a backend web analytics so the admin can go to the backend page login and see web analytics for the website ie bounce rate visitors all information which can be provided by google analytics it would be great to have the data visualised toographs how would i create this backend tool if you guys can provide me some good reading material some links anything which will help me thanks in advance,creating my own backend web analytics for website,looking for some guidance on web analytics
930,i feel very sad because i put a lot of hope into it the job and the company would be great for my career i have definitely been on the interview grind a few times before and have been in the industry for a number a years but holy cow the feelings never go away not for the jobs that would be great to have the nervousness unease occasional hopelessness etc having gone through many hurdles skills development personal development failures etc it still feels just as hard the th time as it did the first i may know what to expect more i may be more knowledgeable qualified etc but gosh darn do the feelings still get me and so the wait begins,this week i interviewed for the job i want,i feel so hopeless
931,hey all i am working on an addon for world of warcraft that will require finding correlated properties when an action is taken some example of properties are the type of action damage healing crowd control etc the amount of time you have to wait until the action is useable again the priority that action has compared to others that are available etc i would like to identify why the player used a specific action based on the state of the game at the time the state is comprised of many different things including the talents customization option that often changes how the actions you take behave the player has selected the type of gear they are wearing the auras effects that modify your character in some way active when taking the action the type of content the player is doing whether or not they are moving whether or not they are actively fighting something etc there are some action properties that are true all the time example an action that always does damage others are true when a single state value is true example an action that should only be used when there is more than one enemy being fought still others are true with a specific combination of state values example an action you should use only when you are wearing a specific item and a specific aura is active finally there are properties that can be true in multiple states example two different auras that each make an action useable instantly rather than taking time right now my thinking is that whenever an action is taken the addon will take a snapshot of the state of the game the thing is i am not sure how exactly to go about extracting useful and accurate information from this data i do not have any formal training in this stuff so please let me know if there are specific concepts that i should look into,how to extract properties about an action from data representing the state of the environment at the time of use,is there a name for this type of action
932,i am an r user sas too and really want to get into python to futureproof my skillset for analyticsdata science and want the generalpurpose offerings as well i am so confused just even installing python and its packages like i do not know where i should run conda i kept trying inside spyder and am so confused with what modules packages and libraries are i installed anaconda i like how in r i get an idea of oh i need to scrape a page how do i do that is simple as realize oh i need to scrape a page how do i do that gt google r scrape webpage gt installpackagesrvest gt requirervest gt rvest gt i have new functionality with documentation all in one rstudio window is it as easy to do in python or will i really need to go through shell to run conda to download packages etc and where can i get documentationhelp from within spyder i really hope i am just not getting it and the heaven of ease that is python is something that i will eventually settle in to,why do i find it so hard to transition to python,how do i get started with data science
933,hi all i know this is a very common sort of question around here but i was hoping for some advice based on my situation in brief i have a masters in physics phd in astrophysics and am currently at the beginning of my second postdoc for a number of reasons i have decided that i want to move away from academia and i feel like something under the umbrella of data science would be right for me python is my main language and i use the typical packages to do analysis for my research numpy scipy pandas scikitlean matplotlib etc though my coding is very academic in that it is dirty inefficient but does the job so i definitely need to brush up on proper coding skills i also have experience with bashscripting matlab and very basic knowledge of sql i am comfortable with advanced maths and stats though a bit rusty as it is been a while since i took those courses i am comfortable with the principles of many standard ml techniques though i have limited experience in actually implementing them for my research i have published papers in scientific journals presented at a bunch of international conferences etc i feel like i probably have a decent set of base skills for the data science field but i am struggling to figure out the appropriate level to pitch myself after scouring linkedin i get the impression that i lack certain skills particularly on the coding front and certain languages sql r etc at the same time i feel like i might be overqualified for very low level entry positions please call me out if i am wrong on this does anyone have any thoughts on where i should go from here i know bootcamps are often suggested but unfortunately i could not dedicate that amount of time even if i could get into one right now i am mostly focusing on some coursera courses eg on machine learning sql as well as reading through some text books in time i will try to work on some small projects to throw on github or something any other suggestions on where i should focus to increase my chances of successfully moving into ds would be much appreciated thanks,postdoc astrophysics looking to move into data science where to go from here,how do i go about learning data science
934,i am trying to drop cases where the comment body text is just true but it does not get dropped with my current code i am able to drop cases that say deleted or removed but not true does anyone know what these true comment is are or why i cannot just drop them thanks for any help below is my code declare where the output directory is outdir cusersjmstrackpaperredditbigquery declare where the input directory is indir cusersjmstrackpaperredditbigquerycomments ampxb join all csv files into one single csv file ampxb create a function to join all the csv files in a folder into one csv file ampxb create the function name the directory where the csv files are and what the output file is def join_csvindir cusersjmstrackpaperredditbigquerycomments outfile cusersjmstrackpaperredditbigquerysingle_filecsv delete isingle_filecsv if it already exists to avoid making more copies oschdiroutdir try osremove isingle_filecsv except oserror pass make sure isingle_filecsv no longer exists if ospathisfileoutfile print error isingle_filecsv still exists else print proceed isingle_filecsv does not exist change to the directory where the csv files are oschdirindir put all the csv files into a list of files to put into the joining function filelist globglobcsv define the total list dflist add all the csv files to the total list for filename in filelist printfilename df pdread_csvfilename printfilename df isubredditunique dflistappenddf join the csv files into one file axis means it will join them by vertical columns concatdf pdconcatdflist axis return the created pandalist to a single csv file output location and name already defined above concatdfto_csvoutfile call the function join_csv ampxb ampxb read single_filecsv into a dataframe data pdread_csv isingle_filecsv ampxb remove all cases that say deleted removed and true in the body data dataset_indexbody data datadropdeleted axis data datadropremoved axis data datadroptrue axis data datareset_index data datadropunnamed axis ampxb ampxb ampxb clean the dataframe databody databodystrlower databody databodystrreplace databody databodystrreplacews ampxb ampxb pddataframedatato_csvdatacsv,why do some of the comment bodies from reddit data say true,i am trying to use pandas to create a dataframe from a single file but i cannot get the file to work
935,hello everyone we have released our paper efficientvdvae less is more with code we present simple modifications to the very deep vae to make it converge up to x times faster and save up to x times memory load we also introduce a gradient smoothing technique to improve stability during training our model achieves comparable or better negative loglikelihood nll on commonly used datasets additionally we make an argument against existing bit benchmarks we empirically show as well that of the latent space is enough to encode the data information without any performance loss thus indicating the potential to efficiently leverage the hierarchical vae is latent space in downstream tasks paper code paperswithcode ampxb,efficientvdvae a sota opensource memoryefficient and stable very deep hierarchical vae,research vae for faster and more stable data
936,suppose i am doing a convolutional network so input to the net is an image and its output is also an image but actually the input to the net will generally be a subset of the input image and the output will generally be a single pixel the cnn is then applied across the whole input image to get the full output image the mean squared loss for example would be a pixel loss just training_data net output per pixel however the kind of loss i want to compute is a function of a square window of the training data versus a square window of the network output for example suppose i am doing a structural similarity index as the loss function then i need nxn pixel windows of both the target image as well as the output of the network however i do not understand how you can feed back the result of multiple invocations of the cnn to get the output nxn pixels and i have not been able to find any tutorial that explains how that works my mental model of a cnn used for image processing is that it is effectively out fin where in is mxm pixels and out is a single pixel am i misinterpreting things should that be instead in is mnxmn pixels out is nxn pixels and there you go you have all of the pixels you need to compute your loss and when that is backpropagated you kind of get an average correction to the net parameters as you are applying the result of nxn invocations of the cnn rather than just one,how do i do gradient descent back propagation on an area loss,how do i deal with a loss function in cnn
937,i know this post has shown up before but im looking for some advice for my situation currently im a data scientist at a large software company ive been doing data science work for years now but ive only held the title for months several months ago i was moved to a new team with a new manager because leadership really wanted someone with a data science skill set on the analytics team my new manager is great but has really struggled finding meaningful work for me to do previously to moving to this new team i was doing a lot of interesting relevant work i developed an application based on a ml model that was efficient scalable for the project and reliable ive been able to spend a good amount of time working on my python development skills and at this point im a pretty strong developer i enjoy the development side just as much as the analysisanalytics part i may have the opportunity to take a data engineer position at a different company for a roughly pay bump long term i think i would enjoy the data science side slightly more but that isnt to say i wouldnt enjoy data engineering i think i would enjoy that work and find it very fulfilling im mainly concerned about the lack of ds work in my current position and i think it would be difficult finding an alternative ds position with only months listed on my resume but im wondering if i should stick it out in my current ds position things may get better since id like to be there long term anyone find themselves in a similar situation and what did you do,considering a change from data science to data engineering,whats your data science superpower
938,i have been contacted by amazon for the first time ever for a data scientist role i cleared the first behavioral round and they told me next one will be a hr technical phone screen they said you decide when you are ready while you brush up your tech skills and let us know when you want to schedule it for since i have no experience with interviewing with big firms how much time should i give myself to study is to weeks reasonable or would that piss them off and make them question me as a candidate there will be questions on ml model i worked on model evaluation and stats theory on probability and a problem solving question where i will have to explain my thought process of building a model for a given case would really appreciate your advice thanks,how long should i give myself to prepare before scheduling my ds tech interview with amazon,how do i prepare for my first data scientist interview
939,this may be a bit longer but maybe someone will get through it and give me some useful advice because i am pretty desperate at the moment when i was in high school i was good at everything science math languages and since all my parents ever told me was get good grades and everything will be ok in life i never bothered much with questions such as what will i do in life or what will my future be like as a teenager graduation came quickly and suddenly i had a full week to decide what college i was going to apply for since the areas i was best at were science mathematics and computer science i eventually decided to study nuclear engineering abroad at the time it felt like a great decision i would learn more about science utilize my love of math and coding and i would be able to say that i am a theoretical physicist the big bang theory just started airing and i certainly identified with the concept i feel this has been the biggest mistake of my life what i did not know was that the university i applied for has a graduation rate meaning that out of people that enroll no more than manage to get their masters it was people that actually managed to finish in my year i was struggling with every subject except mathematics which i found easy compared to other physics subjects despite all of this i was hanging on for years the last subject i needed to get through the undergraduate program was object oriented programming funny that it was actually programming not math nor physics that sealed my fate the instructor was notorious for failing people for the most ridiculous details after i failed the exam twice you had tries by a very narrow margin i became very suspicious to the nature of the tasks not only they were testing some concepts that were never discussed in a classroom but also the time and complexity seemed completely out of whack even for this university is standard after an afternoon of googling i learned why the tasks the teacher was giving us were exactly the same tasks that were featured in a doctorate programming competition i knew this was unfair but i had a plan all the assignments from the previous years there were about of them also had a very detailed solution so for the next two weeks i learned and understood all of those the time of my last try for the exam came and for the first time i felt truly ready when i saw the assignment i could not do anything but smile it was one of those i had studied i finished in record time and i felt i nailed everything even the bonus questions getting through the oral part of the exam was supposed to be a breeze you only discuss your solution and why you chose it the next day only people out of that took the exam passed and i was sure i was going to be the third the teacher told me to sit and then he told me we were not going to discuss my test because it was obvious that i had cheated apparently nobody had ever scored so highly so it is the obvious conclusion for someone that had failed the the exam before i tried to explain what happened but the teacher did not listen and told me to get out he also said he would tell other teachers of me so they would be sure to be extra strict with me in the future this broke me i never felt so wronged in my life so this was the day i dropped out of college i managed to find a job as an english teacher i do not know how exactly but over the years of reading books watching films and playing games i managed to get a relatively high english level despite not being a native english speaker two years went by in a flash and i could not feel anything but regret that i could not live up to my potential i made a decision that as a year old i was going to try to finish college i knew what my strengths are and what i want to do in the future at this point i applied for another university for applied mathematics and statics it took years but i managed to get through it so at this point i had a masters degree in mathematics with the focus on data analysis by the way i was the only person who managed to finish in my year the school was still really hard but at least fair when i started to look for a job as a junior data analyst covid hit people were getting laid of one after another lockdown after lockdown and paired with some unexpected health problems of mine it seems there is something wrong with my kidneys i was also in a car accident and i have an upcoming surgery to reattach some of my muscles together with my mom being diagnosed with cancerit just did not seem like the best time to move to another town and look for a job at this moment in my life i was glad to get any job in my small town i live in again as an english teacher a year went by and the situation has normalized a bit but here i am a soon to be year old with virtually no experience in the field i always thought that it would work out somehow but i am starting to lose hope the other day one of my students in my english class asked me about a math problem she is also studying at university and she did not understand how to do a factor anova easy i thought but after over a year out of school it took me good hours to review the stuff just the basic definition of variance expected value cumulative distribution function ftest at this moment i am not very sure about the things i have learned and with each day i feel i remember less and less i was thinking about enrolling into some online course to review my knowledge but there are so many of them and some of them are not exactly cheap i am also not sure about what to write on my cv i am probably years older that most other applicants that have the same level of experience meaning none i am not afraid of hard work so i would totally go over some extra skills to learn but each job opening has different ones some want r some want python others talk about numpy others mention things i have never even heard ofexperience in back end development signal analysis etc i am currently not hurting for money because my english teaching job is above averagely paid also during my second university i started to gamble online using nash equilibrium combinatorics and other tools to beat alternative poker variants that has always been a very nice secondary source of income that being said i would like to change my career and grow as a person but i am not really sure how to best do that at the moment i have a killer english teacher cv but not a good data analyst cv thanks for reading this far i guess i really needed to rant for a bit if you have any advice for mei am all ears i could really use it right now,am i too old to do this,i feel completely unqualified for data science
940,personally my answer to this would be just a set of exploratory analyses that i conducted for a business unit in my current company that was presented by the sales amp product teams to the executive team for a new product launch this eventually resulted in creation of a completely new business unit in the past year however that talks more to the product owners talents than mine moreover i feel like even in the above scenario i wasnt the person who identified the opportunity it was just a big impact task for which i was the only one in the team with enough knowledge about the data available to complete it this seems to be increasingly true the more time i spend at my current company is anyone here willing to share their experiences thanks analysts have a great week,can you give me examples about a time when you used analytics to accelerate growth in your company,how do you deal with bosses that do not understand data science
941,i am currently working on a model that will predict a keyword is google search rank based off features the labels for the training data can be any integer from i originally started thinking of this as a classification problem that can predict rank between and after completing the model it performed really poorly because predictions that are only off in rank are being penalized the same as a prediction that are off in rank then i switched gears and thought that i might treat it as a regression model after i completed training model i ran some data through it that it had not seen before all of the predictions were between and basically reverting to the mean ampxb is there a multiclassification model that will favor answers that are closer to the label,google search rank prediction model,how to deal with missing features in a model
942,so the issue is although my current role is titled as data analyst i have had a look through so many other data analyst roles and have not found anything that justifies me being suitable for these roles as they are actual data analyst roles my role use excel to run calculations in the model extract data from a huge excel database have helped on a sap migration project through building excel spreadsheets that help us migrate the invoices through allowing for automatic reformatting aaaaand thats basically it that is basically my role there is no drawing insights through collecting cleaning and reproducing useable data for analysis there is no way i provide managers with suggestionsrecommendations now im most of the roles i have looked through they require someone who can provide insights through data analysis retrieve data from sql databases clean this then analyse this to visualise the data and then communicate this in a way the managers can decisions based off of from what i understand i will need to learn sql building and optimising queriesdoing so at the moment learn to use tableau am watching their tutorials and following along learn to etl or clean large datasets this is on the todo list and be able to provide valuable insights that is what i have yet to understand provide valuable insights how do i literally tell the managers what to do ie sell to men aged from cambridge what constitutes valuable insights what happens when they make a decision on your insights but the decision went south the whole insight thing is one that has be really confused could anybody provide me with examples at work of them communicating and presenting insights did you go from raw data to tableau dashboards or are you involved in part of the process what booksyoutube videosonline courses could i use to get around this insight hump how do you know which chartstables to use in which situation,firstly as ive been prowling through this sub you guys have helped me through helping others so thank you for that secondly im having trouble getting into a data analyst role where i am actually a data analyst,how do you deal with bosses that do not understand your work
943,hi all i am trying to predict the end location of metro is my data looks like this metrostart stationto stationtimestatus metro location location arrived metro location location arrived metro location location planned metro location location planned the end location of metro is the last to station location but when metro has a delay or something changes in the planning the end location changes how do i train a model to predict the end locations of the metro is in different situations for example metrostart stationto stationtimestatus metro location location arrived metro location location arrived metro location location planned metro location location planned metro stopped working so metro was planned to ride the last ride now we have metro at location and metro at location witch is twice the amount of metro is and metro is at a different location,how do i model this,how do i go about building a model to predict the arrival of a new location
944,okay so thats pretty genericmaybe lets take an example of creating a model to show risk of climatic floods in an area youd feed in historical floods in the area and features like height above sea level distance from rivers etc obviously theres so many things to consider here so how do you represent those all in features what kind of model would you use how do you apply weightings to features i just have no idea how to approach this kind of thing it feels like theres so many dials to play with there cant possibly be a reliable result how do you validate this kind of thing this is an area i have knowledge on so any help is appreciated,what are some examples of risk models and how do they work,looking for a dataset of historical weather data
945,i graduated with a bs in biology and was offered an ms assistantship in biology for this assistantship i am working with programming languages such as r and some python i know i am still just dipping my toes in the programming community but i was thinking of going into a career in data science after graduation i was wondering if it is possible to get hired as a data scientist with an ms in biology or do i need to have a degree in computer science or mathematics i do want to mention that i am planning on taking computer science courses while i am working on my master is sadly my degree will be in biology but i will have completed some programming courses i was also recommend to obtain certifications for this programs,ms in biology but want to go into data science,biology to data science
946,long story short at my workplace we want to introduce some ml in the portfolio management process and the managers aked me to think about some stock price forecasting models this means that in their minds they push a button and the algorithm makes the magic while i am well aware that it is a very difficult task being the only data scientist there and with limited resources i do not want to waste time building a model that is too complex or resourceexpensive to be used in practice neither i am expecting to correctly predict stock prices at the moment i just want to create a fast simple model that gives a probabilistic output about a stock price is behaviour in the next days based on its historical patterns i ask to you kind redditors is it possible and how i tried to play around with lstm acknowledging that in practice it is not suitable for my current level of experience neither my computational resources so i am trying to use some regression or arima,looking for a simple time series model for predicting stock prices,is there a name for this kind of problem
947,noticed a large difference in likes retweets for realdonaldtrump and barackobama thought it would be interesting to see a comparison between other presidential stats eg previous us presidents or other notable world leaders eg putin over the years anyone have the ability to poll that data or a site that i can get it from easily edit more specifically i would like to have data sets of timestamp likes comments retweets per tweet so that i can plot them over time and with without normalization of follower count not sure if there is a way to track follower count over time would be nice to see counts at the time of each tweet if possible but if so that would also be great to have things i would like to see from these data sets is there a general increase decrease over time or for certain events eg becoming president how do these trends change comparatively eg when trump became president was it a larger impact for trump or obama do some of these twitter handles have artificially inflated follower counts this may be indicated by high followers and low engagement what is the range of response counts is there generally the same per post or is there a range does any of this potentially indicate bots is there a correlation between frequency of tweets and engagement,request tweet statistics likes retweets etc for presidents over time,looking for twitter follower data
948,hi there i am kinda new to the analytics scene so i would greatly appreciate some advice my finance department releases a big excel sheet spanning years of sales data for our products with the raw data and various other tabs containing pivot tables i am a product manager so it has some pretty rich info that i would like to create dashboards for to quickly easily access and communicate data in the youngest on my pm team and our business development person is stuck in the early is i feel like i can get info faster and pilot a new way of processing sales data the problem is that the excel file is distributed monthly as a massive file and is super slow to process in excel i was thinking of creating a local sql database using microsoft access and working it up with power bi is this recommended i would also like to automatically update my database monthly with the new info can this be done without any additional coding i am not familiar with access or sql except for a few introductory videos on youtube guidance and best practices would be greatly appreciated as an aside my background is a phd in chemistry and i was formerly in hw rampd for my product i know python but in my new role i cannot be bothered to write much new code or make dashboards with jupyter anymore the data i distribute to the field is pretty informative since i am an insider to the product,analytics from processed sales data excel sheet,how do you guys get started with data analytics
949,i started a data analyst role months ago it is my first real job following grad school the company is fairly technical relative to its industry and typical da roles and flexible use whatever tool to solve the problem excelpythonretc which i appreciate however my team does use excel a lot and there is a lot of messy pythonr code so far i have been doing small adhoc tasks and monitoring automated reports none of this feels impactfulmemorablechallenginginteresting i understand i have to work my way up to bigger responsibility but it seems like an incredibly slow process i would say i only spend lt of my day actually working and that is sufficient to get what i need done the other is spent sitting around my computer on slack occasionally brainstorming new processes to automate should i be grateful for the slow pace while it lasts or should i keep pressing for more responsibility i value growing a lot at my first job,when does the job get interesting,i feel like i am drowning and i do not know what to do
950,i come from a business intelligence background and i am looking for a way to create data snapshots using a jupyter notebook long story short they told me during the interview process they had a data warehouse and that turns out to be not quite true i probably will not be there long but i have been asked to create something that sounds a lot like something that would be supported by that kind of data structureetl process what i am looking to do is to be able to run a sql query and then dump it into a amonth file with the snapshot date in the file name and the snapshot date in the file the same thing would happen the next month and so on and i would load the files in and append to perform the analysis has anyone had to do anything like this before or can provide any useful resourcesreferences thanks,periodic snapshots for jupyter notebook,how do i create a data warehouse for my company
951,i would like to take my career in a new direction with machine learning and am exploring the different pathways available one way is to go to school and get a masters degree the program i have been exploring is the masters of data science at berkeley the curriculum has what i want and with the distance learning i can be anywhere in the world and still get an education however the tuition for the program is there is also the masters program in machine learning at cmu and the machine learning masters program at university college london but these would require relocating since they are not available online the other path is to take classes online there are several available that i can take from places like dataquest linuxacademy sciencealert udemy etc i can pick and choose which ones i want and complete them at my own pace plus the total cost would be less than of the tuition at berkeley and since i am making a huge leap from being simply a troubleshooter to an ai architect i will need to show potential employers what i can do the plan is to post projects on github showing what i have worked on both in class and on my own i intend to do this regardless of which path i take i am hoping this can show the progression of my knowledge and be the bridge between what is listed on my cv and what i can do so now i am wonderingif the cost is not an issue which of these paths would work best in terms of impressing an employer will it be the degree or the drive that would pique someone is interest to hire me please let me know what you think,is a pricey masters degree worth it,what is the best way to get into data science
952,i want to give the users the possibility to request predictions online and i am evaluating which frameworks i should leverage for this the challenge is not only it should generate predictions on demand but it should also train the model itself for example i have data for each city in a country obviously i do not want to schedule a job that stores dailyweekly predictions for each city which probably will never get called instead i want to provide the code for a model and then train it on historical data and make the prediction based on the city selected by the user i was thinking to use kubeflow but i have never used it before and i am not sure this is the right usecase do you have any frameworks approaches to suggest i can look into,which framework to use to train model and predict online,question about time series forecasting
953,so lets say i want to predict the likelihood that someone will go back to prison recidivism i have different datasetsone has observations of an individuals age whether they found a job their location and their race the second has their age their qualification going into jail their location and their race the third has whether they got support services in prison their age and whether they used to read and workout in prison the fourth is exactly the same as the first but is for a different year and also adds whether they were affiliated with a particular gang you get my point how would i combine all these datasets into making a prediction model for one new individual is it advisable i want to build it such that a person can come wan tell me all these details and i can make the prediction these datasets are for different years and not the exact same people but theres a chance of overlap as its in the same country they all say whether the person ended up back in prison or not,how do i incorporate different datasets with different variables to make one machine learning based prediction model,question about combining two different datasets
954,i was hired just after graduating from a business analytics master is degree as a data analyst intern in july at a fintech saas startup that is about a year old since i was hired i have been mostly setting up all their analyticscrm tools google tag manager google analytics hubspot diagnosing and fixing issues reporting on our kpis and acting as the middle guy between the ceocfo and the dev team to translate our data needs into dev implementations and follow up on them the startup is data is managed by segment to connect our various platforms into an amazon redshift which i access using tableau while i find this a great tool what i find is that in our redshift we have numerous schemas that are practically useless and our only useful table is from stripe showing user signups the date which plan they subscribed to and how much they pay etc this information is still more accessible via mixpanel so i tend to use that to report instead the issue is that we are too dependent on many such online platforms like mixpanel and whatagraph that would not allow for data modelling and highlevel data analytics using python sql etc and i would ideally like to deviate away from them and set this up on my own and be able to use programming languages to explore the data i have just been offered a fulltime contract and now that all these foundations are set up i want to begin preparing the actual data infrastructure for further analytics capabilities the startup wants to hire a few data scientists as we expand in the coming months but i have serious doubts about the data infrastructure for modelling and want to prepare the data for then i do not know where to begin seeing as segment does not allow for changes in what is sent to redshift with our version and i do not know what tools we are missing or what the data infrastructure should look like since this is my first job since graduation and what i have always worked with were already established databases i am also the sole data employee and we do not have a database admin or data engineer to guide us through something of the sort and would need a viable compelling solution that i can pitch to the ceo to help the startup become more datadriven i do not know where else to ask and have always been following this community is posts so i feel like it would be my best bet at figuring something out any help would be greatly appreciated,startup is first data analyst trying to build from scratch do not know how to improve the data infrastructure,how do i go about building a data analytics team
955,i am trying to create a segment in analytics of potential customers who have added a product to their cart i have enhanced ecommerce enabled but cannot get it to work this is what i tried under admingtviewgtpersonal tools amp assets i clicked segmentsgtnew segment from here i clicked enhanced ecommerce i clicked the top middle added to cart button then in the product field i typed in the name of my product i then named this segment test and saved it when trying to create an audience from this by clicking new audience i click import segment and select the test segment from above however when looking at the users over past days it shows whereas this number should be according to my observations i have tried this with several different products and even entire product brands with the same result this leads me to believe that my enhanced ecomerce tracking is not set up properly what could be the problem is there another way to segment add to cart clicks in a more manual way ie not using enhanced ecommerce thanks in advance,cannot create segment to track add to cart,how do i track a specific product in google analytics
956,hello everywhere you can read that the first step in machine learning modelling is exploratory data analysis the alleged reason is that you get to know the dataset and that knowledge would lead you to apply a better model however i do not see that this is true in the reality in my company we are using in production models for anti fraud that i have created with xgboost and in none of them have i explored the data the variables used were the ones used in a previous model and i have added a few ones based on my business knowledge or exploring some cases in our bi tool why should i care about skewness or normality what advantage gives me knowing the dispersion of the data or central tendency measures knowing that some variables are linearly correlated really provide something useful considering that they will not affect negatively the performance of the model and usually computation of a few variables more is not a problem even the ratio between classes seems useless because in my personal case of course all the theory that undersampling oversampling etc has to be used and scale_pos_weight should be the number obtained from a formula has given me worst results when applied than just leaving it as it is from my point of view it seems that xgboost can handle everything with or minimal knowledge about the data and it seems to be one of the best or the best algorithms out there probably i am missing something so i would like to hear your contributions thanks,what is the point of making exploratory data analysis before using a machine learning model,how do you deal with overfitting
957,i have a pretty big project i need to complete for a stats class i am relatively new to data analytics but have some experience running regressions in stata am very comfortable with excel essentially i just need a training data set that will allow me to build a linear regression model and make predictions about a given characteristic preferably something that has a lot of independent variables so i can make some claims about which variables seem to be important in the model and which ones do not something along the lines of zillow is zestimate competition would actually be perfect but i am not allowed to select a topic that is related to predicting home valuation apparently that is been an overused topic in the past i have been scouring kaggle and the google dataset search engine for potential options but i am running into this problem where the data sets are either a super messysplit up across multiple readonly filestoo technical for me to understandcontain anonymized categories with no available description of the independent variables or b too small for example this one that allows you to develop a model to predict graduate school admissions would have worked really well if it had like quadruple the quantity of independent variables if you have any suggestions alternate website recommendations etc i would be forever in your debt thank you in advance for any help,in need of a beginnerfriendly data set that i can model using basic olsregression,how do i go about building a predictive model with multiple variables
958,hi friends happy monday to everyone id greatly appreciate some feedback on whether it matters to do the prep work for graduate school via coursera online recommended textbooks or if it would be important to take structured classes in a university setting since the coursework is fairly densedifficult in some cases i am currently a data scientist at a top us bank and my analytics team manages all of the analyses for our payments portfolios debit and credit my background is in finance and economics i lack the higher level math to understand some of the algorithms we are working on and want to understand things at a deeper level im getting to a point where ive worked on a lot of very cool projects learned sql sas etc and am good from a programming and application perspective but would like to fill in my background formally with some of the higher level math and computer science classes interested in pursuing a comp science masters at a top school and have the following types of classes on my list to takelearn before applying engineering calc calc i and ii linear algebra probability and statistics class will my business stats class count for this discrete math object oriented programming data structures algorithms or automata theory computer organization and assembly language operating systems i really want to be careful and methodical about this and how i approach things ultimately will probably end up getting a masters but would like to avoid paying for the prep classes ahead of that if possible if any of these classes seem unnecessary would also like your thoughts just want to set myself up well for the longterm both breadth and depth wise tia for any thoughtscommentshelp reposting because didnt see a lot of activity on the enteringtransitioning thread and i am not exactly leaving my job or trying to break into data science more trying to evolve will delete if this is not allowed thanks a bunch,prepatory classes pre masters help,is it worth getting a masters in ds if i already have a job as a data scientist
959,i have to sumit a proposal for object oriented design and analysis i am interested in doing a project which comes under the domain of data science i have studied necessary mathematics courses such as calculus basic and advanced linear algebra probability and statistics i also have done a course on information retrieval which is basically related to how a search engine does it is job including web scrapping and presenting data in different modes of reprepsentation in this course i am looking at following data sets to generate a project idea which is equally under the domain of data science and ooad course the data sets are sms spam collection kaggle dataset indian startup fundings collection kaggle dataset computer parts cpu and gpu kaggle dataset chocolate bar ratings kaggle dataset trending youtube videos statistics kaggle dataset the required languages to be used are either java or c no python or r because the course is object oriented design and analysis we are a group of students and we know java amp c python is what specifically i know and the professor has restricted us to java c i am unable to produce an idea which can help me do a project which is both under datascience domain and ooad domain therefore i would like you all to help me in this regard thank you to all,request project ideas for ooad course at university,need help with a project
960,me and my friend developed a pretty good ai based product i literally cant find any data on the internet for my pitch deck im just here to ask this im not going to advertise my product here although i will put a description just for you guys to get an idea of what we made and how long it would take you guys we created an ai based platform to do all forecasting types within seconds we have created neurophate link in comments an ai based to to revolutionize the future of business analytics heres what neurophate can do sales forecasting companies are unaware of the direction their company is headed in solving this issue we do easy to use sales forecast to see when the best time of the year or month is for sales how many sales can you generate over the next couple months with this knowledge in mind the possibilities are limitless businesses may create a better budget to ajoin with a low sales forecast businesses may put more stress on different platforms such as ads or social media to change the result of the forecast customer segmentation companies are wasting time and money chasing the wrong set of customers we provide a customer forecasting and segmentation platform to recommend which customers are more likely to buy from you than the rest this way companies can align theirselves properly to really find out where they can put their ad spend to get the most out of their customers there is no point wasting thousands on ads just to find out you are targeting the wrong people social media analytics for some brands social media is the essential housing of their company if they lose followers they lose sales this might not be the case for other companies such as a finance or bb company this might be for more creative companies who essentially house their companies lifeline on social media after connecting social media accounts we analyze we dont take your data and run it through several processing algorithms to find out which aspects of your page will do well in the next few months and which will fail no companies do this because many bb startups dont understand the potential social media holds ad campaign growth ad campaigns either our favorite or least favorite thing in the world regardless we have to do them to keep our company out their in the world and drag in customers heres where things get complicated the facebook algorithm really is confusing we dont know how well our ads are running and even if they are running well we dont control that really theres only so much targeting you can do to get the most out of your ad campaign however if you create the best ad campaign ever there is still a chance it will fail thats where we come in we measure ad campaign stability give ai recommendations to boost the sufficiently of your ad campaign and then visualize that data for you and forecast the future of ur campaign this is revolutionary getting insights on your campaign daily telling you what you can and cannot do why neurophate many companies are doing this however we are the single and only ai platform that does this allin one that means we are a jack of all trades with quality assurance additionally the need for you to sit there all day creating complicated power bi sheets and random excel models which are driving you crazy is no more neurophate is an easy solution for the least technical people on this planet if this idea interests you the link is in the comments to view moreq,how hard is it to create a simple forecasting model sales customer segmentation social media prediction ad campaign growth,how to measure the impact of social media ads on sales
961,hi guys i really need your honest input on my situation it is really difficult for me to be discreet regarding my situation and so i will just have to be specific i am about to begin my ms in applied stat program at teachers college columbia university teachers college is the graduate school of education and it is debatable if it is really columbia university or not but they are officially the department of education for columbia and all degrees are conferred by columbia however it is definitely a little different than say being at the ma in stats program at columbia or the data science things have been disorganized and i am disappointed by the mentorship thus far i am starting to really doubt if my degree will be worth it or not i will be taking out k in loans and that would scare almost anyone i am really considering dropping out i can still get my tuition refunded and applying for the northwestern predictive analytics program or the berkeley data science program have heard great things about nw berkeley is my hometown what do you guys think sample courseload for my current program applied regression analysis statistical inference computational stat multivariate tats experimental design and linear models electives applied data science columbia ds program machine learning for ds columbia ds do you guys think my program would be worthwhile note regardless i am willing to take the loans out and pay them over time however if i am going to take out k i want to know that the programdegree will be valuable in terms of learning and prestige how difficult is it to get into the nwberkeley online programs i know that is a terrible question but for me it is important because i want to know if i have a good shot at being accepted thanks for the read unfortunately cannot do a tldr here so if you have the time please read and help me out thank you,need advice for my master is program urgent,is it worth getting a master is degree in ds if i already have a job as a data scientist
962,hi guys and girls i have an existing remarketing audience it is default so all users and site wide what i want to do is use adwords to remarket to users to a specific page on my site i do not really want to build an audience from a fresh list on this page and id like to use my existing data from my all users audience i tried editing this myself however it changed the list size from quite large to the exact visitors to that specific pagewhich i want but i also need to remarket to the general website visitors as well to recap i have an existing all users remarketing list i want to keep advertise to them i also want to advertise to a specific page on my site can i use my all users list to do this or do i need to build a fresh list,remarketing to a specific page off an all users audience,how do i track users who have visited a certain section of my site
963,i am currently reading a paper on the mathematics lying behind of the ann how they inspired from biological neurons how they work etc ampxb the paper says that when the synapses the input weight from a neuron to the another neuron and thresholds the minimum required input value which is necessary for the neuron to fire is getting determined namely ann gets trained also the initial binary values firing or not firing true or false of these neurons gets determined so that when the weighted input not exceeds the threshold of the neuron but exceptionally equal to it we can use this initial value as our most optimal output ampxb but then how is it getting calculated understanding the calculation of the synapses and threshold is very intuitive but this make me confused ampxb the article i am reading a begginers guide to mathematics of neural networks ampxb,how the initial default binaryvalues of the neurons in the ann gets determined when we training them,why do neurons get such a hard time
964,i have no knowledge of programming and the level of my mathematics and physics are just high school level it has been a long time since i graduated from high school but if i took a math test now i would be given like score ampxb i have been working in an it company and one of my bosses offered me to learn machine learning from his new startup and he also told me that i will be needing at least highschool level of mathematics ampxb if i accept his offer i would need to study the mathematicsmostly algebra calculus statistics from the basic level the beginning of an ordinary high school for the rest of this year i am just not sure if i can reach the enough level of mathematics to study this field within this year ampxb what are your opinions,what level of mathematics is needed to start tensorflow and ai field,i have been offered a data scientist position but i do not know what to do
965,hi we have created a study group for those of us who are studyinggetting into the data science field we are looking for students there are already two of us total of students professional mentor to help us by providing project ideas case studies guidance etc class schedule monday wednesday friday northern european time classes will be broken down into various sections and will will practice problem solvingcoding daily for example at the moment we have monday problem solvingcoding tuesday tutorials wednesday case study or work on pet projects for your portfolio if you are interested please send me a conversation or message it would be great if you could also answer these questions what is your intention why do you want to study data science and move into that career field where are you in your studies andor career we welcome complete beginners like myself how are you obtaining your knowledge books mooc practice etc what would you like to gain from the group also we would be so happy to find a mentor for the group if you happen to be interested just send me a message ampxb thank you,new private data science study group first online meet up is monday oct,study buddies
966,okay so i was dealing with a problem that a peer posed to me he gave me a dataset and an xgboost model which was trained on the same dataset the dataset contains features and label the dataset is about the marketing campaigns of an agency through channels and the label is the transactions processed by the agency now the question is given the dataset predict how much contribution each channel makes to increase the transactions and given a budget find the optimum budget allocation to different channels so that the number of transactions is maximized i have identified the most important channels and their order as well using correlation but my question is how do i quantify it i am not very fluent in data science i am mostly learning by myself a little help will be appreciated,finding the proper method to maximize the predictions of a given class,how to measure the effect of channel activity on sales
967,hello guys i feel extremely lost so i thought i would ask you all for help i do use this platform a lot silently and it has helped me a lot but i have never posted before a bit about me i am a year old female doing my master is in electrical engineering from top university in usa my original career plan was to follow signal processing but due to the freedom of choosing courses at my university i was lucky enough to get a data science and signal processing track and i absolutely fell in love with data so i ended up taking courses like probability natural language processing machine learning etc now i am an international student here and ideally i should have a summer internship i have applied wide and far to more than internships i am not even hearing back from them i have lost hope for this summer because the deadline to submit my internship offer letter at my university is soon approaching may th i code in python and i will admit that i am not as fast as a traditional cs student however i do write decent code eventually we never got enough exposure to programming in ee during my bachelors back home in india i have done a lot of projects kaggle coursework etc and have worked up on my mathematics and statistics i know i am extremely hardworking and can adapt and learn really fast i am just waiting for that one opportunity to click i am scared too because i have already taken the leap of faith i have spent on this master is and have abandoned my ee path it seems almost impossible to crack data science without work experience and i need some work experience to get started how do i land an opportunity and prove my worth please any help any advice anything that steers my rocky boat in the right direction would greatly appreciate it i want someone to believe in me and give me that chance edit thank you for the responses you have no idea how much responses mean to me right now,any advice or tips for someone who is trying hard,data science career advice
968,for my end datascience bachelor project i am writing an end project and setting up a research question i was leaning towards answering a research question in the decentralized finance space but my teacher says the data has to answer the research question numerically based so not just literature review i have been looking into this more and it seems very difficult to find the right data rq example what influences the interest rates on various stable coins in defi protocols would it be possible to query find the right data from the ethereum blockchain to answer such specific research questions i have only slightly used sql and never worked with blockchains blockchain data or api is before i feel a bit lost and i do not know where to look i am thinking about changing my topic to something that just focuses on market data this seems out of my hands what do you think,data from the blockchain how difficult is it to obtain the right data end project question,data science and blockchain
969,the raw material of carbon steel tube is round tube blank the round tube blank is cut and processed by cutting machine to billet with a length of about meter and then sent to the furnace by conveyor belt for heating the billets are fed into a furnace and heated at a temperature of about degrees celsius the fuel is hydrogen or acetylene the temperature control in the furnace is the key problem generally more common puncher is tapered roller puncher this kind of puncher has high production efficiency good product quality large perforation diameter can wear a variety of steel after perforating the round tube blank is successively rolled rolled or squeezed by three high after extrusion take off the pipe to determine the diameter the sizing machine rotates the cone bit into the steel blank at high speed to punch holes to form the steel pipe the inner diameter of the steel pipe is determined by the outer diameter length of the caliper bit after the steel pipe diameter into the cooling tower through water cooling after the steel pipe cooling will be straightened after straightening the steel pipe is sent to the metal flaw detector or hydraulic test by conveyor belt for internal flaw detection if there are cracks bubbles and other problems inside the steel tube it will be detected after quality inspection the steel pipe is selected by hand strictly after the quality control of the steel pipe spray with paint the serial number specification production batch number etc and hoisted into the warehouse by crane,preparation of carbon steel pipe,is there a name for this type of machine learning
970,hi all i am currently playing with diffsinger which is a tts system extended by diffusion models for the naive version it consists of encoders for embedding text and pitch information and a denoiser where the encoders output is used to condition the denoiser everything is similar to diffwave including denoiser is structure and prediction but the neural net to predict epsilon would be changed to epsilonnoisy_spectrogram encoder_outputs diffusion_step compared to diffwave is epsilonnoisy_audio upsampled_spectrogram diffusion_step while i am successfully training encoders i got an issue during training denoiser i used ljspeech here is what i did first of all as a preliminary experiment i try to check all modules to work well by setting denoiser as epsilonnoisy_spectrogram clean_spectrogram diffusion_step to predict the noisy_spectrogram after the model converges i went back to the denoiser of epsilonnoisy_spectrogram encoder_outputs diffusion_step to predict clean_spectrogram i detached the encoders_output from the auto_grad when the input to prevent from updating to the denoiser to fix the conditioner for model convergence the model was broken when i did not detach allow the encoder to be updated during denoiser training i found that when the range of the conditioner encoder_outputs values is smaller then the model shows better evidence of successful training bellows are the results i have got so far the upper one is the sampled synthesized melspectrogram and the lower one is the ground truth of each image i can see the model converge during the primary experiment ampxb when the encoder is output directly input to the denoiser value range xxx to xxx ampxb when the encoder is output is multiplied by to shrink the range ampxb for case it shows any clues on training on contrary the case shows isome levels of training but it is not what we expected i doublechecked the inference part reverse part but it is exactly the same as that of and diffwave so i just want to know if you have any idea on the successful conditions of the input conditioner of the denoiser why does the model show such an unsatisfying result above do i miss something to process the conditioner i will appreciate all suggestions or sharing of your experience thanks in advance,training tips on diffusion models diffsinger for a tts,why does the output of a denoising model have such a narrow distribution
971,i am doing a research project and need to identify uniquenew events within patient notes stored on an sql database but ignore subsequent mentions of an old event i doubt i am the first person to want to do this or something similar but cannot find anything relevant through google though this could just be the terms i am using i would initially hoped to teach myself how to develop it but i am also slightly time limited is this something i could learn in twothree weeks i have a ok understanding of econometrics regressionhypothesis testingmodelling though very little knowledge of coding i looked at metacademy and the core topics alone seem like a month of learning if anyone knows of any resources which would be relevant i would be very grateful edit just had a thought is it possible for an algorithm to discern whether a person is the perpetrator or the victim of a crime instances of either may be relatively sparse,need to distinguish between mentions of new and old clinical events in patient notes,is there a name for this type of project
972,tldr what tools do you use to classify and manage inhouse nlp datasets i have figured my team is spending a lot of time labelling datasets in somewhat inefficient ways it happens in jupyter notebooks through onceoff programmed widgets or exporting to excel and back which is fine but inefficient for example having to choose which label is correct among labels is difficult and visually impossible in excel it would be great if some other model ordered these options upfront i am aware of the bias since i am the one who usually helps them with tools like that i would like to see what you use for such tasks before i present them different options we usually work on text classification text annotation search results quality evaluation ideally it would manage datasets and have them available through api so we can spend some time labelling and then just doing something like toolxdatasetsfetchname and use it in jupyter i am not asking for the perfect tool but your experience on tools and workflows you use within your teamcompany i have found prodigy from spacy makers and meaning to try it but from the outside it seems to lack something that will help us with search results evaluation and it generally steers towards binary choices which is not always suitable for what we want to do,what tools do you use for creating nlp datasets,how do you deal with overfitting
973,i am starting a phd and i am setting up my newly provisioned workstation i am a little overwhelmed by the assortment of numerical libraries available eg intel oneapi mkl openblas aocllibflame so i thought it may be better to ask if you were setting up a new computer today which combination or single package would i need to be able to get the most out of my hardware intel cpu nvidia gpu i am mostly using matlab and python sometimes using c to write openmp mex code i am also looking into using mpi and gpucuda programming at some point during my study ps is there any benefit to recompiling numpy using the aforementioned libraries,which numerical libraries do i need,what is the best free or very cheap gpu for deep learning
974,as far as i am aware theta is used as the unknown variables that predict certain things for example take the generic house pricing problem if the house is and m and they are all similar in that area due to it being coastal could theta in that instance be the location due to my understanding theta generates parameters x y therefore location preference can generate the higher price x and the size y but afaik we are not meant to distinctly know theta due to the reason of needing the machine another example an apartment is a lower price and smaller size due to it being an apartment is theta in this instance the type of building ie an apartment building as the fact the apartment building leads to smaller apartments and that leads to lower prices obviously anomalies are not counted for etc but it is a general question to help my understanding thanks,am i understanding the use of theta in ml correctly,is there a name for this type of model
975,i made a post yesterday asking for help determining how to find relationships between two datasets but did not include enough useful information in the post i will fix that issue here i have two datasets one has data on the yearly change in harshness index a measure of how difficult a place is to live in the other has data on the yearly change in human development index both datasets have observations each observation corresponding to a subnational region ex us states each observation contains data on the yearly change from to for a total of points of data per observation what i want to determine is the correlation between increase in harshness index and increase in human development index i know that there will be some sort of time lag although i am not certain how large that time lag is and it is likely somewhat different for every regionobservation my desired final output is a single value corresponding to how much change in harshness index presumably affects change in hdi as well as a measure of how significant this affect is ampnbsp my biggest confusion is regarding what method exactly to use to compare the two datasets as a whole one method i looked into was using cross correlation but that leaves me with a list of correlations for each observation but beyond there there is not much i can figure out what to do,best way of finding correlations with lag between d data,how do i find correlation between two datasets
976,looking for recommendations to read messy table data typical problem the flat text csvtsv etc files containing the data i need have been entered by hand and so they have several blank and free commentary lines at the top and possibly some at the bottom the data is typically columns by rows and may contain blank cells and blank rows i have heard that you can use clustering to identify the body of data but so far i have been unable to find any good resources online to start i would like to avoid hard coding to for example ignore rows starting with etc i am hoping to learn how to identify the data also my header column names can change i have a solution for this though thanks,method to read messy data,how to deal with messy data
977,a question for the more experienced professional data scientists and engineers i recently got a data scienceish job and updated my linkedin profile to reflect this part of the update involved including some fancy words in my description like deep learning artificial intelligence data visualization etc not because they are buzzwords but because they actually reflect what i really do at work however because they are buzzwords almost overnight recruiters started sending me messages many of them also try to add me to their network as contacts rather than simply sending a oneoff message and disappearing into the night i just got this job and am not about to leave it however one day i will and i wonder if these recruiters will be a useful resource when that time comes so i am wondering if there is any benefit to actually accepting all these requests to connect even if i ignore their initial messages or do these recruiters actually offer very little in the long run such that adding them to my network would just be a waste of my energy edit i should clarify that while i would also like to hear about people is experiences responding to these unsolicited messages what i really want to know about is the value of actually adding these recruiters as contact to my network like if i do that what practical benefit will that bring to me,are recruiters useful specifically the ones that send you unsolicited messages,what are some of your favorite data science buzzwords
978,i plan on making a career change from engineering to data science this year i have already taken many fundamental mooc and i would like to do a bootcamp after i quit my job question is if i should go into bootcamp for data science or software engineering a buddy of mine who had been learning data science for a while recently went into a coding bootcamp instead of data science because he claimed that most da bootcamps are bad and it is more marketable if i go into swe especially with proper machine learning neural network knowledge what should i do and if you disagree with my friend is opinion what are some good ds bootcamps,data science or software engineering,is bootcamp worth it if i already have a job as a data scientist
979,hi all i know essentially nothing about machine learning but i am wondering if it can help automate some of the most tedious work i do in short i often have to deal with erroneous spreadsheets of datas of lines usually the corrections to these sheets require sorting out the entries for errors and correcting the erroneous ones when done correctly the entries should follow a precise set of conventions in the past i have set up complex errorchecking spreadsheets to help with this work but this is tedious to say the least and does not capture every possible error i can go into more detail on the problembut it will probably get too dense for this intro so can i train a machine learning algorithm using correct spreadsheets i have at least k correct entries to go through and spot errors in other spreadsheets would it also be possible for corrections to be suggested to the user would doing this sort of thing be feasible for someone who is level of coding knowledge is limited to hobby arduino programming thanks,i know nothing about machine learningbut i have a problem and am wonder if machine learning can help automate some of my workflow,can someone help me with this problem
980,hey ranalytics i am currently in a marketing scienceanalytics role at an ad agency basically my role is more reporting than analysis and our team is fairly new doubling only in the last year i know that sql and python would help us a lot but we are stuck in what is comfortable excel so i was wondering if anyone here has either taken sqlpython for data analysis on udemy if so which courses or took the data science path in codeacademy ampxb i am concerned about udemy not being as organized as codeacademy and i am worried about codeacademy not being as hands on as udemy i have no experience with either any insights would be very helpful thank you in advance ampxb,sql and python online courses,data science career path
981,i am working on a project right now to classify news articles by their political leaning using an rnn and i am a little short on training data to try to eliminate my own personal biases i have been pulling the top x posts from rliberal and rconservative and labelling them appropriately since this should reflect the general opinions of those who identify as liberal and conservative unfortunately this method does not provide a lot of training data i have thought about expanding to include other subs besides those two but does anyone know of any better places i might be able to find this kind of data or any other options i can pursue thanks,source of news articles with labelled political leaning,looking for a dataset of political leanings in the us over the past few years
982,i have a x gridworld with rewards and enemies i have been teaching my agent x grid around itself with a small neural network it learns to be reactive quite quickly by getting rewards and avoiding enemies in it is close vicinity however i want the perceptual field to progressively get larger let is say first to x and than to x is there any way for me to transfer what has been learned in the x partial view to make x training faster i have been thinking about keeping the final layers of the network fixed and changing the input layer to a larger size and training only the input layer weights what do you think thank you for all your feedback,how to transfer learning from a smaller state space to a larger state space,how to deal with larger than expected outputs
983,this is my problem i am building a service that receives data in the form of a survey and when a user requests it returns a pdf that is the result of processing all the data through a jupyter notebook the jupyter notebook is the same what changes is the data that should be updated with the newest surveys that add up since the processing of the notebook can take some time i would like to know if there is a way to build a sort of pipeline that helps update the results that is the execution of the notebook faster otherwise i am left with processing the results in a schedule and leaving the clients receiving outdated results until the next time the notebook runs i was thinking instead of processing all the data that has already been processed before process the new delta and add it to the former stored result if possible is there something like that thank you,architectureframework to process incoming data into jupyter notebook and keep the results,what is the best way to store data for faster processing
984,hello i am not sure if i am in the right subreddit but i will make this question anyway i am doing a project and i have been looking for worldwide literacy rates unsuccesfully most of them have too few data databank mix data from different years or they do not have a country code iso if i remember correctly which allows me to work with it so would someone be capable of finding me a literacy rate of the world in excel that includes country codes iso and if possible have the results as recent as possible i would appreciate it a lot by the way how is it exactly measured do they take data from the goverments every year or do they do surveys every or years,request literacy rates worldwide,looking for data on literacy rates by country over the years
985,some background on me i have around years of bidata analyst experience in financial services with a large regional bank for the past couple of years and i just finished an ms in statistics my original plan was for that combination of experience and that degree to position me for a data scientist or similar role but im striking out on that front and not really sure if thats the correct direction to go anymore i really have tried to carve out spaces to do more interesting technical work in the past few years but ive had very limited success and as a result most of my professional work experience is in tableau and excel with some rather basic sql thrown in as well as some javascript and python mostly just to get at data from rest apis and do some very minimal etl im considering trying to end up in more of a data analyst lead or manager position instead and to be honest that probably plays to my strengths better anyway i recently took a slightly more senior analyst role within the same company and while the pay is decent k total comp im not sure how great a job its doing at developing my career further my job is primarily to produce insightsanalyses and help generate polished slide decks for senior management so there are some pros and cons to it pros its high visibility work since the finished product makes its way up to high level managers in the bank i have a pretty good amount of autonomy on that work and im improving my communication skills a lot since these have to be extremely polishedready for final presentation slide decks cons very minimal development of technical skills since im mostly working with excel and tableau still and querying some data with sql also basically no opportunity to go beyond descriptive statistics here so im kind of wasting my degree any kind of predictive modeling project is out of the question its a very busy job and theres no way i could carve out the time or get permission to spend time on that plus banks are very paranoid about that kind of stuff is this the kind of role with high visibility to management and building experience communicating with leaders that would position me well for a more senior position in a couple of years or does this sound like a dead end role that will just lead to stagnation of the limited technical skills i do have,analytics manager career path will my current role help me get there,how much do you guys make off of your skills
986,i have data with only a single feature the recorded value i am trying to create a model to for forecasting looking at different tutorials i first calculated the differences between them and scaled them to then i reshaped it into to simulate online learning that is one sample at a time given time steps to predict time steps here is the model in keras model sequential modeladdlstm batch_input_shape statefultrue return_sequencestrue modeladddropout modeladdlstm statefultrue return_sequencestrue modeladddense activationnone then a for loop to fit the training data one by one for i in range x_testshape modelfitx_testii y_testii verbose shufflefalse epochs batch_size this is the actual vs predicted plot and here is the prediction of the form the last points the predicted values simply go downward the further away it is seems like the model is overfitting and memorizes the training data am i doing something wrong is there not enough data or is there an approach you can suggest that i should try here is the rest of the code used for preparing the training data,improvements for multistep forecasting using lstm,how to deal with overfitting in keras
987,dear rdatascience after much lurking making a first post it is been a year since i graduated and i have been thinking about going back to school data science has been an intriguing field especially since i come from a statistics business background so i am looking to further my knowledge especially gaining some computer science background my question to you all is have any of you gone through a masters degree related to data science if so what are your overall thoughts on the program would you recommend it to people in my boat since it is a fairly new field i feel like there are just overwhelming amount of information on the internet i wanted to get some real opinions instead of school advertisements thanks,looking for thoughts on data science programs,is a data science masters worth it if i already have a job
988,call for papers evorl evolutionary reinforcement learning workshop at gecco july boston usa in recent years reinforcement learning rl has received a lot of attention thanks to its performance and ability to address complex tasks at the same time multiple recent papers notably work from openai have shown that evolution strategies es can be competitive with standard rl algorithms on some problems while being simpler and more scalable similar results were obtained by researchers from uber this time using a gradientfree genetic algorithm ga to train deep neural networks on complex control tasks moreover recent research in the field of evolutionary algorithms ea has led to the development of algorithms like novelty search and quality diversity capable of efficiently addressing complex exploration problems and finding a wealth of different policies while improving the external reward qd or without relying on any reward at all ns all these results and developments have sparked a strong renewed interest in such populationbased computational approaches nevertheless even if eas can perform well on hard exploration problems they still suffer from low sample efficiency this limitation is less present in rl methods notably because of sample reuse while on the contrary they struggle with hard exploration settings the complementary characteristics of rl algorithms and eas have pushed researchers to explore new approaches merging the two in order to harness their respective strengths while avoiding their shortcomings some recent papers already demonstrate that the interaction between these two fields can lead to very promising results we believe that this is a nascent field where new methods can be developed to address problems like sparse and deceptive rewards openended learning and sample efficiency while expanding the range of applicability of such approaches with the evolutionary reinforcement learning workshop we want to highlight this new field currently developing while proposing an outlet for the two communities rl and ea to present new applications and ideas and discuss past and new challenges aim authors are encouraged to submit original research articles case studies reviews position papers and theoretical papers within the following topics of interest evolutionary reinforcement learning evolution strategies populationbased methods for policy search neuroevolution hard exploration and sparse reward problems deceptive reward novelty and diversity search methods divergent search sampleefficient direct policy search intrinsic motivation curiosity building or designing behaviour characterizations metalearning hierarchical learning evolutionary automl openended learning for more information including relevant topic areas please consult theworkshop website submissions authors have to follow the official gecco paper formatting guidelines please see the gecco information for workshop authors for further details regarding formats and how to submit accessible through ampxb related journal special issue to be announced important dates submission openingfebruary submission deadlineapril notificationapril camerareadymay presenter mandatory registrationmay conference datesjuly saturday to wednesday contact informations if you have any questions feel free to contact us giuseppe paologiuseppepaologmailcommailtogiuseppepaologmailcom alexandre coninxalexandreconinxsorbonneuniversitefrmailtoalexandreconinxsorbonneuniversitefr antoine cullyacullyimperialacukmailtoacullyimperialacuk adam gaieradamgaierautodeskcommailtoadamgaierautodeskcom as a published acm author you and your coauthors are subject to all acm publications policies including acm is new publications policy on research involving human participants and subjects,cfp evorl gecco nd evolutionary rl workshop gecco,cfp open source repository of deep learning research papers
989,hello all so i have strange request where i need to get a dataset for a class project an industry that has an affect on the us economy it can be any industry but i need two metrics from that particular industry to figure out how it stands up to keys data elements that are provided consumer price index total us unemployment etc the data does not necessarily have to be aboutwithin the us this is just an experiment to see if the data has any affect on the us economy so for example if i pick the automotive industry i can provide sales figures on cars metric vs trucks metric from any manufacturer the only other requirement is that the data has to have a location element so in my example above i would need to know which city state zip country etc were the cars amp trucks sold to i need to locate the data is the shortest time span possible ie weekly data is better than monthly the minimum number of data elements that i need are as follows quarterly data years data points monthly data years data points weekly data years data points i have tried searching around online but the only place that i could think where this may be available is in a publicly traded company is financial statements ie k any help or guidance on this would be greatly appreciated,request industry datasets that affect overall us economy,looking for us automotive industry data
990,for a personal project i am creating a convolutional network that will be able to recognize shoes in an image i plan to use a sliding window to detect the shoe in the image my question is about the size ratio of the shoe because a shoe is longer than it is tall or wide depending on the direction that it is facing the shape of the shoe will be different for example the side of the shoe is a rectangle but the front view would basically be a square not only does this effect what the show looks like but it could also be angled away from the camera my question is how to handle this should i have a few different classifiers that have different shapes to run over the image or should i crop my data set so that the images of the shoe is always in a square but the shoe can be in various poses within the image basically i am asking about how to apply sliding windows when the the object can be in a lot of different positions rather than only a single view like how a stop sign is always facing a car i am currently leaning toward the square crop that has the shoes in various positions plus background when it could be more tightly fit by a rectangle,object detection on non square objects,how to train a cnn to recognize different sizes of shoes
991,i do not know if this post belongs here but i am from a computer science and mathematics background with professional experience in software development with python i want to work on the data science field when i graduate i understand having someone to guide or mentor you would make the whole process of selfeducation easier so the only thing that i feel i can do is to help someone get better at speaking english english is not my native language but i am proficient in it while they can help me get better at doing data science i am very flexible with the methods and the timing which we could decide after a discussion so please let me know if anyone is interested in doing this,willing to exchange verbal english proficiency for data science mentorshipknowledge,i am a math graduate and i want to get into data science
992,i know posts like this have probably been done over and over again and this question has been asked multiple times but i am not sure if i want to do grad school or not for data science i recently got a data analytics internship for the summer and i have school year left before i get my degree major in informatics i feel like i have skillsets that would work in data science as i have a strong math background taken calc and linear algebra as well as a probability and statistics course money is not an issue as far as paying for it and i was recently looking up the differences between data analysts and data scientists and was wondering what steps i would want to take if i wanted to get a masters and whether or not it would be worth pursuing also my gpa is not phenomenal but i tried looking up minimum gpa requirements for grad schools but had trouble finding some can anyone give their advice on whether or not someone in my shoes should consider or go to grad school also if there is any information that would provide context about me that would be useful i would be willing to provide it,thinking about whether or not i should go to grad school,is it worth getting a masters in data science
993,i am currently about years out from retiring from my first career my current office has a need for a data scientist i see an opportunity to test the waters and get some experience before rejoining the workforce i have a lot of interest in data science but i really have no idea where to begin i have already scoured in the internet but reddit is always a great resource so i am asking here too i already have a degree in an unrelated field and its impractical to get another undergrad i have enrolled in a java course through udemy to get myself started in a language my office is java heavy so it seems practical for those currently working or interning as data scientists is it feasible to be selftaught in this field how long did it take you to learn the basics enough to get a job what languagescourses would you recommend to someone that is completely new,aspiring data scientist looking for advice,is it possible to get into data science without a degree
994,i needed to predict call volume for my work and was struggling to figure out how best to model it eventually i decided to use the fourier transform to help me basically i ran the fourier transform on the residuals of a multivariate linear regression then i filtered out lowsignal values got the sinusoid that corresponded to the remaining filtered fourier values and added it as a new variable to my regression i wrote up a medium article about it here if you are curious to be honest i could not find many resources about whether this method is valid i also could not find many other ideas online on how to model seasonality in data so i wanted to reach out to this subreddit to learn more so two questions is this fourier transform methodology valid what are the advantagesdrawbacks what alternate techniques are there to model seasonality in data,thoughts on using fourier transform vs other techniques to model seasonality,how to deal with missing values
995,currently a medical student and have been interested in data science and cs for a while i took a udemy course in python and built some small projects nothing crazy just a twitter bot also learned a bit of data science tools our medical school also has minors and i am part of the informatics minor i am interested in radiology and noticed that a lot of the projects i am interested in are geared towards mlai i am itching to get more involved in projects like this especially for the development of health technologies but understand i can never really learn this on my own during medical school looking at the resume of physicians that have ms in csdata science or health informatics they are usually directors of the clinical informatics department orand involved in health data startups this is where i want to be in the future my undergrad degree is in biology i have a significant amount of research over years both in wetlab and clinical research i took up to calc in college and a biostats course how do you guys feel especially mds and medical students about getting an ms in data science during medical school,any mdsdos or medical students w ms in data science any advice,i am a medical student and i want to get into data science
996,i am a mechanical engineer who just graduated and has only been working about months i had prior internships and i am beginning to realize every aspect of my previouscurrent jobs that i enjoy involve gatheringprocessing data and then creating visualizations for that data my current job has not felt particularly fulfilling and although it is not bad i feel like i will need change in the future something data related seemed like a clear choice but i wa not to make sure i am not going down another career path that i will end up not liking what is the best way to determine if this career choice is right for me i should mention i already enjoyed high school programming classes did some frontend programming for a website for my dad and took a couple introductory data science courses at my university that all intrigued me what is my best course of action to make a smooth transition and learn more about data scienceengineering,what is a good way to determine if i would actually enjoy data scienceengineering,i am a mechanical engineer who wants to get into data science
997,hello guys i am a current high school junior and im trying to figure out what majorprofession im gonna target for ever since i was in middle school ive known about data science and said that it was going to be my major when asked about it even though i had no idea what it was recently ive been looking online and on this subreddit and received some mixed signals regarding the future job market of this field one of the appeals of ds for me was that i found it lucrative in the way that it was a growing job with a decent starting salary and benefits now i am reconsidering and am asking you guys for your opinion on this is ds gonna continue its amazing job growth or is it gonna become overly competitive to the point that i should just look into software engineeringcs also feel free to insert any related professions that you guys think would eclipse ds in its demand ive heard promising things about data engineering,is data science going to become even more competitive,is data science a good career for me
998,im happy in my current role and not interested in leaving at least not in the next few months for a few specific reasons but ive been willing to schedule an interview with any recruiter who reaches out about a good opportunity usually i make it through at least rounds and then get a rejection and im not sure how to feel about it on the one hand i always feel relieved so i realize i should stick to my original plan of staying put for a little while longer and say thanks but no thanks to recruiters from now on but on the other hand some of these jobs are lateral moves and pretty much identical to my current role which ive been in for years so getting rejected either means i actually suck or maybe im not trying hard enough another sign to just decline interviews anyway not sure if im looking for adviceanswers or similar experiences or just want to share that job searching is still hard even when you have experience and arent even looking,anyone else not actively job searching but still getting rejections lol,i have a job interview for a few months and im not sure if i should take it or not
999,i am working on some content to teach ann is to gradeschool kids i have run across a couple good articles most of which model a simple xor problem using three layers input hidden output however this article is a little different in that it simply goes straight from inputs to outputs with no hidden layer in between most other articles seem to follow the three layer approach for hello world ann models does this technically qualify as an ann for teaching purposes or must we have at least three layers to be an ann input hidden output i want to use this simpler model as the first ann in the content i am producing butbut only if it technically qualifies as a neural net thanks,are single layer ann is appropriate for learningteaching eg input layer straight to output no hidden layer xpost rmachinelearning,question about hidden layers
1000,i apologise for the long post but context is important to my question i am a data engineer at a mid sized company we recently hired a data scientist and they work mostly in pycharm we keep most of our data mainly large transactional tables in parquet files in our azure data lake lakehouse really to this point the ds has been using dask and other tools to do eda and most of the rest of their work however we are getting to the point that the data is too big for this analysis as they arent able to hold it in memory for this reason i have implemented the databricks service for them and set up notebooks while this is very fast and efficient their code doesnt transfer from pycharm to databricks notebooks they are struggling to do their work in databricks as they need to recode everything and learn pyspark the question is are we missing something how can they continue to work in pycharm but leverage our cloud services so that the data size doesnt cause significant slowdown andor memory errors is there an integration i am missing,big data question,how do you store your data for future reference
1001,hi there i was hoping for a little guidance from some people more experienced than i am i am an undergraduate student who landed a data science internship with a nonprofit my first project is to use kmeans clustering to take all the data we have on our donors and make clusters to better understand the profiles of people making donations to our organization so we can market better while i am still in the preliminary stages of this project a big issue i can foresee is our quality of data while we have solid data on the donations they have made we are missing some key demographic info the database has columns for things like net worth income level media preference location age etc but a lot of the records have missing values for these the reason being is that these were collected from email surveys before i joined the team that only of the donors in our database actually responded to my question is do you know of anywhere i can purchase this data or how i can navigate these missing data points,help with an internship project,how do i find the most appropriate data for my data set
1002,i keep hearing about data science and our team uses dashboards from powerbi daily yet i do not know where to really start on learning more some background on me formal education is in programming and i have deep practical experience with sql databases both designing and querying i am also comfortable changing between imperative languages java c etc i also have good experience with application configuration in an enterprise environment i also currently use vscode for process automation tasks working in the internal it side looking out i see lots of demand for data science in our other business areas i am looking to start learning more about that side not so much to be a full data science role but to have to have enough knowledge to be a knowledge support on the it side looking for some suggestions on where to start and open to any advice sort of thinking powerbi python and r may be areas to look into but also know my knowledge is currently so low incoupd be headed in a wrong direction already,advice on where to start,how do i go about learning data science
1003,hi all you were such a tremendous help yesterday i thought i would ask another question that i just encountered another new client whose got some funkiness going on in their google analytics they have the standard advanced filter setup field a gt extract a hostname field b gt extract b request uri output to gt constructor request uri ab field a required override output field from what i understand typical destination goals do not work with this filter explains why they have never had any goal completions despite me completing a few tests recently my question is if i understand correctly the destination goal would have to be setup using regular expression how would i set that up if the destination url is side question i am under the impression that this kind of advanced filter is pointless if there are not any subdomains is that true,destination goals w advanced filters,question about google analytics outbound links
1004,hello i am a junior database developer and i am new to data science and big data i am really interested in those fields and so i took courses on coursera which were something like an introduction into machine learning statistics big data processing and so on currently i want to go a step further and learn r or python i am curious to find out from a data scientist point of view which are the advantages of both r and python as far as i have read r is more suitable for the ones who have solid statistics background and python is much more easier to learn than r but still have powerful data visualization cleaning and modeling tools now my company suggested me to take a specialization from data camp data scientist with python i wanted to ask you if this is worth it and if there are handson exercises that helps the student to apply the theoretical knowledge also any other advice regarding starting a career in data science would be really really helpful thanks in advance,opinions about data camp,r or python for data science
1005,backstory was accepted to georgia tech omscs a few years ago i took a machine learning class and got an a but it was an absolute struggle realized that i did not have a good foundation in computer science concepts and that a computer science degree would not really help my career at the time two years later and i took an aerospace engineering job that turned into a data science job at nasa i love what i do now and i want to get a computer science masters specifically the one from illinois that focuses on data science anyone in this program i want to make the best case for admissions and plan on taking the next year or two preparing any advice or recommendations specifically i would like online courses that provide credit first although i talked to admissions and they do consider online courses through coursera etc thanks,looking to get a computer science masters any good online discrete math algorithms and data structures courses,i have two years left until i graduate with my master is and i do not know what to do
1006,i have a masters degree in cognitive science and a bachelor is in psychology in both degrees i was exposed to the collection analysis and interpretation of quantitative data used spss in my bachelor is and r in my msc i started out without knowing a single line of code and now i can say i am quite confident in r i have carried out simple analyses from descriptive statistics to some more complex analyses like linear mixed effects models all the while having to sift through messy datasets eye tracking data being one of them picked up sql recently but so far did not come across anything i could not do in r i am quite interested in collecting and analysing data like my heart rate data and time spent playing games i really enjoy seeing trends and getting insight from them there is a local company that has the position for a data scientist and a market research analyst i do not have any practical working experience in either role but i would like to ask whether anyone has been in a similar position or with a similar background and managed to land a job in this field thanks in advance,do i have the background to get into data science,how much do i need to know for data science
1007,i am trying to learn to use an autoencoder to denoise a data stream using tensorflow i have loosely followed the example given with tensorflow the key points are my data has the truth no noise and the input truth noise and i use the truth as y_true cost function is the mean of the error squared i am using the rmspropoptimizer sigmoid activation functions it works very well except it does not allow for any of the output values to be negative essentially forcing them to zero you can see and example of the data truth and result here can anybody point me into a direction that would help me understand how to allow for negative output from the autoencoder i cannot image it is my minimization algorithm and the sigmoid allows for negative values any pointers are appreciated thanks edit bullets are hard,autoencoder inputs data valued between and only returns values between,how do i use a negative output in an autoencoder
1008,hi all im a yo college student studying marketing ive also worked with qualtrics and a bit of tableau i do have experience in ios dev and a basic understanding of web dev so programming isnt at all new to me i graduate in a semester and am trying to figure out what new skills i want to gain i dont want to be a marketer lol i believe in gaining skills that will b in demand for years or decades to come im considering taking one of those week boot camps during the summer and was going to go the web dev or robotics road my uncle is a senior android dev but told me i should consider data science i need you guys to sell me on it thanks,should i jump in,is it worth spending my summer learning data science
1009,hi i am trying to build a desktop for research purposes nvidia donated two titan xp therefore i am trying to get everything to assemble the computer our budget is a bit flexible k this computer is going to be used mainly for process d medical image analysis ct mri we prefer it to be stable we will use windows for this computer for deep learning we are going to use either tenserflow or matlab after reading many posts i have generated a list we do have several must have preferences since we already have two titan xp we need to house both of them this is mainly for research we will not overclock also we prefer intel core currently we will use way sli and prefer to have potentials to extend to way sli we will need your advice on since we have two titan xp do we need to build other cooling system other than the cpu cooling is there anything we need to tweak to avoid any bottleneck in the computer if we purchase everything online how hard will it be to build from scratch by ourselves i knew the local fry is store can do it for us but not quite sure if they will have every hardware we want since we are not expert we hate to bring the final list to store and then switch things here and there thank you in advance for any helpful comments,help needed for deep learning computer,is it worth buying a new laptop for deep learning
1010,i use virtual environments all the time for every new project i create a new conda environment i am starting to do more productionlevel data science projects and it seems the trend is to use docker containers frankly i am ignorant about them and just starting to learn literally just starting the tutorials today i am a bit confused on the basic moves here in python which has had virtual envs for a long time what are the added benefits of using a docker container i can see if you are developing in c where the build process has been a complete mess for decades docker containers could fix this but in python we have had virtual environments for many yearsi send someone my environment specification and they create the environment and voila things just work when would a docker container be more helpful when should you use one versus another versus both why would you use both is that not redundant or overkill thanks for any help pointers to videos or articles as i start on containers,compare and contrast docker containers and virtual envs in python what are the main differences and when is it good to use one or the other or both,docker vs env
1011,hi all i am not a data scientist and have no ambition to be let is make that clear however i am wanting to learn enough of the basics to get a bit of background and be able to do some tasks myself be able to communicate and understand the language of data scientists beyond make that data stuff happen i am doing the below course so i wanted to ask two questions how long did it take for you to feel that the time invested in learning data science paid off for those who did the above course or can suggest alternatives did you find it very effective learning one as such in particular i am wanting to obtain what i call basic competency able to perform but am not great at customer analytics machine learning and neural networking data visualisation data preprocessing power bi given this is what the company uses web scraping financial modelling in python ampxb thanks everybody dan view poll,how long did it take for learning basic data science to payback,how do i get better at data science
1012,hi guys i tried searching around the subreddit for something like this but could not find anything in particular i am finding some conflicting info regarding qualificationsjob searching results around the web i have read some stories where people with very reputable master is degreessome even with phd is in quantitative fields stats math comp sci with a few years of relevant experience who claim they cannot get a job then there are some who will claim if you have a strong foundation maybe an advanced degree and get a couple years of relevant internshipspositions you should be set to make your way into the field for those who have gone through the process what do you think is reasonable to expect for those who are trying to get into the field also i am wondering what is meant by entry level data science positions are we talking actual positions titled data scientist and if so i do not seem to see many of these positions that are entry level or are we maybe talking positions like quantitative analyst or data analyst obviously there is no formula a degree from x university and years on your resume will not give you a data scientist job at some great company and countless other factors connections interview skills etc but i am just wondering what some people is experiences might have been like let me know what you guys think my story getting a master is in applied stats at a very reputable university this year not much professional experience but will try to get a good internship this year have just begun learning python tldr what should new graduatescareerchangers expect when trying to get into the data science job market,what to expect when trying to enter the data science field,what are some of your preferred entry level data scientist positions
1013,apologies if this isnt the right subreddit for this question previously my data analysis mostly consisted of straight forward things like linear and mixed models lately though im working with larger datasets several hundred thousand rows million cell matrices bayesian analysis with mcmc and parallel processing my computer just cant cut it so work is buying me a new one obviously bigger and faster is probably better but im wondering what is most important processor speed or memory for processors should i maximize base frequency cores caching or i can only shop at dell so if you have suggestions let me knowright now im aiming for minimum gb ram and a intel i processor in a laptop but bumping from lt ghz base frequency to gt adds gtk any suggestions,computer specs advice,what is the best laptop for deep learning
1014,i am using shopify which has the following thank you page checkoutthank_you however due to how shopify is set up users are allowed to revisit the thank youconfirmation page from their email or even directly because of this i am getting a ton of conversions misattributed to direct this seems to be a pretty well know issue from shopify and i have spent countless hours researching how to fix it and spoken to their support team but have not been able to find a solution does anyway know of a way to tell google analytics to only count the first interaction with a specific page andor to say if checkoutthank_you is a landing page do not count it as a conversion i am assuming this requires some custom javascript,allow ga to only fire once on thank you page,question about google analytics attribution
1015,hi i am student trying to study deep learning and gans i am new to both and i wanted to try recreating the cyclegan paper in order to understand it more i am using tensorflow and i used their open sourced code as a guide however after training for epochs my results looked low quality and the colors are washed out unlike their results i also tried training it a bit longer but i did not see any difference i used their summerwinter yosemite dataset there are some semblance of the transformations so i think i am not too far off i am not sure what i am doing wrong and i hope it is alright to consult the community and ask for advice as to how i can improve here is the link to my code sample results of the code,inquiry request for help regarding washed out color results of my attempt to implement cyclegan,question about gans
1016,hi all i have received help with ab testing questions from this sub thank you i understand that stat sig is not a magical cutoff yet i am surprised to see ab testing tools such as optimizely ab tasty and vwo emphasise this number why would popular tools perpetuate this myth please let me know if i am missing something thank you links to ab testing tools that mention these quotes are in comments unable to include in post is an accepted standard for statistical significance conversely if your test has reached statistical reliability and you have enough information to learn lessons it is best not to let the test go on for too long for your ab testing to be truly effectiveyou must accept the results whatever they are provided of course they have reached statistical reliability we call a variation a winner when its potential loss is below the threshold of caring and its chance to beat all is more than or equal to,ab testing online experimentation even popular tools emphasizing plt,what are some of your favorite statistical tools
1017,does anyone have ideas for opensource deep learning project ideas that they have been wanting to try and buildout i am in a graduate deep learning class right now and an element of the class involves a project i thought it would be cool to build something usefulsustainable rather than just a singleuse application which i would never really look at after the class itself i have been trying to brainstorm ideas and procrastinating lol for a month now and all i have got so far is that i think it could be cool to do something along the lines of a tool to analyze a model during training think tensorboard but better or potentially something in the model interpretability space i am hitting a wall though and would love some starting pointscool ideas,potential open source project ideas,looking for a mentor for deep learning project
1018,background i have a bsms in electrical engineering in my ms i decided i wanted to focus on mlai and took the following courses random processesstatistics pgm cv intro ml intro ai i recently started a job in which i am doing algorithm and ml work and really find myself wanting to dive deeper into the statistical foundation of these algorithms the university near me has a great professional ms applied math program with a data science emphasis with courses such as statistical learning bayesian stats spatial statistics highdimensional dynamic systems convex optimization etc along with options to take other ml courses offered in the cs department that i did not have a chance to take in my first ms should i put the time into getting another ms while working employer would pay for it or is selfstudy a better option,should i get a second masters degree,is it worth getting a masters in data science if i already have a job as a data scientist
1019,i started working on a project in which i want to localize the text in the natural scenery images for example consider an image that contains text in different parts of the image with different sizes for each word so how can i find the locations of all the words in the image previous research i found some information in some papers which explains that they are using a localization networkcnn rnn which produces nn is total words in the image affine matrices for each word in the image and also other variations which uses the sliding window of different sizes sliding across the image and trying to find the presence of text i am not able to find any resources that helps me with the implementation in python tensorflow this is a reference link i came across can anyone suggest me the resources required to achieve this task thanks,implementing text localization on natural scene images using tensorflow,need help with a text compression problem
1020,hi all hoping you can help me navigate a gnarly problem i need to monitor traffic to a certain segment of pages within a larger website but i do not have the advantage of a url differentiator i would like to use tag manager to do this ideally but i do not think a simple regex will work since the key word is found in the header on every page i actually tried a regex filter just now and it was not successful can i use a custom variable maybe if so do i need to find a way to add this variable to every page i add to the segment i can add details if necessary tldr need a way to monitor both overall traffic to a site as well as a segment of pages within it the segment is not differentiated by a url and a regex will not work because the key word is found in the header on every page any ideas,page tracking on google analytics without a url indicator,how do i track a specific section of a website
1021,hello friends i want to create a model classifying succulent plants however there does not seem to be a good dataset and there will be a lot of class what would be your approaches to scrapcreateclean the dataset and to choose the best model for this problem i am not necessarily asking for a whole solution but more of a lead ampxb for context i took andrew ng is course and built some small models of image classification i know this problem is not simple at all but i think this is a project that will allow me to learn a lot and to get out of this framed environment where you are already provided with everything,building a classification model for succulent plant,how do i go about training a model for a specific situation
1022,i am a junior in university studying financemath i used to want to work with quantitative finance but now i want to work in data science the only relevant experience i have is my last internship where i backtested stock trading strategies in r and vba and did some statistical analysis ttests testing significance of correlations etc i was just offered to intern at another quantitative investment management firm the role mostly works with sql and the net framework languages c for the most part i know the experience in sql will be valuable but i am not sure if experience in c will be useful at all i also do not know if working in a financial services firm before graduation will make it harder to get a data science position in a nonfinance company in the future i can work at my last internship again take this offer or continue looking for other nonfinance internships my school is having oci is for these positions in the next month any advice,aspiring data scientist should i take this internship not sure if it will be useful,i am a year old and i do not know what i want to do
1023,hi there hope someone here can point me to the right place i am doing a project that involves cutting a large number of lengths from pieces of raw material stock in many cases scrap from the first cut will be able to supply material for one or two more cuts i am looking for a way to discover how much material to buy based on the quantity of lengths that we need taking into account the overage required to produce the finished lengths another twist is that we would like to keep the cut pieces in graduating or descending order of length for the most part you can imagine a linear change in length cut a cut b cut c and so on however the real numbers will not reflect a linear slope this slope will repeat a number of times to try to sum up we are looking for a way to calculate how much material to buy based on how the size of the raw stock will accommodate multiple cuts perhaps taking into account the ability to group and order the cutting into batches that try to maintain a grouping ok that was a mouthful thanks for your help,looking for easy to use sorting algorithms for a project,how do you deal with overfitting
1024,hey everyone i am planning on attending this webinar nothe macroscope initiative building planetary geoml with omnisci with qampa learn how the macroscope concept can be applied to the monitoring of tree health the exposure of static and moving assets to weather and the analysis of ship movement patterns featured speakers dr mike flaxman spatial data science practice lead and abhishek damera data scientist at omisci will discuss lidar gps cell phones and cube sats machine learning methods applied to geodata which can classify patterns of movement or pixels or geoml modern computing architectures which move algorithms to data and stream highlydistilled information info what do you think i think a macroscope perspective sounds interesting,webinar the macroscope initiative building planetary geoml with omnisci with qampa,data science with no macro perspective
1025,hello i am new to the machine learning field and i am far from being fluent in this practice so please forgive any blatant stupidity anyways i have been working on my first feedforward neural network for a while now but i seem to have run into a problem my network is a standard feedforward network with three layers each with nine nodes using sigmoid activation i tried softmax but it did not seem to work out very well the networks goal is to play tictactoe and makes its move based on whichever output node throws the highest sigmoid value it is fed training examples that are randomly shuffled each example is a board state with xo and a blank space being zero the expected value that is fed into backpropigation is an array with every expected value being zero except for the intended move which is one the problem i encounter is that the neural networks train time screeches to a halt as it gets closer to its intended output at around percent efficiency with the training examples the error becomes far to small and the weight adjustments shrink to the point where i can run it all night and it will hardly advance the mean squared error is dropping it is just dropping so so slowly that it takes hours for anything to actually change in how the network plays i tried implementing a crude form of momentum but it did not seem to help much how do i avoid this problem,how to avoid network becoming painstakingly slow as it comes closer to convergence,how do i train a neural network to play a game like chess
1026,hello i constructed my first little network based on this guide here now when i do a single run of the data from this article inputting into the network and checking to see how my weights have changed my network matched up perfectly with the table provided and i went out upon my way attempting to build a more advanced network based on what i learned however recently i went back to run the test data again and i encounter a strange problem and i do not know if it is the data or my network that is acting up if i have the network run infinity with the same input i assumed that eventually the first output nodes output would approach one and the second would approach zero adinfinitum since there is only one training example and it would be reasonable to conclude it would behave that wayat least i think what actually happens is that the first odd cycles of the network behave as expected and then within one cycle both output nodes rapidly drop to a value slightly above and decrease by minuscule amounts seemingly forever i have no idea why have i designed my network wrong or is this simply a result of the data,i seem to be having a strange problem with my network could anyone test this data for a similar outcome,how do i know if my network is behaving correctly
1027,hey guys the sentence below is generated by the ai after i give it a prompt of james blunt a james blunt a former us deputy secretary of state said the attack was not only inexcusable but troubling in the wake of president trump is victory the use of an attack on citizens who had gone to vote to ensure democratic freedoms was an outrage and an insult and a disservice to the american people blunt said a spokesman for putin issued a denial of the information being peddled in the us you will also be able to have a conversation with it that uses the state of the art pretrained natural language processing model i attached an example below if you are interested in computer vision image processing and generation it also has those covered as such the image generation feature is still under development but definitely let me know your thoughts cheers and have a good night server inv link here,i built a very cool ai in my discord,i just received an evite from my new job as a data scientist and i feel completely unqualified
1028,i often find myself in need to share my findings mainly tables and pictures with collaborators when i started working in data science i was using jupyter notebook a lot so i usually exported ipynb to html and voil but over years i switched completely from notebooks to scripts even though i love new jupyter lab without notebooks creating standalone html file with images and tables was not easy anymore i could not find simple python package to help me with that so i created my own one htmlcreator it exposes simple api for creating standalone html files from python code containing text images and tables embedded inside it has also default styling css so everything looks nicer i have been using it for around years now and recently decided to publish it so others can use it too see examplesbuild_documentpy and its output examplesfirst_documenthtml installation for python gt pip install htmlcreator source code,htmlcreator build standalone html documents from python,how do you store your data when you are not your own
1029,hello all i am trying my hands on an ocr project i have this idea of casting ocr as caption generation problem and wanted to use inception v as feature extractor with rnn head similar to show and tell architecture currently from svhn dataset i have extracted bottleneck tensors of inception and fed them to rnn after embedding to suitable size the result is i get overfitting on training data ie training sequences are generated perfectly but the test results are bad indicating the network failing to generalise i am wondering if it is bad to cast ocr as caption generation problem and if the results i see in training is just the network memorizing stuff during training i would like to have your opinion on this thanks a lot in advance,inception and ocr,question about overfitting in rnn
1030,im a cs major but have been working in the sales and trading world in finance that was just what i fell into in however i really want to work in a more quantitative field again ive been doing a lot of research on data science and given my cs background i thought its a good fit inviting some critique here i have been taking calculus and python and statistics courses to prepare myself for a masters program anyone know anything about this program from what i see it has a focus on ml but its an investment and a risk since ill be leaving my career to do this at the ripe age of,looking at ms at city uk,is a data science masters worth it if i already have a job as a financial analyst
1031,i am currently in my last year of chemical engineering and a teacher gave us some work to familiarize ourselves with r and data analysis with r the first step is to find a dataset on which everything will be done the criteria for the dataset are the following it must contain at least quantitative variables and at least qualitative variable it must be chemistry chemical processes lab results anything health clinical trials related ampxb the test we will do on this dataset are very simple verify the normality anova linear correlation and since this is the very first time i am confronted to datasets like these and i have never used r i am having a really tough time finding the dataset that suits my needs i thought reddit could save my ass once again,engineering student here i am having trouble to find the rigt dataset for a groupwork,looking for clinical dataset with r and python
1032,im a year experienced software engineer with a masters in machine learning i have a strong desire to get experience with machine learning and applied to a couple data science type roles i have an interview coming up and was looking for advice on what is typical in the data science realm as im not actively involved what should i study what subject matter should i expect to be hit is leetcode a thing for data science i read that sql is pretty important in ds interviews the job is pretty low level and my se experience might end up helping me but im curious on others opinions what do you find important with interviews in this field,data science interview coming up and looking for advice,what is the importance of a masters in machine learning
1033,so i applied to analytics related internships one is business analytics managerial trainee at procter and gamble the other is a bi related one my issue is that i prefer pampg and i read a lot of good think about the company culture im in eu tho not sure if that changes anything but their process is quite a bit behind so i either risk rejecting the other one and end up with nothing or take the other one but im not sure if there would be too much difference for an intern between the and considering im changing countries in months for my masters degree it doesnt matter too much right any advice is welcome but basically i should decide between rejecting the offer from my b choice and risking not getting my preferred one or taking the first offer,torn between internships,data science or business analytics
1034,background about me i recently started corporate job where a lot of people use tableau for building dashboards and visualization of data all of my previous data experience is entirely in r and i am rapidly learning python things i am used to doing include basic dataframe manipulation linear regression building principal component analysis mixed linear models and effect matrices ggplot visualization and some basic implementation of decision tree ml models i have a meeting with some of my superiors and it people today where we will be discussing software they want me to use having never used tableau i am not too sure what all of its capabilities are frankly i would prefer to just r and python for everything but i think they will need some persuasion as to why they should let me stick with the tools i am comfortable with and where exactly tableau falls short of pythonr tasks that i will be doing in my job will be automating data reports building dashboards modeling visualization and exploratory data analytics any input to help me understand the world of tableau would be appreciated,question about limits of tableau vs pythonr,is it worth spending too much time learning r or python
1035,i am working on a project for which i need to find some data for and i am not american so i am not super familiar with where i may be able to find these data i found some on the census but it is in a way that is quite difficult to download repeatedly any help is appreciated the variables that i would like by county for and are a raceethnicity black nonhispanic other nonhispanic hispanic b age under under or over c female d education less than hs some college college plus e mean and standard deviation of household income f at or below fpl g rural population density h foreign born i on medicaid j in labor force bls laus k married l total population thanks again,trying to find us county level data for a host of demographic education and health data,looking for data on marriages and family separations by county
1036,hi so i am a very experienced embedded systems developer years experience and for the last year ive been working on this ml sideproject in python i have actual experience in ml but i watched countless hours of different videos a coursera course but i actually found all content mostly irrelevant to my project given that it uses a completely new algorithm for ml unlike any that i have seen though so far i am very protective of the algorithm itself because i am very afraid it will be taken advantage of an i will not get credit for it on the other hand im having a hard time advancing it by myself to a point it can be marketed keeping in mind i have a full time job which i cannot quit basically the algorithm just finds patterns in raw data by using some type of statistical analysis for instance i run it over two online books in english total of million characters and it finds interesting patterns like the word the words that finish with tion computation education i run it over mnist data set and it find edges and solid patterns important to note is that it actually requires very little data to find patterns it will discover edges by analyzing a single x photo my question is how to i advance this algorithm how do i make it known how can i monetize it is there some open source data set i can use to prove my algorithm works is there some competition for data mining i can compete in not image recognition though i hoped to do that with mnist i hoped it would manage to learn recognizing the ten digits but i havent gotten there yet i think as it is now it would be great to find patterns in genetic sequencing or behaviors that cause diseases can someone please provide me with some help on how to move forward thanks in advance,how can i advance my completely new and very promising algorithm for unsupervised pattern recognition,how do i know if my model is ready for production
1037,hey guys i am a beginner in machine learning and a second year in cs i have written a seminar paper on supervised learning and image classification last semester i have extended this work in graphics algorithms class using imgaug and cutout explaining how these algorithms work and why they are beneficial to the quality of the model pretty much only very basic stuff i believe i have a very basic understanding on how it all works under the surface my question is is it possible for a beginner like me to write a bechelor is thesis on reinforcement learning fe in a game like doom making the model complete the first level i have seen some videos like using reinforcement to complete the first level of mario or to learn playing snake much better than a human would where should i start is it even possible any good courses or guides on this subject,bechelor is thesis on reinforcement learning,how do i know if my model is performing well
1038,in this article we will look at some of the important machine learningclassification algorithms we will discuss the various algorithms based on how they can take the data that is classification algorithms that can take large input data and those algorithms that cannot take large input information wait i recommend you to first explore the types of machine learning algorithms machine learning classification algorithms classification is one of the most important aspects of supervised learning in this article we will discuss the various classification algorithms like logistic regression naive bayes decision trees random forests and many more we will go through each of the algorithms classification properties and how they work logistic regression algorithm we use logistic regression for the binary classification of datapoints we perform categorical classification such that an output belongs to either of the two classes or for example we can predict whether it will rain today or not based on the current weather conditions two of the important parts of logistic regression are hypothesis and sigmoid curve with the help of this hypothesis we can derive the likelihood of the event the data generated from this hypothesis can fit into the log function that creates an sshaped curve known as sigmoid using this log function we can further predict the category of class we can represent the sigmoid as follows the produced graph is through this logistic function ex the e in the above equation represents the sshaped curve that has values between and we write the equation for logistic regression as follows y eb bx eb bx in the above equation b and b are the two coefficients of the input x we estimate these two coefficients using maximum likelihood estimation learn to implement logistic regression using sklearn class with machine learning algorithms in python nave bayes algorithm naive bayes is one of the powerful machine learning algorithms that is used for classification it is an extension of the bayes theorem wherein each feature assumes independence it is used for a variety of tasks such as spam filtering and other areas of text classification naive bayes algorithm is useful for naive bayes is an easy and quick way to predict the class of the dataset using this one can perform a multiclass prediction when the assumption of independence is valid naive bayes is much more capable than the other algorithms like logistic regression furthermore you will require less training data naive bayes however suffers from the following drawbacks if the categorical variable belongs to a category that wasnt followed up in the training set then the model will give it a probability of which will inhibit it from making any prediction naive bayes assumes independence between its features in real life it is difficult to gather data that involves completely independent features must check implementation of naive bayes classifier from bayes theorem in data science decision tree algorithm decision tree algorithms are used for both predictions as well as classification in machine learning using the decision tree with a given set of inputs one can map the various outcomes that are a result of the consequences or decisions we can understand decision trees with the following exampleread more,machine learning classification algorithms for data science aspirants,how to deal with missing values in logistic regression
1039,i am a noob trying to up learn time series modelling and have a couple of questions i am hoping someone can help me with i am trying to forecast sales for the company i work for which is a fastmoving consumer goods company i am doing this activity just for my learning as we already have a team that has developed some pretty advanced ml models i plan to start with a basic arima model but hope to move to a multivariate model and compare the two i have the following columns product number actual sales date customer and category all the examples of i have seen of time series models strip columns down to only sales and date but what if i want to split the forecast by customer and category how is this possible i have searched but not found any examples does anyone know where i can find examples of this online secondly i am going to perform feature engineering and intend to use lag and time based features once i have completed the basic arima model what is the typical model that is used to include these features from what i have read sarimax seems like the best option is that right also is it possible to use a multivariate model like var using these new features or would you only use a model like this if i was bringing another kpi in such as weather any advice appreciated,time series query,looking for advice on how to approach this problem
1040,plotly dash comes to mind but because this is pythonbased i figure it might not be readily embeddable in an application that might perhaps be ruby on rails based or am i incorrect in that if i had a page within a portal where a client could fiddle with variables and see the outcome of a model what tool similar to streamlit would i be able to simply use streamlit itself or is there a tool similar to streamlit that lends itself readily to being included as part of a much broader application the functionalities of streamlit itself meet our needs nicely but as far as i know it is much more for quick prototyping rather than productiongrade applications,languageagnostic tools similar to streamlit that are suitable for embedding in productiongrade applications to allow an enduser to fiddle with variables and see the outcome of a model,is there a better way to track the state of an application
1041,hello all i have recently started teaching myself r and python since i have always been enamored with data i have always wanted to tell stories using it now i see that there are a ton of articles here about data science and how to become a ds but i want to take it a step further and actually create a self taught community that can put the how to into action naturally i started a blog and facebook page to chart my lessons and to challenge myself to put my classes to use and i realized that the best way for me to learn was helping others learn the same material and i want to bring that same mentality to others i will also be posting topics lessons from others that i find and generally anything that can help anyone get into the field if anyone here wants to join up you can find us on facebook by searching data science simplified and liking the page i appreciate the time and i hope to see you on the page soon also with the page being new i am looking for people to help run it if they have any free time tldr i made a new page i would like to find other like minds and start a detailed discussionpagecommunity together edit to the edit i cant place words properly there is a new blog post up and it has the links to join up the new group slack channel and discord server if this is a more convenient way to communicate i invite you to take a quick moment to check it out thanks again for giving some time to read,looking for others who want to learn data science together,looking for feedback on my new data science blog
1042,hi everyone i am trying to do an analysis on how some features can predict a target variable that takes the values of or i am kind of stuck and i am looking for any help that someone could provide i started by doing a correlation analysis but when i use functions such as corr in pandas it is not showing any significant correlation between the features and the target the largest correlation is is this happenibng because the target variable is either or all the variables of the dataset are numeric and there are no missing or nan values i am a begginer in data analysis and in my short time learning about it i have not seen any cases like this but after some searches online i came accross the logistic regression which if i understood it correctly is for iscaling the target variable axis and therefore showing a better correlation would logistic regression be a valid approach for a case like this if so how should i apply to a case like this also are there any other steps that i should take or that i am missing i would be greateful for any help thanks,begginer question about predicting a variable that takes or values from a set of features,question about logistic regression
1043,keep in mind my motto here is strong views weakly held and i feel like i do not understand f score all that well so i am mostly just trying to understand it better through this post but through a critical lens because from what i do know it seems awful it seems there is no way to understand intuitively what a change in f score means like if my model improved from to f did it get more precise did it increase the recall by how much what is the tangible meaning of a increase in f it seems i would be much better off by just looking at precision and recall directly those are intuitive metrics i can understand at a tangible level i can even tie it back to revenue increases for the company but by combining the metrics in a way that loses information like with f i lost the ability to understand my models performance in the context of what it actually does i think the big thing i do not understand is why i would use the harmonic mean of precision and recall f score rather than the arithmetic mean arithmetic mean seems way more intuitive and simpler what do i gain by switching to a more complex average of the scores,cmv f score is a terrible metric,is there a better way to calculate f score
1044,hi i am working on a small project i do for fun and therefore i need to collect a bunch of images about k to get the images i already have the links to the jpg simillar to this reddit image now the thing i wonder if i were to download images using the tab save extensions in chrome there are better methods that save time but this one is needed in a matter of seconds can it be seen as a ddos attack i do not know whether it is safe to download that many images from the same website different links but same website in mere seconds so i rather ask first than be sorry later so i already have k links to the images image per link and want to download them using tab save chrome extension is this safe to do for both the websiteowners and me greetings,safe to download many images from in seconds using chrome extension,can someone help me with my project
1045,hi guys i just had a quick question has anyone tried to build a custom google analytics api to plug into tableau and if so did you have any success as oppose to the tableau native connector this is for occasions where access to big query is out of the question as this would generally be the best course of action to take the reasons behind this is because i cannot apply an exclusion filters within tableau is basic api which means it takes way too long to extract the data i am looking for manipulating custom segments will not work either as i am not looking for session or user level data by the way guys i am new to reddit you can call me either ash or arshad whichever suits you and i am a digital analyst by trade thanks again,custom google analytics api for tableau question,best way to query google analytics data
1046,i am by no definition a data scientist just putting it out there i did the analytics for my phd using stata and am fairly comfortable in it problem is that in the new job which is quasiacademic the quality of graphs and visualisation is kind of important graphs made on stata does not cut it the organisation suggestion was to use tableau and i am fairly decent at that problem is that i do not like pointing and clicking i would rather write code and massproduce the visualisations required for reporting moreover i also thought that knowing free software will keep me competitive in the market i started on python and i have been struggling since initially i thought that it was the learning curve but when i started replicating my workflow in stata on python i find myself increasingly stuck in multiple areas with no way out a small example of this is below foreach var of varlist p_ p__p__ p_p_ p_p_ asdoc tab var asdoc tab id__ var row nofreq asdoc tab id__ var row nofreq four lines of code on stata takes all the variables runs a loop prints out descriptive stats with disaggregations and exports it all out on a word file which my older colleagues can also scroll through i just cannot seem to be able to replicate this and cannot find help for it either my initial decision to work on python was because i read that it has the widest support base on the internet every time i try to figure out how to export results of a loop to a word file i keep getting redirected to articles and videos titled how to read and write onto word which is not something i am trying to do in the first place rounding up a few questions for people used to working on stata does moving to r make more sense i generally refer to reddit look at youtube tutorials online articles and stack overflow to learn how to replicate my workflow am i just approaching it the wrong way or should i be looking at other resources i mean i never get any responses on stack overflow and in general my needs seem to be a very weird niche then again i always thought it does not matter what my problem is someone already has posted about it online lastly for people who have successfully transitioned from stata to python did you guys find python more cumbersome ps also if someone knows how to replicate the above code on python do nudge me in the right direction i do not need code just need to know what resource to look at to solve the issue,generic question about softwares not here to start a softwar just a genuine question about python r and stata,how do you guys deal with data leakage in your organization
1047,hi everyone forgive me if im posting in the wrong thread i just need some help im trying to figure out which data science masters program to attend i need an online program to balance work and family life syracuse university seems more credible and they even have information on their website saying where the students work after graduating however i know suny oswego isnt a bad choice either especially since my work place will pay for my degree there but not from syracuse university i already have undergraduate loans however im willing to take more loan if and only if syracuses program is way better otherwise suny oswego has a masters in health informatics with a primary tract in data science im just a little nervous about which program will help me find a job faster after completing it please help me figure out which masters program is better any advice would be appreciated thank you very much ps just a background im currently a medical lab tech trying to become a data scientist ive only scrapped the surface of app academy just to get familiar with some coding please any advice would be wonderful,syracuse vs suny oswego,data science masters program in syrac
1048,hello everyone i am a first year business informatics student in collegedont know if thats the right name as i am from italy and i wanted to know if the math i will study is enough for a career in data science right now i have taken a general mathematics course basic revision of algebra stuffsome set theoryequationssystemsinequalities ecc a bit of geometry like hyerboles ellisses and what notexponentialslogarithmsa bit of trigonometryfunctionslimitsderivativesgraphsintegralsoptimization ecc all for functions of one variable then we did an introduction of functions of two variables and then we studied free and constrained optimization for those i know linear algebra is very imporant however it is not in my bachelor plan but i will self study via prof strang lectures then throughout the last two years of the bachelor i will take a course in statisticsone in econometrics and one in probability that is about all the math in my bachelor in the masters i was thinking of attending the main math subjects are graph theory discrete mathematics and optimization machine learning statistical learning deep learning and artificial intelligence microeonometrics causal inference and time series econometrics advanced multivariate statistics bayesian analysis is a curriculum like this enough math anything i should self study because it is missing i really could use some help,math needed for data science,i am a math major and i do not know what to do
1049,i started a new job as an analyst for a contact center handing the reporting for their phone system i am about months in and feel i should have made more progress i often times am not sure what to do with my time i have gone on calls with my coworker a handful of times to learn how to create the reports he distributes apart from that i have not been assigned any clear reaponsibilites or projects i have thought about making some additions to a couple of those reports but my coworker told me he is in the process of recreating all of them i am used to an environment that has all of the data i will need within sql server here they do not have sql yet and the many sources they get their data from is a little confusing i do not fully have a grasp on it i recieve canned reports through emails that i use to generate a couple reports i am really looking forward to having all of the data within ssms i have been having a lot of down time which i partially blame on a lack of direction but i am also trying to figure out what i can do better with my time thoughts,need advice in new analyst job,how do i go about creating a dashboard for my new job
1050,hi i have some experience in statistical inference and data visualization but it seems i did not learn anything about data analytic reports at all i mean i know where and how to use statistical methods i am good at data wrangling and how and where to use ggplots because i have read many books and articles but i wasam never good to figure out what makes good data analysis report good and i have no idea how to search find books for them such as targeting samples templates etc i have been searching it on google slideshare and other places and i failed to find a good one yet most of them are either related to machine learning approach or too shallow eg do not use pie chart would any one recommend data analysis report books or articles thank you,any good book for data analytic reports,what are some good resources for learning about data analysis
1051,ive been a digital strategist for the better part of my career and adulthood and in an effort to remain relevant and employable i have been toying with the idea of transitioning into cyber security or going down deeper the rabbit hole or so i think of digital strategy by arming myself with data science and analytics skill sets ive registered for a data science certificate course with ryerson university in toronto and thought i get a head start by doing some self study through the course of my research i came across tomi mester where his untold truths about data science hit home he sounds like the real deal but thought i ask some budding data science honchos and aspirants here has anyone taken his course is this guy a good start to sink my teeth in what would be an area to define the rest of my career any recommendations on other portals for a noob like me thank you all,any thoughts on tomi mester from data,data science bootcamps
1052,i have looked a bit into this but i have mostly found white papers and was wondering if i could have a high level representation of how autoencoders are used in feature reduction before i dive deep into it i guess i will start with what i know or think i know autoencoders are used to represent the dataset in that fx x therefore for training it takes x as features and and x as the classification so with that in mind i keep hearing how autoencoders are being used for feature reduction but that does not seem very clear here is what i have tried and my guess and i want to see if i am wrong first you train the autoencoder like anything else so that fx x then you take the layer at the end of the encoding stage where decoding then starts and use the results from the feedforward as the reduced features so an autoencoder is nodesfeature number would look like gt gt gt gt gt gt and the reduced feature set would bet features i have tried this and have had not great results compared with pca that does not necessarily mean that it is a wrong high level view it could also mean more neural network changes needed to be made but before i do more experimentation i wanted to make sure my underlying assumptions were correct,how do autoencoders reduce features,question about autoencoders
1053,i am guilty of spamming this same question to the data science stackexchange and expecting it to be removed there i will pose my problem in this friendly forum i am importing data person records from an external system and want to map their entities to my internal ids persons i have processed before incoming records would include their name and an id from the external system along with context such as an address again with external ids and names ie a textual representation i am sitting on a fairly large amount of manually curated links between previously sent records and what ids they map to in my system i want to exploit that in order to either assign future occurrences automatically or at least come up with relevant suggestions when these assignments suggestions are later approved by humans i would like the system to learn from that imperfections may include everything from missing input data spelling errors in the names to simply wrong external ids i have some background in multivariate analysis and classification and i have worked with fuzzy search in solr but this is new territory for me ampxb i have to distinguish between thousands of persons who i will have seen anything from on to a few hundred times before my gut feeling says this is outside the realm of multinomial classification with eg neural networks or the likes this feels like a task for a search engine like solr or elastic but then i would expect each previously seen recordtoid mapping to be one document which would not allow me to aggregate the knowledge about people i have seen many times in order to increase confidence i have looked into collaborative recommender systems because they too can suggest specific entities based on previously made choices but their feature space does not seem to fit my data i feel like i am missing something,best guess identification of previously seen entities with imperfect data,how to deal with missing data
1054,i am currently learning about nn with the handson machine learning with scikitlearn and tensorflow book i was reading about vanishing and exploding gradients today but i do not understand why the choice of the activation function and how the steepness or flatness affects the gradients here is why when gd is performed the algorithm searches for the weights that minimize the cost function so for that it takes the derivative of this cost function with respect to the weights and finds the direction in which to move in the parameter space in order to find the best weights that will decrease the cost if i am not wrong the cost function is not the activation function so why do we care that relu for example is flat for zlt and that leads to a bad weight choice you cannot escape would not gd work on the cost function instead to tweak the weights and if a neuron is output is far from the real output the cost will be high therefore gd will try to find weights that lower it if the output of the function is because fxw b where fx is the relu function x the input data for that layer w the weights and b the biases but the actual value it should output is then the cost function is the one for which we will compute the derivative in gd to find a new iteration of w not fx is it because if fx is convex then the cost function will be convex as well i am confused,why is the activation function important for gradient descent in nn,why does the activation function of the neural network have such a high cost
1055,i am a cc student transferring fall my options are csumb bs cs or sdsu bs statistics emphasis in data science nothing elite but it will do a concern that i have is that csumb is not super established in cs and a data sciencefocused bachelor is program is a bit nonstandard if you will my target was sjsu cs but that did not happen lol i really do not have an interest right now in any schooling beyond a bachelor is so i am a bit unsure if sdsu is data science would be good enough to get into the field or if i should go the more traditional route and get a cs degree and have more job options overall i might try for a cs minor if i do sdsu as i really do like programming and would like to learn as much as i can but it will probably mean i have to take summer classes if i want to graduate in two years a quick overview of the classes for sdsu and csumb if you do not feel like going through the whole website for each program below i have all of the lower div level requirements done for either program sdsu csumb csumb cs has concentrations in swe or data science but people seem to recommend only doing the swe route that being said i could still take the data science amp ml classes as part of the major electives,thoughts on san diego state statistics data science bs,is a data science masters worth it if i already have a job
1056,i would like to create a complex chart or entries i will be constructing it as i go in a mindmap type way so it needs to be flexibleintelligent in handling big changes or redrawing ie a wouldumb app like adobe illustrator would not be useful will need to export in standard format for large format printing a if it can then export to illustrator once complete all the better i have had a look at xmind and it is kinda what i am after but all the support vids are from and quite useful so not really trusting it just need something that works well i can rely upon can be freepaid post already rejected from techscience subs please help,recommend mac software for drawing complex chartsmindmaps,can someone help me with a project i am working on
1057,i work for a decently sized company k employees b in revenue i am the only web analytics person in the company and i am completely swamped with work there is constant pushback on hiring any new web analysts or for any web analytics related positions but i keep being told how important the data is to our company i do not know what to do i have had bosses in the last years and the newest boss just told me he does not want to hire any more data monkeys it just seems insane to me he is also pushing adobe analytics on me and i worry that getting what little dev resources we get allocated for tracking stories how does ramping up for adobe work i am getting caught up missing meetings because i am double booked people are getting upset but no one seems to stepping back and saying hey we may need more bandwidth to get what we need out of our analytics am i crazy i have worked for smaller companies in the past and am used to being a vital resource wearing multiple hats but this just seems insane,how big are your teams and for what size company,how do you deal with bosses that do not understand data analytics
1058,background a recruiter for a startup reached out to me about a data analyst position after a call with the recruiter they sent me a takehome it had a python part which was pretty straightforward it also had a sqltableau part this part came with three csvs of data not like toy data one was m records they suggested loading it into sqliteonlinecom and using that to test queries and create the tables but thats way too much data to load into a web client i tried loading it into a sqlite db on machine but there are inconsistencies in the csvs that cause it to fail even loading it into python dataframes was problematic difficult data aside the sql questions are fairly vague and the tableau part requires using the tables created in the sql queries to find some insights and then publish a dashboard on tableau public if the purpose of the take home is to test my sql and tableau this doesnt feel designed to do that it feels like an actual project for an actual client that they want me to put together for them look i get that reallife data is dirty and you have to deal with that and in a way this reflects a reallife tasks ive had but ive already spent half a day on this i dont want to spend more hours screwing with data to get it to load so i can do free work for them am i way off base here anyone else have similar experiences,my job candidate takehome feels like unpaid work am i wrong for just saying no thanks,how do you deal with bosses that dont understand your data
1059,hi guys i am working on doing lead gen for a hotel essentially they pay me a commission of the bookings that i bring in i need to show them booking confirmations after the reservation has been done on their site now i know that you can set up adwords conversion tracking such that it records specific transaction amounts for each reservation but how can i set it up such that it also captures the transaction id or confirmation number is that even possible in adwords i know google analytics captures this information but since both these programs track conversions slight differently i depend on adwords data more and need the booking numbers to come from it your help is really appreciated,does adwords give transaction ids for conversion like google analytics,how do i track how many people booked a stay at a hotel through google analytics
1060,need some input or tips in approaching this the problem is to make an offline document form reader that recognizes handwritten digits and uppercase letters only the only thing i am lacking now is the model that can recognize them accurately the dataset i use for training is nist sd minus the lowercase letters and the pretrained model is xception from keras if you know a fastertotrain model readily available in tf and keras with similar or better accuracies in nist sd than this model please let me know too i initially picked xception because of its high accuracy and size compared to the nextmost accurate nasnetlarge based on the sizesimilarity matrix in this site my problem cleanly falls under q but according to the same website it will need a lot of computational power so i was thinking of instead doing the q strategy as i am only using a laptop however this would take a toll on the model is performance i think also i have found no tutorials on training the pretrained model from scratch q is it because it is the same with making a model and just training it how about q i also have some questions regarding setting up the model what does include_top mean does it mean the input layers of the model or the output what pooling parameter should i supply in my problem it can be optional and it can be either max avg or none since the digits and capital letters total to classes i needed to provide classes based on its description i would then set include_top to true and set weights to none uh right this basically means i have to do the q approach and retrain the model from scratch right thank you for any input or tips you can provide,help questions on training a pretrained model on a very different dataset,how to train a cnn to recognize handwritten digits
1061,we have a woocommerce ecommerce website setup with ga advanced ecommerce tracking and are looking to get a centralised reporting or mi tool that allows us to produce reports that include external data like cost of sale so we can look at things like profitability on each marketing channel as well as drill down to some basic sell thru report type information eg we sold product a using a discount code and spent y on marketing and the grossnet profit is z to help guide strategy on driving profitability not just revenue we can upload advertising cost data into ga from tools like adwords and bing facebook ads but for some transactions the products are sold offsite ie on voucher sites and the coupon is redeemed onsite and thus the transaction value is ga is this causes problems with trying to report on profitability and cost of sale information i am looking to investigate different ways of solving this issue as im not sure ga is the best way without potentially overriding information or creating custom dimensions what products should i be looking at that can help with this problem maybe commission a bespoke reporting tool and apicsv upload data too,ga and multiple source cost data other options,how do i track the impact of a marketing campaign on sales
1062,i am searching for a talented data scientist to join my group at a leading biotech company in cambridge ma the position will involve working on a variety of challenging problems that will help progress the scientific platform of the company as a whole as well as individual therapeutic programs i have a full job description but in short i am looking for a phd level candidate with rocksolid data modelingmining biostatistics python and other and communication skills message me if interested and qualified apologies if it is not appropriate to post a job listing directly to this subreddit but it seemed the obvious place to start please let me know if i need to modify move delete this post,hiring data scientist biotech in cambridge ma,i am a data scientist looking for a mentor
1063,hi everyone sorry if this breaks the rules or anything im new here my question is what might be the best course of action to be successful as a data scientist i just graduated in may with a degree in mathematics and a minor in economics ive been really close to finding jobs but havent been able to secure a final spot even though ive had close to final interviews im getting really distraught sad for not securing anything and im considering going back to school i looked at mostly data analyst roles with mathematician position at a gaming company i had one internship but i guess thats not enough for many places to hire i am great at putting work in to my studies i had a final gpa not trying to sound like a douche js i took school pretty seriously can do just about everything in excel and have been slowly learning python amp sql if i were to go to grad school for data science would there be any tips going forward for what to review whether its having a degree of coding knowledgeexpertise classes taken resources to use etc sorry if i sound like an idiot im looking for any help at the moment,foundation for success in data science,i am about to graduate and i have a few questions
1064,i am about to graduate in a month and have no experience but love ml and everything related to it rn i am doing my research paper related to nlp and ml i have taken all courses needed to form a good basis in ml during my undergraduate degree that includes univariate and multivariate calculus linear algebra statistics probability operation research numerical analysis and discrete mathematics other than that i am good at data structures algorithms and oop i have been programming for the last years and have a good understanding of almost all languages and frameworks and do understand ml algorithms from a theory point of view to not just black boxing ampxb i wanna know if my resume is good to get me intern or not and what do you think i should do more to make it stand out also i am open to any advice that you think might help me in my career in ml and ds i been told my resume is way too detailed and need to be very short and to the point ampxb ps i do know i am not good enough but so your advice will be highly valuable to me thank you,resume review entry level data scientist ml related position,i am a year old and i do not know what to do with my resume
1065,hi very niche question here but i am not sure where i can ask pointers to another subreddit would also be appreciated ampxb ok so i am not american and i am trying to understand how the american census type data from the acs works total newbie about it i pulled the data for massachussets from the acs website here ampxb but i am more specifically interested in the greater boston msa aka the bostoncambridgenewton manh metropolitan statistical area now i would like to know what are the pumas public use microdata areas for this specific msa so i can extract only data for this region from the dataset my problem is i am unable to find that information anywhere ampxb i can find the names of the counties that are part of the msa on wikipedia and try to get the list of pumas from this names reference pdf page ampxb but a lot of the names in there are ambiguous and i would prefer to have an official list than guessing from a wikipedia page i was able to find a list of fips place codes for the greater boston msa but as i understand it fips and pumas are not convertible into each other ampxb it looks like this website manages to do it though so i assume this information is out there somewhere ampxb ps i realize will probably need to pull data for nh as well,acs data what pumas are in the greater boston msa,looking for public data sets for the us decennial censuses
1066,hi all so i recently got quite a good job offer from financial company job is junior data scientist right now i am working as some kind of data analyst as you may call it my current stack is python sql and power bi stack in new company is far more advanced although i can cover the ml stuff as i am working with ai on university i was wondering about bi tools they are using they said that they are using tableu and alteryx instead of power bi as far as you know is there any significant difference between those two and power bi and if it will be easy for me to switch maybe any advices thanks in favour,switching bi tools,data science vs business intelligence
1067,i have about different datasets that each have their own characteristics though unique each dataset is a member of one of five larger categories i have run ordinary linear regression calculations on each dataset and have an rsquared for each dataset i can calculate the mean rsquared for each category which gives an estimate of how useful linear regression is for that category i am looking for advice on how to best visualize this i could just do a histogram of category vs meanrsquared but i was hoping for something a little flashier i am a dba who is new to data science so if i did not use the correct terms i would happily take feedback,help with visualization for showing the mean of rsquared for different categories,how do i calculate the correct distribution of features
1068,hello guys i was wondering if there are communities or subreddits where it is possible to find or form teams to compete on kaggle or join other competitions i often try to do some competition for fun to improve my skills but having no realworld experience with data science problems i am a ml engineerdata engineer i quit after facing issues with the steps where i am weaker preprocessing and model improvents through iteration most of the time and the parts where i am stronger code quality robustness automation productization are never put to use then i thought that joining a team would be a great idea to bring my skills to the group and at the same time share the burden of bootstrapping a solution and iterate over it but i have no idea on where to find such a team i know many people with a skillset comparable to my own but almost nobody that has experience on practical data science i am also thinking about starting a meetup for this purpose but i would like to know if there are alternatives,ml competitions fun open teams is there such a thing,looking for a mentor
1069,hi background i am currently doing my first semester at stellenbosch university in south africa i love austria and switzerlandgermany too and my dream would be to live there one day so with the eventual goal of immigration in mind i have to pick between two options i aim on working in the financial sector but with a strong data sciencemachine learning approach to topics such as business analytics and financial management the first being continuing my degree at stellenbosch and then aiming to do a masters in austria i have no idea how difficult or easy it is i always met by an it depends i do however think it might be possible however it might be easier with a degree from austria although i am not sure benefits are it is convenient that is debatable more in line with what i want to do more finance modules it is secure i do not have to worry about depression etc i have a good social network and it is really fun to live here just dangerous and frustrating link page the second option is studying artificial intelligence at the jku i am leaning more on this side for some rational but also some subjective reasons the rational reasons being that successfully completing this degree allows me to emigrate to austria and live there if i can find a job which i think should not be a problem without even having to do a masters then secondly although a might be wrong i think it would be easier to carry on with my masters in austria after having done my undergrad there perhaps even at the same university thirdly i might have a better standing in the job market having lived in austria for so long and having my undergrad from austria i can after my bsc in ai continue on to do something like a cfa or a ma in banking at finance at uni wien link kuss link i have given this a lot of thought but still i am very confused i would really appreciate help,bsc in ai or bcom mathematics,is it worth getting a masters in data science if i already have a job as a business analyst
1070,i am a data analyst for the environmental agency for my state in nutshell i find insights in related to air quality and pollution as they pertain to bringing areas into compliance with the clean air act tools that i use are r python sas qgisarcgis some excel and powerpoint i am not stranger to data wranglingcleaning webscraping collecting data from various resources automating tasks and creating markdown files for presentations i feel that i am well versed in the process i want to open doors for maybe cooperate role as as data analyst and what concerns me a bit is have just some exposure to advanced excel data visualization other than ggplot in r and sql sql is not required to pull data at our agency because we have a few user interfaces to work with our data bases i am really not sure what i should do to maybe cover these bases there is a lot of free sources out there that cover some of these topics but not sure how to go about it i have considered taking google is data analytics cert another piece of info is that i am planning to go to grad school this fall hopefully georgia tech or ut austin but this is longterm commitment ampxb at my agency i always volunteer for all scripting jobs or interesting analysis to keep me learning but i am unsure what i can be doing outside of work to open up new opportunities as an analyst tldr what should i cover as an analyst given what i know to branch out to other roles such as analyst in cooperate setting,currently a data analyst a bit concerned at the next step in my learning need guidance what should i be doing,data analyst to data scientist
1071,hello all firstly thank you very time for your time and checking my post i am new to data science and confused on what should i learn next i highly appreciate your responses tldr learned python pandas numpy matplotlib and seaborn and sql moderate proficiency in both should i go ahead and learn machine learning or spend more time with python until perfection and learn data structures and algorithms course long version i am an aspiring data scientist i do not have a computer science degree i have been trying my best to self learn python and sql for the past year i started with python and sql and learned the basics and learned how to do data cleaning then i learned pandas numpy matplotlib and seaborn libraries and learned data cleaning and visualization with these libraries i practiced a lot of coding questions however i am still at intermediate level with python and sql i learned enough to perform exploratory data analysis through pandas numpy matplotlib and seaborn libraries i never formally learnt data structures and algorithms that most cs grads would know my question is should i go ahead and start learning machine learning or should i spend more time in learning and perfecting python and learning data structures and algorithms,self study suggestions please answer,how to learn python for data science
1072,i am implementing a unet model for nuclei segmentation the model is working fine and the segmentation was successfully done however i want to save the contours on a json file to properly load it in a web app ampxb here is my original image enter image description here ampxb and here is the corresponding predicted mask enter image description here ampxb i tried to use findcontours on the mask but overlapped cells would be recognized as one note that overlapped cells got that green boundary to differentiate nucleis ampxb what i want is to get the coordinates of the single nuclei contours and save it as a json like this ampxb _jpegfilename_jpegsizeregionsshape_attributesnamepolylineall_points_x all_points_yregion_attributesfile_attributes ampxb this is my predict function where i save the mask of each imagetopredict ampxb if __name__ __main__ t timeitdefault_timer args_models best_resnet__foldh weights ospathjoinargsmodels_dir m for m in args_models models for w in weights model make_modelargsnetwork none none printbuilding model from weights formatargsnetwork w modelload_weightsw modelsappendmodel osmakedirstest_pred exist_oktrue printpredicting test for d in tqdmlistdirtest_folder final_mask none for scale in range fid d printpathjointest_folder formatfid img cvimreadpathjointest_folder formatfid cvimread_color if final_mask is none final_mask npzerosimgshape imgshape out_channels if scale img cvresizeimg none fx fy interpolationcvinter_area elif scale img cvresizeimg none fx fy interpolationcvinter_cubic x y x y if imgshape x int imgshape x imgshape x x x if imgshape y int imgshape y imgshape y y y img nppadimg y y x x isymmetric inp inp for flip in range for rot in range if flip gt img img else img img if rot inpappendnprotimg krot else inpappendnprotimg krot inp npasarrayinp inp preprocess_inputsnparrayinp float inp npasarrayinp inp preprocess_inputsnparrayinp float mask npzerosimgshape imgshape out_channels for model in models pred modelpredictinp batch_size pred modelpredictinp batch_size j for flip in range for rot in range j if rot pr nprotpredintj k rot else pr nprotpredintj k rot if flip gt pr pr mask pr mask lenmodels mask maskymaskshape y xmaskshape x if scale gt mask cvresizemask final_maskshape final_maskshape final_mask mask final_mask if out_channels final_mask npconcatenatefinal_mask npzeros_likefinal_mask axis final_mask final_mask final_mask final_maskastypeuint cvimwritepathjointest_pred formatfid final_mask cvimwrite_png_compression elapsed timeitdefault_timer t print notime f minformatelapsed ampxb ampxb do you have any idea how to get the coordinates of each classified nuclei the json part should be easy but i do not get how can i get the countours coordinates should i do it after the predicted mask is written or should i do it on my predict process ampxb kind regards ampxb,get the contour coordinates in a final predicted mask,i am trying to train a cnn on a single image but i do not have any luck
1073,this post is reproduced from zhihu and translated using deepl for all enthusiasts to communicate i have been writing samples for the past few days mainly referring to the pytorch implementation and inevitably encountered some problems caused by the differences between static and dynamic graphs again in addition mindspore has recently made some progress on static graph syntax support but the ease of use is not so obvious which triggered the impulse to write this article since it is a random thought there will be no structure so i wrote it wherever i thought of it supernatural dynamic graphs obsolete static graphs from the emergence of pytorch to the present the userfriendliness of dynamic graphs i believe no one will have any questions freedom of writing debugging convenience code that is the formula of the cool the toiling public who have been suffering from tensorflow for a long time are looking forward to it and the students who want to start deep learning with a low threshold are also looking forward to it to some extent the lowering of the ai threshold and involution is actually accompanied by the popularity of dynamic graph frameworks i personally do not use many frameworks in depth because the beginning of the ai years have been keras and then pytorch open source has been using pytorch later i also had a shallow taste of the old version of paddle as well as mindspore since pytorch has been eating up tensorflow is share step by step and then tf has shifted to eager mode across the board and as dynamic graphs continue to gain popularity the concept of dynamic and static graphs is in fact little known among most people engaged in ai perhaps i am just ignorant looking back at these several domestic frameworks unfortunately whether before or after the birth of pytorch most of them have taken the tflike route and then desperately trying to make up for it it is been now and there are still people experimenting with static graphs in fact we all vote with our feet when i write a bit of wrong code the c stack overflows when i want to change a model but also need to pay attention to the syntax restrictions when i want to manipulate the gradient but to go around to complete when i want to write a brand new layer but have to care about how to write the code of control flow each of the above is a reason to stay away from static graphs when i tried the old version of paddle this is how i was discouraged even with the free v gpus i really cannot carry this learning threshold later mindspore encountered the same problems even if the morphology has been optimized a lot dynamic and static graphs really need to be unified so mindspore is playing the slogan of dynamic and static unification and is practicing it physically in the current environment of mainstream motion pictures it is still worth a compliment to be able to motivate a group of people to use it but we also face the dilemma of migrating after the experiment is completed with pytorch back to the topic do dynamic and static graphs need to be unified in terms of mindspore is practice it is to let the compiler gradually support the full python syntax and then translate it to computational graphs and send it down to device for computation pytorch has been criticized for being too flexible and then difficult to deploy although there is now a good deployment path with onnx as an intermediate ir the common perception is probably that dynamic graphs are suitable for academia and static graphs are suitable for industry dynamic and static unification from an ai fullscene perspective the first thing to clarify is that the full scenario mentioned here is not the same thing as the one advertised by hw the full scenario of ai must cover scientific research moreover the development of the whole ai field is probably like a coin pusher constantly throwing coins in quantitative change triggers qualitative change and then a milestone piece of work appears and drops a bunch with a clatter and only after that these milestone models will be enshrined by industry and deployed everywhere obviously the full scenario of ai is research deployment with the former being versatile and the latter being stable that is why there are numerous inference engines but not many make training frameworks the success of pytorch is then best explained by the fact that it responds to the needs of the people who use it the most rather than focusing only on the almost stable and customized deployments in industry so following the trajectory of this ai field to see the role that deep learning frameworks should play it probably looks like this satisfy the need for a magic model for a large group of scientific people support or even derive a new milestone model support the export deployment and largescale application of milestone models looking at the matter of dynamic and static unification again the dynamic graph is unstoppable and the inevitable choice for the scientific research scenario static graphs are more suitable for exporting and deploying models generated by scientific research the industry frameworks seem to be choosing to let one side gradually approach the other i think the gap between the two is better to be bridged by something rather to be forcibly eliminated in other words people are not very resistant to secondary code modifications when exporting models and deploying them and a oneclick export is good but adding a conversion is not unacceptable so training using pytorch then exporting as onnx for deployment is not a bad choice a few thoughts on mindspore static graphs as defaults will not appeal to the research crowd static graph syntax cannot and does not need to support the full range of python syntax as a framework with almost optimal support for static graph syntax it should actually encourage users to use dynamic graphs first until they need to deploy the model of people do not at which point the compiler should give enough guidance information to guide modifications to the model the modifications here are nondestructive to the model in industrial training scenarios using static graph to train milestone models have enough impact at this point the model is fixed and more stuffed with data static graphs can be exported directly for deployment so a more reasonable approach should be dynamic graphs as default static graphs for deployment requirements guidance provided for compiler errors static graph training export the biggest advantage of mindspore is that it is compiled by way of ast parsing and this tool that can bridge the gap i found it to be an almost faultless process from the time i came across mindspore later mindspore changed the default mode to graph mode looking at the people using static graphs painfully i thought why bother summary finally a few more words few people can answer the question why should i use mindspore when i have pytorch if the above approach is implemented the reasons i could give would probably be something like freedom of science how free pytorch is to write models and how free it is to use me seamless deployment no need to convert for deployment just convert to static graphs according to guidance finally in fact quite want to spit a few more words still hope that no matter what deep learning framework is it can be honest about the fact that it is a tool rather than core respect ai science respect ai researchers that is all,a little thought about the unification of dynamic and static graphs,what is the best free graph library for pytorch
1074,i have been interested in machine learning for a long time now and i made a self pact to learn going through countless youtube videos questions on reddit and quora i came up across many different viewpoints on how to begin i picked up a python machine learning book a few months back but soon realized that i needed the math to learn properly so i dedicated months of my time to learning all the math and now that i am finally ready to really understand machine learning im hoping you all can provide me with a good course or book that could teach me the concepts well instead of just applying libraries in python any recommendations,help with machine learning,what are some of the best resources to learn about machine learning
1075,i started a ds position monts ago today i had an informal presentation where i introduced an object detection system detectron to my team and i am a bit frustrated the level of expertise of my team including me is not too high in ds dl or ml so my role is that of the person who studies understands and explains models to the senior developers who are trying to break into ds field i really worked hard during past week but i have the feeling that i was not able to transfer all the knowledge to my collegues i could not answer some question and i think that my boss is not completely satisfied i think one of the problem is the mathematical and statistical complex of the models metrics evaluationsetc sometimes trying to understand everything can take months and even working hard it is always something that you are not able to anwser i would like to know how do you face with this complexity how do you prepare your presentations in which you have to explain models and mathematical concepts in understandable way and where do you focus when you have to understand a model the architecture the training process the evaluation process thank you,dealing with complexity,how do you deal with bosses that do not understand your work
1076,hi all i am currently interning as a data scientist so far the work has involved very little machine learning or much of any work tbh are most data science jobs like this should i be looking at other industries that do more machine learning it does not even have to be deep learning albeit that is neat too but it would be nice if it could be something other than just oh we have literally any data set and we need to solve literally any problem i will only accept linear model do not worry about the choosing features we can do that later on one hand as an intern it is not my responsibility to select models or whatever i am also only getting paid quite crappily hourly with no overtime so it is not exactly in my best interest to spend all my time on this on the other hand if this is how data science i am really concerned how can i get involved with some more technical where would i even find those jobs what should i search for them or is this feeling just because i am an intern for reference i am a math phd decent coder and familiar with the usual machine learning things esl andrew ng is deep learning series slowly working through the deep learning booketc and diving deeper into the reinforcement learning literature following this and his sequel so it is not like i am some random lol i took one udemy class and now i know everything person,machine learning heavy jobs,is it worth getting a phd for data science
1077,as a new graduate engineer i am struggling to find my first job in data science and machine learning field i relate this not to the lack of skills but to the lack of professional experience as i only have done one internship in the data science field now due to the actual world situation it is clear that i will not have a job in the shortterm i want to profit from the free time i have to improve my cv and increase my chance for being called for interviews ampxb i do not know if there is a possibility to make a new professional experience while being confined in my room for at least a month actual restrictions here in europe such as remote internshipjob for free or contributing to some open source projects related to data science my aim is to add a new professional experience in my cv because i think it is the main component i lack on my cv ampxb so you experts in data science field what can you advise me to invest my time on in the shortmid term until we overcome coronavirus crisis in order to get my first job ampxb ampxb i have already thought about few paths but i do not know which one to focus on enroll in new online courses to learn new skills and get certificates improving my github profile by writing documentation of my repos doing new data science projects and writing about them in a blog remote workinternship for someone for free to get new professional experience btw do you need a data scientist,how to improve my data science cv to get my first job investing free time given by coronavirus restrictions,what are some of the best free online courses to learn about data science for someone new to the field
1078,hello i have an interview for a role on monday and part of the interview includes a one hour assessment of a dataset which i will not see until the start of the interview however i have a general overview of the assessment specifically the task is to determine the best way to proceed with marketing a key product to customers the dataset i will receive will be based on a previous campaign that was done and this is to be used to produce a model i appreciate that the question is somewhat hypothetical but any advice on what type of task this might be ie regression classification i have been preparing on the idea that i think it will be a clusteringcustomer segmentation the tldr would be how would you model a marketing a product to customers any and all advice would be welcome and appreciated,interview preparation advice,how would you approach this problem
1079,i am a computational biologist currently a part of data science team i do not know extensively about data science but have learned in bits and pieces in my coursework and by self genomics and bioinformatics heavily utilise this now to my question my current organization is setting up a lims laboratory information management system they expect me to take up a role of data engineeringdata science ik these two are different but i do not have the complete skillset the end expectation from my end would be to have a dashboard of key performance indicators this will come from interacting with different departments and merging the data or retrieve it what questions should i ask myself others what set of skills i need i know python r basics of sql i know dashboard systems that exists how do i help to setup though i do not know much i am willing to learn and contribute as it is my personal interest the workflow is in place i know some kpis but still i feel lost or not having enough depth to understand,data engineering lims,how do i go about learning data science
1080,here is a pic of how the data table looks after importing into pythonpandas from a pdf i am basically trying to get all the variables on the row side market letter to a column while keeping the data it describes intact since i am importing from a pdf i have no idea how with this structure for example i need a column labeled as market a column as letter so market will have a data point for each letter for each quarter again since it is pdf and all the data is there i need to keep it in tact if that makes sense i am not sure how to do this using melt or pivot somehow i need to swing the variables to columns and observations rows and i am lost at how to do it with this format any python data science experts care to weigh in ignore the summary garbage i am deleting it,help getting dataset imported via into tidy data format,how do i deal with missing data
1081,i have two sites a marketing site and an app on a separate subdomain the signup flow looks like this someone comes into the marketing site for example they sign up on a subdomain for example conversions are firing as expected but i am losing the referral path i have added mysitecom as an excluded referral for both the marketing site and the app some other details these are two different properties with two separate ids under the same google account so the marketing site has id uaxxxxxxxx for example whereas the app has id uaxxxxxxxx does this matter should they be the same here is what the code looks like on the marketing site ltscriptgt functionisogramigoogleanalyticsobjectririrfunction irqirqpushargumentsirlnew dateascreateelemento msgetelementsbytagnameoaasyncasrcgmparentnodeinsertbefoream windowdocument iscript gacreate uaxxxxxxxx auto allowlinker true loads the linker plugin ga arequire linker instructs the linker plugin to automatically add linker parameters to all links and forms pointing to the domain appmysitecom galinkerautolink appmysitecom ga isend pageview ltscriptgt the code inside of the app is sent through a library so not a standard implementation but here are the relevant parts var googleid windowmyenvgoogle_tracking_id function isogram igoogleanalyticsobject r ir ir function irq irq pusharguments irl new date a screateelemento m sgetelementsbytagnameo aasync asrc g mparentnodeinsertbeforea m window document script ga gacreate googleid auto allowlinker true garequire linker garequire displayfeatures gaset appname my app if windowmsenvalpha galinkerautolink mysitelocal else galinkerautolink mysitecom gasend pageview i appreciate any help this has been driving me crazy for over a week now,google analytics need help passing referral path in crossdomain tracking,google analytics not showing up in analytics
1082,i posted over in rlearnmachinelearning but no one answered so i am trying on here before i try rmachinelearning here goes my question i have a dataset of images along with some other information that describes each image in the dataset my objective is to conditionally generate this auxiliary information from new images after trying and failing with many different models i finally found that a simple vae is capable of modeling this auxiliary information and i am capable of sampling from the distribution the vae learned very well but that is only half of the work next i would like to condition the vae on these images such that i can generate new samples from the distribution based on a condition image for example if you would train a vae to generate new images from mnist and you want to generate a specific digit you would have to condition on the class label what if i want the condition to be the image itself my hunch is that this would be more tractable if i first represent the images as a latent vector feature extraction and then condition on that vector how would i go about creating meaningful vectors should i train another autoencoder on my dataset that just learns to encode the images that way i could condition on the latent vectors that the ae learns or would it be better to use a pretrained model sorry if my question is a bit vague about what i am trying to model but for the sake of my laboratory i cannot reveal too much thanks for any pointers and if anything needs clarification ask me,conditioning a vae on an image the image itself is the condition,how to generate a latent condition vector from a vae
1083,hello i will be teaching an upper level th year and msc course in data science this fall at a canadian university i would like to get some opinions on what you believe are the most important concepts that i should try to convey during this course the students have a basic programmingmath background proficiency in some objectoriented language knowledge of basic calculuslinear algebra my objective for the course is that the students obtain a strong base in machine learning and statistics as they relate to data science both from a mathematical and programming perspective to this end im wondering the following are there any specific visualization toolsapis that could be useful for conveying data science concepts ie things that would allow them to visualize machine learning algorithms such as clustering through gradient descent to gain an intuition for how the algorithm works which textbook would you recommend which mathematical exercises are most important for developing a strong data science intuition how much of the course should be theoretical equations on board proving correctness etc and how much should be programming based working with real data are there any specific data sets that could be used throughout the entire course to gradually work up to more and more complex applications while maintaining some familiarity with the dataset at large ie a dataset that is useful for illustrating both basic and advance concepts what programming language should the course be taught in right now i think the obvious answer is python but im open to other suggestions thanks,tips for teaching upper level undergrad data science course,what should i be teaching during this course
1084,hi everyone a master ai student here i bought a really wellequipped machine still waiting for delivery and would like to know what recommendations there are from the community regarding software especially for the operating system i would like to install a flavor of linux what would you recommend i have tried pop_os lately but was not happy with the ui also i would like to avoid compatibility issues with cuda i have worked on an old macbook pro for the past few years and used colab for my experiments since i have always worked with anaconda and use pytorch that is sorted out is there a guide for anaconda etc you can recommend that can help me set up the box anything i should be awareof tips tricks of the trade,setting up a new deep learning machine any tips from the community,is it worth buying a pc with a dedicated gpu for deep learning
1085,i started a new data analyst job a couple months ago i was under the impression based off the job description and interviews that i would get to use sql even my first week i was told they were going to get me sql access fast forward a couple weeks and they finally ask the it vp he says no and my management team has not really been pushing it because of the fight it requires so essentially i am stuck asking for reports from another coworker who does have access i was asked to create a report by a higherup and told them i was going to have to ask someone else because i did not have access they looked pretty disappointed i am no expert in sql yet i have used it a little bit in previous jobs learned it in my current program and have taken a couple classes i have been looking at senior data analyst roles to understand what i need to know for my future career path and a lot of it centers around work experience with sql would you quit your job if they refused to give you access to sql,would you quit your job if you were not allowed to use sql,how do i go about getting a job as a data analyst
1086,hello i am a freshman who is majoring in cognitive studies i will be taking a lot of psychology and psychogyrelated classes however i also plan to minor in scientific computing which will hopefully give me a solid cs background and quantitative methods which i hope will give me a solid statistics background i am absolutely fascinated by the field of data science and i still have so much more to learn about what the field even encompasses do you think i am preparing myself well in college based on my majorsminors and the set of skills i hope to adopt lt to go to graduate school in hopes of becoming a data scientist that is d any books you recommend on this subject i find lots of different information online thanks for reading ampxb more information on said majorsminors cognitive studies emphasizes an appreciation of the scientific method and the research process scientific computing quantitative methods,college gt data scientist need advice,data science as a career
1087,if you liked the x nerf speed up from a month ago you definitely will love this fresh new way to train nerf x faster proposed in a paper by thomas mller and the team at nvidia that utilizes a custom data structure for input encoding that is implemented as cuda kernels highly optimized for the modern gpus specifically the authors propose to learn a multiresolution hashtable that maps the query coordinates to feature vectors the encoded input feature vectors are passed through a small mlp to predict the color and density of a point in the scene nerfstyle how does this help the model to fit entire scenes in seconds lets learn full summary blog post instant nerf arxiv code subscribe to casual gan papers and follow me on twitter for weekly ai paper summaries,how to train a nerf in seconds explained instant neural graphics primitives with a multiresolution hash encoding minute paper summary by casual gan papers,r nerf explained in minutes
1088,hi guys i posted a question over on rhomeworkhelp but i thought maybe the people over here would be able to help too i will paste it here so you do not have to follow the link any reference for understanding likelihood functions and error functions would be greatly appreciated btw gt for a binary classification problem with t in and output y which represents ptx if there is r probability that the label on a training data point is incorrect what is the likelihood function data is iid i am going to get an error function from this but i do not understand likelihood functions very well any recommended resources i can look at after this problem thanks everyone gtedit more info on my progress i am thinking it is a bernoulli distribution something like ptxwyxwt yxwt w is weights since this is a machine learning problem i am thinking that r probability of incorrect labels would be multiplied by t in the exponents does not feel quite right though,likelihood function for binary classification with some incorrectly labeled data xpost rhomeworkhelp,question about overfitting in keras
1089,i am reading this paper and i am having issues understanding it it says gtin this paper we present a multiclass embedded feature selection method called as sparse optimal scoring with adjustment sosa which is capable of addressing the data heterogeneity issue we propose to perform feature selection on the adjusted data obtained by estimating and removing the unknown data heterogeneity from original data our feature selection is formulated as a sparse optimal scoring problem by imposing norm regularization on the coefficient matrix which hence can be solved effectively by proximal gradient algorithm this allows our method can well handle the multiclass feature selection and classification simultaneously for heterogenous data and i have a question what is norm regularization is it l regularization or both l and l regularization i am trying to figure it out how the process works,i need help understanding a paper,how to deal with outliers in logistic regression
1090,hi i am looking for some career advice because i do not know many data analystsscientists outside my team for background i am a yo hr data analyst in a federal agency with fulltime employee benefits i only started two years ago after finishing my masters program in international economics considering that i pivoted from the nonprofit sector the pay and worklife balance in this new job are better than anything i have ever had next year when i hit my year mark i will be paid kyear with weeks of paid vacation but i am afraid the work is not challenging enough we are an entirely excelbased shop and our analytics do not go much deeper than a few pivot tables and bar charts i have learned enough python in my spare time to automate my monthly reporting calls and most common adhoc requests so i might be working hours each week because our data architecture is so old most of my actual work time is spent exporting csv files from our database and saving them as the import code for my jupyter notebooks sql is not used or supported by our database vendors and while we are about to launch power bi dashboarding will be new to our team though bc we have no sql these dashboards will be built on excel workbooks currently this job will cap out at k if i stay forever with small increases every year as inflation adjustment and if i want to make more than that i need to find a new job i think at some point i will want to leave for a faanglike senior analytics or data science role that offers better comp and has stronger data pipelines to prepare for this i am trying to punch above my job description is weight i am learning sql in my spare time i have experience with inferential stats through my grad school studies and i am building reports that use the basics like linear regression i already have a lot of experience with power bi through grad school and i have practiced my pandas skills by building jupyter books for others my question for the sub is am i a complete idiot for wanting to leave i know for a lot of people this is a dream gig but for the sake of my career i feel like i would have better longterm returns if i used this time to build skills and transition to an analyticsdata science gig elsewhere is there anything i should be aware of if i want to transition from the public to private sectors,career advice golden handcuffs in the federal government usa,is it worth taking a paycut to pursue data science
1091,i read from time to time on some papers that you should always start with a simple model and check if it can completely overfit data then you could add some more layers or bigger kernels to try and find more complex features and get better validation accuracy unfortunately i cannot recall the exact papersguides where i found this tip and what they said but i am pretty sure what i described is close to that do you guys apply this method when you are starting a project with new data at what point do you say ok stop i have xx accuracy and yy loss i cannot overfit more than that in general what is your workflow when building a new model,overfitting questions regarding dl,how do you deal with overfitting
1092,i work for a big tech company and told them i would like to transition to data analytics they have given me my first assignment and doing it well would accelerate my transition the question they want answered now is is this specific failure responsible for missing quoted deadlines i plan to answer this by looking at the previous cases and finding what percentage of missed deadlines are due to fail events and what percentage of the failure events are due to different error codes for context i will include cases that meet the deadline and calculate the same percentages i will probably use simple pie charts to represent the numbers if possible i would like to give them more information from the data provided and visualize the data well anybody could calculate percentages i want to do something to encourage them to keep bringing me these assignments it may be overkill but i was thinking of running a regression as well in order to give them more than a yesno maybe that failure is only responsible for missed deadlines within x types for example i do not want to be irritating and give them way more information than they asked for but i would like to capitalize on the opportunity they are giving me the information i have case id type time quoted actual time variation between quoted and actual time passfail related to the part of the process i am looking at failure code if failed thanks,i have my first data related assignment at work advice appreciated,how do you deal with missing data
1093,for more background information im a college junior whos interested in the data science field any background information would be nice ive heard this description of the job which really enticed me a programmer who is too skilled in statistics to be just a programmer or a statistician who is too skilled at programming to be just a statistician i really like computers and programming i really like statistics just kind of made sense to me so ive taken a lot of interest i posted something very similar on rstatistics and was told that this would be the place that could give more informative answers im planning to go into a basic data analysis job and then transition into something with more computer programming like data scientist what is the best route to do this should i get a major in statistics minor in cs then work to gain experience then go back for statistics mastersphd should i go for a major in computer science minor in statistics then go for a mastersphd in computer science im not exactly sure how statisticians are able to gain mastery of both statistics and computer science i definitely want to do both but what is the best way to gain knowledge and mastery of computer science in college thank you for taking the time to read and answer this,what college majors or disciplines should i do to go into data science,how much statistics do you really need to know for data science
1094,i know a professor in the ee department that does research towards big data analytics none of the courses in the department teaches data analytics we do have a machine learning and pattern recognition course i can take but that is about it will it be more beneficial to find a good program at a different college in applied math i am worried that even if i receive my phd in ee and do research in data analytics i will not be a strong candidate compared to people in the math department who have their phds in statistics or should i get my phd in mathematics and statistics to better maket myself in industry when doing ml work or get a phd in computer science does it inherently matter at the end of the day,doing data science in ee department good idea,is a phd necessary for data science
1095,realesrgan overview while there are many blind image restoration approaches few can handle complex realworld degradations yet realesrgan by xintao wang and his colleagues from arc tencent pcg shenzen institutes and university of chinese academy of sciences takes realworld image superresolution sr to the next level the authors propose a new higherorder image degradation model to better simulate realworld data this idea together with an improved unet discriminator allows realesrgan to demonstrate superior visual performance than prior works on various real datasets motivation classical degradation model which consists of blur downsampling noise and jpeg compression is not complex enough to model realworld degradations models trained on these synthetic samples will easily fail on realworld tests the goal of this work is to extend blind sr trained on synthetic data to work on realworld images at inference time hence a more sophisticated degradation model called secondorder degradation process is introduced to compensate for the larger degradation space the vggstyle discriminator is upgraded to a unet design additionally spectral normalization sn regularization is applied to stabilize training read the full paper digest or the blog post reading time minutes to learn about the downsides of the classical degradation model how a higher order degradation improves the superresolution quality how to fix ringing and overshoot artifacts and why a unet generator with spectral normalization stabilizes training meanwhile check out the paper digest poster by casual gan papers realesrgan details full explanation post blog post arxiv code more recent popular computer vision paper breakdowns gtsimsiam gt gtvitgan gt gtbyol,realesrgan training realworld blind superresolution with pure synthetic data by xintao wang et al,research paper explained in minutes why reales gans are superior to image degradation
1096,i am a studentdoctor of pharmacy learning the ways of data science and want to start some ml projects to build my portfolio and learn through the process can anyone please provide some problem statements worth solving specifically in the healthcare domain i want to start with basics without the use of deep learning nlp and image processing so the projects need to be simple which then might lead to a capstone i have some ideas of my i would like your suggestions on these topics outbreak prediction classifying stages of disease based on various underlying parameters recommending clinical trials to doctors for particular patients reducing hospital stay and readmissions predicting risk of metabolic and cardiac diseases predicting readmissions for patients suffering from chronic diseases how much money will a patient cost the government healthcare system his own self and how can it be reduced i would appreciate your councelling on these topics and the main question of what else can be done and are these feasible project ideas,new ideas for ml healthcare projects portfolio and capstones and advice on my ideas,looking for clinical datasets for a portfolio project
1097,guys i have posted the question on stack overflow so i will link it here not an optimizer instance error ampxb the full text ampxb i am using tensorflow with the standard dnnclassifier estimator it seems that the optimizers in tfoptimizers are not instances of the optimizer expected by the classifier ampxb i have already used tfoptimizers and the new keras implementation at tfkerasoptimizers and get the same error even using the estimator call as a lambda function still returns the same message lr tfoptimizersschedulesexponentialdecay initial_learning_rate decay_steps decay_rate optimizer tfoptimizersadamlearning_ratelr classifier tfestimatordnnclassifier feature_columns n_classesdftargetnunique optimizeroptimizer classifiertraininput_fnlambda df_to_dataset train batch_sizebatch_size steps everytime i execute i get the same message does not matter which optimizer i choose ampxb the given object is not an optimizer instance given lttensorflowpythonkerasoptimizer_vadamadam object at xffdadagt,need help tensorflow problem with optimizers,why does my caffe not work
1098,i am years old and recently graduated with a bachelor is degree in economics from an average school with bad grades i would consider myself a novice in excel and python i currently work as a customer service rep for a company that provides financing services but since i am a csr i dont work with any data or use any data analysis tools apart from excel once or twice a week this is a contract position and it is set to end in months i would like to be in a data analyst or data entry role when my contract expires and just wondering what tools or skills i should be working on that will improve my chances of landing a job in this field i live in toronto,which skill should i focus on to get into any data science role as soon as possible,what are some of your favorite data analysis tools
1099,hey ranalytics i am posting here to really seek for some help or advice in terms of web analytics i recently landed a role as a data analyst for a webrelated company for anonymity purposes i will leave the company name out it is a fairly smallmediumsized company so unfortunately due to some circumstances when i joined the company i became the only data analyst however i am actually really really junior and i consider myself quite lucky to have gotten the role i am also fairly new to the field well very new and have limited domain knowledge i am writing here because i want to know if there is anyone on this sub that could provide me some resourcestoolstipsanything for me learn in regards to web analytics or perhaps be willing to connect with me and teach me a thing or two at my current level i am able to somewhat be on the areporting side of data however i want to and need to be able to improve myself to be able to generate insights and stories from the insights some examples of things that i would love to know are are there any musthave visualizations that i should create to monitor specific metrics how do i create prepost analysis what should i look at if i want to see changes in ishopper behavior i know there is a multitude of possibilities but it would be nice to have some examples of where i can start to look at this and more anyways if you have read this post thank you very much i really appreciate any help i could receive,really would like some help or advice as a noob in web analytics,i am a new data analyst and i have a few questions
1100,this sub sees a lot of questions about how to become a data scientist but there are relatively few if any threads on the broader data jobs ecosystem how these different careers are related to one another and what possible progressions there are within each a lot of articles and blog posts i have read talk about the data analyst as a junior data scientist position the work is typically characterized by descriptive statistics database queries and handwritten reports do analysts work alongside or under data scientists or is the nature of their work typically different enough that there is not significant teamwork by extension what is the data scientist is general role at this point is the expertise of a typical data scientist almost exclusively geared toward ml or are there other use cases for their extensive statistics and mathematics backgrounds to what extent are data scientists engaged in the data engineering space are they just consumers or are they actively involved in developing and maintaining pipelines finally we have data engineers how do they fit into the bigger picture are they just building and maintaining pipelines in essence functioning as dataoriented systems administrators are they at all involved in productionalizing models designed by the data science team how much knowledge of math statistics and ml does a data engineer need to be effective in the role i would assume it is less than a data scientist but is the theoretical part of the job small enough that this advanced stem training is nice to know but not particularly functional i imagine a lot of this varies companytocompany but it would be nice to hear different experiences,the data careers space domains and intersections,what is your data science superpower
1101,say i am trying to understand how unemployment drives burger sales at mcd is in the usa one could build a timeseries model with a couple variables like unemployment to predict monthly burger sales on a cw basis but there are so few data points whatever relationship found could easily be some kind of spurious correlation i am wondering if the following approach makes sense ampxb look at change in unemployment by state month over month perhaps compared to cw average regress against change in burger sales by state month over month also perhaps compared to cw average ampxb now i have transformed data point to and by comparing response to cw average whatever things are driving burger sales other than unemployment are hopefully controlled for ampxb so i am working on a problem like this and i wonder if the approach i am outlining is a reasonable and b standard if b then can anyone point me to a good resource to learn more thanks,time series state results,is there a good way to model this kind of data
1102,hi everyone i have been working as a data analyst for a medium sized company for just over years i do not have a mathsstatisticscs background i studied biology at a leading university during which i had a little exposure to r nothing i really remember but that is all i managed to wrangle my job through a contact and have learnt everything on the job i have found myself very bored in my job recently and am struggling to find a way of advancing my skill set any further it seems as if the only career progression i could really make at this company would be going into management or project coordination the bosses do not seem committed to investing any timeresources into any real cutting edge data analysis when a request comes up it is quicker and easier to hack something together in sqlvba that kind of works rather than doing anything sophisticated a lot of time is spent simply maintaining legacy systems and it is hard to find a business case for anything particularly creative or cutting edge when what we are doing at the moment works fine although i am sure they would love someone who is skilled in data science to offer solutions nobody in any senior position has any experience with things such as statistical analysis or machine learning so there is nothing driving any development in these areas and nobody to mentor those of us that want to explore these areas i would love to learn and develop my skills in pythonr but without anything to apply it to and no time at work to learn the skills i cannot see how this would happen i was promised that i would be using these technologies when i was offered the job but that has not transpired and i do not want to fall behind in my skills compared to the rest of the workforce i know that i need to look for another job but i am worried that my lack of background knowledge and lack of experience with the more data sciencey side of things will hold me back in fact a lot of job postings specifically ask for statsmaths degrees and experience in languages that make me feel like a dinosaur i have strong sql skills and experience with cubes data warehousing tableaupowerbi the majority of my work day is spent writing sql code validating data and generating data reports and i also inevitably end up doing stuff which is not really my responsibility like dbadminoperational jobs i have tried teaching myself some python primarily pandas when i can but i rarely have time to do that at work and it is difficult without a project to can apply it to and with nobody i can speak to about it i really want to break into data science but i worry that my lack of any real world experience with commonly sought after skills and my lack of a statisticalmathematical background will make it very hard to find the right job outside of my company any advice on how i can break out of this funk would be greatly appreciated thanks,bored data analyst wants to get into data science but worried i lack the background knowledgeskills,what are your thoughts on data science as a career
1103,hi all i completed a master is degree in psychology and recently decided to not go through with a phd for several reasons my program was very researchintensive and i have had a strong background in research as a student and in various jobs for the past four years a significant amount of my time is spent cleaning participants data and creating new variables with excel and i have used r and matlab to work with datasets with k rows i seem to enjoy playing with numbers and asking the right questions in order to come to a conclusion about the data i want to continue working in research and was looking into short programs that would boost my knowledge in statistics and working with data since many research jobs that require a master is seem to like these skills that is how i found out about data science and big data analytics i am looking into a course certificate program that i qualify for at a university in town but i am trying to determine whether something like this is useful outside of data scientist jobs as well or even with just this certificate would i be able to apply to data scientist jobs i feel like i can bring with me the critical thinking and analytical strategies common in experimental investigations thanks for your help,certificate in data science,i am a psychology student looking to get into data science
1104,i am studying data science do not have a data job at the moment i have been using pandas with data i get from my job for about a year now but i think i have somewhat outgrown strictly tabular data structures my problem i work for a large logistics company us domestic shipping our system automatically produces a sort report txt at the end of every sort with useful operations data pandas worked great for compiling these reports and finding useful patterns eg high noreads on camera tunnel x however i want to get into image processing so i can better troubleshoot scan tunnel camera issues i am able to gather scan tunnel image data from every package that is sorted top bottom left right of package along with the image data there is tabular data such as the name of the shipper destination etc the sort reports and image data are produced by completely different systems the end goal i would like to be able to organize this data so that the images are associated with their respective sort report and package data i would like to eventually have an image processing pipeline however i still do not know how i should go about even storing the data i do almost all of my computation on an aws sagemaker instance in short how do i store all this data while preserving the relations they have to each other,what kind of data structure should i use to store mixed data beginner,how do you store your data
1105,hi everyone i would like to introduce you to my new data science project from scratch series i decided to make this series because i have gotten many requests asking me to show how i work through each phase of a data science project i also think data science projects are one of the best things you can do to learn the field and appeal to employers so far i have only uploaded part but i will be adding a new segment every monday wednesday and friday until the project is complete i go through project planning data collection data cleaning eda model building and productionization i hope that this helps you on your data science journey,how to make a data science project from scratch new series,data science project for school
1106,i have been working as an analyst for a couple of months now and i am curious what people is journeys have been like in the analytics field where have you found yourself growing most in did your career take any unexpected turns also where did you feel about your abilities were starting out compared to where you think they are today many of my friends have ended up in softwareengineering and they all have told me that they were truly horrible at their jobs starting out i have not heard many selfreflective stories from people in analytics though i am curious because i absolutely feel like i have so much to learn and have so much growth ahead of me i am hoping that hearing others journeys can put things into perspective thanks,what was it like first starting as an analyst out vs now,how do you feel about your data science journey
1107,i am probably looking to change my job within the next few years after i finish my doctorate my current supervisor has informed me i will get a bigger salary bump if i leave and come back with the phd rather than stick it out and try to negotiate with my current company so i assume i will be at a disadvantage when i go through this process as i will be applying as a student i am a manager right now and would like to interview for a similar or higher level role i have casually interviewed with a few places in the past and have been frequently surprised at the types of things asked for data science manager or director level roles one company we will call them swamazon for anonymities sake asked me to code a regex function at the level of write a function that splits the string another company while trying to assess technical skillset went into depth about having me code a group by function in sql neither was very interested in seeing examples of anything more advanced from me either i cannot tell if they asked this because they assume someone who manages a team must be an idiot or if i just look like an idiot but curious to hear if this is standard these days what do you guys typically ask when interviewing experienced data science folks,what types of questions and coding samples are normal to expect when one is interviewing or thinking about prepping for a data science job interview at a manager or director level,how much do data scientists get paid
1108,ive been working as an inhouse data scientist for a midsize product based company for years stable career path decent compensation nothing to complain except that i need an option for relocation to other countries as my work visa might expire next year and my company doesnt have global offices i started applying to companies with global offices and got an offer at mckinsey however i feel quite shaky about the data scientist work at an consulting firm amp the work life balance the compensation offer is not that great either and im still in the negotiation process the only highlight is that they offer relocation which is what im looking for in the beginning and i guess the name of mckinsey is good to have on the resume would you recommend taking the offer if it means it might not be legit data science work worse work life balance bad compensation hoping to negotiate its higher than my current salary but much lower than market average if i stay at my current company i will be promoted in a few months and paid even more than that but no relocation but relocation opportunity and brand name how is the exit opportunity to tech companies if i take this offer,data scientist offer at consulting firm should i accept,is it worth taking a paycut to relocate to a new city
1109,i am still relatively new to working with neural networks and i was wondering what the best practice is for adding in features which you do not have historical data for when you do have it for all other features in a timeseries model specifically as a learning exercise i am creating a neural network basic for now recurrent in the future which predicts the price of a stock index original i know i can get historic data for most things except twitter which i have found to be very difficult to get historic data past what the api allows at scale unless you are willing to spend k with that said how would adding in the twitter data affect things if it starts a year or two after all the other data starts is this less of an issue in a recurrent model,question about adding new features w no historical data in nn timeseries,how do you deal with missing data in a neural network
1110,i am predicting an integer value bike availability in a public station during the data pre processing step i transform every value to float and normalize it in the process of training the nn keras outputs the results for every epoch and it says that the accuracy is when i plot the data overplayed with the predicted data i get an accurate prediction how important is the accuracy value that i get from keras as i see in the prediction is not important because the predictions are great the problem is that if the real value is bikes and it predicts bikes it is considered as an error if a human saw this value it will not be considered as an error how should i approach this,improving keras accuracy,question about overfitting in keras
1111,my wife was a high school math teacher she recently quit teaching to try to break out of that field entirely and got a different job a marketing related position it doesnt look like she has much future in this career path but the purpose of the switch was to move out of teaching rather than to find a new career right off the bat i am looking for softwaredatabase recommendations tutorials certifications etc that she can invest time into in order to better equip herself to find jobs in a data science oriented role tableau is bucks a month billed annually and i am not really equipped or ready to make that sort of an investment for something she may or may not like in the long run,entry level job qualifications,is it worth spending money on a new computer for my wife is data science career
1112,hello all i am currently a data scientist with years of experience and prior to that i have been a performance analyst for more years currently i work in a really good startup with huge opportunity to grow so i do not want to move yet also i have loads of free time i only work hours a day thus i decided to start doing some freelancing i signed up on upwork but can not seem to get my first job since i am not rated and i have tried everything even extremely lowering my rates just to get the first few jobs to get a rating also one more problem most of the projects i worked in my company are confidential since its a very competitive market and i have signed an nda so i cannot just post them on upwork for anyone to see my question here do you have any advice on how to start freelancing on upwork also are there other platforms that i could use any advice in general would be realy appreciated,help looking for freelancing jobs,data science career advice
1113,hi all as part of the interview process of a data science role i have been given a take home case study the context is that the company has purchased data and want me to present my findings and recommendations to a nontechnical audience the problem is essentially a regression supervised learning but i think the predicted values themselves are not as important as opposed to the rank of the predictions although i have a technical background i have never done data science before ie analyse a dataset build models and glean insights so i have been spending my last few days furiously learning r and regression algorithms without asking for help to solve this specific problem i am hoping to get some guidance my overall plan is this focus on learning types of regression models due to time constraints linear regression decision trees random forests investigate data train regression models on the training set identify which features are significant and understand if they make sense i am thinking this does not apply to random forest as they are more black box compare performance of regression models on the test data set based on results come up with summary of findings and recommendations in the business context my questions are does my approach make sense ie fit small number of regression algorithms focus on findings and recommendations as opposed to fitting fancy models what are the key things i should be focusing on when communicating results what does the scope of recommendations likely include eg data does not have much value so do not investigate further purchase more data to get better understanding is there a detailed tutorial for r on how to fit a regression tree using rpart in terms of choosing the parameters assessing goodness of fit etc is there an automated way in r to do stepwise regression for fitting a linear model also open to hear how other people fared in similar situations,adviceguidance needed for a case study for a data science interview,how do i go about building a regression model for a business problem
1114,i have been considering a midcareer switch from a nontechnical field to a more quantitative one i have some math and cs backgroundhopefully enough to get into a ms in data science program but probably not enough to get into a quantitative phd program an ideal path for me would be to do an ms in data science work for a few years in the field and evaluate whether i should do a phd eg in stats or computer science so that i can advance further in a subdiscipline like machine learning my question is assuming my background in math think singlevariable calc and linear algebra and cs think introlevel college is not enough for a phd program now will the ms in data science put me in a position to be a phd candidate in the future or do data science masters programs teach mostly professional skills and so would not be a good preparation for phd studies thank you,ds masters subsequent phd studies,is a phd necessary for a career in data science
1115,i am a web developer and i hate my job and the industry and my coworkers it is pretty much a fashion industry with arbitrary rules and trends and idiot lemmings running from one thing to the next they have their head stuck in the sand and they want the world to stay the same they want to feel like how they did when just knowing how to code was enough to make you special well coding is getting easier if not more paint by numbers and i am just sick of the whole scene it is pseudointellectualism makes me sick i am sure many of you are developers and of course i am not talking about you i am just talking about the developers that i know and my impression of the industry i have been studying math for the last few years with the sole purpose of being able to do machine learning and also d graphing my worst yes my absolute worst fear is that machine learning will get so easy that those developers will follow me after i have put in all this work i do not want joe awesome web developer to be able to do more than i can by just using aws or azure or some other ml api will i have any advantage because i understand the math and can implement the algorithms on my own,will machine learning ever be in the domain of web development,i am a web developer and i hate the industry
1116,hi all i am kind of new to machine learning and i need advice on the machine learning model that is implemented in my app the app is idea is to get an specific articleexarticle about facial recognition everyday based on user is broad interestextechnology my idea is to get a couple of words subtopicsthat are related to the user is main interestexample main interest technology subtopic networks gmachine learningplaystationetc then preform reinforcement learning with those subtopics to be able to get me an article that i would like to read based on the previous attempts preformed by the model and to avoid repitation of the same topic the varince between the upper confindence bound is measured to avoid negelecting a sub topic or the repetation of one so i want to know ig that is a good model to work with or if there is any better model i pretty sure there is that is able to preform what i want thank you so much,best model for recommending articles based on previous rating of articles read by you,is there a better way to approach this problem
1117,my goal is to create a database of outdoor gear specs most importantly brand product weight and retail price my background is in data analytics and some data engineering but this is a stretch for me confident i can figure out the web development stuff once i have a plan for obtaining the data this database will use an algorithm to help people make sound ultralight gearbuying decisions my classic albeit very niche example of this is the person who buys ultralite bd camalots and then carries their polarfleece jacket up the whole climb another more relatable example would be the person with all the expensive lightweight backpacking gear who also brings the polarfleece layer i will admit i am not a polarfleece fan the ultimate goal is to help people quantify the value of their next ultralight gear purchase or to optimize their packing list for their next weeklong backcountry trip while i could use webscraping i am curious if there is a better solution out there webscraping would be sufficient for a onetime solution but i want this project to be ongoing to include new gear lighter stuff is always coming out if this is not the appropriate subforum please direct me to the correct place and i apologize for my mistake,pulling uptodate data from small websites in the outdoor industry api webscraping other best method,i am a new data scientist and i have a question for you
1118,kaggle dataset page all electronicallyavailable texas appeals court cases filed since as of total cases full datasets approx gb download sample rows or full dataset in either sql or json format sample datasets approx mb data source aggregated by parsed fields include caseid createdat unix timestamp sitecasenum courtkey and httpreq detailed case information is not parsed within these datasets although case data is available in a standardized html structure sample case from data source case count by court courtcase countcase key court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of appeals coa court of criminal appealscoscca supreme courtcossup,all digitized texas appeals court cases since,court of appeals case database
1119,hi all i am looking to pull ga reports into tableau which can give me an insight into the flow from the point someone types into the search bar on our website to look for a product to what their next clicks seem to be product new consecutive search how much time it takes to click on a product from that point view the details page of a product we also have separate logs of these events happening in splunk without the actual search text being mentioned in the log whats confusing for me now is how to proceed with this task the visuals on ga are quite disconnected and do not give a good overall picture how do i see what the following actionclick was right after a search event would it be easier to first pull the ga data into tableau and then try to visualize it is there a way to make use of the splunk logs along with ga information would there be any value in those logs for this specific use case would i need to find a common user level id between both splunk and ga in order to connect that information,ga search related use case,how do i pull data from two different product ids
1120,i have been working on creating a neural network implementation in c for shits and giggles it is a feedforward network where you configure different layers and it back propagates the gradient steps to take right now i am working on the titanic problem and have gotten which i am happy with but i want to keep trying with new types of layers etc i think i have got some bits of it mixed up in my head so can someone clarify or correct these statementsquestions the errorlosscost function is only used as a measure of how well the network is learning it plays no part in the gradient that is fed back through the network mean square error is good for measuring predictions binary crossentropy loss is good for measuring truefalse classification errors crossentropy loss is good for measuring a larger set of classes in a classification problem or more classes i guess it is combined with a softmax layer prior to it the gradient error that is fed back from the output value back into the output neuron is just the difference between the correct output and the output it gave ie if the output neuron used a sigmoid activation and it output when the correct output should have been then the error that is put back is dropout layers randomly drop out a node by making it output for one training sample only even if it is a minibatch or stochastic you still randomly drop out for each sample dropout requires you to divide or multiply the outputs of the nondropped weights while training or while predicting inverted dropout i think it is called maxout activation function is superduper and works by outputting the inputweight that is the highest of all it is inputs when combining maxout with dropout a node that is dropped that therefore provides a output is still considered by the maxout as one of the possible highest values the node does not technically dropout maxout has no derivative function the error that is received by the proceeding node during backprop is passed to the input that had was the max if there is a tie you can just pick the first input,i think i have got some elements of neural networks confused in my head can someone help me clarify,question about backpropagation
1121,i am looking at call center data and exploring how quickly a call is made after an event in minutes for a variety of reasons some legitimate a call might not be made for multiple hours this is not intuitive to the data or possible to filter out therefore taking an average gives a much higher number than is likely to represent the average speed for general cases ideally what i want to do is find the average speed for all general cases and then contrast that with the total volume to determine whether the outliers are within an acceptable range ie if of all calls are made within min but of the calls range from minutes to hours then this might be acceptable versus discovering the average is min for only of the calls working out the median would be a simple task or taking the mode but i am not sure if this is quite the best approach i was thinking about rounding to the nearest whole minute then multiplying by rounding to the nearest then dividing by and finally taking both the mode and midrange to see what the difference between them is would love to hear some thoughts,call center analytics average vs median vs mode vs something else,how do you handle outliers
1122,q deconv hi there i recently read the doc about the deconvolution also be deemed as transposed convolution implementation in the caffe framework in the doc it is mentioned that convolutionlayer computes each output value by dotting an input window with a filter deconvolutionlayer multiplies each input value by a filter elementwise and sums over the resulting output windows in other words deconvolutionlayer is convolutionlayer with the forward and backward passes reversed deconvolutionlayer reuses convolutionparameter for its parameters but they take the opposite sense as in convolutionlayer so padding is removed from the output rather than added to the input and stride results in upsampling rather than downsampling it says that the deconvolution layer reuses convolutionparameter for its parameters so my question is that why not learn the parameters instead of just taking the learnt parameters of the convolution layer q gan in adversarial networks we can add a nbyn noise to the original nbyn image so as to fool the cnn model the sign of the element in the nbyn noise matrix should be the same as that in the gradient matrix so if we add a regularizer to constrain the gradient to satisfy that for each real image the gradient to each pixel should be as close as possible to zero will that help to solve this problem,confusion about the transposed convolution implementation in caffe,question about overfitting with d arrays
1123,landed a datascience position but it is centred around sap shana selfdatascience submitted an hour ago by tonosnaj freshly graduated from phd in mathematics eubased my research has nothing to do with dsstats just mathphys and quantum mechanics all theoretical i have always wanted to switch job into doing more exciting stuff like data science and ml i have applied everywhere and usually got rejections perhaps due to my nonprogramming experience in my research and that the my topic do not match all except this local company who offered my a junior position as far as i understood it their service is centered around sap shana a cursory search on sap gives the impression that once you are in sap you are stuck with sap with little room for expansion into other careers would this be a good first career move ps the salary will be k pa lesser than my current postdoc salary but i am sick of my research and academia,first data science job with focus around sap shana,is it worth taking a paycut to switch to ds
1124,so i have seen a ton of master is in data science or analytics popping up like there is no tomorrow a good number of them also seem to require hardly any technical prerequisites so my question is when compared to a master is in a more traditional quantitative science like statistics cs and physics can an ms in data science or analytics really hold its own a ms in data scienceanalytics seem rather narrow and hyperfocused compared to other degrees and i am not sure how companies actually view them it seems like universities are offering these as cashgrabs tbh i just do not see how an ms in analytics can compete with a phd in say applied math for a data scientist role,are ms in data science programs actually viablevaluable in industry when compared to graduate degrees in statistics physics math cs etc,is a ms in data science worth it if i already have a job as a data scientist
1125,reading through esl and i am wondering if the use of sophisticated methods such as reduced rank regression with shrinkage are even worthwhile in the industrial data science setting rrregression is supposed to be used when multiple yresponses exist but i do not think they offer that much of an advantage compared to just performing normal regressionlasso etc in terms of prediction accuracy perhaps i am supposed to simply get a theoretical understanding of these methods so that i have some working fluency in different types of shrinkage methods otherwise i do not really understand the need to study these topics with such depth happy to change my opinion simply looking for a good reason,how often do you use fancy regression methods,question about the use of regression in industry
1126,im an undergrad that just started helping a professor with research he wants me to improve his current method for gettingstoring tweets right now the program uses the search api and does some kind of recursive search on retweetscomments on news articles for top news outlets the api is called with java and stored in mysql again my goal is to improve it my idea was to use the streaming api instead of the search api dump everything into an amazon fire hose store raw data in s and load into elastic search plus kibana as a ui basically follow this tutorial the current program is logging about k tweets a day can anyone speculate if the proposed setup would be a significant improvement i know that speaking strictly data limits the streaming api should have a higher capacity but i dont how it behaves in practice i also no there are issues with time delay on the search api and only getting a certain percentage of tweets with the streaming api if anyone has experience with the api id appreciate the advice,anyone pull news related tweets from the twitter streaming api what kind of volume can i expect,best way to store tweets for future reference
1127,hey everyone i am a student graduating this year and currently work at the university i study at where i am essentially the business analyst there has not been a business or data analyst position here before in fact i started as a business intern before getting promoted to parttime lol i have been able to do my job mostly with excel i just download reports from websites and clean them reformat them etc or just straight up googling shit but i would like to be able to develop more technical skills while also applying them towards my job so i would want to create automated dashboards in tableau for the different departments which would use data from the crm we use and the registrations system database neither of which i currently have access to lol how exactly should i do this like where do i even clean the data would i connect tableau to the database i am pretty sure they use either mysql or microsoft sql and then just clean it in tableau maybe using the custom sql script option when needed do i clean the data with sql andor excel and then put that into tableau if i did it that way would i create a second database just for clean data and then i would query that database instead of the real database for analytics projects there is decades of information there and i would just want relatively recent information so idk if it made sense to grab like the last years clean them move them to another database and then automate both getting new information from the og database to the analytics database and the tableau dashboard which would be based on the dashboard of just recent information essentially if you have done something like this before what does the work process look like and how does the data flow between each step nobody technical works here so i cannot really get help from any coworkers and i feel like school was too theoretical so i do not know what i this looks like in a practical sense thanks in advance,questions about automating etl from databases to tableau never done any practical work with real databases before so i was hoping for some clarification,what do i need to know to get a job as a data analyst
1128,hi i am doing a project for a datamining class there are no specifics for the project and we are free to do a pet project as part of the class below are some ideas that i am floating around in my head i would like any help with any of the topics below and also some knowledge on how and where to find the data sets related to the topics dutch disease with the drop in oil prices towns all over the us have faced economic set backs and repercussions a study on such a town and maybe a game theory model based on the data would be something that i thought might be a good project for the class energy usage for a particular state in the us with data sets broken into sources of energy imports from other states or countries exports to other states revenue generated by such exports costs for energy production for state and costs of imports and lastly alternative sources and the impact it would have based on cost fracking data based on production wells locations and its impact hubert is peak theory on individual wells again tying back to impact and alternatives to keep the economy from crumbling of the town,help with class project,looking for a data set with us economy and energy costs
1129,quick overview of my background eu bachelor is in business administration code math in the program got insanely lucky during my studies and landed a few data related jobs and internships they were in data engineering and dashboarding i had to make a few data products from scratch while working closely with business i got good connections from each of these internshipsjobs that i always leveraged for the next one after this i did a premasters of math stat econometrics programming operations research y and an information systems master with a machine learning major y so key takeaway it is never too late to pivot to data science regardless of your degree if you play it smart after this i worked a bit in data science consulting doing part data engineering part data science work then i took up a position as a data scientist official title research assistant at my uni is social science faculty to kill time while i roundup the last bits of my ai msc june since it is a position the uni i can use it as an important reference for a phd in a faculty that better suits me later on since the job market can be competetive i need to plan ahead what i want to do come september i have the following options return to data science consulting pro is good pay very nice people i am used to the tech stack already stateoftheart tools smart experienced colleagues and importantly the door is always open i can relax and commit to this position in april i do not have to decide right now funnily enough i think i am best at communicating with stakeholders prioritizing features scoping projects horsetrading so consulting is a good fit cons i hate dashboards and data viz in general i can make ok visualisations that convey what the business needswants to know visually stunning or ux designer level viz is something i am terrible at and just dislike doing in general towards the end of my stay there i hated it because more and more stakeholders wanted storytelling with data no computer vision nlp it is strictly business facing logistics marketing finance use cases other ml use cases exist but i like keeping it simple kmeans glm is or sarimaprophet because they have the best profit time spent ratio if they fail something else can be used of course though machine learning engineering pro is all pro is of data science consulting except the last one additionally i get to work on computer vision nlp projects dashboards and a limited amount of data viz the work is mostly focused on data prep ml cons they want me to sign and commit asap biggest con because their recruitment for sept ends around january i could look at other mle positions but honestly the competition is rougher than in data science some top mle positions would not want to take me since i do not have either a pure cs or mathematical engineering msc aside from the concrete offer i have idk if i could land any other phd in ml ai stat or ai pro is highest net salary years of investing in your own future i can will be encouraged to take statistics operations research and cs ms level courses to fill gaps in my knowledge could potentially open a lot of doors i have the necessary grades experience and references to land it cons working on publications one in statsml and one in sociology right now and to be honest literature review sucks the experiments and analysis are fun though of course they start hiring pretty late for sep biggest con here if i decide that i want to do a phd i cannot have mle as a plan b because that ship would have sailed tldr currently what i want to do by order of preference is phd gt mle gtgtgt ds there is a lot of uncertainty in landing option i know you can go to industry and go back to do a phd but that is not really an option for me so what would your advice be considering all of this,phd machine learning engineering or data science what should i do next,data scientist to data engineer
1130,i am trying to train cnns to find objects which are not found in the typical computer vision datasets i think this is time consuming because i will have to label all objects by hand at most using video tracking i thought maybe it is possible to train a neural net to detect similar objects then it shows the user all the kinds of objects it found in the data and then the user selects the one he is interested in maybe uses the data to train a more conventional object detector i do not know if this is possible though i would not know how to train it especially because most objects of the same class will be found in different pictures is there some work in this direction,speed up labeling by detecting similar objects in a neural network,object detection using cnns
1131,i have a bs in biochemistry and am in the process of transitioning into data science to keep options open i decided to pursue a ms in data sciencescientific computingcomputational science thesis option instead of pursuing one in comp bio but due to my experience in genomics research i am afraid that i will be only competitive to enter a program if i write my thesis in biological sciences first is this the right approach or is it preferred to specialize is it possible to transition into other fields like cybersecurity aimachine learning finance neural net database architecture if so how can i find which topics are common to these fields another option would be to pursue a degree in math and take electives related to a specific field but i do not know how much more marketable a ms in math is compared to one in data science thank you all for your time and help,question versatility of computational biology,how do i know if i am ready for data science
1132,so i just graduated with a bs in biology but i do not want to continue my career in this field i want to enter the tech field something like data scientists i have been looking up a lot of things and saw that there are a lot of boot camps that teach you the necessary skills to get a job as a data scientist what do you guys think about this suppose i get in this boot camp would i be able to get a job with just a bachelors and some skills learned from a boot camp course please give me some suggestions of career paths i can look into also thank you,data science boot camps,data science bootcamps
1133,hello i have got a few million ecommerce html pages different domainsshops and would like to classify them into categories product category content maybe someone here has a good idea of how to accomplish that and could outline an approach my idea so far is extract statistical features from each html page amount of images amount of prices amount of links etc label a hundred pages manually use a supervised classifier to do the job i have got two concerns questions the confidencequality of my outcome would purely depend on the statistical features that i chose to gather different shops have different templates should the features classifier be trained executed per each shop separately or is there any thinkable approach which would be able to perform in a generic way thanks already for your help chris,i would like to classify html pages into groups right approach,how to deal with a lot of data
1134,background i am a masterscs and around years experience in data engineering my industry experience is mostly with spark kafka sql noosql and aws building data migration and etl systems initially i liked data engineering better and always attempted to stay in the same field however now i feel like i want to switch to a data scientist role or even a machine learning engineer dream to add i do have experience with data science tools and techniquessparkpysparkpandas numpy building and hyper parameter tuning ml models cnnslstms tensorflowkeras etc through my projects in my masters however companies seem to value titles more than my experience and since i have never held a data scientistmle title i keep getting approached by recruiters for senior data engineer roles but cannot get an interview even for a junior data science role despite applying to so many places how to overcome this i have seen people with non cs degrees become software engineers and data scientists surely it should not be impossible for me is there anyone who has done this who can advise thanks in advance,how to switch from data engineering to data science,data scientist to data engineer
1135,tldr what is the most accurate way for me to collect web traffic event data for ad hoc analysis i am trying to get a grasp on web traffic and conversion behavior on an ecommerce site google analytics and facebook pixel tags are setup but ga is missing transactions or has bad data and neither ga or facebook provide access to event level details for data validation ad hoc queries i would like to send page views and data transactions to a data warehouse bigquery but am not sure of the best practices way to do this i have read about using ga tags to fire events to an external source and know i can use tag manager but would not both of these options make google a single point of failure would custom javascript be more reliable i do not want to reinvent the wheel but if ga is not getting the right data then neither will i i would appreciate any advice on which direction to go and the best way to configure this type of pipeline thanks in advance,google analytics vs tag manager vs custom javascript for tracking web traffic,best way to query facebook ads with google analytics
1136,does anyone use this in their job i absolutely hate it in my last job we had a database within ms sql server when i started this job my coworker sent me straight to his data repository where he stores data from multiple sources other than stunting my ability to learn by not working with the data straight from the source there are so many limitations no ctes no temp tables you cannot even tab in the query all of his queries consist of nested derived tables and subqueries that are so hard to follow the syntax of jetsql requires odd usage of parenthesis the where clause will be wrapped in like parenthesis we have acess to a backend through postgre but it does not store much historical data another backend is in ssms with historical data but it still has limited data it is also a live db and i was told not to run any extensive queries on it i guess this just turned into a rant i cannot even find many resources to learn the differences between jetsql and tsql but it seems like a waste to even try to learn it,microsoft access jet sql,how do you store your data
1137,hi everyone i am a developer wondering about the feasibility of developing a service to group together news from numerous sources something like what google news does the goal web client makes a get request to a news api and receives a large data set data set analysis using trained model topic in question output original dataset where each entry has an extra field with story id to group news about the same story for someone with very limited prior data science experience in only ever having used provided models and datasets to run predictions with predefined outputs how feasibledifficult would it be for me develop the machine learning portion of this thanks very much,question about news aggregating grouping,how do i cluster multiple data sources
1138,hello i would like to apply an selfattention mechanism on a multichannel audio spectrogram so a d tensor in the original transformer paper selfattention is applied on vector embedded words within a kind of temporal sequence on my multichannel spectrogram i would like to apply selfattention both on the temporal and frequency axes so that the analyzed vectors are through the channel axes on tensorflowkeras multiheadattention layer there is a attention_axes parameter which seems to be interested for my problem because i could set it up to something like and hope attention will be applied on the wanted dimensions however i do not understand how it works since it is different from the original transformer paper and i do not find any relevant paper addressing selfattention in several dimensions in the same manner also the source code does not help me the algorithm is split into several submodules which are not selfexplanotory to me any insights would be precious thanks a lot,how does multihead attention on multiple attention axes works,question about the selfattention mechanism
1139,hello people i have recently used the titanic dataset from kaggle and built a machine learning model for the competition titanic machine learning from disaster with the given training dataset i built the model and the random forest classifier i used gave accuracy on validation dataset accuracy is the evaluation metric required by the competition so i generated predictions for the test data and submitted the output but the competition scoreboard gave me score from the other answers in kaggle forums i read that the score gives the percentage of correct predictions for the test data so it means none of my predictions are correct ampxb my questions how could that happen despite a decent accuracy on validation dataset and i am seeing only and in the scoreboard how is the categorization accuracy calculated ampxb thank you in advance,categorization accuracy in competition,question about using the correct test score in a classification model
1140,hello i am currently a sophomore in my bachelors in university i am currently looking for an internship and have offers the first is a data analytics internship from a smallish accounting firm i would be working with tools like azure sql and aws the second one is a software engineering internship from a fortune defense company where i would be working with embedded systems in ccjava the defense contractor is offering a good amount more per hour i could work in a hybrid format which i really like and i might be able to get ml experience at a fortune company some time down the future however i feel as though the accounting firm might be a lot nicer and give me skills that might be more applicable what do you guys suggest thank you,software engineering or data analyst internship for machine learning career,i am a software engineering major and i would like to get into data analytics
1141,im trying to build a business case for attribution modeling in my company and i need to plan for several technical improvements before we can move on to that project and work with decent data one of them is the direct traffic issue its increased since the itp releases of course and thats why i really want to move to a server side solution however i would like to hear your thoughts about how much direct traffic is considered fine to start working with attribution right now were averaging and i feel like it would be completely useless to spend resources on that when almost half our traffic and conversions cant be attributed to any digital channel,how much direct traffic is alright to start working with proper attribution modeling,how to measure traffic from a specific channel in google analytics
1142,hello all i was working on a transferlearning project with xception and keras using the tensorflow backend i had k images i wanted to split into a testing positive and negative and an training positive and negative however when i run the script to separate the data it only reads images out of the k looking at the code i see nothing wrong it reads all the data and then separates it the way it should can anyone help me out as to why the k images are not being shown the code to separate the images can be found on lines my code can be found here the data to separate can be found here thank you in advance for all your help,splitting images between train and test,negative image separation with keras
1143,i will graduate in a couple of weeks with a statistics degree but the only work experience i have on my resume is an accounting internship i did during high school where i basically did data entry and menial office stuff i was supposed to start a data analyst internship around the summer of but it got canceled due to the pandemic i only started job hunting for data science jobs through mostly indeed last month with many rejects unsurprisingly on a day when i was down bad and randomly started to apply to entrylevel staff accountant positions for shits and giggles all of a sudden i am getting bombarded by recruiters and staffing agencies for various entrylevel accountingfinance roles near my home even with a mediocre resume this is what i am thinking since i have no relevant experience that pertains to data analystbusiness analyst roles should i accept all of those recruiters requests prepare and try to do well in the interviews slave it out for a year then start applying for data analyst roles i could even save up money as a staff accountant for years and attend ms in statistics programs as another route,aiming for accounting positions only in the short run,is it worth spending my summer learning data science
1144,hey everyone i am ironing my resume at the moment but feel like it is painfully generic i want to increase my chances of getting noticed especially with ats involved i would like to get some feedback from industry experienced lads in this sub on how to improve my resume or is it even worth enough to continue editing or start from scratch a bit about me i am working on master thesis and would finish in couple of months and starting to apply for jobs in the industry i am interested in computer vision although i wont mind working on any machine learningds field as long as my foot is in the door thanks for your time link to pdf,entry level resume critic,resume critique
1145,hi all i am proficient in stata but need to learn to do some datawrangling in sql preferably quickly i know sql is not that hard but it would be nice to look up the function name in stata language and find something similar in sql does anyone know of an online tool like a sort of google translate that has been created to give examples of how to accomplish the functions from one language in another ofc i am not expecting anything as thorough or advanced as google translate but even something with a way to search for basic functions in one language and come up with analogous ones in another would be awesome also project alert if this does not exist for someone looking to create a really cool tool,is there any online dictionary or thesaurus that helps you to go between coding languages,how do i use google analytics to create my own data
1146,i am an undergrad at a state school with a major in industrial engineering and a minor in comp sci i am interning this semester purly industrial and with my free time have started taking coursera data science courses i will not take any data analytics as part of my minor i was wondering if paying for the coursera certificates would be at all worth it would any possible future employer care at all about that would listing online classes on a resume help hurt or do nothing on a resume i am just trying to get something on my resume that is data science related to hopefully get my next internship in that field thanks,coursera certificates,resume advice for a recent college grad
1147,i was reading this blog ampxb at the bottom of this site there is a note this has been a long post and necessarily will have left a lot of questions open first and foremost how do we obtain good settings for the hyperparameters learning rate number of epochs dropout how do we choose the length of the hidden state or even can we have an intuition how well lstm will perform on a given dataset with its specific characteristics we will tackle questions like the above in upcoming posts ampxb has anyone ever seen this new post also has anyone ever tried following this tutorial i tried to copypaste the code from the tutorial but i got some errors see here ampxb thanks,does anyone follow the rstudio blog,how do you handle outliers in your data set
1148,i am a final year games programming bsc student currently beginning my final year project which is will take place over the next months i have already submit my proposal stating that i will be developing an agent to play texas holdem poker using neural networks it is now time to start narrowing that down and to decide on the specifics of the project so i have decided to post here for some advice the first and most important thing that needs to be taken into account is the amount of time that i have in these months i need to design develop and test with program then write a dissertation regarding this what type of texas holdem could be possible for this project whether it is headsup or not limit or no limit i have decided that i think reinforcement learning would be the best approach for this as there are databases full of poker hands online that can be used for training i am starting to worry that i will not have enough time to complete this project so any advice would be greatly appreciated,final year project reinforcement learning in texas holdem,what type of model would best be suitable for this project
1149,hi everyone i see in many cases in ml that we have the following situations d scalar d vector d vector d matrix d matrix vector and so on while i know the existence of the matrix cookbook which has a list of such derivatives i would really like to learn them from first principles and get an intuition for them when encountering them in my studies ampxb a quick search around gave me the following references i went through both of the above and seem to get what they were doing but did not quite stick with me i am looking for pointers to resources which delve in more detail about matrix calculus and maybe with exercises as well ps i have done linear algebra and calculus as part of my curriculum so i believe i do have the necessary background to understand the material just could not find one that is exhaustive intuitive thanks,good references for matrix calculus,how do i go about learning about d matrix
1150,hello guys first of all thank you for taking your time to read this i will try to be clear and concise about my problem i am studying a master in data science and i have the chance to do a placement in industry for the summer where i will do my master is thesis i wanted to know your opinion about the project that i have been offered and if you think it is a good choice for my future development as a data science it has the following characteristics threemonth internship in big investment company present in more than locations good reputation according to glassdoor objective improvement of an existing machine learning algorithm that tries to explain how investment market behaves programming in matlab skills developed are ml statistics finance and investment knowledge the work will be individual but i will have the support of a team of ds the final decision will be mine of course but i just wanted to know your opinion about it i do not know very much about investment but i find it an interesting field that i always wanted to learn neither i am interested in any particular field basically anything related with ml would be interesting for me the thing that does not totally convince me is programming in matlab i have experience on it that is no problem but i am not sure it is being used in other industries like python or r and if it will make it more difficult for me if i want to search for a job later on could a project in python always be more beneficial thank you again for reading this this is a great community,opinions about choosing an specific master is thesis,i have been offered a data science internship but i do not know what to do
1151,i am an undergrad currently studying data science and i want to know which is better between finance ibanks hedge funds private equity or tech in overall ever since i was in high school i only want two industries which is finance or tech but it is very hard for me to decide because i do not know someone who has been in the same industry what are your insights on which is better in terms of overall satisfaction pay work environment culture etc ampxb as i researched tech firms have better work environment and flexibility finance firms have better pay and better performance bonus margin but they have very strict command chain and the softwares they are using is in a very close environment,finance vs tech,data science vs tech vs finance
1152,i have been trying to learn tensorflow and specifically to use it to implement a modification of aghajanyan is softtarget paper which led me to want to calculate things such as moving_average sessrunpred feed_dictx mnisttrainimages y mnisttrainimages keep_prob to then proceed to do some additional training of the network and then update the moving average using moving_average betamoving_average betasessrunpred feed_dictx mnisttrainimages y mnisttrainlabels keep_prob however i have found that even just running moving_average sessrunpred feed_dictx mnisttrainimages y mnisttrainlabels keep_prob moving_average sessrunpred feed_dictx mnisttrainimages y mnisttrainlabels keep_prob leads to running out of memory i am trying to run this on a microsoft surface using bash on ubuntu on windows and the precise error is the following tensorflowpythonframeworkerrorsresourceexhaustederror oom when allocating tensor with shape node convd convdtdt_float data_formatnhwc paddingsame strides use_cudnn_on_gputrue _devicejoblocalhostreplicataskcpureshape variableread can anyone explain approximately what i might be doing wrong,causing memory leaks or something of that sort in tensorflow,why does my tensorflow model not work
1153,i am currently interested in making an ssn and my current task idea is to have it train on a never ending maze where the network has to move to the top to complete the maze and as it moves to the top more maze is added on the input would be black and white by grid with the maze walls black not firing spikes and the places it can step white would fire spikes it would have to process this grid to figure out where to step to get itself closer to the top and as it gets closer to the top more maze is added on each time an output fires the grid would change to reflect the new position ampxb does anyone have any better ideas for a task to train an ssn with i am looking for something that is as simple as it can be where the input changes over a timecourse ampxb ty,task ideas for a spiking neural network,looking for input on how to go about creating a neural network from scratch
1154,hi we are just starting off in developing a data strategy at our rather small company but in the meanwhile we want to start collecting data and set up the processes for automatic data collection in almost all parts of the business so we can have a reference point in starting off with the strategy there are of course data sources that already have structured data that can be queried mostly related to marketing like google analytics search console facebook marketing and the like then there are those data sources that we have to quantify in some way related to clients finances managementhr and the like that although seem to fit more in the structured data category than unstructured they do not already have an inherent and evident structure to them so we have to collect and store these data in some way that is as usable and resource efficient as possible before we decide on a specific data architecture so i guess my question would be generally how do you approach storing different kinds of data in a way that is resource efficient and also easily queryable i was thinking of doing something like ga does with scopes dimensions and metrics and trying to fit everything in this paradigm for now what do you think what are your rules of thumb for starting off with collecting data like this thanks i have read the rules and i do not think i violate them because my question is highly subjective and although some technical aspects are very important in the end it is more of a personal preference,what is your approach in structuring data in a general way,how do you store your data
1155,hi i am learning mlai and today i am going though the decision tree algorithmi am having little difficulty understanding the entropy i am reading this article understanding the gini index and information gain in decision trees so it defines the entropy like this gt what is entropy in the lyman words it is nothing just the measure of disorder or measure of purity basically it is the measurement of the impurity or randomness in the data points an on the next line it says this gt a high order of disorder means a low level of impurity i am having difficulty to understand the above linedoes it says that more disorder or randomness leads to low impurityshould it not be reverse like more randomness means more impurity cannot get the intuition behind this,cannot make sense of a high order of disorder means a low level of impurity,question about the randomness of decision trees
1156,i work as a data analyst of sorts and spend all of my time programming with r within rstudio i sometimes use python at my job and i also do some small personal projects in python at home i started learning data science and the tooling around it close to years ago and i began with python the single biggest challenge as someone not coming from a computer science background was getting my laptop up and running correctly it was partly for this reason that i gravitated to the r ecosystem because it felt so much easier to begin working with data now that i am both more familiar with python and working with programming tools more broadly i want to transition to python at work and home but my personal laptop is a complete kludge of installs environments paths you name it essentially i tried following a variety of tutorials and blog posts to get my python data science set up going years ago without knowing what i am doing i would like to be able to effectively clean up my python workflow and tooling but i cannot find any tutorials or resources for going from a complicated mess of a laptop to a clean work flow all of the resources i have found are about setting up python the first time i apologize if this is vague but i am just hoping to find some sort of tutorial that explains how to go from a messy python existence to a clean one essentially i am trying to work towards having anaconda installed in a virtualenv i want to be able to launch jupyter lab from the command line within the virtualenv as well as having the flake linter package installed and the path configured correctly to use with atom in the same virtualenv any advice is greatly appreciated,any advice on how to clean up a kludge of a python setup,python for data science
1157,hello guys i have been trying to learn web scraping with python and beautiful soup package for the last few of days i was trying to recreate the output made in a tutorial i found on youtube intro to web scraping with python and beautiful soup the author web scraped information from neweggcom after keying in graphics card the codes are as follows so far from urllibrequest import urlopen as ureq from bs import beautifulsoup as soup my_url uclient ureqmy_url page_html uclientread uclientclose page_soup souppage_html htmlparser containers page_soupfindalldiv classitemcontainer lencontainers container containers lencontainers gave correct number of products which was search results the author isolated the first element so he could create codes and iteration to extract later on some information such as the brand and name for all the graphics cards ampxb here is what i got by entering containerdiv ltdiv classitembadgesgt ltdivgt i was hoping to get the html codes enclosed by ltdivgt tags named iteminfo class th line below which was also the one shown in the tutorial i did follow the steps accordingly but i also understand that the web page had been updated since then could you let me know where i was wrong thank you ltdiv classitemcontainer gt ltproduct imagegt lta classitemimg href ltdiv classitembadgesgt ltdivgt ltimg altgigabyte geforce gtx directx gvnwfocgd gb bit gddr pci express x atx video card srccneweggimagescomproductimagecompressallsjpg titlegigabyte geforce gtx directx gvnwfocgd gb bit gddr pci express x atx video cardgt ltimggtltagt ltdiv classiteminfogt ltbrand infogt ltdiv classitembrandinggt lta classitembrand href ltimg altgigabyte srccneweggimagescombrandimage_xbrandgif titlegigabytegt ltimggtltagt ltrating infogt lta classitemrating href titlerating gtlti classrating ratinggtltigtltspan classitemratingnumgtltspangtltagt ltdivgt ps please go easy on me i am a noob and selflearning data science ampxb,web scrape with beautiful soup,i am trying to implement a google tag manager for a client and i got the wrong results
1158,i feel like i fit the title but trying not to get hung up on titles in need of mentoring or literally any advice recently excommunicated from a master of city amp regional planning at georgia tech and still alive one helluva spatial nerd i have put in the work and have years of related experience but not sure how to navigate the job market not trying to sound pretentious at all i am super humble with no idea what i am doing not trying to start right at top i know that is not practical my first job out of undergrad was as a gis technician with an esri internship already completed in grad school i was a gis research assistant and used a slew of data science skills for whatever projects needed me including transit and growth modeling the rabbit hole goes deeper than this keeping it short for now much obliged to any input yall have a fantastic week,any spatial data scientists out there,data science career advice
1159,hi all i am in an interesting situation where i am the resident of an ultrarenewable energy home for research purposes we are collecting electricity usage data from every outlet every appliance and every load in the home we are also collecting flow meter reading from just about every faucet and water source in the home so we also know how much water is being used and where it is being used i have months and months of data down to the average power usage per minute obviously from a research perspective this is a goldmine of data i am performing a selfstudy of machine learning and data analytics and i am interested in seeing how i can use this data to help me answer questions about the home i was wondering if any of you smarter people than i have any good questions that may be answerable using this data and machine learningpattern recognition algorithms for example there is a concept called energy disaggregation aka nonintrusive load monitoring which takes a wholehome energy signal and separates it into the component appliances loads since i have the signals inputs and loads my classification targets i think that it would be pretty straightforward to develop a disaggregation algorithm using a basic lms algorithm but i was wondering if any of you had any interesting questions that could be answered using ml or pattern recognition for this type of application,questions to answer using the data acquired from a renewable energy home,is there a name for this type of algorithm
1160,hi i hope everyone is doing well in these testing times i am an electronics and communications engineer and have been working as a data analyst for the past years most of my work also entails predictive models like xgboost and recently i have also picked up some nlp now i am looking to apply for a masters degree i feel that there are other ms in cs vs ms in ds reddit posts out there but my confusion is a bit more deep so i will try my best to structure it well i do not have a background in cs most of the folks i have seen do well in data science analytics or ml engineer usually have a bachelor is in cs so should i do a ms in cs almost everyone with a ms in data science is able to get a job as a data scientist so i should apply to ms in ds but it will blow away my cover for software engineering roles which i would not like but are a good backup in the long run since most software devs or data scientists will be in management positions later on in their career it does not matter that i do not have backup software engineer roles because i will be a manager ms ds programs are few in number and my overall profile is not that good to get into great programs my background is not in cs so it also limits my options for ms cs i applied to a mix of mscs and msds programs this year and got into ut dallas mscs and usfca msds i am considering building a stronger profile and applying again but only in either mscs or msds as you can see i am using a lot of variables to think about this i am probably overthinking yes but i seriously want to make a good decision i would really appreciate perspectives that would help me think and opinions that do not digress a lot from the mentioned points thankyou so much for reading through i really appreciate your help thanks,please help me prune my career decision tree,data scientist vs software engineer
1161,i am working on a problem in which i have several instances that have predictors that have activity over various different time periods ie lt months to well over months originally i attempted to use knowledge i have about this problem it is an opportunity to sale conversion model and learned that the average time for a deal to close is about months so i broke my predictors up into three month intervals however i took another look at the lengths of these deals and see that there are a variety of instances that have durations that are not even close to months so this idea does not make sense the only idea i have gotten is just creating a duration column where i subtract the start and the stop date and then just do the summation for each predictor however i feel that the instances might get incorrectly labeled because some might have an overwhelmingly higher amount of activity than another due to the duration of the deal has anyone else encountered such a problem not sure if this is a common problem but a quick glance at googlereddit did not come up with anything i could be asking the problem wrong,how to aggregate data for instances that occur over very different time periods,question about time series forecasting
1162,hi fellows data scientists and data engineers i am in the field for months now and i find it difficult to find hobbies matching my job i feel that i lose my focus on my main activity when i am watching a movie or when i am listening to music that led to certain anxiety about losing performance and i am even finding it difficult to go out to a bar to drink with friends or meet new people because i feel i will lose my grasp on what is important to me finding a job in the field after my months bootcamp for the sake of my mental health and my wellbeing though i cannot put aside every source of pleasure for data science and statistics therefore my question what do you do in your spare time and how do you organize your worklife balance in order to not turn into a robot,worklife balance,data science and mental health
1163,i have setup two different event goals for my campaign but when i look at events i see that the total amount of events are more than unique events this is i am sure but cause our website has the option to make an application multiple times is there now any way i can see which events were associated with the unique events or at least see some report that shows me a better view of something like this x amounts of events under y unique event completions i have tried seeing this on event actions and labels but not seeing anything useful there i have thought of doing custom reports someone that knows more about analytics can perhaps tell me what i should at least have in there i assume people come across this discrepancies between events and unique events in goal completion a few times,unique events and event goals,how do i track how many unique events are being reported on my website at a given time
1164,i have several thousand of images in the format seen in this picture and i am looking for a method to convert this into a simple table in which and i tried text recognition software like adobe without success now i am considering the sklearn python module so far i have managed to load the image into python and turn it into a numpy array and i uploaded some correct results and turned it into an array aswell looks like this import csv from pil import image import numpy im imageopentraining_imagepng training_data numpyarrayim with opencorrect_resultscsv rb as f correct_results listcsvreaderf for what i can see the sklearn process seems to always go the same way import a model modelsome_model train it modelfittraining_datacorrect_results predict predicted_resultsmodelpredictnew_input_data now i would like to know how i can transform this numpy array into a form that can be used by modelfit and which model could i use for this so far i had no success with my research,python sklearn ocr for survey answers with special characters and,can someone explain to me why i am getting this error
1165,i am working with object detection and want to train an algo on d images generated by some rendering software i will ask the subs of those softwares directly but i am looking for input on the project as a whole not only which software to choose the objects in question are packs of bottles wrapped in either blank or colored plastic and stacked on pallets currently my only specific requirement for the software is that it somewhat realistically models the behaviour of light for those transparent plastic materials i was thinking about unity ease of use but thought blender might be better for that requirement i am just starting this project and only got some nn and dl experience so i just got a rough idea of how to approach the actual algorithm any input is appreciated i know i have left out many details that is either because i have tried to keep the post short or just me being ignorant,detection blender or similar to generate artificial datasets,how to train a cnn on a single object
1166,i live in se asia and im about to lose my job in oil and gas luckily though i have enough money to survive for a considerable amount of time and want to retrain as a data scientist however long it may take i have no wife or family and can move functionally anywhere in the world if i had a preference i would like to stick around in se asia even if i have to become one of these hipster backpacking nomads ive already completed some basic online courses in python and one in data science and machine learning i think the best option would be to go to some wellrespected and known institute and get educated and get qualifications there and then find an entry level industry position is there anything that matches this description alternatively i can just continue doing online courses in stats and coding and filling my boots with certificates from udemy is this a viable route my sincere thanks in advance,retraining as a data scientist best options for me,is it worth getting a phd in data science if i already have a job as a data scientist
1167,i am currently in a good ms in statistics program and have years of work experience as a data engineer at a big tech company in the bay area i am very much considering a phd as i absolutely love the subjects of csstatistics and i feel like that insatiable curiosity isnt even being met in my masters program still i know that i do want to end up in the industry getting to apply all the great things ive learned will i notice a significant different in how intellectually stimulating and interesting the work i can do with just this ms vs a phd or will it be pretty even once i go back into the field,rate of interesting work for those with an ms vs phd,is it worth getting a masters in data science if i already have a job as a data scientist
1168,i have a bs in applied and computational mathematics with emphasis in actuarial sciences having an impossible time finding a career in analytics i feel like i messed up not pursing an internship in college because now i have the degree but no experience i also have wondered if part of the problem is my degree title it is a mouthful i have been given mixed messages by recruiters on going back for a master is degree some say that is what i need for a job others say it will be harder because i will be overeducated in conjunction with my lack of experience in the field so i guess maybe i keep fighting it out trying to find an entry level data analysis job does anyone have recommendations or insight on getting a master is and finding a job,data analyst masterswill i be over educated and underemployed without experience,what is the best way to get into data analytics without a degree
1169,for a project i have a dataset of some medical scans from different patients the dataset consists of grayscale x images these images contain a lot of useless information that i do not need meaning that i can segment the image so that i only get the useful part of the data my task is to do this using a linebased approach meaning that i should be able to input a x image and get a vector of dimension x as an output here is a rough example of what the input and the output should look like what type of architecture or what type of method should i use to achieve my desired result note that it should be a deep learning approach as i will have to compare it with conventional image processing later,linebased image segmentation using deep learning,how to deal with a very unbalanced dataset
1170,new to data here so i am quite confused sometimes using apis and please excuse me if i am not using the best technical terms so i am running into the problem of trying to find data for census tracts andor cities perhaps i do not know where to download the data or if there is a filter from rd party websites that can draw that data but i just cannot find it i am trying to strictly find data for age and gender for cities tracts or counties most of these third party sites go too far and provide processed data pie charts or summarized charts for example i go here its great but i am trying to get the data that led to what they got basically i am trying to replicate what this website does but i do not know where to get the data in csv form any help would be greatly appreciated,need help trying to find raw census data for tracts in csv form,looking for data on gender wage gap between men and women
1171,hello there i am a year old with a ba and ms in speechlanguage pathology and am currently working as a fulltime speechlanguage pathologist but am hoping to make a career changetransition into data science i have always had a strong interest in mathematics data analysis and computer programming with a natural inclination to discover explanations for the seemingly inexpiable so i feel data science a natural fit because my background is not related to computer science mathematics or analytics i will have to return to school to get a relevant bachelormasters presumably one in data science although i hear data analysiscsmathstatistics degrees allow for entry into the field as well the uncertainty of leaving a career with excellent job security for one i am less familiar with is foreign territory but have found the presence of a subreddit dedicated to data science comforting i was wondering if any of you had advice for me in steps i should take in maximizing the likelihood of a successful data science career transition based on reading the subreddit and pages that appeared on google it seems i should be focusing on learning programming languages such as python sql and r prior to school i do not anticipate being able to learn these languages or even one in its entirety prior to starting school again but they seem like baseline skills for work that are glossed over in noncomputer science programs i am in the process of applying to data science programs in my area near providence rhode island is anyone familiar with the quality of the data science programs at university of rhode island university of massachusetts dartmouth andor bryant university i am looking for physical schools that are both nearby and affordable although have not entirety ruledout online programs i hear uc berkley has a solid program umass dartmouth has an accelerated bs to ms degree program that would theoretically allow me to get out of school in back into the work force at a faster rate my gpa was gt and in undergrad and grad school respectively in the event that helps you to recommend programs once i have my bachelors is there a type of entrylevel position i should look into so i can transition into a more competitive job upon receiving my masters lots of questions with very few answers at the moment i sincerely appreciate any advice you folks are rdatascience can give me in advance,tips for a career transition into data science,is a masters in data science worth it if i already have a job as a data scientist
1172,hello all i am a student doing rd year infosec degree joined months intern in ds company they told me remote internship because far distance amp no money because exp gained they wanted me to make python scrapers then deployschedule online amp make then broad scopelike for fb instagram etc every weeksthats days a week so that is days they trash my scripts amp give me new scope because they changed plans then they blame me for being lazy they make me come ever one every week in a month for nothing no help also they tell to google if not found then blame me for docker app bug _ wtf is this shit i wrote then all the above more elaboratory gave mathematical equaltions dividing how i spend my rs like a codeslave everyday will they fire me for all this should i complain to the university or wait for now,my internship is troubling me how to not get fired,is it worth spending hours a day a week at a data science job
1173,my advisor will teach a ml class for the first time next semester and she has been looking around for a textbook for a while because in our university there are statistical learning classes i amp ii she wants to focus her ml class on nonstatistical methods the idea is to first give an introduction to all ml methods and then elaborate on the nonstatistical ones today i recommended her this book understanding machine learning from theory to algorithms and she said it does not elaborate on nonstatistical methods enough by nonstatistical shes referring to things like neural networks reinforcement learning genetic algorithms decision trees support vector machine does anyone have a recommendation that fits this criteria thanks,textbook recommendation for nonstatistical machine learning,is there a general consensus to which machine learning textbooks should i read
1174,video paper abstract semisupervised domain adaptation ssda aims to adapt models from a labeled source domain to a different but related target domain from which unlabeled data and a small set of labeled data are provided in this paper we propose a new approach for ssda which is to explicitly decompose ssda into two subproblems a semisupervised learning ssl problem in the target domain and an unsupervised domain adaptation uda problem across domains we show that these two subproblems yield very different classifiers which we leverage with our algorithm mixup cotraining mico mico applies mixup to bridge the gap between labeled and unlabeled data of each individual model and employs cotraining to exchange the expertise between the two classifiers mico needs no adversarial and minmax training making it easily implementable and stable mico achieves stateoftheart results on ssda datasets outperforming the prior art by a notable margin on domainnet,d a brief paper review mico mixup cotraining for semisupervised domain adaptation,research a new approach to udacity sgd regression
1175,so i have started studying about capsule network for my classification project and thought about giving it a shot above my cnn implementation but i saw that it takes about to mins to complete only one epoch whereas my cnn model takes hardly seconds my laptop specs th gen i gtx ti gb ddr ram and i have also noticed that it is been a while since it was introduced but it seems not many people are implementing this what is the reason ps i did not complete my training of the capsule network as it was taking a really long time on my computer and did not want to invest my time if it was not much benefitial,what is the status of capsule network rampd,is it worth spending hours on a pc for deep learning
1176,i am new to the study of computer science but have found it to be the career path i lost want to go down i was recently presented with the opportunity to apply for this internship learning data science or alternatively software engineering i am extremely interested in ai research but i found that when it comes to cs a lot of career paths interest me in the field ive been told that data science tends to be uninteresting and math heavy while software engineering is far more versatile and useful i should also mention i have dyscalculia a math learning disorder so i worry that the disorder will make it harder for me to understand certain concepts though im willing to try regardless in the experience of people on this subreddit what is the more important branch in ai research software or data science which career path is the better bet long term i see varied answered when i google this,is going into data science ideal for ai researchengineering,is data science more useful than software engineering
1177,i have yet to finish a degree in anything but i hate my current career choice and am considering going back to school and making the jump to ds looking for some honest feedback here as a year old woman is it even worth it i am wanting to do the full degree program because a i really want the foundation in statistics mathematics and comp sci b i did the cert program for my current career project management true fact its a shitty thing to go into if you do not love communicating with irresponsible people and i really had to fight to get noticed i am wanting less of a fight to stand out also that is the second reason for the degree so with my age and gender is it worth it,making the jump,is it worth getting a second bachelors degree
1178,i am working with the stanford imageparagraphcaptioning dataset i wanted to see how many imagecaption pairs the data set had so i downloaded the dataset which downloads paragraphs_vjson and wrote the following code import json with open wouldesktopparagraphs_vjson as json_file data jsonloadjson_file printlendata was the output just for a sanity check i then downloaded the training val and test splits and tried to see if their total sum would give me the same number with open wouldesktoptrain_splitjson as train_split train_split_data jsonloadtrain_split with open wouldesktopval_splitjson as val_split val_split_data jsonloadval_split with open wouldesktoptest_splitjson as test_split test_split_data jsonloadtest_split printlentrain_split_data lenval_split_data lentest_split_data was the output exactly short of what i expected i have no idea why this simple sanity check is not working any ideas,stanford imageparagraphcaptioning dataset confusion,how do i train a cnn to work with multiple data sets
1179,i joined a company after finishing my masters with a sr ai engineer title in the bay area after about a year i was promoted to staff engineer now im thinking of changing jobs but have to come to realize that my company has inflated my title im having to answer awkward questions in interviews about why my title is that of a very experienced person im also concerned about a job change looking like a step down in my resume since ill most likely get something like an engineer position do you see this situation as a problem i suspect its because ai practitioners command a higher salary in the bay area than the companys salary levels allowed for entry level jobs so to provide us with a competitive salary our titles are inflated its a healthcare company,joined a company with an inflated title now what,how much do data scientists get paid
1180,hello hope i am posting in the right place i have a project i am working on in which i have many pdf documents i need to flag those which have handwriting in them and ignore those that contain only printed text most of the documents are scanned documents and all have been ocred my language for this project is r and and notably i am using the package pdftools i tried to identify handwriting by assuming that those documents which were handwritten were poorly ocred which is often true and extracting sequences of characters that did not make sense ie text like this _ however this method is not reliable and sometimes just finds those documents which are not handwritten but are of poor digital quality i am looking for some ideas on how i might go about this any nudge in the right direction would be helpful,looking to identify document has having handwriting not ocr,how do i use ocr for text extraction
1181,hej i am working on a project that requires me to find a shortlist of candidates out of a couple thousand possible solutions now i have some descriptors and a very computationally intensive way of accurately scoring my solutions so i can only sample around of the potential solutions i already have a potential solutions that have been scored but they have been hand picked and are somewhat similar i have been reading about optimization algorithms in the context of the optimization of machine learning hyper parameters but those mostly seem like continues variables and you can chose the parameters independently i was wondering if you guys had any opinions on what would be the best way to approach this my first instinct would be to take a random sample and than combine the outcome with the already tested solutions and than basically do hill climbing using the descriptors to find similar solutions to the best candidate found so far interested in hearing your opinions cheers fpm,algorithm for optimization problem with discrete number of solutions,looking for a data set with multiple variables
1182,hi i have recently fine tuned the m gpt model on top domains and their content to generate domain names in addition to the domain name it also generates what the company is about sometimes it just makes up some new business domains out of nowhere maybe i should brand the product as random startup idea generator you can test it yourself over here some examples the nonprofit that builds homes for people with special needs in minneapolis minnesota firstpointhomes org a melbourne based vape shop servicing all your vaping needs we stock a wide range of vape products including starter kits atomizers vv mods rda and more home to vapors shield starter kit atomizer rda and more gamevape com temura cloud is powered by google cloud install and run any nodejs app on top of temura cloud temura io our cloud resourcesolutions help you take full advantage of the benefits of hybrid cloud computing on your data center data center or even in your data warehouse hybridize your clouds with our easy to install coolers and storage solutions and you will be well on your way to having a fully functional environmentally safe computing environment that you can confidently count on configur co i will open source the code shortly on with a medium article let me know in comments what do you think about it,p fine tuning openai is gpt model to generate domain names,best cloud storage options
1183,a team of researchers from google brain in zrich and deepmind london believe one of the worlds most popular image databases may need a makeover imagenet is an unparalleled computer vision reference point with more than million labelled images it was designed for visual object recognition software research and is organized according to the wordnet hierarchy each node of the hierarchy is depicted by hundreds and thousands of images and there are currently an average of over images per node in a paper published last year the google brain zrich team proposed big transfer bitl now a sota imagenet model looking at what were considered mistakes in bitl google brain researcher lucas beyer suggested most of these could in fact be label noise rather than genuine model mistakes to quantify this idea beyer and his google brain colleagues joined deepmind researchers in a recent study to determine whether recent progress on the imagenet classification benchmark continues to represent meaningful generalization or whether the community has started to overfit to the idiosyncrasies of its labeling procedure here is a quick read google amp deepmind researchers revamp imagenet the paper are we done with imagenet is on arxiv,r google amp deepmind researchers revamp imagenet,google researchers propose a new deep learning approach for image labeling
1184,hey there new to the career on my first contract and things are challenging i need assistance in building a pipeline that can tokenize powerpoint pdfs as well as scrape webpages without any fine tuning i am basically building an application for the client in python where they can input a pdf or webpage a set of terms and then the model outputs visualizations regarding the terms within the submitted pdfwebpage the outputs need to be greedy and output any numerical values associated with the term example input documentwebpage reportpdf input terms word words phrase of importance isecond phrase output word sales increased phrase of importance was reduced million of words was sold last quarter i have written the model which is greedy and works decently well when given strings or documents i have written but building a reliable and low maintenance pipeline is where i am struggling as well as developing it in an application please note i am the only person on this contract and they have no software engineers no data engineers no data departments they do not even have a database built yet i am storing all of the data i scrape myself getting paid hr for this so i would like to keep it going open to any and all help willing to skypezoom as well,building an agnostic nlp pipeline,is there a name for this type of model i want to use
1185,hello my name is thomas and i am doing my master thesis in economics this winterspring in doing this master thesis i wanted to look at salary dispersion in the nfl because i fancy the sport a lot and find the fact that the nfl has a hard cap interesting i am not quite ready with a research question yet but i have a theme and need to find sources to find a good dataset and help with choosing the best possible model for predicting how salary dispersion influences the actual players i already found that sportrac and capology have a lot of good data but that data is more about teamplayer performance i think any help is greatly appreciated and i would not discard anything,need some professional help for master thesis data set,looking for sports related data sources for master thesis
1186,hello i am somewhat new to looking at residuals to assess how well a glm is fitting this is a link to crunched deviance residuals with predicted frequency on the xaxis and the residual on the yaxis i am concerned because these residuals are less than zero and because the residuals tend to become more negative as the frequency increases these residuals are coming from a glm using the poisson family and a log link in case it is helpful this is in an insurance setting where the frequency is about what do you think are these residuals a sign the model is not performing well if so what can i do to improve the model performance i could tweak variable bucketing definitions more but i cannot tell if this is a sign that there is something systemic wrong with my model could using a negative binomial distribution help standardized pearson residuals were centered around zero and looked pretty good but i have read deviance residuals are generally more indicative of performance,crunched deviance residuals,is there a negative residual feature in a regression model
1187,hello i am doing my master thesis and a question that i have right now is how to improve the automation tests the company that my thesis is part of wants me to do a framework or something that can select tests to run when a piece of code is changed or when a feature is added i have been looking into it but without any luck does anyone here have experience with this can anyone provide papers that explain this in theory or the type of ml algorithms that would be the best for this situation or tools that already implemented this or source code thank you very much in advance and hope you guys have a great day,question machine learning and automation tests how can i use it,how do i go about creating a feature testing system for my master thesis
1188,hello there is a deep model for prediction the outputs are some numbers between and in the dataset the outputs are i built a model and its loss value equals to and i would like to reduce it i printed the outputs after evaluating the model by test values and some of the predicted values are more than or less than i decided to set up the final layer to predict just in in training step therefore i set a lambda layer after final dense layer to clip output values the codes def relu_advancedx return krelux max_value def createmodel model modelssequential modeladdconvd activation arelu input_shape padding isame modeladdmaxpoolingd modeladdconvd activation arelu padding isame modeladdmaxpoolingd modeladdconvd activation arelu padding isame modeladdmaxpoolingd modeladdflatten modeladddense activation arelu modeladddense modeladdlambdarelu_advanced modelsummary return model i tested the model with and without the relu_advanced and unfortunately the loss value is increased i do not know what may happend that the loss is increased while there is no value much than or less than zero thank you,restricting the output did not improve the loss value of the model evaluation,why does the loss function in keras always return the same result
1189,hi is there a name for the process of buildingvalidating a model of individual behavior when you only have aggregate data available for the response variable but do have individuallevel data for the predictor variables i have tried googling various things and cannot get anything to pop up i am hoping to find a book or two on the subject my particular usecase is i have lots of variables for voters age sex zip code etc i would like to predict if they will vote democrat or republican but i only have precinctlevel results precincts vary in size from registered voters to but most are around i have precincts in my mind a good model would cause my predictions for individuals to create similar results to the actual precinct results when aggregated a second related question what is generally considered best practice when using census or similar aggregated data as a predictor variable for instance if i have the median income for a census block is it ok to simply assign this to an individual living in that census block this seems a little simplistic so i was wondering if there are any good resources particularly books on the subject thank you,validating models for individual behavior using aggregate results,looking for demographic data for the us primaries
1190,quick background i have minimal knowledge in this field currently working in healthcare and found myself moving more towards project manager type work in the process of trying to decide the next step in my career i found myself looking into and enjoying data analytics i completed sql and python classes through code academy and enrolled into udacitys data analytics nanodegree from there planning on my bs in management data alytics from wgu starting in july while looking on indeed job titles seem to overlap and jobs skills are all over the place my ultimate goal would be to work as an epic analyst however there are so many option i just dont know what direction to go once completing schooling the more i look the more option come available also im in washington state so opportunity seem to be plentiful right now any help would be great,can someone define data analysis scientists engineer and architect please,is it worth getting a masters in data analytics if i already have a job as a data analyst
1191,hi everyone i am a yale grad in economics and math ba who is been working as an actuary for about six months the data science department at the company i work for has an internship for master is degree students next summer application due in about a month i have passed five actuarial exams in one year so i should basically have my asa requirements done by june the average to attain asa is over four years i have scored highly on every exam and i already have some insurance domain knowledge so my hope is that they will consider me despite the lack of a master is so far i have gone through introduction to statistical learning applied predictive modeling regression modeling with actuarial and financial applications r for data science r graphics cookbook i am also pretty proficient in general use python if i want to maximize my chance of being considered for this internship what i should i learn do over the next month do i need some kind of project i was thinking about building an nfl spreads predictive model but i would rather not spend all month on one project if i would be better off taking some online courses or something,finished isl and applied predictive modeling what can i learn do in a month that can get me an internship,is it worth spending a month learning r or python for a data science internship
1192,hello all quick question about spacy ner let is say i train a spacy model to identify brand names and in the labeled data i am using the word apple is tagged as brand and amazon is not but i augmented this spacy model using word vectors would this spacy model be able to extrapolate that amazon is also a brand based that apple and amazon are similar words and apple was tagged as brand in the training data even though amazon was never tagged in this same training data i am actually working on a ner model to extract technical keywords out of a document but there are countless keywords including skus etc so creating a master list of all the keywords is not feasible if ner will not work for this problem does anyone have any other ideas thanks,question about spacy ner,how do i track a specific person based on their name
1193,while i do not want to overstate the complexity of the field days is awfully short spend most of my time on the basics of statistics then have a look at or very common techniques eg linear regression and logistic regression take a dataset that interests you and do some descriptive statistics on it counts max min median plots etc and discover as many weird things in the data as possible weird meaning stuff that does not seem right now try to answer a question for yourself on the above dataset do this by a solving the weird stuff b getting the data into a format that works for c one of the common techniques you studied it is okay if you hack the code together with lots of googling do sanity checks on your results though allow me to elaborate a bit basic statistics one of the most easy pitfalls is to just take offtheshelf implementations of algorithms and throw them against your problem but most algorithms are based on assumptions and all of them have some limitations a good grasp of basic statistics will help you determine whether the assumptions hold what they mean for your choice of algorithm reason about the limitations they imply the impact if they are not present which is not always dramatic any time spent here will pay dividends every time you have a look at a new algorithm so no worries if this takes up nearly all your time common techniques early on you actually better go deep than broad because many conceptselements return any way in other algorithms i mention two types of regressions because in many cases you will get a decent answer with these techniques also it is in some sense amazing how something that is basically wouldraw trendline in excel actually goes so deep not that all of it is taken that heavily into account in practice but it still is good to have it in the back of your head especially for those times where you get weird results weird data stuff this is the largest timesink always and it is very important hence the mantra garbage in garbage out take any realworld dataset which has not been precleaned and you will find weird things a hugely overrepresented value companies who like to code missing as duplicate id is a variable which is actually an id amazing how many student dreams are shattered by pointing this one out if they have a nearly perfect model missing values mislabeled cases misspellings everything is on state level except for this one state for which they are reporting counties instead you need to experience it to acknowledge it and almost any realworld dataset a critical eye will make you do just that try it well you did not learn all this not to use it right also making sense of your results is important and being critical for them as well it is so easy to make a logical mistake which is not programming mistake ie the software will run but the result will be very wrong if you want to go all the way take your results to a friendfamily and try to explain highlevel what you did what the results are and what they mean again speaking from teaching experience there are people who are really good at the technical stuff but cannot transfer the relevant implications of it to a nontechnical person,how should you plan your day to learn machine learning in days,how do you deal with bosses that do not understand data science
1194,i am interning at a company that is growing a community and my current task is helping them set up analytics dashboards for the customer service team we want to understand how many messages are coming by hour so that we can give the cs team more relevant shifts the problem is that we use an automated chatbot whenever someone visits our page a messenger dialogue pops up asking interested users to type a set command to get more information this means that there is a huge discrepancy between the amount of messages we receive and the amount of true inquiries that we receive to solve this i have done the following created a graph that displays user activity by overall from yesterday i have applied a filter to this graph show that only users who performed the event messages received where event count is at least are included this narrows the population to around finally i have had this graph organize the information by number of events that occur hourly ampxb so i assume that this graph is showing me the amount of conversations by hour in which a user sends at least two messages meaning any conversation in which the person sends a message behind the command to initiate the bot comparing the chart to the number of messages we receive on our cs platform it seems relatively accurate but to get a bit more information i duplicated the graphs and changed step three i created two separate graphs that show information organized by unique users on an hourly basis and information organized by average number of events per user on an hourly basis this is where my confusion comes in the relevant graphs display the following information ampxb at there were events performed i assume this means conversations in which messages were sent by the customer that being said there were only unique users and on average each user completed events but looking through the messages that came in last night at there are actually ampxb total conversations that of them are from one of our other accounts testing new chatbot commands none of these conversations had more than messages that seems to mean that all of the information i received from fb about messages received last night is false that being said information received using the same filter about messages received during the hour period is accurate can you help me to understand what is going on,fb analytics seeking confirmation that filter does what i think it does,how do i deal with fake accounts
1195,hello for my bachelor thesis i chose to work on a facial recognition project and i was assigned to implement a cnn model to identify employees in the workplace i had almost no experience with any kind of programming so the first step was to inform myself on the subject of machine learning and neural networks i took some online courses to learn the basics and moved on to research what were the stateoftheart technologies used in this field as i continued my research i found myself interested in the lightweight models that do not use very deep cnns squeezenet mobilenetv i plan now on learning about mtcnn for facial detection and alignment then maybe add a mobilenetv model for recognition and use triplet loss or a cosinemarginbased loss because this is my first time working on a project involving a lot of programming i have never worked on python and have only some basic knowledge of c i find myself lost at what steps to take i have decided to focus on getting so basic jupyter knowledge since i will be using google colab and pytorch but still feel lost and overwhelmed when looking at github repositories no idea how those things work and those looong lines of codes my questions are do you have any tipsadvices for a beginner like me i plan on allocating months to this project do you think that is a sufficient amount of time ampxb thanks,helpful advice,how do i go about building a facial recognition model from scratch
1196,i have been using anaconda for the past years now i am not by no means accusing anaconda package as useless or unwanted they actually did a pretty good job at packaging stuff and make the whole dependencies easily manageable i have read many books on the topics related to data science and ai almost all of them taught to use anaconda or else something readytofly like colab i was wondering is it actually the way a software engineer would really like to do their stuff coming from an applied math major i just felt like never actually got into much of hacking stuff before and programming for pure fun so the other day i tried to read the documents of pip virtualenv pipenv etc to finally come clean independent from anaconda and create my own version of a stack but i took me more than hours and no result got frustrated and ignored the task for later that is the reason i am coming to discuss this to you guys somehow i do not want to let that idea goes off at the same time i am not willing to go into the nuts and bolts of diy will you guys help me or at least point me to some stepbystep tutorial or any book that discuss such tinkering thanks in advance,how to create your own python toolbox,how do you go about building your own ml projects
1197,so i have just started playing around with rnns lately and can manage to do some simple stuff like word and char rnns but i have a problem i would like to tackle that involves multiple sequence types and i am not sure if it is possible to implement in a rnn to elaborate a bit on what i mean by multiple sequence types i have several thousand numeric sequences of differing lengths which i would like to train on and then use the model to predict new sequences however for each of these numeric sequences i also have an identical length sequence made up of letters the letters have some effect on the numeric sequences though i am not sure how much of an effect and so i believe the rnn should be able to use the letters sequence to improve prediction accuracy so rather than feeding the model a list of sequences in training and then predicting new sequences i want to feed it two lists in training one numeric sequence and one letters sequence and then when the model is built i will give it a sequence of letters which it will use to predict a numeric sequence anyone know if something like this is possible or know of any similiar examples this is probably explained terribly so just ask for clarification if needed thanks,rnn with multiple different sequence types,how to train a neural network to predict a sequence
1198,hi all i am working on a project in which i have created public use microdata this dataset will be published and i am currently working on completing the user guide and documentation files i have formatted all of my variable groupsdescriptions in formatted tables seen in social survey dataset documentation and have made everything look purdy s of tables the problem is it is so tedious to copy these over into wordformat in excel for image export etc i know there are packages for this type of thing r lang but i needed to do some very particular formatting and thus endless hours were spent in excel doing so so what i am looking for is a document formatting software mac or templates word google docs etc resources that would make this easier i am looking for something that handles tables and figures well can easily be places and moved around etc while at the same time isnt limited when it comes to text formatting i am open to manuscript editors as well i have ulysses but it does not really have the formatting power i am looking for anything that could help is greatly appreciated,documentationuser guide formatting help,how do you organize your data
1199,i am doing the guide that is linked in wiki for engineers right now i have more weeks to go to finish the coursera class i understood the theory and did all the assignments as best as i can using vectorized implementation etc doing ungraded assignments etc now i want to plan what to do next so i do not fly blind once i am done with the course coursera recommends me a course called neural networks for machine learning by university of toronto i am in deep learning path is this course worth it there is also the following courses or should i ignore these and go straight to reading the deep learning book,what to do after finishing coursera course,how do i go about learning about deep learning
1200,i am trying to calculate an estimated time of arrival of truck t located at point a to point b here is a list of data sources wiki there may be more out there the objective is to calculate an estimated time of arrival assuming t is already following the fastest route there is no need to direct the truck just calculate an estimated time of arrival this is step one of the problem step is to be able to use previous data of other trucks tsubn to calculate a better estimation of time in case of traffic road outages etc i am not to worried about figuring out step yet i just have a problem in that i do not even know where to get street data speedlimit data and whatever else i could be missing,data source and gis to use for this problem,how to calculate arrival time of a specific vehicle
1201,does anybody do a lot of causal inference i recently looked into dowhy and ananke but i have found these to be very black boxy like its not clear what its estimating and how it got there i need to do a mediation analysis both with just mediator and also with multiple and need to potentially use glms outside olslogistic and also survival models im pretty new to this area i looked at the mediator r package and seems like it can handle this but just mediator i want to have multiple so i looked into dowhy and ananke in python but these packages are feeling like a black box and i dont know how to interpret the final answer very well also for simple cases i was getting different answers to the mediator package also how complex of a causal model do you generally build the idea of causal inference over ml is interpretability but when you add so many things into a dag it starts getting as black box as ml and is the effect from the causal inference methods ever truly causal when you dont ever know if the assumptions hold is it just a fancy way of deriving better associations,what causal inference packages and models do you use,how do you deal with missing data
1202,i was thinking of applying to the program but i noticed one thing selfdirected no classes in the faq it seems like the time spent is intensive and i was told by a person at insight that i cannot do anything else ie take classes to finish degree while in the fellows program anyway i was wondering what your thoughts were of the program what made it intensive i read that you have to come up with your own project is this a project you work with other fellows while i can get coming up with some sort of project for the data science fellows program i am not sure how that applies with the engineering side of it,has anyone gone through the insight data engineering fellows program,is a data science masters worth it if i already have a job
1203,so a bit of background i am yo for a start really good at mathbetter than my classmates anyways and a programmer i started andrew ng is course on coursera in the summer vacation finished it in about months all i did after that was trying to completely rewrite the course assignment using only numpy the main reason for doing so was to understand the backpropagation algorithm the course did not explain why it works when school came around i was forced by my parents to focus on my studies winter vacation came after and i had time to start andrew ng is other course about convolution neural networks and everything went fine i finished it just before vacation ended did a few projects autoencoders blah blah blahetc and i felt like a god until i tried to read one of the research papers and i could not understand jack shit and then i opened the research paper that broke me generative adversarial networks by ian j goodfellow i spent weeks trying to understand what was written in there forcing myself to grasp what is in there learning probability which i always hated therefore did not touch looking at different resources and demistificationetc until i finally gave up and dropped the whole thing but i found myself not able to focus as i used to for a few weeks and just thought of myself as less smart than what i was before my confidence and selfesteem got reduced and most importantly i was afraid of solving hard math problems that i always enjoyed even when i could not crack them i have now to force myself to code some simple stuff like mp tag editor and now about two months later when i wanted to go back continue practising i was afraid again what can possibly be happening and how can i reverse it what should i do please help,i started learning data science a few months ago and now i am afraid of touching the keyboard d,is it just me or is deep learning so much easier now than it was a few months ago
1204,hi everyone i recent started my job in one data agency at the entry level after graduation the data agency is doing sort of social listening ironically they hired me because i had written script to automate the process of producing powerpoint it was my mvp to show them while i was dloing internship but at least it works anyway i am really confused at my job where all my colleagues do not have programming background and they use data science toolplatform to process data or filter data from my point of view it is quite not what i learned in uni school projects are focusing on classification optimization algorithms etc however it is more predictive datasets and my job is to deal lots of descriptive data ie text data i am pretty upset about this situation where i did not enjoy that much it is pretty dummy manual stuff i still do not understand these values of data science tools what should i combine python or simply use python the worst thing is the company expects me to do innovation without telling me how to do it would like to hear more opinion from you experts on reddit thanks,ominiscope vs python r,how do you deal with bosses that do not understand data science
1205,i am a materials engineer who has integrated machine learning into my current role at an industrial materials company over the last years i have started looking for jobs to test the market for data scientist job titles and got a few hits with my background manufacturing companies had a higher hit rate than other companies i have an offer on the table for a fully remote position in a manufacturing company headquartered in the ca the position is within a newer analytics organization the data infrastructure seems to be better than i have seen in my current company but not fully established the role focus is a bit vague so proposed projects had pretty big range of topics the offer seems pretty good for nonfaang and fully remote k total compensation in my current mcol city but i have some reservations about the position fully remote seems to be new to the company but this group is being staffed with remote positions i may be open to relocation in future but want to stay away from hcol areas if possible team is very new and small so expect heavy workload to show value the company has been making public statements about big dataai but not sure if fully committed beyond buzzwords company has analytics center in india which is not uncommon in manufacturing but i have concerns about growth of us team vs growth of india team going forward i would greatly appreciate any input or comments on this opportunity experience with new data science teams or any thoughts on data science in manufacturing,job offer in manufacturingiot,remote data science jobs in manufacturing
1206,so the title is not really giving much information about my problem sorry about that but i could not find something short to describe it i am currently trying to come with a neural network which will receive a window of images in a video and predict if there is a specific event which occurs to elaborate more about what kind of videodata i am talking about i will give a short explanation i am working with cellularbiology cells data videos of them the task which i am currently facing is taking labeled data of cells which are going to undergo an event of fusion meaning they will start disappearing i want to use deep learning to detect those events in real time and apply something to the celldoes not need to concern any of you i have background in deep learning but cannot find a good state of the art suitable solution to my problemi am not really sure what is state of the art or not but do not want to be wasting my time on toy examples that have no chance of working in the real world will a simple lstm net will do the trick if so how can i train my model to say whether there is an event or not in other words what will be the target simply ones and zerosindicating there is an event or not i am not really sure what path to take since there is too many complex information on the internet hoping someone can give me some advice,detecting specific events in videos using deep learning,looking for advice on how to approach a problem
1207,hi everyone i took a job as a data consultant specifically on data scienceanalytics my specific role has been outlined to me on basically client interaction and technical work we will mainly be working in sqljavapython im super excited for the opportunity ill have months of training but im still looking for outside learning to get me comfortable in the field and introduce me to the field i have a financeecon background data analytics concentration and i believe i was l chosen because i have a strong sense of business acumen that will help me on the consulting side but i fear im a little weaker on the actual data side does anyone have any good resources to help me anything helps,incoming consultant in data scienceanalytics field learning opportunities events to follow books to read podcasts to listen to anything helps,data science career advice
1208,im currently a data analyst although most of what i do is actually financial analysis with a bs in economics and a minor in biology im in a unique situation where my employer will be paying for me to obtain a second degree ive decided to put this to good use and pursue either a second bachelors degree in computer science or a masters degree in applied statistics with the ultimate goal of landing a data science job either within the organization or outside of it both degrees would take roughly an equal amount of time to complete and cost is a nonissue but i cant seem to decide between the two i did some research but couldnt find a definitive indicator either way which degree seems to be the best for the resume if my ultimate goal is a data science gig,bs in computer science vs master of applied stats for ds jobs,is a data science masters worth it if i already have a job
1209,i am looking for an algorithmic framework that can help me do steps and of the following i am not responsible for the implementation only for coming up with a framework for the backend algorithm ampxb algorithm step use fuzzywuzzy to compare a word against a library of words and determine the best match algorithm step use existing tuples of word correct match from library that were manually matched in the past by individuals to improve the algorithm from step algorithm step allow users of this application in the future to identify errors in the matched words and choose the right match manually when they choose the right match it feeds into the algorithm to improve it ampxb any advice you have would be much appreciated thank you,what kind of algorithmic framework can i use to do the following,i am trying to implement a word matching algorithm and i have a question
1210,how does intellectual property work for published research based on approaches developed while consulting for a company for example let is say i am working as a consulting data scientist at walmart while working there i develop an interesting modeling methodology i want to publish a paper on and give conference talks about since walmart hired me they own my output if walmart is ok with me publishing the research methodology as long as they retain rights to the research how does licensing work since i would be publishing based on work they paid me for in a software context it seems similar to open sourcing some code i developed under a specific license such as gpl or mit,consulting data scientists how can i publish research based on consulting work for a company,licensing issues for research
1211,hi i am trying to train a gan on the mnist fashion dataset but whenever i train the thing it keeps returning each epoch w tensorflowcoredataroot_datasetcc optimization loop failed cancelled operation was cancelled w tensorflowcoredataroot_datasetcc optimization loop failed cancelled operation was cancelled w tensorflowcoredataroot_datasetcc optimization loop failed cancelled operation was cancelled w tensorflowcoredataroot_datasetcc optimization loop failed cancelled operation was cancelled w tensorflowcoredataroot_datasetcc optimization loop failed cancelled operation was cancelled w tensorflowcoredataroot_datasetcc optimization loop failed cancelled operation was cancelled it does not seem to actually train every time l look at the generated images here is the code import tensorflow as tf from tensorflow import keras import matplotlibpyplot as plt import numpy as np x_train y_train x_test y_test kerasdatasetsfashion_mnistload_data x_train x_train def plot_multiple_imagesimages n_colsnone n_cols n_cols or lenimages n_rows lenimages n_cols if imagesshape images npsqueezeimages axis pltfigurefigsizen_cols n_rows for index image in enumerateimages pltsubplotn_rows n_cols index pltimshowimage cmapbinary pltaxisoff nprandomseed tfrandomset_seed codings_size generator kerasmodelssequential keraslayersdense activationselu input_shapecodings_size keraslayersdense activationselu keraslayersdense activationsigmoid keraslayersreshape discriminator kerasmodelssequential keraslayersflatteninput_shape keraslayersdense activationselu keraslayersdense activationselu keraslayersdense activationsigmoid gan kerasmodelssequentialgenerator discriminator discriminatorcompilelossbinary_crossentropy optimizerrmsprop discriminatortrainable false gancompilelossbinary_crossentropy optimizerrmsprop batch_size dataset tfdatadatasetfrom_tensor_slicesx_trainshuffle dataset datasetbatchbatch_size drop_remaindertrueprefetch batch_size def train_gangan dataset batch_size codings_size n_epochs generator discriminator ganlayers for epoch in rangen_epochs printepoch formatepoch n_epochs for x_batch in dataset phase training the discriminator noise tfrandomnormalshapebatch_size codings_size generated_images generatornoise x_batch tfcastx_batch tffloat x_fake_and_real tfconcatgenerated_images x_batch axis y tfconstant batch_size batch_size discriminatortrainable true discriminatortrain_on_batchx_fake_and_real y phase training the generator noise tfrandomnormalshapebatch_size codings_size y tfconstant batch_size discriminatortrainable true gantrain_on_batchnoise y not shown plot_multiple_imagesgenerated_images pltshow train_gangan dataset batch_size codings_size ampxb i am using aurelien geron is handson machine learning with scikitlearn keras amp tensorflow here is the repository hope this is the right sub for questions,problem with training a gan in tensorflow,why am i getting this error
1212,hey all i am brainstorming some questions to ask when or if i get interviewed for different data science bootcamps galvanize metis and general assembly i was hoping i could get some more perspective on what i should be thinking about when making the decision to go with a bootcamp and also what i should be asking them i am still on the fence about joining an immersive program but i thought it would not hurt to apply and go through the interview process see below for a list of some of the questions that i have come up with placement statistics what are the number of graduates that get placed in a job within the first months or so who are the professors mentors and what are their backgrounds studenttoteacher ratio how active is the alumni network and how often do they interact with current students fallbacks of an immersive bootcamp how involved are the mentors in job searching after graduation any other questions or big ideas that i am missing big thanks,applied to data science bootcamps in san francisco what sort of questions should i ask them,data science bootcamps
1213,hello everyone quick question i am working on a low resource language that even large multilingual models such as mbert fail to represent properly so can i finetune these models on mlm just like they were originally trained and then finetune it again on a specific task in other words finetune mbert on the masked language modeling task using a domainspecific corpus finetune the resulting model on a different task say semantic analysis test the model does this make sense is this equivalent to training a bert model from scratch using the same multilingual corpus in mbert with my corpus added to it or is it different if so how is it different thank you for your time i really appreciate any knowledge on the matter,does this process make sense finetuning a bert model twice once on mlm and then a second time on a specific task,question about using bert for multidomain modeling
1214,every time i think about this thing i go in a downward spiral of depression i am at that point in my career where i am not really sure if i want to go into data engineering or machine learning i have a little exposure to both sides and am not sure yet which one i like more as we know the whole machine learning pipeline has a lost of steps ranging from data collection aggregation cleaning the whole process of creating the model and eventually deployment which part of the machine learning process will you think will be automated in the near future what should i focus on more right now if i want to be future ready i have a background of bachelor is in computer science,concerned about automation in machine learning,what is your data science roadmap
1215,hello everyone a number of volunteers product software management backgrounds are trying to build a model to predict how oxygen demand will shape when supplies improve they wish to be able to help agencies distribute to the correct places logistics issue as you might imagine there is a model they are trying to build but too many unknown variablesuncertainties do we have folks in data science who can help even if you can add a little it helps a lot if you know folks with relevant forecastingdemand prediction experience it could be immensely valuable we can share whatever data points we have but most people in this sub probably already know what this entails thank you so much,covid india related ask,looking for a data science mentor
1216,stellargraph is an opensource library implementing a variety of stateoftheart graph machine learning algorithms the project is delivered as part of csiros data we are thrilled to announce the major milestone of a full release of the library the culmination of three years of active research and engineering v extends stellargraph performance and capability with new algorithms for spatiotemporal data and graph classification an updated stellargraph class and better demo notebooks and documentation new algorithms include gcnsupervisedgraphclassification supervised graph classification model based on graph convolutional layers gcn deepgraphcnn supervised graph classification based on gcn a new sortpooling layer and asymmetric adjacency normalisation graphconvolutionlstm time series prediction on spatiotemporal data combining gcn with a lstm model to augment the conventional timeseries model with information from nearby data points enhanced algorithms deepgraphinfomax can be used to train almost any model in an unsupervised way for example hinsage for unsupervised heterogeneous graphs with node features unsupervisedsampler supports a walker parameter to use other random walking algorithms such as biasedrandomwalk in addition to the default uniformrandomwalk the new release incorporates extensive performance enhancements some of which include stellargraph class now faster easier to construct and smaller with reduced memory usage to support larger graphs better demonstration notebooks and documentation to make the library more accessible to new and existing users better neoj connectivity including graphsage neighborhood sampling from neoj and a demo notebook for loading and storing neoj graphs node feature sampling now faster via better data layout speeding up configurations of graphsage and hinsage addition of proteins dataset for graph classification demo creating a relationalfullbatchnodegenerator now x faster and requires much less memory x smaller jump into the new release on github stellargraph is a python library see full v release notes here we always welcome feedback and contributions with thanks the stellargraph team,r announcing the release of stellargraph version opensource python machine learning library for graphs,r announcing the release of stellargraph version open
1217,as the title suggests i m am looking for some advice on whether i should drop out from my masters in data science amp business analytics i am about months into the program total duration years but i feel that the pace is rather slow and for a person without any programming skills i am extremely worried that i will not be well prepared enough to land myself a job upon graduation on a side note i tend to learn more from a minute youtube video than the hour lectures at the university so there goes the question what is stopping me from dropping out if i am able to learn more at my own pace my second concern is that different classes are teaching in different languages for example we are learning r for machine learning sas for data mining python for deep learning on top of that seeing that most companies prioritize python as one of their job requirements at least in my country malaysia and knowing that i only have years to learn i am starting to wonder whether my time is being wasted on learning other languages and only to end up being proficient at none here comes the second question what is stopping me from learning data scienceprogramming from websites like freecodecamp udacity data camp udemy and people often only spend months on the online courses why should i continue the masters program is it really worth the time and money lastly the program does not offer as much practical work as i would have imagined to my knowledge employers often ask for your portfolio during the interviews and again the university does just the exact opposite of that as we focus mainly on theorybased assignments we do have capstone projects is that enough so the final question would be what is stopping me from dropping out to build a personal portfolio that i can actually show to the employers i sincerely thank you if you manage to read up to this point i have been questioning myself on whether my decision was right by enrolling into the masters program i do not have any seniors or friends who are in the field as i come from a psychology background so i am resorting to all of you in this community before i make any irrational or impulsive decisions once again i would like to thank you in advance for your words and advice much appreciated,advice needed to drop out or not,i am a year old with two years of experience in data science and want to make the jump to the next field
1218,i am extremely lazy by nature i hate doing work and always try to find the easiest way out machine learning is my ticket out of work through work there are countless of ways that i can think of machine learning can make things so much easier just today i found this website that google is marketing team sent me unrelated work stuff that just happened to use machine learning im currently working in the ecommerce industry working as an ecommerce specialistdata analyst with a strong focal endgame to be in machine learning but just from something small like that makes creating ads that much easier for me and my time i think something like that is amazing and it itches my scratch every single time not really sure why i posted this just wanted to share why i want to keep learning this industry,the only reason i want to further my learning in machine learning,how much do you use google analytics
1219,i have seen this practice done in blog posts and i wanted to get the opinion of the community let is say i have a regressor that predicts some continuous variable i can take some holdout data and make predictions with the intention of calculating the absolute value of the differences between my predicted values and the true values with that data you can train another regressor to predict with the same input data as your first regressor what the difference between the predicted value of your first model and the true value is likely to be with that you take your original models predicted value and the output of your second model multiplied by some z score depending on the confidence interval you are looking for almost treating the output of your second model as the standard error of your original models prediction to me this seems to be one of those cases where this practice is not exactly rooted in statistics but can be useful to construct these pseudoconfidence intervals my question to you guys is am i right to be critical of this practice or is there some statistical reasoning that validates this in any case i do see the usefulness of the approach but i question it is legitimacy what do you think,using regression to predict standard error amp confidence intervals,question about confidence intervals
1220,tldr i have been a data scientist for years now and with time i have grown quite bored and disillusioned with it and i wanted to figure out if it has happened to anyone else or i am kinda weird fellow data scientists i have a very unusual question to ask you i originally got into the data and analytics space working in operations research for a large ecommerce and logistic company from there i became a data analyst for a successful mobile app and then a data scientist for a boutique consulting company i currently work on building and deploying ml models for large clients on the azure ecosystem i also volunteer as a project manager for a data charity i basically experienced it all educationwise i have a msc in industrial engineering and management with a specialisation in operations research mathematical optimisation and a msc in computational statistics and machine learning from a top university in the uk both degrees awareded with distinction i also coauthored research papers on ml in journals and conferences sounds like a great career does not it actually i never truly enjoyed it despite data science is such a cool career on paper the things that bother me are i feel i am neither meat nor fish not technically skilled enough to be a software developer and being more involved in the development of the key features of the product nor soft skilled enough to play a pivotal role with the product business operations management team i have experienced how difficult is for a data scientist to change career path within an organisation my experience has always been that people who do not have our background tend to see us like curious animals who only love to play with data and to code and as a result of that we tend to be pigeonholed into our roles and discarded if any interesting opportunities arise within other departments of the company despite our subject matter expertise excitement for the product business and any soft skills we might have i have noticed how dss are almost never recognised and praised by the company is leadership team for their work as opposed to business managers pms swes marketing managers and designers i miss the tangible outcome of my work for most of the day i sit often lonely producing code but i cannot touch nor see the output of my code and that is frustrating because i feel that i cannot share my achievements with others including my family i think that if i were a civil engineer or even a software developer i feel i could feel way more excited about what i produce i am not looking for advice on how to mitigate my circumnstances at the end of the day i have decided that i will retrain myself in the field of chemical or sustainable energy engineering to overcome this disappointment and work on more meaningful projects and if i could go back in time i would not get into data science again but i wanted to ask if you or someone you know have ever felt the same sense of disillusionment or is it just me i have asked a few dss in person and no one has felt like this apart for not being praised properly thank you and sorry for the long essay,did anyone regret choosing ds as a career or has got disillusioned with it,data scientist to data engineer
1221,i wanted to know which tools and languages i should be learning so i manually collected the text from over job postings i wanted to be sure my time spent building sideprojects to improve my portfolio was wellspent i did a deep dive on the occurrences and cooccurrences of different tools languages and skills to answer that question the only way i know how with data i am a seniorlead data engineer so i specifically wanted to know how required skills would change with the progression from juniorgtdegtsrgtstaff key takeaways python and sql is no longer enough to stay competitive as a data engineer at top tech companies data streaming is hot and building portfolio projects that showcase your skills is one way to stand out in the market soft skills are king and a dedicate focus on improving communication management and continual learning is crucial to stay competitive here is the full writeup if there are any toolslanguagestechnologies that i missed please let me know i am curious did any of the findings surprise you i was surprised to see java as popular as it is for data engineers,analysis of faang data engineer job postings indemand skills for data engineers in,data engineer to data scientist
1222,i am fishing for new ideas on how to keep tabs on projects we had been using a trello board where each team member had a column that represented what they were working on that was a legacy from the previous dept head now as i keep writing business reviews and summarizing our work i realize there is these big projects that team members are working on for multiple months maybe multiple quarters examples paid search ds colab a number of attemptssuccess to add value over a month timeline continuing program own the company is daily sales forecast create model analyze previous model for quarterly catalog mailings use nlp and web scraping to suggest new products to our buyer team build out recommendation system manage reporting measuring of ab testing system manage slow effort to automate a ton of existing excel reports it just seems like these things do not change i am wondering what other ways people use to track a team is work,ds bosses how do you keep track of your team is projects,how do you manage your data pipeline
1223,hi guys imagine a data set where most features are there all the time but a few are missing for of records the complete records are too few to train a neural network so you want to make use of the data with missing features maybe a model can be first trained using only the features that are always present and then trained further a few iterations on data augmented with the rest of the features in the coming days i aim to obtain some experimental results as a sort of proofofconcept that such an approach is possible i would like to hear any of your thoughts on this matter so i can get going in the right direction straight away and get some valuable results thanks for reading and for your time,looking for guidance training neural net with some features missing,looking for data set with missing features
1224,so in my workplace my team which is data science and machine learning focused almost vanishes in months people left in july and more in october my boss also left the company two weeks after that hr is too fkn slow getting new people and suddenly i was literally alone in my team working with my exboss boss only at the beginning of november we hired someone and this week more people incorporated the team so i got super promoted salary increase and with the responsibility of managing a team of people where of them are literally new to the industry and no ml experience only theory right now i am working my ass off as you can imagine teaching the new guys and trying to keep the boat afloat with all the projects that were on production but i am completely new to the managing side of things i have years in the company and my work was mostly individual now i am faced with the challenge of having people under my wing and i know absolutely nothing about team working scheduling agile or time management methodologies i have never taken any leadership courses in school i was the quiet one that did the work and let the extroverted present it because he was so much better than me at presenting results i am just some dude that was having a comfy job not doing much and having little responsibility and now i am responsible for an entire team do not get me wrong i like the challenge and i want to be the most prepared to teach and mentor the new guys while being a good boss that delivers the expected results i need advice resources and whatever help you guys can give me tldr i was a pawn in my workplace everyone left several people got hired and i will now lead them while i have absolutely no experience leading a single person,resources for managing ds teams,how do you handle bosses that do not understand your work
1225,hello i graduated at an unknown state school in political science and economics dual major no math with a gpa recently i have been looking into learning more about data and analytics i am fortunate enough that i landed a job with the state government as a data analyst and am using a little bit of python for basic data manipulation automating pivot tables transforming and manipulating dataframes stuff just beyond excel i have been utilizing python much more recently and am enjoying getting better and better at it i am also learning about powerbi with my job for data visualization and manipulation i have only taken one formal class in python where we cleaned data and made some visualizations so by rdatascience standards i am quite new to all of this but doing these tasks have made me more and more interested in learning these skills i always thought stem was quite dreadful but when you use stem in an area where you have a passion for me it is politics and public policy these skills become incredibly exciting so i ask you what courses should i take to better pursue these skills i have been looking at some masters in data science and data analytics programs but i would like to take some more time working and learning before i commit to a masters degree i have also been thinking on going to my local cc and taking some math stats and cs courses to get a better background what courses would be good for specializing in data should i go back to university and get a degree in math stats cs or something else i am thinking on enrolling in calc because honestly getting an undergrad in econ without the calc was pretty painful because i felt so limited i honestly want to get calc just because i honestly enjoy math and because i really enjoyed game theory so i would like to really understand game theory econometrics and public economics maybe there are some interesting applications with ds thanks,pursuing ds with no stem background advice for a recent undergrad,is a data science masters worth it if i already have a job
1226,hey everyone thank you so much for the love you have shown gptclient these past few weeks it is really encouraging and motivating to continue working on it because of your support from the previous reddit thread i was able to find out what most of you do with the library i also noted some concerns regarding usecases and installation it gives me immense pleasure to announce the arrival of gptclient v features pass in prompts through an array most popular feature request support for the recentlyreleased m model checks your system for model assets before downloading new tutorials on how to use the client patches windows users voiced their concerns over the emojis in the readme that were messing with the installation process in this update no component that is to be installed by a foreign system contains emojis some functions have been changed and added to accommodate the nowmodular nature of the client if you are currently using v converting is very simple ampxb if you are new to gptclient feel free to check it out here if you like the project and want to use it a on github would be appreciated ampxb cheers,introducing gptclient v,i have been working on a project for a few months now and i feel completely overwhelmed please help
1227,just for fun i thought it might be interesting to use a year is worth of my telegram group chat history to train a model to predict the speakerchatter to simplify things i used only the top speakers and balanced the dataset to message samples each at a max length of characters i am getting really poor performance about test accuracy at best i know a lot of the example text classification problems they can do a lot better i am wondering if i just have an inferior model insufficient data or if this kind of natural text classification is known to be more problematic it feels different somehow from the classifying by genres or negative neutral positive comment type stuff,text classification by speaker,i am trying to build a model for text classification and i have a few questions
1228,hello everyone thanks in advance for reading i could use some help here so i am gonna try to make it short and i will simplify it a lot algorithm threebased features spend feature target target i have spend feature and target for every day showing a weekly seasonality i am predicting target with a recommended spend for the next day right now first improvement since i actually need a weekly recommended spend i will predict weekly avg_target with weekly avg_spend this way we also get rid of the ups and downs within the week now feature which also correlates with spend but not exclusively correlates well with target what i would love to do is adding feature to the model but we do not know the value when predicting it is of the same nature as target we could say it is a postmortem feature and as i said it depends on spend my little newbie mind could think of the next approaches predicting weekly avg feature for the next week with weekly avg spend and ingest it along spend to predict target kind of awful and actually it is not only feature but and which would imply having models with outputs to ingest those outputs to the main model train and predict target with spend and last week avg feature but they do not correlate well i do not know if i am explaining well sorry about it but as a conclusion what i need is to include the information given by feature in the model since it is a great predictor of target but we cannot know it in advance as we could if it was day of the week recommended spend or so ampxb any tip would be super appreciated thanks a lot,help with project approach,question about time series prediction
1229,hi i have created an android app consumption tracker to help you track your consumption of things basically for each item you enter name purchase date quantity and cost and other details and later you mark the item as used when it is completely used you can monitor your consumption and view stats and charts about your expenses features add as many items as you want capture and add photos of items manage and assign categories to items view stats and charts about expenses in a given date range export data to csv file create and restore local data backup copy here is the link i would love to hear your feedback i hope you find the app helpful and useful,i have created an android app to help you exploit data about your consumption i would love to hear your feedback,can i use google analytics to create a data tracker for my android app
1230,multimillion dollar annually ecommerce website that uses zen cart unfortunately i am taking on some new responsibilities and am now going through our google analytics data to find more opportunities to get conversions and expand our seo visibility this was not a focus in the past and due to a variety of offinternet circumstances we dominate the market and industry and have been getting by without much focus on seo this month we have experienced a hefty drop in sales yoy on the zen cart site and we are struggling to figure out why site traffic has stayed almost exactly the same yoy with some slight increases in daily traffic but nothing major this drop is recent the first months of were great and an increase over last year for the same months scouring through analytics and search console data to figure out why a drop in sales might be occurring and am coming up with no real ideas related to technical issues or the site itself as our traffic and search visibility is basically the same if not up from last year yoy one thing i have noticed is that when looking at user flow in google analytics there is almost no follow through it shows drop offs on the starting page this obviously is not true in any way and it most likely has nothing to do with the drop off in sales we have experienced as the user flow for the same time period last year is the same thing drop off on the starting page is there a way this can be fixed one thing that i am thinking is the issue is that it is zen cart is fault take a look at an example page url ourwebsiteindexphpmain_pageproduct_infoampcpath_ampproducts_id obviously a shitty page url and it does nothing for us seo wise the starting page in analytics is indexphp and shows drop off i assume this is because of the way the urls work and because every page on the site has the indexphp prefix to where whenever someone eventually does leave the site it is counting it as the starting page i am trying to get a plan in place to switch over to shopify because zen cart is archaic and all types of these issues exist but is there anything i can do in the meantime to get this data,ecommerce website google analytics showing no through traffic after starting page,is there a reason why traffic from google analytics is so different from what it was a year ago
1231,i am training a convolutional network on a task similar to video classification and i am seeing a gap between the training and the validation error that starts at after a few thousand iterations and progressively increases until it is about ie the difference between training and validation error is and the validation error is higher i have already rigorously analyzed my data preprocessing and loading pipeline and came to the conclusion that the training and validation data are processed in the same way i have always thought that overfitting happens towards the end of the training procedure that is why we use early stopping however my model is overfitting from the very beginning does anyone have a similar experience,neural network overfitting from the beginning of training,why does overfitting in keras always produces worse results than training validation
1232,ive applied for a role at wellrespected agency theyve sent me a brief that sounds quite close to what id expect to face while i have the general understanding of what can be done here id appreciate your insight as well see the brief below you have a traditional fmcg client with a limited firstparty customer data set collected through various promotions run on their website they are aligned to the google stack for advertising ga sa dv but the adobe stack for martech audience manager analytics campaign they would like to improve their ability to run customercentric marketing and have come to our agency for support please outline your approach for helping them measure and achieve their goal in addition the client is keen to understand the data landscape they would like to technically understand how the data from their crm goes into adobe audience manager aam and how they would integrate a thirdparty data vendor my general approach would be to manage and push audiences through adobe into dv and sa ads using their website metrics to create said audiences you can then measure their success through the adtech stack adobe launched adobe experience platform which is essentially a cdp from adobe i also wanted to check integrate that on my suggestions they could also integrate their logged in info or piifirst party data with aam manage it there and active it on dv by using someone like liveramp or eyeota to do the matching into the adtech stack google obviously doesnt pass back any info from their end into adobe so any thoughts on how to address that would be also appreciated happy to discuss,interview presentation how to connect adtech and martech google adobe,how do i track how many people visited my website through a specific channel
1233,hi everyone i am looking to transition from mechanical engineering to data science and have been scouring this subreddit for days i am currently doing udemy is python data science course and i am learning about numpy panda and all the main python libraries rn as my first project ever i think it would be cool to do a study on youtube facebook instagram social media analytics for a given page i have no direction though i was wondering if anyone has any experience with this i would love to talk to you and see if it is worth pursuing these platforms already have a set of analytics tools and i am able to export csvs tldr python nooby wants to do a project on social media analytics wants to get some insight and advice from friends in the data god subreddit,datascience and youtubesocial media analytics,looking for a mentor for my first data science project
1234,i am about to end my second semester of sophomore year at a top cs school umd i am pretty sure i am going to end my c programming class with around a c and my linear algebra class with a c this will probably bring my gpa down to a or so i know i have time to bring up my gpa but will the c in linear algebra greatly hurt my chances of getting an ms in data science after undergrad should i consider retaking it most of the programs i looked at explicitly mentioned completing linear algebra as a prerequisite ampxb alternatively if my school releases pf grading for this semester would it be harmfulbeneficial to pass linear algebra and my c programming class,will a cs or ps significantly hurt my chances when applying for an ms in data science,should i take a linear algebra cs class
1235,rant hey gang stand back its rant time analytics is a new field at my work and im here to pioneer it i work in corporate at a large medical devices company ive had the luxury of an amazing boss some amazing colleagues and decent budget but for the love of fucking god i am so sick of being thrown responsibility or projects because good ol mary in sales watched a video on gesture recognition the ideas are a great and i have a framework for filtering them but the fucking pressure the initiation of projects with data no aim at data collection no quality assurance or risk management and the icing on the cake we should roll out an mvp in months what in gods name is that shit im the asshole im always the asshole here are my requirements if we wish to complete this project in the given time frame so why cant you develop it now bro for starters im not a full fledged software engineer deep learning god i ask for resources or a relaxed time and i get i dont need advice i know what i need to do i just love this community and felt the need to rant,im so sick of corporate morons,i hate data science
1236,im asking this question as i potentially am interested in data science however my gpa was subpar so far in undergrad and am wanting to pursue a ba over a bs as a bs only has extra cs classes that i dont think would help and a physics class that is not related these classes wouldnt be very hard time consuming though for me but i just see them as pointless and it would take another semester and i want to graduate asap as its already my fifth year of college since i transferred twice so i have a few options get a ba and get work experience and try for data science jobs once i get more experience and if all fail then try for masters or get a bs would take an extra semester of stupid courses and do the above im just afraid that if i ever decide that work experience isnt helping and so i want to pursue data science through getting a masters that my ba va bs decision could be significant in getting into grad school any suggestions or experience thanks,masters or work experience,is a masters in data science worth it if i already have a job
1237,i am starting college now and i am looking for some advice on my major i would like to work in data science but aspects of software engineering such as ai and deep learning are interesting to me i was wondering if i would be better off doing a duel major in computer science and stats or cmda and neuroscience or really any mix between the cmda neurosci my reasoning for neuroscience is because i think the skills from an experimental neuroscience degree at vt might transfer well into ai and deep learning research any suggestions would be great i am just looking for the best combination to match my interests and give me the skills to work in the fields where i am interested,virginia tech cmda for data science,where to start
1238,i have a traffic network of several different sites and i would like to compare data like bounce rate time on site similar goals etc across these sites which are all set up under the same ga account is there a way i can compare these different data from different profiles in one combined profile so i can avoid jumping from one profile to another to compare this data i was looking into choosing the setting tracking multiple domains but that does not seem give the feature to compare data between different sites but more track users across several domains any tips or links to a solution to this problem would be greatly appreciated,google analytics question tracking multiple domains,tracking users across different domains
1239,so i have a semi working backpropogation algorithm but what i cannot seem to wrap my head around on every version of neural network implementations is the derivate of the sigmoid function being used to calculate the error of a neuron so i understand the formula is effectively this for an output neuron o where w is the expected output o is the actual output and  is error o wooo except what i see right away is if the actual output of a neuron is or very very close to then the expected output does not matter o w w i feel like i am supposed to be applying the sigmoid function a second time somewhere right now if my output neuron is outputting a something like and i feed back in a as the expected output it still thinks it has an error of like or something infinitesimally small like that which is very very wrong since its basically as far away from the fed in value as possible here is a link to my code,backpropogation confusion,why does the output of a neural network have such a large number of neurons
1240,hello i would like to invite you to m conference advances in forecasting machine learning and statistical methods and a novel hybrid approach website this will be an amazing day miniconference cohosted by unic university of nicosia and nyu on dec th and dec th at the tribeca rooftop the conference is headlined by nassimnicholas taleb who needs no introduction and spyros makridakis a distinguished university of nicosia faculty member one of the top statisticians in the world who invented data forecasting competitions and a lot of other speakers from google uber sas etc at this conference we will be presenting the results of m the largest makridakis forecasting competition by far as well as covering related topics we would love to see you there and also any suggestions about participants and sponsorsmedia partners,forecasting conference,nyu data science conferences
1241,there is a lot of concern that ds is becoming oversaturated but what i do not see much of is a discussion of industries that are barely aware of the existence data science example i work for an education consulting firm and there are mountains of data in this space that people need to use but have no idea what to do with when i started this job in the so called state of the art for creating and disseminating a predictive model was the trend function in excel they paid a consultant hundreds of dollars per hour for years to create it my first week there i blew everyone is minds by throwing it into a traditional time series model and creating a simple dashboard for it in r shiny it is been two years and people are starting to catch on to what is possible we are getting all kinds of requests for projects that involve machine learning and i am starting to notice firms looking for data scientists data engineers and analysts the quant experts within the field have a narrow focus on inferential statistics used in social sciences and have no clue how to approach tasks data scientists and analysts have been tackling for decades even though they are now being asked to to use my least favorite buzzphrase this field needs thought leaders to show people what they can do with the data they are sitting on the demand is there but few people are tapping into it that makes me wonder what other fields are just now discovering what they can do with data science what kinds of opportunities are you seeing,there are plenty of fields that have not even scratched the surface of data science yet,what is your data science superpower
1242,i am currently doing a bachelor of data science y and i am not sure how comprehensive andor useful the degree is in terms of knowledge and job opportunities the course makes you choose between majoring in mathematical data science or computational data science and i feel like you do not get enough knowledge of the other subject to get a balanced understanding basically statistics vs machine learning with little crossover i feel like this divide in knowledge makes this degree less useful in real world data science but i could be wrong i have the option of doing a double bachelor of computer sciencemathematics for five years which i gives me a broader knowledge of both fields as well as giving me the option to choose courses that relate to data science database base systems machine learning ai etc but its an additional two years of uni that could be spent looking for a job in terms of job prospects and knowledge would do a broader comp scimaths degree be better than a specific degree in data science especially when the data science degree does not allow much room for growth outside of data science,bachelor of data science vs computer sciencemaths,data science vs computer science
1243,im a data scientist in my s with a total of years experience in a tech company and in a fmcg company im now considering a switch to a new job and wondering which route to take one way would be to be in tech and i foresee no problem in terms of career except that i find it easy to burnout another would be to do marketing fraud prevention for non tech companies fmcgbanksinsurance i have experience working in such roles and i personally found it more rewarding in terms of the impact i see my work make in the organization vs tech where im constantly upgrading my skill but had very little work satisfaction the salaries are ofcourse higher in tech but are competitive in both ranging above k where do you advise me to go work next i think this next step would be a vital decision in my career thanks,career opinion ds in tech vs nontech companies,data scientist vs tech
1244,i did university of washington machine learning course in coursera a few months ago and i want to learn reinforcement learning my machine learning skills are not toplevel of course but i guess i can get around but i am going to do a theoretical course on the subject in a few months in university i am not looking for a deep dive right now because i am a cs student which makes life harder is it possible if so where to learn some basic nice stuff with programming or i should start only when i have time to get into it big time and please do not say udacity because i feel my brain cells are dying watching their videos,is reinforcement learning feasible for a beginnerish,is it possible to get a job as a data scientist without a degree
1245,hi guys so i am working at a startup where as the chief data scientist re only person i was tasked with learning computer vision for a new application we are developing my background is in mathematics i have used r extensively i know some python for a course i completed in college but i am not pro previously most of my work involved performing data analytics with some simple modelling the company paid for all courses mentioned below and i took roughly months to complete almost all of them still had most of my full time tasks to do so i was not dedicated to learning computer vision the courses purchased and their price below udemy sale udemy sale udemy sale udemy sale off sale ampxb i will give a short review of each with it is pros and cons and summarize scores below in a table ampxb deep learning and computer vision az opencv ssd amp gans created by hadelin de ponteves kirill eremenko superdatascience team review this course was good however i have no idea how it got such a high review on udemy of the course covers nice details of building a complex cnn in keras however i do not feel this was useful at all since a lot of this was fluff in my opinion lots of this exist freely in tutorials outside you are essentially paying for watch some type code without explaining much theory of why he is doing what he is doing i also felt it did not prepare me much for taking advantage of this knowledge in doing own projects pros covers the basics of what he teaches detail is often lacking but the core knowledge is there his code works always a plus since libraries and packages get updated frequently his chapters on vgg and resnet are detailed and useful cons outside of vgg transfer learning and resnet most of the his stuff is very shallow i do not feel like i have learned anything i could not read in a blog somewhere can be said about most courses but this one seemed very much lacking in detail code along courses are good but tend to waste a lot of time i am not a total noob i do not need to be reminded to import numpy as np continuously lacks interesting projects score ampxb python for computer vision with opencv and deep learning created by jose portilla i enjoyed this course quite a bit it is not a deep learning course though at most he has a basic intro to using keras and how to implement cifar and mnist but those things are everywhere the opencv and cv basics are taught very well and i like his voice and positivity he is a good teacher and does it well pros covers the basics of opencv well all code works has a deep learning section for added value instructor is upbeat and easy to follow cons the deep learning stuff is basic and pretty much fluff to boost the value of this course it is very basic and can be found elsewhere for free it does not have that many cool projects to do score ampxb deep learning computer vision cnn opencv yolo ssd amp gans created by rajeev ratan i loved this course it was my go to reference in doing so many things the content in this course is insane and he provides a full virtual machine with everything preinstalled useful as all code works perfectly the explanations are very good he does not always go into detail but when he does it is taught quite well the only issue i have is that i can see beginners sometimes being turned off since he rarely explains the code he is more like here is the code that does this this line this and this function was built to do this if you are a beginner it is understandable you would be confused however the code content and number of projects was far more than the other courses probably even put together except for the pyimage course but we will get there so to me it is worth it it covers all the details of computer vision rather than just pieces that look cool pros amazing and detailed content excellent theoretical explanations shows you how to get the best performance out of a cnn and built a variety of things very fun projects enthusiastic teacher who you can tell has a passion of cv cons not for absolute beginners now none of these courses are but this one goes from easy to relatively hard quickly instructor at times talks too fast and skims explanations of code score ampxb computer vision intro opencv in python with deep learning created by rajeev ratan this is the older course of instructor above and it shows it is been updated quite a bit but some of the videos are not the same as the code he provides that is not a deal breaker and he does mention it but it sometimes does make you wonder if was a mistake or intentional that said all code works on opencv which is awesome and all code works perfectly a virtual machine is also provided nice touch this course has some excellent opencv tutorials fun projects and there is some added deep learning stuff so it is quite cool not as much fluff and good explanations again pros easy to follow and i feel more of the opencv basics were thought all code works and explanations are on point bonus deep learning stuff fun projects enthusiast lecturer cons audio bad at some times not much maybe like mins appears to have been recorded with his laptop mic vs external mic code in video is not always the same as the downloadable code he provides score ampxb deep learning for computer vision with python practitioner bundle created by adrian rosebrock this is the mother load now it is extremely expensive compared to the others but this course teaches almost everything you will need i wish the imagenet bundle was included at this price but that module is over this course covers all key areas of deep learning in computer vision it does not have any opencv well some but pil or imultils are used more often the videos are lacking detail they are more like introductions or overviews of each chapter the course material and code is where the value is and it is excellent in quality the code is not always easy to follow but he explains almost every line in the book so he makes up there it too also comes with a virtual machine with all packages preinstalled pros probably the best resources for practical deep learning computer vision online excellent explanations by a very experienced and passionate teacher all code is explained nicely because of his experience you know he covers the most relevant and important topics cons not for beginners obviously but it should be noted if you are a beginner you will feel overwhelmed going into this course explanations on video are most fluff he does not really teach it is more of an overview of what is covered in the book which is real meat of the course expensive score ampxb course namecostcontentexplanationscode qualityvalueoverall score deep learning and computer vision az opencv ssd amp gans python for computer vision with opencv and deep learning deep learning computer vision cnn opencv yolo ssd amp gans computer vision intro opencv in python with deep learning deep learning for computer vision with python practitioner bundle udemy has varying pricing so course price fluctuates almost daily it seems that was a sale price off most times the course does not seem to be on sale so the regular price is ampxb tldr so there you have it the best course out of those and the one i keep coming back to most often was deep learning computer vision cnn opencv yolo ssd amp gans i gave it a however it should be noted if money is no objection get this deep learning for computer vision with python practitioner bundle course it is very similar to the course above but on steroids that said we are comparing a course that is under to a course that is almost a course that has more video content an arguably better vm more stuff installed and covers mostly the same content the instructor even recently added some facial recognition and has a tutorial on building your own custom yolo object detector something the course lacks footnote was able to find an embded coupons for rajeev is courses to get it an even cheaper price of jose nor adrian has not responded to providing coupons here feel free to ask me any questions on the above courses also please add your feedback if you have done any of them,a review of python deep learning computer vision courses warning long,what are some of your favorite deep learning libraries
1246,hello fellow data science savages i had a tricky question that i would love to crowdsource some solutions for problem i am trying to clean out all the social posts written by doctors vs patients i have already started to separate based on typical identifiers such as as a patient vs being a doctor or my patient vs my doctor and patient here vs i treated patient the issue is that this process of coming up with ways a patient self identifies compared to a doctor is extremely manual on the upfront i wanted to check if the community knew of any libraries previous code or other research that could help speed things up any and all ideas thoughts and suggestions are more than welcomed always all the best ne,how to best identify if a social post is written by a doctor vs patient,looking for a data science mentor
1247,what are your favorite papers involving ml and temporal data or time series i came across some papers about the use of lstm networks to improve image and speech classification and am curious about other examples out there either within or outside of the cv space what researchworkpapers with ml and time series have excited you recentlythanks ampxb the papers im referring semisupervised spatiotemporal cnn for recognition of surgical workflow chen y sun ql amp zhong k j image video proc spatiotemporal pain recognition in cnnbased superresolved facial images bellantonio m haque m a rodriguez p nasrollahi k telve t guerrero s e anbarjafari g in international conference on pattern recognition icpr workshop on face and facial expression recognition capture learning and synthesis of d speaking styles daniel cudeiro timo bolkart cassidy laidlaw anurag ranjan michael j black may preprint to appear in cvpr edited,what are some mp and temporal data or time series papers you like,what are your favorite research papers involving image recognition and time series
1248,hi i am new at this and i would really appreciate any insights i need to preprocess data for a tensorflow estimator and currently i have lots of datasets in bigquery as i understand it the pipeline will look like querying bigquery for relevant data host relevant data on gcs as tfrecords use tensorflow is dataset api to read in data train tensorflow estimator deploy i know that the dataset api allows you to parse the tfrecords into tensors or feature_columns which can them be inputted into the estimator nicely but i need to do some text preprocessing on tfstrings ideally i would vectorize everything from the raw data to the tfrecords in pure python but i am not sure how it would scale i would like to know when is the best place in the pipeline to preprocess data,how to preprocess at scale,best way to store and query large datasets
1249,a great short presentation of neurips paper deepsvg a hierarchical generative network for vector graphics animation by researchers from eth zurich amp epfl presentation animations look really cool btw paper abstract scalable vector graphics svg are ubiquitous in modern d interfaces due to their ability to scale to different resolutions however despite the success of deep learningbased models applied to rasterized images the problem of vector graphics representation learning and generation remains largely unexplored in this work we propose a novel hierarchical generative network called deepsvg for complex svg icons generation and interpolation our architecture effectively disentangles highlevel shapes from the lowlevel commands that encode the shape itself the network directly predicts a set of shapes in a nonautoregressive fashion we introduce the task of complex svg icons generation by releasing a new largescale dataset along with an opensource library for svg manipulation we demonstrate that our network learns to accurately reconstruct diverse vector graphics and can serve as a powerful animation tool by performing interpolations and other latent space operations paper code,neurips min talk deepsvg a hierarchical generative network for vector graphics animation,researchers from china propose a deep learningbased ai for image generation
