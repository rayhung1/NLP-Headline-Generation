Index_ID,ref_post,ref_title,candidate_title
0,suppose you are on a data science team and are given a dataset and problem statement after preliminary steps you know you need to train for example a classifier what does this process look like if you are trying to follow a principled data science workflow and organize yourself according to something like cookiecutter data science the goal is to have a reproducible workflow that is transparent so that anyone on your team could see how you arrived at your results and do it themselves this process naturally involves a lot of experimentation with pipeline steps and model selection as well as hyperparameter tuning one approach i could think of would be to do all of the experimentation with interleaved commentsdiscussion in a notebook say experimentsipynb and then once i pin down the best pipeline configuration for my problem reproduce the entire pipeline in a script modelpy which trains a model from the raw data and saves it are there better ways to do this it is hard to find examples of professionallevel implementations of tools like sklearn amidst the masses of beginnerlevel tutorials out there links to example projects would be appreciated,what does a good scikitlearn workflow look like,how do you organize your results
1,i would like to request a datasite that ranks the best films of all time using the average of the films performances with academy awards box office and critic amp audience rating flickmetrixcom has a similar system but it only ranks the data using aggregate critic and audience scores thats why i believe adding in the other data will give us a more accurate idea of what the best movies are in the method im suggesting i was able to figure out gone with the wind is likely the best movie of all time its in weighted box office sales won oscars including of the main categories and has an on flickmatrix which has already compiled the other scores for me im just unable to create a system or dataset like flickmatrix that uses my system and i had to manually figure out the data for box office and academy awards and add it to flickmatrix data,dataset request ranking best films of all time,request flickmatrix movie score data
2,i have been considering a midcareer switch from a nontechnical field to a more quantitative one i have some math and cs backgroundhopefully enough to get into a ms in data science program but probably not enough to get into a quantitative phd program an ideal path for me would be to do an ms in data science work for a few years in the field and evaluate whether i should do a phd eg in stats or computer science so that i can advance further in a subdiscipline like machine learning my question is assuming my background in math think singlevariable calc and linear algebra and cs think introlevel college is not enough for a phd program now will the ms in data science put me in a position to be a phd candidate in the future or do data science masters programs teach mostly professional skills and so would not be a good preparation for phd studies thank you,ds masters subsequent phd studies,should i do a phd in data science
3,hi everyone i am a practicing attorney considering making the leap to data science my ultimate goal would be to work in financial servicesfinancial industrylegal analytics as that is where my experience is and i feel very comfortable in the corporatebankingfinancial world i have a few questions i was hoping some of you may be able to help me with has anyone else made the leap to data science from a nontechnical career if so how was the experience and are you glad you did it i would be especially interested in hearing experiences from former lawyers or current lawyers who have folded data science into their work what math would you recommend that i learn to prepare for a masters in data science my last math class was over years ago and i think it is fair to say that i am probably at the calc i level on a good day someone recommended that i learn python does anyone have any good recommendations books online class etc for selfteaching specific recommendations would be highly appreciated what are the job prospects for an older studententrylevel job seeker assume earlymid s when finishing the degree i am not worried about the school side so much since i have always been a good student passed two bar exams etc but am concerned that employers may view me as damaged goods because of a previous career thank you so much for your time,career change to data science,what are the job prospects of a data scientist
4,hey everyone i want to become a data analyst and then down the road transition into a data science career i have an applied economics bachelor is and a supply chain management master is i have learned r and python during school and also javascript on my own i have javascript frontend apps projects is my bachelor is and master is combination a good combination for this path field i started learning sql power bi tableau python on my own at freecodecamp is there a roadmap or anything for becoming a data analyst also my previous javascript knowledge and projects would help me in any way getting my first data analyst job a last question a company reached out to me with a supply chain analyst job should i accept it or just focus on the general data analyst path sorry if i am asking stupid questions,how should i start,data analyst job or not
5,hey everyone i am one of the creators of sieve and i am looking for general thoughts on this problem part of what we are trying to do is build easy ways for software engineers and data scientists to interact with rich data imagine making queries and aggregations on videos in the same way you might with numbers and text right now the way we are thinking about it is to turn videos into something that works with the structure of a database like mongodb everything in an image or a video is an object even the frame itself is an object with a large bounding box and each of these objects has some attributes and can be tracked over time with some form of object tracking given that the objects are tracked they can each basically be returned as a timeseries of each of the attributes associated with that object a separate part of our api is a system that automatically allows one to define entities like people dog car cell dirty kitchen or any other object by making api calls in which they are basically providing labeling data that automatically trains a fewshot classifier on these objects our longterm goal is to build a general index over visual data and we think building a great query language great ways to define entities within the query language are important this can be the simple abstraction such that anyone can process and understand visual data such that they do not even need to know computer vision or deep learning for that matter ampxb find all intervals where a person is walking slow get all parts of the video where motorcycles are entering the intersection with speed greater than find all intervals of video with a clean kitchen,building an api query language for rich data like images and video,what is the best way to build an api for describing and defining entities in a video
6,hey all i am hoping some of you can help me with a potentially sensitive question i am in the late stages of interviews at a firm for an analytics manager position i know it is not true data science but it is close it would involve a small number of direct reports it is a large fortune based in the se us i am not natively an american but i tend to pass for one i have noticed that all and i mean literally all of the folks i have met in my interviews up down and lateral in the analyticsdata teams are all eastern asian or indian i do not care about working with different cultures but it seemed a flag to me that there are no americans there should that concern me that working conditions are poor ie americans would leave under those conditions or is that typical in expanding analyticsdata science teams at this point,joining firm company culture concern,is it normal to have a bad working environment for an analytics manager
7,i would like to take my career in a new direction with machine learning and am exploring the different pathways available one way is to go to school and get a masters degree the program i have been exploring is the masters of data science at berkeley the curriculum has what i want and with the distance learning i can be anywhere in the world and still get an education however the tuition for the program is there is also the masters program in machine learning at cmu and the machine learning masters program at university college london but these would require relocating since they are not available online the other path is to take classes online there are several available that i can take from places like dataquest linuxacademy sciencealert udemy etc i can pick and choose which ones i want and complete them at my own pace plus the total cost would be less than of the tuition at berkeley and since i am making a huge leap from being simply a troubleshooter to an ai architect i will need to show potential employers what i can do the plan is to post projects on github showing what i have worked on both in class and on my own i intend to do this regardless of which path i take i am hoping this can show the progression of my knowledge and be the bridge between what is listed on my cv and what i can do so now i am wonderingif the cost is not an issue which of these paths would work best in terms of impressing an employer will it be the degree or the drive that would pique someone is interest to hire me please let me know what you think,is a pricey masters degree worth it,what is the best way to get a masters in ds
8,greetings i would like to ask for advice from this community i am entering the world of ai and while i am not completely new to probability programming or automation i have a lot to work on luckily there is alot of online content to help with studying but time is limited so i have to focus my efforts obviously i should learn ml algorithms and libraries for python only right now but i believe there is more to it than that what i would like to ask i do not come from a cs background the most i have done is programming some microcontrollersvectorial calculations with matlab is it beneficial to invest time in some software engineering course to make it easier to develop scripts or is it overkill as a ml engineer it would be a significant time investment is it possible to start a career in ml without data manipulation tools something like sql spark i intend to get to them when feasible after starting to work but is it a necessary precondition for the job i have not been able to find a conclusive answer by just looking at job ads or kaggle is python used in the industry or are other languages preferred i only really know c but i am not even going to try with it i want to thank everyone who takes the time to read this and even more those who answer,seeking advice for learning path,is it a good idea to learn python without using other languages
9,hello i am a computer engineer and for one of my projects is ai detection for crime scene evidence analysis and for me to do that i need a photo or video datasets of crime scenes i tried searching everywhere i cannot find any database of crime scene photos does anybody know of anywhere i can find some photos or it forensic competitions that have such datasets i need it urgently please help a professor suggested using kaggle however i could not find anything plus i am not sure how i can use it the dataset does not even have to be real i just need anything to start working on my project thanks,crime scene datasetphoto and video database,looking for crime scene datasets
10,some background i have been learning python for over a year now and i know some sql a bit of r and i have completed some small projects using data science data engineering practices i also know how to work in excel but i do not really have experience using databases i am totally willing to make the time and money investment in something like a bootcamp and i have the means to do fulltime training but i do not want to do this if there is a better faster way to get into the industry what i really want to know is what can i do that will get me a job in the field asap is there some specific bootcamp that will make this happen if so what are the best bootcamps or some particular tech skill i could learn that would basically guarantee that i am hireable very soon if i something like learned microsoft sql server or tableau and given my other skills would this be likely to get me hired i have been looking into bootcamps like thinkful springboard and data application lab the concern i have about these is actually that i already know a lot of the stuff they teach and i am worried that these will be a waste of time and not elevate me to where i want to be i also worry about it taking months to complete these programs as they estimate i would like to be finished in no more than about months thoughts,i want to transition into the data scienceanalyst or related field rather than asking whether i should choose a particular boootcamp or learn some language i would like to hear opinions on what path should i choose that will land me a job of some kind in the field as soon as possible,what is the best bootcamp for getting a job in the field asap
11,hi all i have created a python module to extract sngrams which is different from traditional ngrams as it embodies linguistic syntactic trees thus making it less arbitrary than traditional ngrams as it goes without saying quality of input feature affects model performance this will help you improve your model accuracy even further built on language models of spacy it can help especially for text classification information extraction query understanding machine translation question answering systems below is an example from sngramextractor import sngramextractor ampxb sngram_objsngramextractortextmeta_tagoriginaltrigram_flagyes texteconomic news have little effect on financial markets outputsngram_objget_sngram printtext print isngram bigramoutput isnbigram print isngram trigramoutput isntrigram economic news have little effect on financial markets sngram bigram cloud_every has_cloud lining_a lining_silver has_lining sngram trigram has_lining_silver ampxb textevery cloud has a silver lining outputsngram_objget_sngram printtext print isngram bigramoutput isnbigram print isngram trigramoutput isntrigram ampxb every cloud has a silver lining sngram bigram cloud_every has_cloud lining_a lining_silver has_lining sngram trigram has_lining_silver ampxb pypi,psngram linguistic features for improving machine learning and deep learning model accuracy for the first time in python new release,python sngram objs
12,i am looking at some of the modeling programs the company has been using and there are options to smooth binned data layered linear on bin linear on avg linear on log avg and variable gradient are these methods commonly used in any algorithms i am not sure how i would implement it into r ampxb variable gradient is the most confusing it groups data from neighboring bins with a bin factor being determined the level of smoothing is determined by the radius all bins contribute to the calculation of the bin factor with decreasing weight as the distance from the target bin increases the weight is equal to radius distance radius ampxb once you calculate the overall factor a calculation is performed for each bin weighted by an exposure with various radii and a selected credibility level the calculation that yields the largest distance from is then selected as the factor to be used for that bin ampxb over multiple iterations of the model the factors are blended until the model converges and we receive a final coefficient for that bin ampxb since it is a program i have no clue what is going on in the background to calculate the convergence or what type of model this is it ends up being a multiplicative model so i am guessing it is a log linked glm,does anyone use any type of gradient smoothing for binned data,what is the name of this model
13,let is say i have created a fraud detection model i already have a process that cleans the data and stores the trainable data in a table in a database and now i want to set up a recurring job that retrains my model every x time period how do people go about this when we want to retrain the model does not that data have to be loaded into the environment that the new model is going to be retrained i guess i am confused at how exactly the model takes the data from the database and starts training on it do people use spark to load it into the environment with the modeltobe then start the retraining process does not that mean that the retraining environment has to have enough space to cover that data being brought in apologies if this has already been asked but i have not seen a clear answer from this subredditfrom what i have found on google thanks so much for any assistance,setting up a model for retraining in production,how to set up a recurring job in retraining
14,i am working with a dataset of patient performancedata and patient demographics for people with a medical condition i am trying to assess the effect of a treatment on the patients and as i am trying to replicate a randomized experiment from a observational study i am performing matching between the treatment and control group when i try to perform mahalanobis distance matching however i keep getting the following warning on matlab warning matrix is close to singular or badly scaled results may be inaccurate rcond e the warning was caused because the determinant of my covariance matrix was very close to so when i calculated the inverse of this matrix as i need to do for finding the mahalanobis distance the matrix element values become very close to as well after reading about this warning a little bit i found that when this warning is displayed the results of mahalanobis distance matching is not very reliable i thought this was because my matrix became very sparse after i introduced onehotencoding to split the multicategorical features into many different features and hence some of my new features were for category values that had very few occurrences less than to address this issue i got rid of the category values with very low occurrences less than or binned them together with other lowoccurrence category values into slightly larger bins so their chances of occurring increased and my datamatrix was less sparse so i reduced the number of features from to and i plotted the histograms for all my features to see their distributions and this is what it looked like note that the element values have been normalized to by subtracting the feature mean and then divided by the feature standard deviation it looked visually satisfactory to me but i still kept getting the same warning in matlab when i tried finding the determinant of my new covariance matrix it was still very small e in a further attempt to fix this issue i checked whether removing all of the categorical features if we consider the onehot encoded features made things any better by making the matrix less sparse the new featurehistogram looked like this this time when i tried mahalanobis distance matching the warning was removed because the determinant of the covariance matrix was larger e so i tried to see if i could include one of the removed multicategorical features without facing the same problem as these are important features i would prefer to include when doing my matching i added a categorical feature with possible values and all the values very well distributed see histogram below but alas simply including these new onehotencoded features seems to cause the determinant of the covariance matrix to become so small that i start getting the same warning in matlab is there any fix to this issue or is it simply impossible to reliably perform mahalanobis distance matching on this dataset without leaving out the multicategorical values,is mahalanobisdistance matching between points not compatible with onehotencoded datasets,question about mahalanobis distance matching
15,hi all i am applying for a data science internship with a well known company in the sf area think uberairbnbpinterest etc one of their points under qualifications is amust be currently pursuing a master is or doctoral degree preferred fields of study are statistics math economics or related discipline this presents a few problems namely that i am a junior undergraduate studying cs that said i have more experience than the typical undergrad and from what i have seen the typical masters student with respect to data science here is what i have got going for me very proficient using python r and sql among many other data analysisscience tools just finished a summer internship at a wellknown tech company as a data science intern built the company is new anomaly detection system in r from the ground up and deployed it just started a fall data science internship in nyc with an ecommerce company will be working on customer segmentation with some sql reports and machine learning taking two data science masters courses tutoring for a masterslevel algorithms course i know i do not fit their exact description but do you think i should apply anyways i would love to intern here and would appreciate any tipsexperiences any of you have had on applying where you do not necessarily meet every single criteria thanks,education level on applications,should i apply for a data science internship
16,i m am a junior in college major in statistics i go to a non target school and work as an intern at the center for predictive analytics at my university upon graduating i will receive a full fellowship to continue doing analytic research for our math department thus i will not enter the full time job market for approximately years from now i am planning to do some part timeremote work during my years of grad school this semester i have started building the habit of hours per day for self studying and working on ds projects i am committed to keeping up a similar routine for the next years with the intent that i might achieve hours of data science experience within the next years i decided to follow the ds career path after reading a book about big data i think it is a good career for me as i am into data math etc but i am also in it for the money and and mostly motivated by achieving a high salary so that i can save up money and start my own business in my s maybe idk is it unreasonable for me to expect that i should be able to far exceed a salary of k assuming high col within a decade from now if now how many yoe should i expect to achieve similar salary,how many yoe should i expect to have before i hit kk salary range,how many yoe should i expect from a career in data science
17,hello i am soon to be graduating student this spring in an undergraduate data science degree after doing extensive research i feel like my program had not emphasized math courses as much as i will only have calculus under my belt i have been looking at different graduate schools and i am looking at an ms in computer science i wonder though if my program has lacked sufficient areas for a program like this i was wondering if anyone here has had a similar issue i am starting to think my undergraduate degree in data science was a mistake and that i should have pursued a bs in either computer science or statistics here are some examples of what i have taken cs algorithms and cs data base management cs machine learning data science unsupervised learning data science management structured data data science other general data science things stats intermediate states stats regression stats principle study design stats experimental design by the time i will graduate i will have a minor in stats otherwise i could pursue a ms in stats or data science but i think i am wrong if i pursue those areas since with stats i would have to spend time taking the additional math before the more advance courses and i think the data science ms would just redoing things that my program already covered thoughts,a potential blind spot for new data science degrees,ms in data science
18,a little background on myself i graduated from a good university with a degree in civil engineering then i worked years in construction management and hated it over that time period i took a few classes and began teaching myself programming and data science i created a website and started uploading all the project that i had completed it took a while to get a job but i finally landed a job as a data analyst and love it i had thought about getting a masters during my job hunt since it took so long but stuck it out and landed this job i want to continue my career in the data science direction and want to know how revered masters and phds are in this field a lot of times high level data scientists at great tech companies either for sure have a masters and a lot of times have phds my main draw back on getting these degrees is the money it would cost because i feel like i could honestly teach myself the same skill set without having to pay for the school all in all i have a good job working as a data analyst but how far can this experience im gaining get you without having a masters or phd i almost went into structural engineering career path after college but everyone i talked to said that you had to get a masters and that was that so im interested to see other peoples perspectivesthoughts on this for data science to sum it up is it work it to pay for mastersphd and what curriculum specifically would you get the most out of as it relates to data science,should i get a mastersphd,phds in data science
19,i checked out the faqs but was hoping for some targeted feedback i am currently entering the th year of my phd in neuroscience on top of a bachelors in psych and a masters in neuro i fundamentally love my work but recent observations have convinced me that continuing on the path of academia is just not right for me and my family late last year i took up python and have completed a couple of small projects to help automate my lab and expedite data analysis it got me thinking about data science i figure i have two years to make myself into a something that some company somewhere will want how can i do it my thoughts are to get some mooc certificates complete a handful of projects in the lab that use data science to save timeimprove outcomes etc network by shouting out of my window at cars driving by i realize that my path is nontraditional but i am hoping there is a way to repackage many of the problemsolving and analytical skills that i have earned in my science education thus far as groundwork for a job in data science all feedback is welcome,two years until i apply for jobs what should i work on,how do i get a job in data science for my phd
20,data science has tremendous growth opportunities and is one of the hot careers in the current world many businesses are thriving for skilled data scientists data science requires many skills to become an expert one of the important skills is python programming python is a programming language widely used in many fields it is considered as the king of the coding world data scientists extensively use this language and even beginners find it easy to learn the python language to learn this language there are many python data science courses that guide and train you in an effective way what is python python is an interpreted and objectoriented programming language it is an easily understandable language whose syntaxes can be grasped by a beginner quickly it was found by guido in it is supported in operating systems like linux windows macos and a lot more the python is developed and managed by the python software foundation the second version of python was released in it features list comprehension and reference counting this version was officially stopped functioning in currently only the python version x and later versions are supported why python is used in data science python is the most preferred programming language by the data scientists as it effectively resolves tasks it is one of the top data science tools used in various industries it is an ideal language to implement algorithms pythons scikitlearn is a vital tool that the data scientist find it useful while solving many machine learning tasks data science uses python libraries to solve a task python is very good when it comes to scalability it gives you flexibility and multiple solutions for different problems it is faster than matlab the main reason why youtube started working in python is because of its exceptional scalability features of python language python has a syntax that can be understood easily it has a vast library and community support we can easily test codes as it has interactive modes the errors that arise can be easily understood and cleared quickly it is free software and it can be downloaded online even there are free online python compilers available the code can be extended by adding modules these modules can also be implemented in other languages like c c etc it offers a programmable interface as it is expressive in nature we can code python anywhere the access to this language is simple so we can easily make the program working the different types of python libraries used for data science matplotlib matplotlib is used for effective data visualization it is used to develop line graphs pie charts histograms efficiently it has interactive features like zooming and planning the data in graphics format the analysis and visualization of data are vital for a company this library helps to complete the work efficiently numpy numpy is a library that stands for numerical python as the name suggests it does statistical and mathematical functions that effectively handles a large narray this helps in improving the data and execution rate scikitlearn scikit learn is a data science tool used for machine learning it provides many algorithms and functions that help the user through a constant interface therefore it offers active data sets and capable of solving realtime problems more efficiently pandas pandas is a library that is used for data analysis and manipulation even though the data to be manipulated is large it does the manipulation job easily and quickly it is an absolute best tool for data wrangling it has two types of data structures ie series and data frame series takes care of onedimensional data and the data frame takes care of twodimensional data scipy scipy is a popular library majorly used in the data science field it basically does scientific computation it contains many submodules used primarily in science and engineering fields for fft signal image processing optimization integration interpolation linear algebra ode solvers etc importance of data science data scientists are becoming more important for a company in the st century they are becoming a significant factor in public agencies private companies trades products and nonprofit organizations a data scientist plays as a curator software programmer computer scientist etc they are the central part of managing the collection of digital data according to our analysis we have listed below the major reasons why data science is important in developing the worlds economy data science helps to create a relationship between the company and the client this connection helps to know the customers requirements and work accordingly data scientists are the base for the functioning and the growth of any product thus they become an important part as they are involved in doing significant tasks ie data analysis and problemsolving there is a vast amount of data travelling around the world and if it is used efficiently it results in the successful growth of the product the resulting products have a storytelling capability that creates a reliable connection among the customers this is one of the reasons why data science is popular it can be applied to various industries like healthcare travel software companies etc big data analytics is majorly used to solve the complexities and find a solution for the problems in it companies resource management and human resource it greatly influences the retail or local sellers currently due to the emergence of many supermarkets and shops the customers approaching the retail sellers are drastically decreased thus data analytics helps to build a connection between the customers and local sellers are you finding it difficult to answer the questions in an interview here are some frequently asked data science interview questions on basic concepts q how to maintain a deployed model to maintain a deployed model we have to monitor evaluate compare rebuild q what is random forest model random forest model consists of several decision trees if you split the data into different sections and assign each group of data a decision tree the random forest models combine all the trees q what are recommendation systems a recommendation system recommends the products to the users based on their previous purchases or preferences there are mainly two areas ie collaborative filtering and contentbased filtering q explain the significance of pvalue pvalue lt rejects the nullhypothesis pvalue gt accepts nullhypothesis pvalue it will either except or deny the nullhypothesis q what is logistic regression logistic regression is a method to obtain a binary result from a linear combination of predictor variables q what are the steps in building a decision tree take the full data as the input split the dataset in such a way that the separation of the class is maximum split the input follow steps and to the separated data again stop this process after the complete data is separated best python data science courses many websites provide data science online courses here are the best sites that offer data science training based on python greatlearning coursera edx alison udacity skillathon konvinity simplilearn how data science courses help in a successful career postcovid pandemic the economic downfall due to covid impacts has lead to upskill oneself as the world scenarios are changing drastically adding skills to your resume gives an added advantage of getting a job easily the businesses are going to invest mainly in two domains ie data analysis of customers demand and understanding the business numbers it is nearly impossible to master in data science but this lockdown may help you become a professional by indulging in data science programs firstly start searching for the best data science course on the internet secondly make a master plan in such a way that you complete all the courses successfully many shortterm courses are there online that are similar to the regular courses but you can complete it within a few days for example analytix labs are providing these kinds of courses to upskill yourself so this is the right time where you are free without any work and passing time you can use this time efficiently by enrolling in these courses and become more skilled in data science than before these course providers also give a data science certification for the course you did this will help to build your resume data science is a versatile field that has a broad scope in the current world these data scientists are the ones who are the pillars of businesses they use various factors like programming languages machine learning and statistics in solving a realworld problem when it comes to programming languages it is best to learn python as it is easy to understand and has an interactive interface make efficient use of time in covid lockdown to upskill and build yourself,why python is used in data science how data science courses help in a successful career post covid pandemic,python for data science
21,to be as brief as possible i graduated with a bachelor is in political science almost a decade ago for some reason thinking that i would be okay just having a degree after many years of bouncing around i started taking some moocs which led me to eventually completing a master is in analytics degree i got hired on over a year ago by a fortune company to do wouldata science but it turns out that most of the tools required to do such work r python are not approved for use due to the open source component sas is approved but my department still has not received its licenses i work with billions of rows of data on a daily basis using teradatasql and find trends inconsistencies make recommendations etc but i am really missing the predictive side that i studied so hard to learn given the above what is the best way to transition into a role where i can do more predictive work i do not even need a wouldata scientist title but i just want to work on modeling and use machine learning etc should i put a github together and put some project work in there i just feel a bit hopeless as in without any onthejob predictive analytics work i will never be able to transfer into one of these roles in the future,how to transition from data analyst to a data science role,what is the best way to get a master is in data science
22,from a press release in an effort to inject more financial transparency into college sports the knight commission on intercollegiate athletics has unveiled a revamped and innovative college athletics financial information cafi database the new resource provides unprecedented access to athletics revenues expenses and debt as well as institutionwide academic spending for more than public ncaa division i colleges and universities dating back to the free openaccess database provides telling documentation of major college sports finances at a time when institutions face lawsuits to direct more financial benefits to studentathletes for the first time database users are able to view rich graphics that demonstrate by institution conference or competitive subdivision where the money comes from and where the money goes in college sports,knight commission unveils new college sports financial database,college athletics financial information database
23,i work for an ecommerce company and we are getting to the point where automating much of our warehouse inventory management makes sense i came across this harvard business review article which though interesting is a little sparse on the details for instance it mentions that the team had to account for lowvolume product orders that befuddled its datahungry machinelearning algorithms but it does not go into any details how they went about that it does not have to be amazon but i would like to find some resources that would help me understand how best to go about tackling this problem and problems like it if you cannot think of any available resources how would you go about taking hands off the wheel,how to learn more about amazon is automation,harvard business review question
24,hello all so i come from a biology genetics background but i would lile some computer science baclground to increase career growth please forgive me for my lack in knowledge of these terminology but i want to make sure i make the right choice before committing to a master is program which might not help me in the long run usf health informatics i originally thought health informatics is the same as bioinformatics but now i am thinking they are not what career choices do i have with health informatics the advisor was not so clear in that department and provided vague career choices he said salary ranges kk usd but im still confused in what they actually do uf medical microbiology i knowvery close to what i am already in but they offer bioinformatics and unix bioinformatics as electives and i figured ill get a taste of what these courses entail and how they are used in the medical field the advisor here said that there is a possibility of getting a graduate cert in bioinformatics all depends on covid class settings but we didnt go too in depth on what bioinformatics can do career wise is there any other program field i should consider i am not a math wiz nor knowledgeable in coding but i am very curious about these fields what advice do you have for a sciencebiology lab tech like myself thanks in advance and stay safe everyone,confusion regarding bioinformatics and health informatics,bioinformaticians vs data science
25,im currently in healthcare and have clinical and administration background i wanted to start self teaching myself sql and get my foot in the door as an analyst in healthcare ive truly always been scared at of math and numbers i never thought i would ever try to get into a role that required the word data or even analyst but i want to learn entry level skills and shift away from patients is self teaching yourself enough to be marketable for entry level data analyst jobs how hard would it be for someone who has never dived into sqlpython to teach themselves especially only having administration and clinical background are the beginner courses super hard to grasp at first im taking udemy courses and some good old youtube to help me start off any input,is it hard to become an entry level data analyst,how hard is it to learn sql for someone who has never been a data analyst
26,hey there will try to keep this short i am a master student in the internet of things with a focus on data analysis i have been looking for summer internships since two weeks with over applications i had only interview and the rest directly refused me i would say the interview went well it was more about introducing myself and them introducing the company and after week i got a call that i was rejected i am applying a tons of applications and mainly in the domain of data science and data analysis i really do not know what is wrong with my resume i included a link below you can find all details about me would love to have a feedback thank you,what is my wrong with my resume,i got rejected for a data analyst internship and ms in ds need help
27,cross post from rcscareerquestions background i have been a data scientist for about years now i have a bachelors degree in economics i started out doing risk modeling for an insurance company about months ago i was hired by a small consulting company my role here is more of a machine learning engineer i create machine learning systems to automate business processes i am proficient in python sql and r ampxb current job issues machine learning is a hard field to do consulting work in most companies that have adequate data infrastructure already have a data science team those that do not have the appropriate infrastructure cannot benefit from machine learning as a result i am getting little experience in my current role so i am looking for a change for every project i have there are weeks of no work doing this time i get certs and do research right now i only have uipath certification ampxb general concerns about the field of data science i live in a medium sized city on the east coast not a ton of data science jobs additionally i do not enjoy the modeling aspects of the job nearly as much as the engineering i understand most commonly used models when to use them their pitfalls etc however my interest with them is very applied i do not have any desire to develop new machine learning algorithms only using preexisting tools to add business value i would like to use machine learning as one of many tools to automate business processes ampxb future steps i am thinking about leaving machine learning specific roles in favor of a software developer role but i do not know if i could close to my current pay k i can take a slight pay cut but not too significant ampxb questions could i get a decent job as a python software developer with my current experience should i just try to get a machine learning engineer at a different company any other input ampxb tldr i like the engineering side of machine learning the most in a dead end job what should my next step be,data scientist looking for a change,should i try to get a job in data science instead of engineering
28,hi everyone i will keep this short because i was just finishing up this post and i got a blue screen and lost everything i had typed for the past hour hahahah dear god here we go again i will laugh if the diagnostic test crashes my pc sorry for the format or misspellings in advance i just want it to be done basically i am going to start applying for jobs on data analysis and i need insight on whether what i am preparing myself with is useful or not some information about myself i am and a night time college student doing a bsc cis recently i just finished a course on sql and found the whole design and visualization of data to be super fun and interesting so much so that i have decided that this is something i want to pursue work experience was a part time job fixing and selling computers been doing this for about a year now and found it really boring since every thing that was damaged was the same things specially ram left it about a month ago and with my free time i have been finding more about the data analysis profession now then i will list what i have been doing with my free time to prepare for the job this will have things that i think are needed and those that i think would be fun to have some knowledge of afterwards ill link and paste the description of job listing that i feel has the most things in common with the rest job listings ampxb things that i have been teaching myself are statistics sql and excel i did take courses on these two but it was to general power bi classification decision trees and model evaluations starting this today i am looking to run some linear regressions to see the relationship between advertising costs and their expenditure i have lined up to learn six sigma and their methodologies but i am not sure if it worth learning this yet intermediate knowledge on visual c and basics of java down the line i will look into r or phyton i have seen vmware pop up in some job listing so i have it on the list of things to know about hadoop analytics and hbase saw some listing that had these and i want to know if they are needed ampxb and that is about it on things i am doing i saw somewhere some predictive analysis on determining the infected outburst of diseases and i thought a similar project could be fun to better understand the spread of diseases ampxb the insight i am looking for is into what preparations i should be focusing on for a job as a data analyst the following list will be an the job description of a job listing provide organization and management of case files review data completeness of information proper execution extract data from data base obtain additional information from other investigative agenciesdata base establishmaintain physical file prepare noticesadvertisements receive suspense petitions claims process sharing requests reconcile inconsistencies prepare declarations gather information and organize investigative package verify case files and case tracking system maintain internal status information on the disposition of all forfeited assets assure information is accurate and perform analytical computations necessary to process data conduct and reconcile inventories distribute and receive documents assist lead analyst or official in obtainingcollecting all documentsinformation to complete case file provide administrative information and assistance concerning case to other investigative agencies local law enforcement agencies us attorney and other doj processing units and higher headquarters extract data from agency data base for management and program reports perform word processing relevant to case documentation perform data entry relevant to case ampxb,looking for insight on data analysis on these job description,what is the best way to get a job in data analysis
29,im at a bit of a crossroads in my masters in data science ive got options when it comes to two groups of courses for the first i can take database systems which covers dbms architecture models sql data modeling and entity relationship diagrams i could also choose to take artificial intelligence which covers heuristic and stochastic searches logical and probabilistic reasoning game playing planning and reinforcement learning this one is the most pressing as i need to choose one for the fall second i can take machine learning which covers current research in the field derived from recently published literature pretty vague i could also take advanced data mining which covers clustering classification and pattern recognition this one concerns courses next year im hoping to get some insight on how choosing one or the other would benefit a career in data science and to see what professional data scientists would recommend for career options thank you,masters course selection,which course should i take for my masters in data science
30,i graduated in dec and had a data analytics job lined up in a small management consulting company in dc starting this summer got an email yesterday saying they will be rescinding my offer due to the covid pandemic tbh i kinda saw this coming and was applying at other companies i had an interview at oracle scheduled but they went under hiring freeze weeks ago and now they are ghosting my emails i have applied to over jobs and had referrals for a couple and havent heard back or rejected as far as skills go im pretty good at pythonsql and had a couple technical internships and decent side projects graduated from a nontarget with a cs degree and mostly applying to data analyticsjunior data scientists positions i network almost everyday on linkedin and apply to atleast jobs everyday would appreciate any advice,recent grad who had his offer revoked and interview cancelled,rescinding an offer for a data analyst position
31,hi all i am interested in learning what capabilities and techniques other data science teams have and i was wondering if i could post a quick survey here i think this is in line with the sub is policy especially since hopefully people is answers will be interesting clarification by you i mean either yourself or someone who can work with you do do this almost immediately eg not having to go to it or anything like that do you use other programming languages than python if so what do you use bi tools such as powerbi qlik etc do you have a direct connection to a database or do you just work through an api or library or something else if so what is the main database eg postgres ms sql do you have the ability to host dashboards eg using dash for internal to your company use do you have the ability to host dashboards for clients do you have the ability to set up an api for internal use do you have the ability to set up an api for public use which industry do you work in how large is the company just order of magnitude eg etc,what capabilities does your team have,what is your data science team like
32,i have an undergrad degree in finance and have been working at an asset management firm for over years now while the experience has been awesome i realized my passion lies elsewhere and want to get into data science as a potential career change preferably to something closer to business intelligence or business analytics ive been looking at graduate degrees in business analytics like the one from nyu stern to help me transition i know this is not purely data science but i think it uses a lot of related skill sets i was hoping to get some advice from people here on whether there is a place for me in the analytics field especially coming from a non techengineering background would firms value my less traditional background from a data science standpoint,transitioning to ds from financeinvestment background,is it possible to get into data science from a nontechengineering background
33,i am working in the field of machine vision where accuracy and performance both play a major factor in deciding the approach towards a problem traditional rule based approaches work quite well in such cases i am gradually migrating towards deep learning due to its umpteen advantages where the results seem promising albeit with two huge caveats lack of training data in this field to be precise lack of erroneous data performance issues on inference accuracy and speed are required in equal proportion and cannot be compromised in industrial settings point plays a strong factor i have been dabbling with transfer learning techniques and using pretrained models to overcome this situation for simpler applications such as classification this suits and gives good results in other cases such as detection and localization i have tried using maskrcnn which gives really good results but poor inference speed means it is not production ready the worrying factor in both the cases is how slow detection and inference is compared to traditional vision algorithms a solution would be to buy machine vision software specifically from companies such as cognex halcon etc who sell deep learning bundles they are quite expensive and are to be used out of box with minimal modifications which does not suit me currently point is highly necessary in production lines where each iterationimage may take less than ms for execution deep learning gives a lot of opportunities in getting state of the art results with very less data in most of the situations but in general without inference optimization in using apps such as tensorrt the time metric does not give good results is there an approach in using open source that can solve both point and point creating a cnn from scratch is out of the question,overcome caveats on using deep learning for faster inference on limited performance availability,is there a way to solve the problem of inference in deep learning
34,hi as part of my cs masters thesis i am working with vector representations of words i am trying to increase the similarity between one word vector w and another w by transforming w however i want to do this in a way that an attempt is made to maintain the similarity between w and the other vectors wwn as best as possible i have spoken to my academic supervisors about this and they suggested using gradient descent as a way of finding a transformation matrix which can do this unfortunately i have no idea about how gradient descent could be applied for this or even if it can be used to solve the problem could someone help me understand how such a problem could be solved using gradient descent if not are there any other solutions to this problem thank you,increase similarity between two vectors whilst maintaining similarity to other vectors,how to apply gradient descent to a vector representation
35,i am hoping somebody here has some experience with marketing mix models and canprovide some guidance i have experience working around mmms but i have always been at a firm that outsources the actual model building to a consultant i have never gotten close to the nitty gritty details of the model building process i am experienced in r or well versed enough to googlefu my way through most issues if i am successful this will be used as a forecasting tool not an roi measurement accuracy is necessary but nobody will be getting fired because of it is outcome i have gone through the unpleasant process of collecting and aligning weekly sales data with weekly media data impressions by media channel tv print digital for the past months i have also created a comprehensive list of sales promotions and major holidays that impact the business i am looking for advice on what process to take when attempting to build this thing here is my current roadmap determine seasonality holiday impacts and underlying trend of the data probably use the forecast package in r for this but i have also thoughts about just using dummy variables to let my model take care of that after i have deasonalized the data i will build the first draft of the model with media data will probably use a gam approach which i think will handle the minimum thresholds and diminishing returns that are common with advertising pressure a pretty good article about that is here i should note that i am not married to the gam approach review model fit and significant variables do some variable clustering and generally tweak the model apply some type of adstock tranformation to better account for the lag impact of the media i have found a few approaches online that look promising with this seeming to have promise rerun model and play with adstock functions until i have something worthwhile my question is do i need all of these steps or can i just dummy out the seasonal impacts and include the untransformed lagging media variables in my first pas of the model how do i go through the process to both account for the s curve of media impact and the adstock effect of the media,marketing mix model help,retraining adstock model to account for the lag impact of media
36,hi all i am relatively new to machine learning i have using tensorflow and keras for a few months now and want to try and move on to some more complex problems i was wondering if i already had a model in place would a neural network be well suited to learning how to solve a rubik is cube i have practised using reinforcement learning and qlearning and it feels like those systems could be applied to solving a rubik is cube but i could be being stupid if this seems like to advanced a project another problem i would be interested in solving is a chess game this seems like the traditional ai problem but i worry that the reason why it is more well known is because of the complexity of it thanks in advance i would appreciate any feedback hope i am not being too naive in my initial thoughts,project help,is there a model to solve rubik is cube
37,i am conducting some graduate research on a data visualization website and am looking for people to interview the interview should last minutes and i can compensate you paid through venmo or paypal ampxb the research is to make design recommendations to improve the site for users i am studying user experience design ampxb i am looking for people who are educators journalists or those involved in newsmedia those interested in data visualization or statistics andor people who have a keen interest in world news ampxb if you are interested tell me a little a bit about yourself via email at saraheliotuxatgmaildotcom and let me know your availability i will be conducting the interviews this thursday through friday,data enthusiasts paid interview graduate research project,looking for people to interview for a data visualization website
38,hi everyone i have an odd question i have several vectors representing muscles species vectors in each species and different orientations for each vector different time intervals for this work what matters is not the length of the vector it is the direction it is pointing does anyone know a good way for me to describeshow this so it is easy for other people to understand simple describing it as shifting n degrees around the dorsalventral axis m degrees around etc does not seem to be a good idea with so many vectors and different axes there is no way a person would get a good idea of what is happening if you have any advice i would definitely appreciate it,i need help representing data about d changes in vector orientation,how do i explain the direction of a vector in pytorch
39,i cannot view any data in the behavior flow section for my ios app in google analytics i set up tracking months ago and the behavior flow section has always looked like this you may have applied a condition such as a date range an advanced segment or a goal for which there is no data i only want to view pathing between events the events are set up and recording properly there have been hundreds of thousands of sessions in this time frame so there should be sufficient data to pull from there is a ga document for mobile apps which states that events paths are automatically tracked in the behavior flow section i am seeing that i do not have any data for screens so maybe that could be the problem do i need data for screens to view the behavior flow even though i only want to view paths between events if so how do i set that up i thought screen tracking was set up automatically,why cannot i view any data in the behavior flow,how do i set up a behavior flow for my app
40,i am currently in the midst of interviewing for data science jobs in the bay area i have a master is in statistics but am having trouble talking about my experience i have browsed this subreddit but have not found answers to this specific question i get really nervous in interviews so i want to have written down what exactly i want to communicate about my past projects right now i am able to communicate the problem ie did the drug work the method logistic regression repeated measures mixed model etc and the outcome ie pain scores improved over time but struggled in my last interview when asked for more details because i did not know what details he might have wanted and when i asked he said something like just tell me more about that logistic regression i did not follow it this was a phone interview so i was not sure what level of detail i should go into what other details should i be ready to present what all the variables were how regression works how i coded the variables what the estimates were one of my issues is that the projects i am discussing have been lengthy and very complicated so should i choose smaller projects i am beginning to think presenting a homework problem where i did a basic linear regression or classification tree would be much easier to talk about but of course i would not say it was a homework problem tldr any advice on what exactly interviewers want to know about your past projects any insights to help me feel less intimidated,interviews what do they want to know about my past projects,what should i be prepared for a data science interview
41,this is a long story then if you do not mind reading everything i write in this post and then give me any advice i will be very thankful i am a student of forestry engineering at a university in colombia in this career there is a lot of forest measurements and ecology analysis that make me fall in love with r and little by little make me fall in love with statistics and programming i realized after those subjects i wanted to combine ecologybiology with data science i started to search where to learn it and i found a lot of mooc is options datacamp udemy and so on every one of them selling the impressions that with those mooc is anyone could be a data scientist searching more deeply i realized that those courses just make an introduction of what really data science is i have to practice a lot on real problems on real situations different of practicing with the iris dataset or the titanic dataset and i am okay with it but keep reading i will explain why i have fo find another strategy since i am in south america the currency of my country is devaluated so investing my little budget on those mooc is is expensive i do not want to invest a lot of money in courses that i cannot use to apply for a job later or in which i have to study at a different university to really study data science i realized that the best way to be a professional data scientist is that i have to study at another university but i do not have the money at this moment the thing is that if a have to practice a lot search real datasets and accumulate projects more than certifications of a complete career track on those mooc is then i will have to learn from other sites books i wish free and other courses i have read a comment on quora that a course with more practical skills challenges exams is python for data science and machine learning bootcamp then it will be great to see the free course of deep learning in coursera the person who said that believed that those courses are better than datacamp dataquest so i have to start over there but i want another opinion and if that is a great introduction then what is next how can i keep learning when i complete those courses in the future i want to save money for studying this career at another university in another country but meanwhile where should i learn and gain experience with data statistics and programming plus my country made an alliance with a mooc of latin america called platzi to give free courses in ai platzi says that with their courses you cand find a job but i am studying their courses and there are only videos the practice and challenges are all by my self i will finish all these courses on platzi because it is a great opportunity but where can i find more information to practice and become a person that can find a job with it and save money to study those areas professionally noe i know that my practice and portfolio is more important than the certifications so most of the mooc is are practically lying to their students when they say that they cand find jobs with their career tracks and courses thank you for reading all that thank you for your advice and sorry if my engish is not clear or if a have a lot of errors,confused and lost at where to start,what is the future of data science
42,hi fellows im a yearsold senior from brazil and i need to decide either to enroll in an economics bs or a computer science bs i recently started to learn coding and decided i want to study data science in deep during undergraduate studies i havent yet decided wich field but been reading about analytics bi machine learning and deep learning i think that building a business foundation and learn coding by my own could give me valuable insights and job opportunities especially internships and trainee programs on the other hand im afraid that it would limit my possibilities in terms of knowledge and credential itself id be glad if you could share your experiences and advices with me,bs in economics or bs in computer science,economics or computer science bs
43,i am trying to feature scale my data and used the following code sc standardscaler x_train scfit_transformx_train ampxb i am getting the following error ampxb traceback most recent call last file ltstdingt line in ltmodulegt file homeanoushkajlocallibpythonsitepackagessklearnbasepy line in fit_transform return selffit fit_paramstransformx file homeanoushkajlocallibpythonsitepackagessklearnpreprocessing_datapy line in fit return selfpartial_fitx y file homeanoushkajlocallibpythonsitepackagessklearnpreprocessing_datapy line in partial_fit force_all_finiteallownan file homeanoushkajlocallibpythonsitepackagessklearnutilsvalidationpy line in check_array array npasarrayarray orderorder dtypedtype file usrlibpythondistpackagesnumpycorenumericpy line in asarray return arraya dtype copyfalse orderorder valueerror could not convert string to float us citizen gtgtgt x_test sctransformx_test traceback most recent call last file ltstdingt line in ltmodulegt file homeanoushkajlocallibpythonsitepackagessklearnpreprocessing_datapy line in transform check_is_fittedself file homeanoushkajlocallibpythonsitepackagessklearnutilsvalidationpy line in check_is_fitted raise notfittederrormsg name typeestimator__name__ sklearnexceptionsnotfittederror this standardscaler instance is not fitted yet call fit with appropriate arguments before using this estimator ampxb can anyone please explain me how to fix it this is my first predictive model so i do not have a lot of experience please help,why am i getting error while performing fit transform,python ltstdingt error when using sklearn
44,i have been working on a timeseries model using rnns and have seemed to have limited success i was hoping to get some help clarifying a few questions note that my model is not for prediction instead it is more like a recurrent variational autoencoder where i am trying to learn latent features of the sequence if i assume my data is a d sequence of length n n n how do i divide the data up into batches i know minibatches are typically of size batch_size seq_length num_features but do i split the data into minibatches using an overlapping sliding window approach or a nonoverlapping window eg minibatch one goes from does minibatch two go from or my gut feeling is that the former is more appropriate when you are using a nonrecurrent nn to model the data eg you will only evaluate the loss on the last element of the sequence as you need the rest of the data for context hence in order to model the entire sequence you need to ensure that every item of the sequence is input such that it is the last element whereas with an rnn as you have a state that you can feed in you are able to evaluate each element of the sequence and can therefore feed in the data much more efficiently in nonoverlapping blocks edit also note that i only have a single sequence of say length,a few questions on modelling time series data with recurrent neural networks,how to divide a timeseries into batches
45,hello im mainly using r for my scripts and benchling to take notes i want to know how to have an organized and reproducible workflow now i have a folder with scripts that have the next structure _functions_to_clean_datar _clean_datar _function_to_analyze_datar _analyze_datar but sometimes i have to make some corrections or add more data for that i need to rerun or change some scripts that i used earlier and take notes on benching this is messy since after that i cant run my scripts in order and have the same final results since i need data that i got for example in script to make the corrections in script it would better use r markdown or what should i do please excuse my english,how can i have an organized workflow in r,how do i organize my scripts
46,im a university student majoring mathmatics in undergraduate school and ill go graduate school in math or statistics i want to be a data scientist that managing data making results now im studying programming such as r python and math linear regression real analysis i have questions the first is im thinking about mooc in data science and therere moocs one is data analyst in udacity second is data science specialization in coursera both has pros and cons i cannot decide which one is good for me you should think that im a student and ill go to graduate school the second question is beside mooc im not sure about what i have to studyshould i study computer science like algorithm graph theory or math statistics,moocs for university student,udacity vs moocs for data science
47,i am trying to model a simple neural net to classify data amongst classes the data is quite high dimensional with rows and columns with the last column being the labels which have encoded into integral values for classification purposes i am referring to the proposed architecture in where it is used on iris data to get a conventional learning curve but my learning curve is coming to be something unusual which i have not seen before ampxb does my learning curve graph signify that the model performs poorly as it does not go down like a conventional one using the gradient descent optimizer or is it just some point i am missing any comments in this regard would be appreciated ps the accuracy i am getting based on the above model is close to thanks,can a learning rate graph look unusual and weird,is my learning curve normal or does it just mean that my model is performing worse than a normal one
48,how do you manage different models over different datasets and repeated experiments for instance i hash the hyperparams and create a directory with that hash and put everything that belong to that experiment under that directory i run or runs with same hyperparams and take the average of those for that particular model and dataset this works well for a model a on dataset a but at times i find it difficult to compare experiments of different ie comparing model a and dataset a model a on dataset b or model b on dataset a currently i am trying to intregrate dvc for data versioning in my workflow but before jumping in with two legs i wanted to know how others do it,how do you manage multiple experiments in ml,how do you manage different models on different datasets
49,i checked my google analytics account after about a month i was surprised to see a significant uptick in pageviews and visits however i saw that many of most visited webpages are not something i have hosted for example the typical urls supported on my website are bmicalculator bodyfatpercentagecalculator and so one but the ones i seeing now are sharebuttonto compliancedonxyz so it seems that these new pages are almost some random urls when i try to access these on my site mysiteblahsharebuttonto i get but google analytics reports page views for this page over the last month what is happening and what should i do to avoid these situations is my site compromised,pages i am not hosting are showing in google analytics,google analytics pageviews not displaying upticks
50,hi i have been working in data analytics for the retail arm of a bank about years now i have a keen interest in social sciencedevelopment econ grad and have been thinking of switching for some time now could not because of some personal reasons background econ grad skills include python sql tableau stata plus some research exp i have questions any advice on how i make the switch now if i want to move to an organisation like the gates foundation any social science datasets that i could work on to get my hands dirty and of course add in my resume this is not the stereotypical change in career plan question so any advicesuggestionscriticisms would be a big helpful,advice on switching career to development sector,advice on transitioning from retail to data analytics
51,q blocks cloud affordable supercomputers for highperformance computing applications like ml model training running simulations big data analytics or creating the next deep fake powerful gpus cuda amp tensor core gpus for ai data science amp design lightningfast computing results costeffective x costeffective package gpu hours data security state of the art security standards dockerized volumes sha encryption salts gpu power launching a gpu powered the virtual computer on q blocks peer to peer computing platform is really easy here is a quick demo train ai models faster select a gpu instance select an ai framework of your choice select access method cli or jupyter lab get a supercomputer at your service one more thing for get gpu hours why qblocks x better breakthrough computing paradigm the community of people with a deep love for supercomputing crafted with love for the crazy ones what is q blocks imagine the uber of computing a way to use millions of underutilized sources of computing to build your next ai model gone are the days when supercomputers were just limited to scientific institutes or governments by connecting together these computing sources spread across the worldq blocks envisions bringing access to a supercomputer in your hands get access to free compute hours contact information facing any trouble in getting started send us a contact form message water street vancouver bc vb b canada ampxb about q blocks q blocks is building affordable supercomputers using peer to peer technology built by a team of scientists and engineers to help our tribe get superfast computing results read the vision for a brief background and the secret master plan,affordable supercomputers for ai data science amp design,q blocks cloud gpu for ml applications
52,hllo all i am python and javascript and scheme developer looking for a project idea a few months or years back i started a project to help me with graphdb and conceptnet with the hope to put it to good use for doing some nlp stuff that was a graphdb embedded in python that is very easy to install or very easy to run similar to sqlite with a gremlin api anyway after some time fiddling around text summarization question answering wikification and reading about opencog i figured out that that nlp does not really need my project and most of the work done in data science evolves around crunching a lot of matrix operations best done in ram or with the help of gpus they are a few like opencog that do use relational model for both their kb and algorithms but i found no other examples so there is no need for my biggerthanram relational data store i diven into the world of datascience a bit deeper i discovered that one of the weaker point of the datascience work flow was wrangling basically some kind of extracttransformload or extractloadtransform if you prefer the tasks handled by google dataprep but that niche is already taken there is even free alternatives i would like to help the datascience community with some working software but i do not know what to do by the way would you find it useful to be able to version a graph and maintain multiple versions of it in the same manner that is done with source code with git,a python developer with too much free time needs your input,looking for a project idea for opencog python and gremlin
53,st year comp sci undergrad and self teaching ml basics so will be prone to misinterpreting things ampxb i understand that a big problem with neural networks are that they are black box models it is difficult to understand how they achieve outcomes given certain input data this is an issue when nn models could effect the health and safety of individuals ampxb what i am wondering is that if we could describe a mathematical form of the function encoded by neural network models would it help researchers gain insight into how they work ampxb i guess that the mathematical form of the function would be just as cryptic as especially for deep learning models there are a lot of inputs but i have no idea which is why i am asking,would having a mathematically described function that approximates the function encoded in a neural network help researchers understand how a neural network gets its output,can we talk about a mathematical form of the function encoded by neural networks
54,two data scientists walk into a library at the end of a long day data scientist to the librarian can i get a copy of this book on statistical methods goes on to share the name of the obscure book data scientist to data scientist theyll never be able to find that book the librarian clacks away on the keyboard for a couple of seconds before replying found it here are the details of its author publishing house and borrowing history oh and someone left a comment saying they found it super useful for understanding logistic regressions i can grab it for you in a jiffy data scientist to data scientist ummmm why cant the same thing happen with our data that is what a data catalog is here for with the need of data and metadata management and collaboration data catalogs are increasingly becoming relevant read what are data catalogs and why should data teams care about them here,what is a data catalog and why should you even care,what is the name of the book statistical methods and why should data teams care about them
55,i wonder if there is such a way to do this i have code that runs on google colab but even with gpu enabled it is training super slow so i am wondering if i can do that on gcp instead i can have an instance with a p gpu however it is such a pain to install cuda the drivers and everything that comes with it idk why but there is a gazillion ways to install them anyways it is a pain even using the public images like cdeeplearningtfentcuvubuntu after installing when when you try to do import tensorflow as tf printnum gpus available lentfconfigexperimentallist_physical_devicesgpu the output is is there a proper way to do this or just manually install everything also can someone verify that tensorflow runs gpu by default like no need to set it like witih keras or tf,how to get google colab environmentimage to gcp,how to install cuda on gcp
56,hi all i want to let you know about a project i had been working on called flashaiio which addresses some of the operational issues i came across when delivering models to clients or at the workplace i prefer spending my time building great models instead of thinking about the infrastructure complexities of hosting and serving them so i put together a service to do exactly that so if you want to enable clients colleagues or apps to send inference requests to your models flashai lets you do this via web requests serve your models without any hassle the workflow is straight forward train your model locally then upload your model file to flashaiio and then send inference requests to your model currently this service supports scikitlearn tensorflow and pytorch models try it out at flashaiio please let me know what you think and if you have any suggestions for other features,host and serve your scikitlearn tensorflow and pytorch models within minutes,delivering models to clients using flashaiio
57,baidu has answered this question empirically but i do not have a good background in math so i do not understand the answer gt many studies theoretically predict that generalization error learning curves take a powerlaw form m mltsupgtltsubgtgltsubgtltsupgt here  is generalization error m is the number of samples in the training set  is a constant property of the problem and ltsubgtgltsubgt or is the scaling exponent that defines the steepness of the learning curvehow quickly a model family can learn from adding more training samplesltsupgtltsupgt unfortunately in real applications we find empirically that g usually settles between and exponents that are unexplained by prior theoretical work here is the same text as a screenshot in case any of the math notation does not display properly for example for image classification on imagenet gt the top classification error exponent is ltsubgtgltsubgt on the other hand the exponent for top classification error is ltsubgtgltsubgt how can this be expressed for a nonmathy layperson for example how much improvement in accuracy results from a x increase in training data x x,in layperson is terms how much does deep learning performance scale with training examples,how can i express a nonmathy layperson is knowledge of generalization error learning curve
58,honestly i would like to hear how the industry deals with these issues product line x needs a product npv evaluation and a pricing model while i have transactions on the aggregate product line x i do not have a reliable transaction data for product x in product line x i notify my boss who asks for a solution i propose that the servicing team input transaction data into the system when they service the product servicing team agrees to implement the new procedure into their practices to my boss and the cfo the servicing team does not carry out the process my boss knows and he has not been pushing for any follow up for months now i have moved onto other models and projects but as i run into these problems more and more often i find myself getting apathetic towards everything and any hope of interdepartmental solution this morning i just could not deal with the guy next cube over talking about this concert he went to last week for the th time and just went home there have been better opportunities but i just cannot quit on the work that i have been building for so long now,business process change implementation,what is the industry is approach to dealing with npv transactions
59,i recently started looking for new roles after years working for the same company and bit out of touch with the market i came across some job postings with title senior analyst data scientist or senior data scientist analyst either it should be senior analyst or data scientist or just senior data scientist the job description lists everything a ds should know mode building stats experimentation cloud etc i recently interviewed for one of those rolesfortune non tech but the tc they offered seemed more like a normal senior analyst kind role around k base for a mcol city i was assuming for a ds role with yoe would be around k k base am i targeting the wrong kind of jobs or its the normal compensation for ds right now,what exactly is senior analyst data scientist role i am confused with responsibilities and corresponding tc,senior analyst or senior data scientist
60,i am looking for online resources for this type of issue i am facing but the problem is i do not know what this issue is called or if it even has a name so i have a movie dataset each row observation is a unique movie and one of the columns is a string list of genres you have stuff like scifi adventure zombie war scifi etc this list is not always the same lengths for each row using the way i am taught in my classes is to take all the genres mentioned in the whole column and just onehotencode them but what i am worried is that this will just create a large amount of columns and new movies can always add new genres i was wondering about grouping up the genres in a more workable amount i could use pca on the fully onehot encoded genre columns set but pca creates unreadable columns and it does not tell you what genres were grouped into which i would like to have scifi timetravel together or pirate historical together and since the lists are so arbitrarily organized if a new batch of data with a new genre comes in the pca would have to be redone right i want to see some online resources for different ways of dealing with this than just pca please note my example is arbitrary it could also be a clothing dataset with lists like jacket denim loosefitting etc,dealing with when observations have a variable list of traits,best way to group a large number of genres into one hot encoding
61,need help creating a data set ill be using analogies below to help avoid industry specific jargon usage i have a group of friends who all have different food preferences and budgets min and max theyd pay for dinner as well as food they like and food they dislike i need to create a dataset for their preferences so that if on a given night i say id like to go get italian and pay i would be able to pivot the data and see whose budget im within and who likes italian food and who dislikes italians food the problem is i cant figure out how to organize the preference section of the data set while min and max price are easily added as a single cell in a spread sheet for each person some of the individuals like foods and dislike what is the best way to organize the data so i can easily analyze the data set to figure out which individuals i would and would not like to ask to go to dinner with any videos or help would be greatly appreciated thanks for any help that comes my way,creating a data set from scratch having trouble,how do i organize a data set
62,hi all hope this is the right place to ask i am yo and have a background in computer science bsc and software engineering msc currently i am working as a software engineer but am not really happy with the work i am doing as it does not feel very challenging i have been looking at more math and statistics including ml related topics and feel like this would be very interesting for me to dive into is there anyone that went through a similar situation i feel like it might be a bit late for me to still start on this as i have already finished my studies what do you think are topics an in which order i should jump into to get the knowledge i need i have some basic knowledge on calculus linear algebra and statistical methods but this all needs to be refreshed any recommendations on how to approach this possible resources to read would also be very welcome i also like working on projects to get more of a feel on it any ideas for small problemsapplications i could work on to put the things i learned into practice,advice for a beginner,what should i do to prepare for my first job as a data scientist
63,activation functions might seem to be a very small component in the grand scheme of hundreds of layers and millions of parameters in deep neural networks yet their importance is paramount activation functions not only help with training by introducing nonlinearity but they also help with network optimization in this article we will explore the paper by google brain titled searching for activation functions the paper proposes a novel activation function called swish which was discovered using a neural architecture search nas approach and showed significant improvement in performance compared to standard activation functions like relu or leaky relu we will first take a look at the motivation behind the paper followed by a dissection of the structure of swish and its similarities to silu sigmoid weighted linear unit we will then go through the results when swish is applied to several nlp tasks along with the pytorch code to train your own deep neural networks with swish topics covered include motivation swish explained pytorch code notable results conclusion reference article link,article the swish activation function,swish a new approach to searching for activation functions
64,i am currently in a dual major for computer information systems and data analytics at my state university i am highly feeling that i am not learning a lot in my data analytics courses and want to try to do something through my work that would be valuable to the company while being able to learn more on my own my intended idea was to understand customer attrition by creating first creating a customer ranking system based on things they do in my company is program they use for example for a fleet maintenance program a customer may be scored on the number of work orders they create their parts purchase orders etc these would have some type of weight attached to them that would have to be decided essentially i would use these scores to predict which customers are at risk of leaving us is this something that is possible using ml and what advice would you have for me our customer data is in an aws environment,creating a customer attrition model for my work,is it possible to use ml to predict customer data in aws
65,yesterday i asked a few people about creating a program that can automatically categorize reddit submission into appropriate subreddit using title text the first version is ready and it works a lot of people helped me yesterday and thanks to comments by udeltasheep and uolbaa i was able to create it it is very bad code right now since i just learned python programming and my knowledge of ml is very limited mainly sentdex videos but i feel super happy that i was able to create this program here is how i did it please bear with me because i know i am a total noob first run this google big query select subreddit title from fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ fhbigqueryreddit_posts_ where subreddit in programming business wouldesign entertainment iscience isecurity worldnews politics amobile istartups google amicrosoft bitcoin facebook amazon amovies gadgets notechnology linux gaming apple wouldesign amusic then export the results into a table and export it again to a csv file to your google storage bucket then install google data labs and create a notebook then use the following program to run it i have still got a lot to learn and my next challenge is to create a small webpage so that people can enter the title in a web form and it shows the correct subreddit using it,p automatic reddit categorizer update first version working,python cnn algorithm to categorical reddit submission
66,i recently signed an offer to start working as a data scientist after the summer i am extremely excited as the role is known for being ml stats data engineering heavy dashboarding type projects will not be part of the role as they fall under the other teams my background is masters level noncs so i have not formally learnt data structures and algorithms i know the basics of the most important data structures lists sets hashmaps queues contigous data structures etc and intuitions about their corresponding timespace complexity they were needed for some advanced courses eg combinatorial optimisation w c together with some sorting search algorithms binary search dfs bfs but here typically only what was needed was covered for now until i graduate i am looking at areas i can improve before i start working aside from dsampa i have also identified extra cloud skills i have entry level azure certs already but i can go for more cicd testing frameworks and webapi skills for model deployment i do kind of reason dsampa while writing code but maybe actually formally learning about them would make me a far better programmer should i potentially just try and wing it with my current knowledge what do you think are they really that important aside from leetcode you get on interviews which i no longer have to do in the past i have always avoided selflearning these as i believed my time was better spent on extra math stat than on dsampa,is data structures and algorithms worth spending my time on before i start my job,what are the most important skills for a data scientist
67,hello all i am a marketing analyst with a large company that has many brands i am their first analyst so i have been responsible for a lot of data wrangling across all of their different marketing channels along with our new digital marketing manager and have been responsible for doing all of their campaign reporting after spending a couple months doing manual exports from each marketing tool we use while getting my feet under me i am finally sick of having to log in and pull data from different marketing tools in an effort to get all of our marketing data into one place i have been working with a developer to build a database on amazon redshift to take in our data from a a variety of sources like pardot and google analytics to finally make reporting easier i am running into one sticking point though what tool can i use to get all of my social media data into one place to import into my database we were thinking about using hootsuite but it does not appear to have a reporting api is anyone aware of a similar product that does i really want to avoid having to build out an individual connection for each brand is linkedin facebook and twitter profile i guess sprout social has a reporting api does anyone have any experience with that i am pretty new to marketing analytics but have been working as an analyst in market research and revenue management for years i am well versed in salesforce google analytics sql powerbi and excel and have been working withlearning python for the last half year ampxb thanks all,social media management platform with reporting api,what is the best way to get social media data into a database
68,hello i trying to figure out how the kernel trick gives rise to a decision boundary in my particular case i am looking at string kernels where strings are classified i get that kernelization helps to make decision boundaries for nonlinearly seperably data but whenever they are explaining they usually only seem to show how the dot product give you a similarity score between two data points not how it partitions a set of data into two categories for example in this above link the lili commentator simply gives an example of what looks like two datapoints in d space x and y and calculates the dot product between them but i do not see an explanation about how this product can be used to determine similarity between the two points or how it can be extended into a decision boundary between two groups of points does someone have some insight in regards to this,how do kernels in svms give rise to decision boundaries,how does the dot product give us a decision boundary
69,hello everyone going to try to keep it as brief as possible to start a bit about my background i graduated with a bs in petroleum eng and did well in school been more than a year and still having a difficult time landing an engineering position without any experience ive been recommended by many people to start a masters program but im having a troubling time deciding what to pursue some have told me to go into ms data science while i continue to search for an opportunity few others have recommended to pursue masters in mechanicalchemical which would open more engineering opportunities now there is quite a few people who have recommended ms in data science and i want to possibly enroll in one of these programs preferably an online program oil and gas is moving rapidly into automation and relying heavily on data science given my undergrad degree directly related to oil and gas i think a ms data science could complement it it would make me more competitive while also allowing me to move into another industry should the oil industry go to shit there is also the possibility of pursuing a masters in chem eng degree and just learning data science on the side through certifications i am having a trouble time determining which route i should pursue if you could share some suggestions or insights on this matter id really appreciate it thank you all in advance ampxb tldr bs in engineering grad but cannot find an opportunity should i pursue ms in data science maybe an online program or ms in chemical engineering while getting data science certs on the side,looking for post undergrad advice,ms in data science
70,q what kind of industry job can i get with interest in text analysis what should i learn more ampxb i have background in graduate studies in social sciences so i have background in using statistical analysis for data analysis but i do not have background in big data analysis nor adept at using statistical software to process big data ampxb current skills r and python i cannot say i am very fluent but i have studied it for a while so i am used to the software for python i am currently more interestedlearning the language to conduct text parsing and analysis ampxb experience i have graduate level research experience where i extracted government recordsused text analysis to gain qualitative information ampxb would a data science certificate necessary to enter the industry are text analysis jobs all tied to big datatext mining if this is so i am considering one year program in big data analysis,what kind of industry job can i get with interest in text analysis,what kind of industry job should i get with interest in text analysis
71,using normal linear regression methods recommend items users have weights assigned as per the movies they like movies have weights assigned as per genre among many other features can train bothways predict weight for movies or users and get a combined cost function predicting features here as well hence called collaborative filtering also there may be unknown values as all users have not rated all movies so changes in cost function is eminent accordingly train model to predict weights of users movies and output to compare with is the user ratings to account for new users normalise the data by taking means and hence also transform the output so each new user has mean as default rating rather than which would not help to train the model once trained among several things model can be used to predict rating for other movies and suggest the one which is most familiar to the ones user liked,day recommender systems,how to train a model to predict weights of movies
72,hi all very new to the data science world and was wondering if someone could point me in a direction any direction the problem i am trying to solve is i have a market place at practically every instancepoint in time my supply outweighs my demand only a portion of my supply is sellable the portion of my supply that is sellable can also go back into the supply pool similar to how a consultant can take on multiple projects at once for every isupply there is an ideal set of matches on the wouldemand side what are some basic models that can help me manage my isupply so that they can always find their ideal wouldemand counterpart i am not looking for an answer but maybe a few models i should explore eg is this a multiple regression problem should i do tfidf and then match using something else etc thanks,best models for managing inventory supplydemand,best models for isupply management
73,hi all like many i would like to enter into data science field but i am in s so i understand i am in the danger zone with respect to career development i read upon few articles on what to learn but it is confusing there is no clear curriculum if you want to do it without enrolling into school i have intermediate programming skills nothing fancy i have high school math skills excluding calculus i knew it back in the day but not anymore i think i can understand logic decently ok i have time and i can put in effort so all you wise data scientist people kindly tell me what to learn math programming to get started as a beginner data scientist if you include resources to learn from as well that would be awesome many many thanks,curriculum to get started,how to get into data science without enrolling in school
74,i am a sole data analyst at a startup and there are many days when i start my day without knowing what i am necessarily going to be doing usually a bug in the data is reported to me and so i spend the days fixing that or someone asks for a report adhoc and i make it for them but as i have improved the infrastructure now there is not as much bugs popping up and i have automated many reports so i do not get asked to do as many anymore and i am trying to find new tasks to do so my question is what is your routine like as a data analyst say you want to be forwardlooking and plan for the next week or month how do you decide on a goal and roadmap,what is your routine like as a data analyst,what is your routine as a data analyst
75,i am not a data scientist but i feel like you all could help me out i am trying to collect data for all firstlevel administrative divisions for all countries and i am having a hard time i started with this web page and just scraped all the data there however the formatting is such that i would have to manually go through to separate all of the data into the correct divisions i was thinking about getting data from this wikipedia page but the data is so dispersed that i would invest more time into engineering the data collection than it would take to manually separate the first source is data ampxb where can i just get a dataset of all countries and their firstlevel divisions ie just state and not counties cities etc,get data for all firstlevel administrative divisions for all countries,need help finding data for firstlevel administrative divisions
76,hello ampxb currently we are using logistic regression as statistical method that predicts if loan taken by the customer will be bad or good depending on the probability of default and cutoff point that we have set the problem is that the current model is a bit biased towards some type of clients and i want to rework it from scratch since previous model have been working for a long time all sampled data is already passed through the prism of the model so i basically only see approved customers that may be less than of all customers the question is what should i do if i will make my new model based on only of data that came trough the prism of the model i will face problems several problems relative low default rate rare events predictors that were included in previos model and were really strong wont affect current sample and wont be included new potentially weaker predictors will be included in the model but old predictors from previos model wont so it may lead to worse model in general that only affects my sample of data etc what is industry best practice where should i get all the data if using sampled data is not possible because of a problem i described above thank you in advance,logistic regression for predicting goodbad customers scoring model development,what is the industry best practice to get all the data from previos model
77,so i did not want to be too specific as the above is my general framework but i am not really a web developer and would call myself a data analyst at the moment not a scientist yet however i am happy to provide more details if that would help in your responses i am basically wondering what the architecture of this would look like and if there are any resourcesinfographics as to how to get started specifically step b would that be a mysql database to house the data in the interim before i manipulate it what are some good resources for the interaction of front and back end web design gosh i hope all that makes sense i am happy to clarify and thank you all in advance for your time,tapping this sub for some resources i am looking to a tap into some api feeds b do stuff with the resulting data graph manipulate etc c deliver it in the form of a data product web mobile etc,what is the architecture of mysql database
78,hi i am new to machine learning so any help would be greatly appreciated ampxb i am trying to build a basic model that detects anomalies by comparing a rate value against max and min thresholds and classifying them appropriately i have features in my dataset rate of change max threshold min threshold i tried using decision tree and random forest algorithms and they all seem to be going by only the rate of change feature when i look at the feature_importance it shows up as so it doesnt look like it even considers max and min thresholds is it possible to tweak the feature priorities i would prefer the model to look at the threshold values as well is there a way to boostmodify feature selectionimportance,question about feature importanceselection,how to tweak feature priority for feature selection
79,could anyone help with when i use the pretrained model for englishtogerman translation at why am i getting some random translation output phungarchlinux opennmtpy python translatepy model available_modelstransformerendewmtpyonmtaveragedepochpt src datasrctesttxt output predtxt replace_unk verbose sent orlando bloom and amiranda kerr istill love each other pred nein viel leicht nicht pred score sent actors orlando bloom and amodel amiranda kerr want noto go notheir iseparate ways pred seh r interessant und interessant pred score sent however in an interview bloom has isaid nothat he and kerr istill love each other pred seh r interessant ist auch die tatsache dass das ganze noch nicht vollstndig umgesetzt wurde pred score sent amiranda kerr and orlando bloom are parents noto notwoyearold flynn pred seh r interessant und interessant pred score,random translation output with pretrained opennmtpy model,help with english togerman translation
80,i am trying to predict a time series of a discrete number of amplitudes from continuous curves of the same time resolution i have a feature extractor that comes close and just rounding it works pretty well but sometimes it predicts the wrong label roughly of the time however the feature extractor also has an additional couple of hundreds of meaningful time series builtin so i was thinking i could augment the rounding heuristic with them to improve the predictions but how would i go about combining them though i also have a decent set of supervised examples of how the time series should turn out example the red line is rounded from the blue line and should therefore follow the green line completely but that does not always work because of noise in the blue line,how do i combine several time series into one given a dataset of how the end result should be,rounding heuristic for time series prediction
81,your isp internet service provider can see each individual website that you view and in some cases can actually see the data and parts of the website that you are viewing recently in the uk they passed a law requiring isps to keep every individuals search history for years and this is happening in other countries when there is not even a legal requirement you can stop your isp from breaching your privacy using a few different methods the first of which is using a vpn this costs a monthly subscription fee however this not only protects your browsing history but can also be used to torrent privately without any risks or to protect your ip address from malicious people online nordvpn is one of the largest vpn companies however many other providers can be found online the second method is using the brave browser it is similar to chromefirefox but it has a built in adblocked and built in tor support which hides what websites your are visiting from your isp you simply download the browser and click the settings in the top right and click new private window with tor this is my preferred method as it not only protects your privacy but also blocks ads while you are browsing,do not allow your isp and government to save your browsing history,isps can be used to hide your ip data
82,i am trying to do the below linear regression in tensorflow but my output is all inf and nans my input dataset has to be yx noise where x is a normal distribution of size and noise is gaussian with mu and sigma output loss w b loss w b loss e w b loss e w e b loss inf w e b e loss inf w e b e loss inf w e b e loss inf w e b e loss inf w inf b inf loss inf w nan b nan loss nan w nan b nan loss nan w nan b nan loss nan w nan b nan import tensorflow as tf from sklearnmodel_selection import train_test_split import numpy as np import pandas as pd from matplotlib import pyplot as plt noisenprandomnormalastypenpfloat x_datanprandomuniformastypenpfloat y_datax_datanoiseastypenpfloat pltscatterx_datay_datas pltshow xtfplaceholdershapedtypetffloat ytfplaceholdershapedtypetffloat learning w and b over the epochs wtfget_variablenameweightdtypetffloatshapeinitializertfzeros_initializer btfget_variablenamebiasdtypetffloatshapeinitializertfzeros_initializer y_pred tfaddtfmultiplyx wb loss tfreduce_meantfsquarey_pred y optimizertftraingradientdescentoptimizerlearning_rateminimizeloss epochs with tfsession as sess inittfglobal_variables_initializer sessruninit for e in rangeepochs _csessrunoptimizerlossfeed_dictx x_datay y_data printlosscwsessrunwbsessrunb pltscatterx_data y_data ro labeloriginal data pltplotx_data sessrunw x_data sessrunb labelfitted line pltlegend pltshow,linear regression on tensorflow all nans,pytorch tensorflow error
83,i built a cnn to classify different classes it performs well on most of the classes giving approx accu per class current each class has images but in the future there is a possibility that i might get more data for each class for instance i get more data for some class how should i retrain the model should i retrain the entire thing ie with old and new data should i retrain the model with only new data here i fear that as the model will get new data for a single class the model can possibly forget what it has already learned or might affect the accuracies of other classes if anyone has worked on this problem before please help,retraining cnn with new data,how to retrain a cnn model
84,i am graduating with a masters in management and will be spending the next few months learning some technical data analytics skills i have signed up for a month bootcamp that will teach me data science through the pandas library in python starting from a beginner coding level however looking at the jobs i will be applying to business intelligence most jobs list that they will love it if i know python but they expect me to operate in sql or in some cases r i have only done a small hour course in sql to learn the basics i am curious to know given i will spend the next three months learning data analysis through the pandas library how hard will it be to pick up sql later are the skills very transferrable apologies if this is a sillyobvious question,question about learning sql after learning data analysisbased python pandas library,how hard is it to get a job in data science
85,hi everyone to start off i am not exactly that good at selflearning entire fields of subjects i taught myself some python and sas sas was more learned on the job tbh but never really to the point of doing my own data science projects okay so i am a year old recent graduate in economics as of last year and i have just started a parttime msc in econ but with a specialization in data science and numerical methods basically a lot of econometrics and classes on mlbig data manipulationnlp it would take me years to complete the program i have also just begun a job as an economist at the government my previous job was waaaaay off course the job will involve a lot of sas programming and producing statistics on international trade data as i have been told naturally i would love to get a job that is more in line with dsml out of school so i was wondering if acquiring experience as an economist would be relevant when i will be applying for ds jobs right now i have no experience with ml and like i said selflearning is not exactly my forte so i figured that taking courses related to the field would provide with a solid springboard towards acquiring all the necessary skills plus i will be able to use the projects done in school for future interviews am i missing something has anyone else done a similar path from economist to data scientist for example am i wasting my time and will my experience be relevant for that future career switch thank you,economist that just started a msc in econ specializing in data science and numerical methods should i just drop it and focus on selflearning everything,econometrics vs data science
86,hi there i have been wondering about this for a while without focusing too much on the specific algorithm used are there practical applications of synthetic datasets i know deep learning in general needs vast amounts of samples that are not always easy to find so what if there could be a tool that can generate high quality examples be it images sounds texts or videos for example single letters or group of words on all kinds of backgrounds maybe animated d rendered objects and multiple scenarios angle lights words pronounced on different background noises and so on and so forth of course the trained deep neural network would then be finally trained on a realworld dataset what do you think,do you think generated datasets when realworld ones are scarce can help training and if so who could find them useful,is there practical applications of synthetic datasets
87,i am trying several different word vectorizations for a binary classification problem the series x consists of lemmatized spacy docs row per review using x and y ie the ratings i used traintest split for what i believe is the correct setup for sklearn is tfidf vectorizer ampxb tfidf vectors x_train_tfidf x_trainmaplambda x strx x_test_tfidf x_testmaplambda x strx ampxb cv tfidfvectorizer ampxb x_train_vec cvfit_transformx_train_tfidf x_test_vec cvtransformx_test_tfidf ampxb and this goes into whatever classification algorithm i am using i am a bit more confused on the general flow that should be done using spacy is own word embeddings this is what i originally did spacy vectors x ispacy_vecs xapplylambda x xvector spacy_array nparraylistx ispacy_vecs dtype npfloat ampxb clf_lr_spacy logisticregression ampxb spacy_clf clf_lr_spacyfitspacy_array y spacy_pred spacy_clfpredictspacy_array ampxb it works but the overall method does not seem sound to me that is that i am not withholding any data as a test set at the same time i do not believe there is a fit or transform for the spacy vectors so i thought it made more sense to train the vectors on the entire corpus ampxb my question concerns the methodology here have i set up the spacy or tfidf for that matter vectors correctly is it proper to get all the embeddings and then split the data,spacy word vectors and sklearn,spacy vs tfidf
88,hi there ampxb i have recently been going through tutorials on creating multitouch markov attribution models in r here ampxb from this i have created a set of users about that have a path to whether they converted or not some users may even have multiple conversions for example user a gt b gt c gt a gt conversion user a gt a gt c user c gt b gt a gt a gt conversion user a gt b gt c gt gt c these users have followed different paths with touch points in various marketing channels a b c to either converting or potentially dropping from their search i also created the time between each touchpoint so for example my dataset has user a lt b lt c lt a lt conversion lt i have been trying to find a source on lead scoring models in machine learning but have not really had any luck i have been thinking of using the transition matrix from that the number of days in the path and the number of touch points to assign a sort of lead score but it all seems sort of arbitrary is there some way to analyze the entire paths of every user and predict how close they are to converting let is say a conversion is i do not really have labels for nonconverting users since when they do not convert their just sort of in an indeterminate state can anyone point me in some sort of direction on this i am a bit lost thanks,lead scoring model for marketing,multitouch markov attribution
89,hello i am in bit of a situation right now i have an interview coming up for a data analyst role hiring manager reached out to me for the phone interview and it went well after i cleared the phone interview recruiter started taking care of the process i have asked the recruiter atleast times what to expect in the coding round she has been avoiding that question the interview date has not been set up either i gave thursday as my availability and they said we will send you the invite by monday they said something like this before as well but did not send anything now i have been preparing sql really well and i know how to work with dataframe using rpython i do not know how to do any leetcode type python questions since the recruiter has not been responding should i email the hiring manager on monday about what to expect although i will not learn something in days that i do not have any knowledge of but it will be good to know what to expect so that i am not shocked any help would be really appreciated i am a little stressed right now because it seems like a really good opportunity thanks,is it okay to email hiring manager if the recruiter is not responding,how to prepare for a data analyst interview
90,hey there i am messing around with google data studio for work but i have stumbled upon a problem and i am not sure how to solve it we have many campaigns all in two languages dutch and french i tried making a filter so that the person viewing the report can select to view only the data of french campaigns or only the dutch but i have not found a way to do this the way i want to ideally i would make two custom dimensions one for the nl campaigns and one for fr i tried to look into it but the formula confuses me gt_lt does anyone knows what formula to use for this i know it has to be something with contains fr but nothing seems to work for me p,google data studio create language button,how to filter out of dutch campaigns in google data studio
91,greetings background i am not from a data science background i am a phd in humanities who stumbled on text analytics then quickly fall in love with it with little knowledge my research is now heavily based on topic models using the stm package in r my supervisor has no idea what am i doing since she knows nothing about data science and thought i am a normal humanities kid when she accepted me when i explore the field of topic modeling i found lots of interesting topic models i would like to try such as hdp keywordassisted tm embedded tm etc however there was little choice in r even python seems to only relying on gensim which certainly do not contain all the model so i am curious why does the r community seem to have little support for topic modeling furthermore is there a way to use the model that has not been developed into packages in my analysis i am learning python do not just tell me to switch to python xd,newbie why so little machine learning model package in r,topic modeling in python
92,hi everyone i have put a lot of work into getting a deeplabv model trained and it is working well but the output sometimes misses sections of the object and i am trying to figure out how i can postprocess the segmentation masks to improve the segmentation result my use case is industrial but the image below illustrates the issue where the segmentation mask misses parts of the object circled in red i tried grabcut using the segmentation mask as marks to improve the segmentation result but i could not get it working my thinking is that i should be able to do something like grow the mask to nearby pixels that are similar does anybody have any ideas or advice on how i can postprocess my segmentation results to make them better thanks,need help postprocessing image segmentation masks,how to postprocess the segmentation masks
93,i am using the following keras implementation of the wavenet architecture ampxb when my input shape is x y with z number of filters in all types of convolutional layers d casual the output is of shape x z i would like my output to be of shape x and so i changed the number of filters for the very last convd layer to be and got my desired output shape ampxb if numbers help more than variables input number of filters output desired output ampxb my fear is that in doing so i am losing learned information is this true is there another way to get the desired output ampxb any ideas will be much appreciated thanks in advance,wavenet output dimensions,keras wavenet output shape
94,hello i am a physics teacher who is been looking for a career change for some time now and i have settled on data science i am wondering if there is anyone here who is made a career change into the field that could possibly help me out bonus points if you also came from teaching haha my main issue is i am not sure how to build up practical experience and demonstrate it to a potential employer i am currently working through dataquest and after i have completed some of that i was planning on trying to build up a portfolio of projects but from there i really do not have a plan and if i am being honest i am not even sure that is the best way to develop my skills i am also looking to know your story of how you landed your first data science job how did you do it did you find your job through a connection in any case how did you demonstrate your competence with no experience in the field looking forward to hearing people is responses thanks either way,has anyone here made a career change into data science what was your experience like,career change from physics to data science
95,hello i am currently doing my capstone project for my postsecondary data science certificate the project which is based on modelling virus outbreaks in north america is due by april the problem for me is that i am currently working full time and i get a limited minute in person window to see my supervisor each week for project clarificationsuggestions i do not really know which data science tools best describe modeling my problem since for my certificate program i have been taking gaps in between classes due to the fact i was doing my undergrad as well as doing the certificate program ampxb by taking certificate classes one at a time instead of altogether it has become difficult for me to refresh my knowledge on the subject since a lot of the relevant coursework i have done were a long time ago i have been making an attempt to go back to my coursework assignmentslabslectures to help me with the project as well as going over modules on linkedinlearning but i feel like i need more direction with the limited interaction i get from my supervisor i would like to know if there are any resources online that can help me in regards to my capstone,need data science project supervisionresources,what are the best data science tools for my project
96,hey everyone i have a background in linguistics and i am quite new to the field of machine learning there is something that has been bugging me for the past few days that i hope you can help me get a better understading of namely the difference between an algorithm and a model in his blog jason brownlee says that he likes to think of the model as the specific representation learned from data and the algorithm as the process for learning it however i struggle to grasp the difference between the two as well as which one comes first let is consider this snippet of code model decisiontreeclassifier modelfitx_train y_train in the first line i instantiate a specific model in the second one i train it however is the decision tree created by the algorithm or does it already exist as some sort of blueprint for the algorithm to operate on i apologize for the lack of clarity,difference between model and algorithm,difference between an algorithm and a model
97,hello my name is simon wright i need your help to create an ai to play eve online there are bots that can play but all they do is mine asteroids which is boring and ruins the game is economy i am years old but i want to learn i have a step plan step have bot watch streams of the game to learn step have bot learn to farm the npc enemies until it gets good step have it participate in real pvp battles this is an experiment mabey when it gets good a bunch of getting together to create an all ai fleet edit is eve online to complacated for reinforcement learning,eve ai,need help creating an ai to play eve online
98,firstly im in the uk unsure if that makes a difference im currently studying a joint economics and finance degree exact same number of econometrics modules as pure econ how viable is a career as a data scientist for me and what would you recommend i do in my free time to flesh myself out im currently in my second year and currently studying dynamic regressions with timeseries data only the second week of the module so a lot more to come first semester covered ols multiple linear regression gaussmarkov assumptions and some tests for heteroskedasticity however its spelled i achieved around in this module for the highest grade in the uk university system and econometricsstats have been by far my strongest modules so far im comfortable with multivariate calculus and have done enough constrained optimisation that every time i close my eyes i see a lagrangian my course doesnt teach r and instead uses stata and eviews which i think theyre going to phase out within a couple years but im currently working through a book to learn it once ive done this im gonna have a go at an extensive project that i can do over time using r would i possibly be looked over what else could i do to strengthen my chances im already planning on taking every econometrics module i can which should be about half in my final year,entering data science with economicseconometricsfinance background,what else can i do to help me become a data scientist
99,suppose i have an amazon product name dataset comprised of smartphone name and their accessories such as iphone x gb oppo a black airpods pro phone case iphone x clear huawei p pro tempered glass protection cheap softcase for oneplus t blue black two tone oneplus t iphone pro max best case design when a buyer checks out with a phone i would want to recommend its accessories so when the buyer puts in an iphone x gb to their basket i would want the recommendation engine to recommend airpods pro and phone case iphone x clear but not the cheap softcase for oneplus t because it is for another phone and preferrably not the case for iphone too as it would be incompatible is there a way to solve this i have been thinking to use some sort of nlp to process the various product name especially for the accessories as they can be varied but i am puzzled at how to really implement it any suggestions,gadget accessories recommender system need some ideas amp questions to answer,help with nlp recommendation engine
