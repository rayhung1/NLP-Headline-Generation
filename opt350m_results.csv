Index_ID,ref_post,ref_title,candidate_title
0,some background i have been learning python for over a year now and i know some sql a bit of r and i have completed some small projects using data science data engineering practices i also know how to work in excel but i do not really have experience using databases i am totally willing to make the time and money investment in something like a bootcamp and i have the means to do fulltime training but i do not want to do this if there is a better faster way to get into the industry what i really want to know is what can i do that will get me a job in the field asap is there some specific bootcamp that will make this happen if so what are the best bootcamps or some particular tech skill i could learn that would basically guarantee that i am hireable very soon if i something like learned microsoft sql server or tableau and given my other skills would this be likely to get me hired i have been looking into bootcamps like thinkful springboard and data application lab the concern i have about these is actually that i already know a lot of the stuff they teach and i am worried that these will be a waste of time and not elevate me to where i want to be i also worry about it taking months to complete these programs as they estimate i would like to be finished in no more than about months thoughts,i want to transition into the data scienceanalyst or related field rather than asking whether i should choose a particular boootcamp or learn some language i would like to hear opinions on what path should i choose that will land me a job of some kind in the field as soon as possible,some background i have been learning python for over a year now and i know some sql a bit of r and have completed some small projects using data science data engineering practices. i also know how to work in excel but i do not really have experience using databases i am totally willing to make the time and money investment in something like a bootcamp.
1,hi all i have created a python module to extract sngrams which is different from traditional ngrams as it embodies linguistic syntactic trees thus making it less arbitrary than traditional ngrams as it goes without saying quality of input feature affects model performance this will help you improve your model accuracy even further built on language models of spacy it can help especially for text classification information extraction query understanding machine translation question answering systems below is an example from sngramextractor import sngramextractor ampxb sngram_objsngramextractortextmeta_tagoriginaltrigram_flagyes texteconomic news have little effect on financial markets outputsngram_objget_sngram printtext print isngram bigramoutput isnbigram print isngram trigramoutput isntrigram economic news have little effect on financial markets sngram bigram cloud_every has_cloud lining_a lining_silver has_lining sngram trigram has_lining_silver ampxb textevery cloud has a silver lining outputsngram_objget_sngram printtext print isngram bigramoutput isnbigram print isngram trigramoutput isntrigram ampxb every cloud has a silver lining sngram bigram cloud_every has_cloud lining_a lining_silver has_lining sngram trigram has_lining_silver ampxb pypi,psngram linguistic features for improving machine learning and deep learning model accuracy for the first time in python new release,hi all i have created a python module to extract sngrams which is different from traditional ngrams as it embodies linguistic syntactic trees. This will help you improve your model accuracy even further built on language models of spacy. It can help especially for text classification information extraction query understanding machine translation question answering systems.
2,i am looking at some of the modeling programs the company has been using and there are options to smooth binned data layered linear on bin linear on avg linear on log avg and variable gradient are these methods commonly used in any algorithms i am not sure how i would implement it into r ampxb variable gradient is the most confusing it groups data from neighboring bins with a bin factor being determined the level of smoothing is determined by the radius all bins contribute to the calculation of the bin factor with decreasing weight as the distance from the target bin increases the weight is equal to radius distance radius ampxb once you calculate the overall factor a calculation is performed for each bin weighted by an exposure with various radii and a selected credibility level the calculation that yields the largest distance from is then selected as the factor to be used for that bin ampxb over multiple iterations of the model the factors are blended until the model converges and we receive a final coefficient for that bin ampxb since it is a program i have no clue what is going on in the background to calculate the convergence or what type of model this is it ends up being a multiplicative model so i am guessing it is a log linked glm,does anyone use any type of gradient smoothing for binned data,i am looking at some of the modeling programs the company has been using and there are options to smooth binned data. variable gradient is the most confusing it groups data from neighboring bins with a bin factor being determined. factors are blended until the model converges and we receive a final coefficient for that bin ampxb since it is a program i have no clue what is going on in the background to calculate the convergence.
3,let is say i have created a fraud detection model i already have a process that cleans the data and stores the trainable data in a table in a database and now i want to set up a recurring job that retrains my model every x time period how do people go about this when we want to retrain the model does not that data have to be loaded into the environment that the new model is going to be retrained i guess i am confused at how exactly the model takes the data from the database and starts training on it do people use spark to load it into the environment with the modeltobe then start the retraining process does not that mean that the retraining environment has to have enough space to cover that data being brought in apologies if this has already been asked but i have not seen a clear answer from this subredditfrom what i have found on google thanks so much for any assistance,setting up a model for retraining in production,Do data have to be loaded into the environment that the new model is going to. be retrained in before it can be trained on it. Does not that mean the retraining environment has to have enough space to cover that data being brought in apologies if this has already been asked but i have not seen a clear answer from this subreddit.
4,i am working with a dataset of patient performancedata and patient demographics for people with a medical condition i am trying to assess the effect of a treatment on the patients and as i am trying to replicate a randomized experiment from a observational study i am performing matching between the treatment and control group when i try to perform mahalanobis distance matching however i keep getting the following warning on matlab warning matrix is close to singular or badly scaled results may be inaccurate rcond e the warning was caused because the determinant of my covariance matrix was very close to so when i calculated the inverse of this matrix as i need to do for finding the mahalanobis distance the matrix element values become very close to as well after reading about this warning a little bit i found that when this warning is displayed the results of mahalanobis distance matching is not very reliable i thought this was because my matrix became very sparse after i introduced onehotencoding to split the multicategorical features into many different features and hence some of my new features were for category values that had very few occurrences less than to address this issue i got rid of the category values with very low occurrences less than or binned them together with other lowoccurrence category values into slightly larger bins so their chances of occurring increased and my datamatrix was less sparse so i reduced the number of features from to and i plotted the histograms for all my features to see their distributions and this is what it looked like note that the element values have been normalized to by subtracting the feature mean and then divided by the feature standard deviation it looked visually satisfactory to me but i still kept getting the same warning in matlab when i tried finding the determinant of my new covariance matrix it was still very small e in a further attempt to fix this issue i checked whether removing all of the categorical features if we consider the onehot encoded features made things any better by making the matrix less sparse the new featurehistogram looked like this this time when i tried mahalanobis distance matching the warning was removed because the determinant of the covariance matrix was larger e so i tried to see if i could include one of the removed multicategorical features without facing the same problem as these are important features i would prefer to include when doing my matching i added a categorical feature with possible values and all the values very well distributed see histogram below but alas simply including these new onehotencoded features seems to cause the determinant of the covariance matrix to become so small that i start getting the same warning in matlab is there any fix to this issue or is it simply impossible to reliably perform mahalanobis distance matching on this dataset without leaving out the multicategorical values,is mahalanobisdistance matching between points not compatible with onehotencoded datasets,i am working with a dataset of patient performancedata and patient demographics. i am trying to assess the effect of a treatment on the patients. When i try to perform mahalanobis distance matching however i keep getting the following warning on matlab warning matrix is close to singular or badly scaled results may be inaccurate rcond e.
5,hi all i am applying for a data science internship with a well known company in the sf area think uberairbnbpinterest etc one of their points under qualifications is amust be currently pursuing a master is or doctoral degree preferred fields of study are statistics math economics or related discipline this presents a few problems namely that i am a junior undergraduate studying cs that said i have more experience than the typical undergrad and from what i have seen the typical masters student with respect to data science here is what i have got going for me very proficient using python r and sql among many other data analysisscience tools just finished a summer internship at a wellknown tech company as a data science intern built the company is new anomaly detection system in r from the ground up and deployed it just started a fall data science internship in nyc with an ecommerce company will be working on customer segmentation with some sql reports and machine learning taking two data science masters courses tutoring for a masterslevel algorithms course i know i do not fit their exact description but do you think i should apply anyways i would love to intern here and would appreciate any tipsexperiences any of you have had on applying where you do not necessarily meet every single criteria thanks,education level on applications,hi all i am applying for a data science internship with a well known company in the sf area think uberairbnbpinterest etc. One of their points under qualifications is amust be currently pursuing a master is or doctoral degree. preferred fields of study are statistics math economics or related discipline this presents a few problems.
6,i m am a junior in college major in statistics i go to a non target school and work as an intern at the center for predictive analytics at my university upon graduating i will receive a full fellowship to continue doing analytic research for our math department thus i will not enter the full time job market for approximately years from now i am planning to do some part timeremote work during my years of grad school this semester i have started building the habit of hours per day for self studying and working on ds projects i am committed to keeping up a similar routine for the next years with the intent that i might achieve hours of data science experience within the next years i decided to follow the ds career path after reading a book about big data i think it is a good career for me as i am into data math etc but i am also in it for the money and and mostly motivated by achieving a high salary so that i can save up money and start my own business in my s maybe idk is it unreasonable for me to expect that i should be able to far exceed a salary of k assuming high col within a decade from now if now how many yoe should i expect to achieve similar salary,how many yoe should i expect to have before i hit kk salary range,i m a junior in college major in statistics. i go to a non target school and work as an intern at the center for predictive analytics at my university. upon graduating i will receive a full fellowship to continue doing analytic research for our math department. I am committed to keeping up a similar routine for the next years with the intent that i might achieve hours of data science experience.
7,hello i am soon to be graduating student this spring in an undergraduate data science degree after doing extensive research i feel like my program had not emphasized math courses as much as i will only have calculus under my belt i have been looking at different graduate schools and i am looking at an ms in computer science i wonder though if my program has lacked sufficient areas for a program like this i was wondering if anyone here has had a similar issue i am starting to think my undergraduate degree in data science was a mistake and that i should have pursued a bs in either computer science or statistics here are some examples of what i have taken cs algorithms and cs data base management cs machine learning data science unsupervised learning data science management structured data data science other general data science things stats intermediate states stats regression stats principle study design stats experimental design by the time i will graduate i will have a minor in stats otherwise i could pursue a ms in stats or data science but i think i am wrong if i pursue those areas since with stats i would have to spend time taking the additional math before the more advance courses and i think the data science ms would just redoing things that my program already covered thoughts,a potential blind spot for new data science degrees,i feel like my program had not emphasized math courses as much as i will only have calculus under my belt. i am starting to think my undergraduate degree in data science was a mistake and that i should have pursued a bs in either computer science or statistics. with stats i would have to spend time taking the additional math before the more advance courses.
8,a little background on myself i graduated from a good university with a degree in civil engineering then i worked years in construction management and hated it over that time period i took a few classes and began teaching myself programming and data science i created a website and started uploading all the project that i had completed it took a while to get a job but i finally landed a job as a data analyst and love it i had thought about getting a masters during my job hunt since it took so long but stuck it out and landed this job i want to continue my career in the data science direction and want to know how revered masters and phds are in this field a lot of times high level data scientists at great tech companies either for sure have a masters and a lot of times have phds my main draw back on getting these degrees is the money it would cost because i feel like i could honestly teach myself the same skill set without having to pay for the school all in all i have a good job working as a data analyst but how far can this experience im gaining get you without having a masters or phd i almost went into structural engineering career path after college but everyone i talked to said that you had to get a masters and that was that so im interested to see other peoples perspectivesthoughts on this for data science to sum it up is it work it to pay for mastersphd and what curriculum specifically would you get the most out of as it relates to data science,should i get a mastersphd,A lot of times high level data scientists at great tech companies either for sure have a masters or phd. My main draw back on getting these degrees is the money it would cost. I feel like i could honestly teach myself the same skill set without having to pay for the school.
9,i checked out the faqs but was hoping for some targeted feedback i am currently entering the th year of my phd in neuroscience on top of a bachelors in psych and a masters in neuro i fundamentally love my work but recent observations have convinced me that continuing on the path of academia is just not right for me and my family late last year i took up python and have completed a couple of small projects to help automate my lab and expedite data analysis it got me thinking about data science i figure i have two years to make myself into a something that some company somewhere will want how can i do it my thoughts are to get some mooc certificates complete a handful of projects in the lab that use data science to save timeimprove outcomes etc network by shouting out of my window at cars driving by i realize that my path is nontraditional but i am hoping there is a way to repackage many of the problemsolving and analytical skills that i have earned in my science education thus far as groundwork for a job in data science all feedback is welcome,two years until i apply for jobs what should i work on,i checked out the faqs but was hoping for some targeted feedback. i am currently entering the th year of my phd in neuroscience on top of a bachelors in psych and a masters in neuro. Recent observations have convinced me that continuing on the path of academia is just not right for me and my family.
